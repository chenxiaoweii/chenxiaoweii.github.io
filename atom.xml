<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一期一会</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.dujiong.net/"/>
  <updated>2016-11-24T07:49:39.294Z</updated>
  <id>http://blog.dujiong.net/</id>
  
  <author>
    <name>dujiong</name>
    <email>dujiong.uestc@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis之数据库的实现</title>
    <link href="http://blog.dujiong.net/2016/11/17/Redis-db/"/>
    <id>http://blog.dujiong.net/2016/11/17/Redis-db/</id>
    <published>2016-11-17T11:46:03.000Z</published>
    <updated>2016-11-24T07:49:39.294Z</updated>
    
    <content type="html">&lt;p&gt;本文对Redis服务器的数据库实现进行说明，包括服务器保存数据库的方法，数据库保存键值对的方法，以及针对数据库的添加、删除、查看等操作的实现方法，最后，会对服务器保存键的过期时间的方法和服务器自动删除过期键的方法进行分析。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;服务器中的数据库结构&quot;&gt;&lt;a href=&quot;#服务器中的数据库结构&quot; class=&quot;headerlink&quot; title=&quot;服务器中的数据库结构&quot;&gt;&lt;/a&gt;服务器中的数据库结构&lt;/h3&gt;&lt;p&gt;Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中，db数组的每个项都是一个redis.h/redisDb结构，每个redisDb结构代表一个数据库。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct redisServer {
    redisDb* db;    //    保存着服务器中的所有数据库
    int dbnum;        //服务器的数据库数量
    ...    
}

typedef struct {
    dict *dict;            //保存着数据库中的所有键值对    
    dict *expires;        //键的过期时间，键为数据库键，值为过期事件
    dict *blocking_keys;    //正处于阻塞状态的键和相应的client
    dict *ready_keys;        //可以解除阻塞的键和相应的client
    dict *watched_keys;        //正在被WATCH命令监视的键和相应的client
    struct evictionPoolEntry *eviction_pool;
    int id;        //数据库ID
    long long avg_ttl;        //数据库键的平均TTL，统计信息
} redisDb;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在初始化服务器时，程序会根据服务器状态的dbnum属性（配置文件database选项）来决定应该创建多少个数据库，默认情况下，该选项的值为16。&lt;/p&gt;
&lt;h3 id=&quot;切换数据库&quot;&gt;&lt;a href=&quot;#切换数据库&quot; class=&quot;headerlink&quot; title=&quot;切换数据库&quot;&gt;&lt;/a&gt;切换数据库&lt;/h3&gt;&lt;p&gt;每个Redis客户端都有自己的目标数据库，默认情况下，Redis客户端的目标数据库为0号数据库，客户端可以通过执行SELECT命令来切换目标数据库。&lt;br&gt;客户端redisClient结构的db属性记录了客户端当前的目标数据库，该属性是一个指向redisDb结构的指针，该指针指向redisServer.db数组的其中一个元素，即客户端的目标数据库。&lt;br&gt;用户执行SELECT命令切换数据库，Redis便修改redisClient.db指针，让它指向服务器中的不同数据库。 &lt;/p&gt;
&lt;h3 id=&quot;数据库键空间&quot;&gt;&lt;a href=&quot;#数据库键空间&quot; class=&quot;headerlink&quot; title=&quot;数据库键空间&quot;&gt;&lt;/a&gt;数据库键空间&lt;/h3&gt;&lt;p&gt;如前文所述，redisDb结构化的dict字典保存了数据库中的所有键值对，该字典被称为键空间。&lt;br&gt;键空间和用户所见的数据库是直接对应的：&lt;br&gt;（1）键空间的键也就是数据库的键，每个键都是一个字符串对象；&lt;br&gt;（2）键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任何一种Redis对象。&lt;br&gt;因为数据库的键空间是一个字典，所以所有针对数据库的操作，比如添加一个键值对，删除一个键值对，或者在数据库中获取某个键值对等，实际上都是通过对键空间字典进行操作来实现的。&lt;/p&gt;
&lt;h4 id=&quot;读写键空间的维护操作&quot;&gt;&lt;a href=&quot;#读写键空间的维护操作&quot; class=&quot;headerlink&quot; title=&quot;读写键空间的维护操作&quot;&gt;&lt;/a&gt;读写键空间的维护操作&lt;/h4&gt;&lt;p&gt;当使用Redis命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，包括：&lt;br&gt;（1）在读取一个键后，服务器会根据键是否存在来更新服务器的键空间命中(hit)次数或键空间不命中次数（miss）次数，这两个值可以在INFO status命令的keyspace_hits属性和keyspace_misses属性中查看；&lt;br&gt;（2）在读取一个键后,服务器会更新键的LRU事件，这个值可以用来计算键的闲置时间；&lt;br&gt;（3）如果服务器在读取一个键时发现该键已经过期，那么服务器会先删除这个过期键，再执行余下的其他操作；&lt;br&gt;（4）如果有客户端使用WATCH命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将这个键标记为脏，从而让食物程序注意到这个键已经被修改过；&lt;br&gt;（5）…&lt;/p&gt;
&lt;h3 id=&quot;设置键的生存时间或过期时间&quot;&gt;&lt;a href=&quot;#设置键的生存时间或过期时间&quot; class=&quot;headerlink&quot; title=&quot;设置键的生存时间或过期时间&quot;&gt;&lt;/a&gt;设置键的生存时间或过期时间&lt;/h3&gt;&lt;p&gt;客户端可以使用EXPIRE或PEXPIRE命令以秒或者毫秒精度为数据库中的某个键设置生存时间，在经过指定的秒数或者毫秒数之后，服务器就会自动删除生存时间为0的键。&lt;br&gt;客户端可以使用EXPIREAT或PEXPIREAT命令以秒或者毫秒精度为数据库中的某个键设置过期时间，过期时间是一个UNIX时间戳，当键的过期时间来临时，服务器就会自动从数据库中删除这个键。&lt;br&gt;下面是部分源代码(db.c)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//下面四个函数对应文中四个命令，最终都调用expireGenericCommand函数
void expireCommand(redisClient *c) {
    expireGenericCommand(c,mstime(),UNIT_SECONDS);
}    

void expireatCommand(redisClient *c) {
    expireGenericCommand(c,0,UNIT_SECONDS);
}

void pexpireCommand(redisClient *c) {
    expireGenericCommand(c,mstime(),UNIT_MILLISECONDS);
}

void pexpireatCommand(redisClient *c) {
    expireGenericCommand(c,0,UNIT_MILLISECONDS);
}

void expireGenericCommand(redisClient *c, long long basetime, int unit) {
    robj *key=c-&amp;gt;argv[1],*param=c-&amp;gt;argv[2];
    long long when;

    if(getLongLongFromObjectOrReply(c, param, &amp;amp;when, NULL)!=REDIS_OK)        //取出when参数
        return;
    if(unit == UNIT_SECONDS) when *= 1000;    //传入的时间是以秒为单位的
    when += basetime;

    if(lookupKeyRead(c-&amp;gt;db, key) == NULL) {    //取出键
        addReply(c, shared.czero);
        return;
    }

    // 在载入数据时，如果服务器为附属节点时，即使EXPIRE的TTL为负数，或者EXPIREAT提供的时间戳已经过期，服务器也不会主动删除这个键，而是等待主节点发来显示的DEL命令
    if(when &amp;lt;= mstime() &amp;amp;&amp;amp; !server.loading &amp;amp;&amp;amp; !server.masterhost) {
        robj *aux;
        redisAssertWithInfo(c, key, dbDelete(c-&amp;gt;db, key));
        server.dirty++;

        aux = createStringObject(&amp;quot;DEL&amp;quot;, 3);
        rewriteClientCommandVector(c,2,aux,key);
           decrRefCount(aux);

        signalModifiedKey(c-&amp;gt;db,key);
        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&amp;quot;del&amp;quot;,key,c-&amp;gt;db-&amp;gt;id);

        addReply(c, shared.cone);
        return;
    }else {            //设置键的过期事件
        setExpire(c-&amp;gt;db, key, when);
        addReply(c, shared.cone);
        signalModifiedKey(c-&amp;gt;db, key);
        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC, &amp;quot;expire&amp;quot;, key, c-&amp;gt;db-&amp;gt;id);

        server.dirty++;
        return;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;过期键删除策略&quot;&gt;&lt;a href=&quot;#过期键删除策略&quot; class=&quot;headerlink&quot; title=&quot;过期键删除策略&quot;&gt;&lt;/a&gt;过期键删除策略&lt;/h3&gt;&lt;h4 id=&quot;三种删除策略&quot;&gt;&lt;a href=&quot;#三种删除策略&quot; class=&quot;headerlink&quot; title=&quot;三种删除策略&quot;&gt;&lt;/a&gt;三种删除策略&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;定时删除：定时删除对内存是最友好的，在设置键的过期时间的同时，创建一个定时器，让定时器在键过期时间来临时，立即执行对键的删除操作。定时删除的问题是对CPU时间不友好，在过期键较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间，这样会对服务器的响应时间和吞吐量造成影响。     &lt;/li&gt;
&lt;li&gt;惰性删除：惰性删除策略对CPU时间来说是最友好的，因为程序只会在取出键时才会对键进行过期检查，这样确保删除过期键的操作只会在非做不可的情况下进行，不会在删除其他无关的过期键上花费任何时间。但惰性删除的缺点是对内存时最不友好的，如果数据库中有很多的过期键，而这些键又恰好没有访问到，那么它们也许永远也不会被删除，这样无用的垃圾数据占用了大量的内存。       &lt;/li&gt;
&lt;li&gt;定期删除：定期删除策略是前两种策略的一种折中，每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行时长和频率来减少删除操作对CPU时间的影响。但是定期策略的难点也正是在于确定操作执行的时长和频率。   &lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Redis的过期键删除策略&quot;&gt;&lt;a href=&quot;#Redis的过期键删除策略&quot; class=&quot;headerlink&quot; title=&quot;Redis的过期键删除策略&quot;&gt;&lt;/a&gt;Redis的过期键删除策略&lt;/h4&gt;&lt;p&gt;Redis服务器采用的是惰性删除和定期删除两种策略，通过配合这两种删除策略，服务器可以很好地在合理使用CPU时间和避免内存浪费之间取得平衡。&lt;br&gt;Redis过期键的惰性删除策略由db.c/expireIfNedded函数实现，所有读写数据库的Redis命令在执行之前都会调用expireIfNedded函数对输入键进行检查：如果输入键已经过期，那么该函数将输入键从数据库中删除。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int expireIfNeeded(redisDb *db, robj *key) {
    mstime_t when = getExpire(db, key);        //键的过期时间
    mstime_t now;
    if(when &amp;lt; 0) return 0;
    if(server.loading) return 0;    //服务器正在进行载入，返回

    now = server.lua_caller ? server.lua_time_start : mstime();
    //当服务器运行在replication模式时，附属节点并不主动删除 key，它只返回一个逻辑上正确的返回值，真正的删除操作要等待主节点发来删除命令时才执行 
    if (server.masterhost != NULL) return now &amp;gt; when;
    if(now &amp;lt;= when) return 0;        //未过期

    server.stat_expiredkeys++;
    propagateExpire(db, key);        //向AOF文件和附属节点传播过期信息
    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED, &amp;quot;expired&amp;quot;, key, db-&amp;gt;id);

    return dbDelete(db, key);        //从数据库中删除键
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;expireIfNeeded函数就像一个过滤器，它可以在命令真正执行之前，过期掉过期的输入键，从而避免命令接触到过期键。&lt;br&gt;Redis过期键的定时删除策略由redis.c/activeExpireCycle函数实现，该函数在redis.c/beforesleep和redis.c/serverCron两个函数中调用，且分别对应ACTIVE_EXPIRE_CYCLE_FAST（快速过期）和ACTIVE_EXPIRE_CYCLE_SLOW(正常过期)两种处理模式。以下是关键部分源码。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void activeExpireCycle(int type) {
    //静态变量，累计函数连续执行时的数据
    static unsigned int current_db = 0;
    static int timelimit_exit = 0;
    static long long last_fast_cycle = 0;
    //默认每次处理的数据库数量
    unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;
    long long start=ustime(), timelimit;

    if(type == ACTIVE_EXPIRE_CYCLE_FAST) {         //快速模式
        if (!timelimit_exit) return;
        if (start &amp;lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;
        last_fast_cycle = start;        //执行快速处理
    }
    if (dbs_per_call &amp;gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    //处理的时间上限
    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;    
    timelimit_exit = 0;
    if (timelimit &amp;lt;= 0) timelimit = 1;
    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION;

    for(j=0; j&amp;lt;dbs_per_call, j++) {
        int expired;
        redisDb *db = server.db+(current_db % server.dbnum); //当前要处理的数据库
        current_db++;
        do {
            ...
            if ((num = dictSize(db-&amp;gt;expires)) == 0) {    //数据库中带过期时间的键的数量
                db-&amp;gt;avg_ttl = 0;
                break;
            }
            slots = dictSlots(db-&amp;gt;expires);        //数据库键值对的数量
            if (num &amp;amp;&amp;amp; slots &amp;gt; DICT_HT_INITIAL_SIZE &amp;amp;&amp;amp; (num*100/slots &amp;lt; 1))  //数据库的使用率低于1%，跳过
                break;
            while(num--){
                dictEntry *de;
                long long ttl;
                //随机取出一个带过期时间的键
                if ((de = dictGetRandomKey(db-&amp;gt;expires)) == NULL) break;
                ttl = dictGetSignedIntegerVal(de)-now;        //计算TTL
                if (activeExpireCycleTryExpire(db,de,now)) //如果键过期，则删除它，并将expired计数器加1
                    expired++;
                ...
            }
            ...
        } while (expired &amp;gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);

    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;其他&quot;&gt;&lt;a href=&quot;#其他&quot; class=&quot;headerlink&quot; title=&quot;其他&quot;&gt;&lt;/a&gt;其他&lt;/h3&gt;&lt;p&gt;Redis的数据库功能很强大，也比较复杂，本文只是对其中的一些基本功能做了简单说明和分析，其他的一些功能和实现，比如持久化方式和复制功能对过期键的处理，将在后面的文章中继续学习。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文对Redis服务器的数据库实现进行说明，包括服务器保存数据库的方法，数据库保存键值对的方法，以及针对数据库的添加、删除、查看等操作的实现方法，最后，会对服务器保存键的过期时间的方法和服务器自动删除过期键的方法进行分析。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之发布与订阅</title>
    <link href="http://blog.dujiong.net/2016/11/13/Redis-pubsub/"/>
    <id>http://blog.dujiong.net/2016/11/13/Redis-pubsub/</id>
    <published>2016-11-13T10:13:33.000Z</published>
    <updated>2016-11-23T12:03:19.622Z</updated>
    
    <content type="html">&lt;p&gt;本文分析下Redis的发布与订阅功能，该功能有点类似网络中的多播或者广播的感觉，即当一个客户端向某个频道发布消息时，频道的所有订阅者和与这个频道相匹配的模式的订阅者都会收到该消息。&lt;br&gt;Redis的发布与订阅功能分为频道的订阅和模式的订阅。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;   &lt;/p&gt;
&lt;h3 id=&quot;相关的数据结构&quot;&gt;&lt;a href=&quot;#相关的数据结构&quot; class=&quot;headerlink&quot; title=&quot;相关的数据结构&quot;&gt;&lt;/a&gt;相关的数据结构&lt;/h3&gt;&lt;p&gt;首先看一下服务器和客户端与发布/订阅相关的属性。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct redisServer {
    ...
    dict* pubsub_channels;    //字典，键为频道，值为链表，记录所有订阅这个频道的客户端
    list* pubsub_patterns;    //订阅模式列表，为pubsubPattern结构
    ...
}
typedef struct redisClient {
    ...
    dict* pubsub_channels;    //该客户端感兴趣的频道列表
    list* pubsub_patterns;    //该客户端感兴趣的模式
    ...
}redisClient;

typedef struct pubsubPattern {
    redisClient* client;            //订阅模式的客户端
    robj* pattern;                    //被订阅的模式
}pubsubPattern;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;频道的订阅与退订&quot;&gt;&lt;a href=&quot;#频道的订阅与退订&quot; class=&quot;headerlink&quot; title=&quot;频道的订阅与退订&quot;&gt;&lt;/a&gt;频道的订阅与退订&lt;/h3&gt;&lt;p&gt;频道的订阅与退订在Redis中对应的命令分别为SUBSCRIBE和UNSUBSCRIBE。&lt;br&gt;首先学习SUBSCRIBE相关的源码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void subscribeCommand(redisClient* c){
    int j;
    for(j=1; j&amp;lt;c-&amp;gt;argc; j++){
        pubsubSubscribeChannel(c, c-&amp;gt;argv[j]);    //第二个参数开始的都是要订阅的频道
    }
}

int pubsubSubscribeChannel(redisClient* c, robj* channel){
    dictEntry* de;
    list* client=NULL;
    int retval=0;
    //将channels放入客户端c-&amp;gt;pubsub_channels的集合中
    if(dictAdd(c-&amp;gt;pubsub_channels, channel, NULL) == DICT_OK){
        retval=1;
        incrRefCount(channel);        //与该channel关联的引用计数加1
        //在server中查找这个频道的客户端链表是否存在
        de = dictFind(server.pubsub_channels, channel);
        if(de==NULL){    //不存在创建一个
            clients = listCreate();
            dictAdd(server.pubsub_channels, channel, clients);    //添加进字典
            increRefCount(channel);
        }else{
            clients = dictGetVal(de);    //如果已经存在，则直接获取频道所对应的客户端链表
        }

        listaddNodeTail(clients, c);    //将客户端添加到链表的末尾
    }
    //回复客户端
    addReply(c, shared.mbulkhdr[3]);
    addReply(c, shared.subscribebulk);
    addReply(c, channel);    
    addReplyLongLong(c,dictSize(c-&amp;gt;pubsub_channels)+listLength(c-&amp;gt;pubsub_patterns));

    return retval; 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，客户端就订阅了频道。&lt;br&gt;UNSUBSCRIBE命令的行为和SUBSCRIBE的行为正好相反，当一个客户端退订某个或某些频道的时候，服务器将从pubsub_channels中解除客户端与被退订频道之间的关联。&lt;/p&gt;
&lt;h3 id=&quot;模式的订阅与退订&quot;&gt;&lt;a href=&quot;#模式的订阅与退订&quot; class=&quot;headerlink&quot; title=&quot;模式的订阅与退订&quot;&gt;&lt;/a&gt;模式的订阅与退订&lt;/h3&gt;&lt;p&gt;如前文所述，服务器将所有模式的订阅关系都保存在服务器状态的pubsub_patterns属性里面。&lt;br&gt;模式的订阅与退订在Redis中对应的命令分别为PSUBSCRIBE和PUNSUBSCRIBE。&lt;br&gt;下面是PSUBSCRIBE相关的源代码。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int pubsubSubscribePattern(redisClient* c, robj* pattern){
    int retval=0;

    //看客户端是否已经订阅了这个模式
    if(listSearchKey(c-&amp;gt;pubsub_patterns, pattern)==NULL){    //没有
        retval=1;
        pubsubPattern* pat;
        listAddNodeTail(c-&amp;gt;pubsub_patterns, pattern);
        incrRefCount(pattern);

        //创建并设置新的pubsubPattern结构
        pat = zmalloc(sizeof(*pat));
        pat-&amp;gt;pattern = getDecodedObject(pattern);
        pat-&amp;gt;client = c;

        listAddNodeTail(server.pubsub_patterns, pat);
    }
    //回复客户端
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同频道订阅操作类似，只是在数据结构上有些许差异。&lt;br&gt;模式的退订命令PUNSUBSCRIBE是PSUBSCRIBE命令的反操作：当一个客户端退订某个或某些模式的时候，服务器将在pubsub_patterns链表查找并删除那些pattern属性为被退订模式，并且client属性为执行退订命令的客户端的pubsubPattern结构。&lt;/p&gt;
&lt;h3 id=&quot;发送消息&quot;&gt;&lt;a href=&quot;#发送消息&quot; class=&quot;headerlink&quot; title=&quot;发送消息&quot;&gt;&lt;/a&gt;发送消息&lt;/h3&gt;&lt;p&gt;当一个Redis客户端执行PUBLISH &lt;channel&gt; &lt;message&gt;命令将消息message发送给频道channel的时候，服务器需要执行以下两个动作：&lt;br&gt;（1）将消息message发送给channel频道的所有订阅者；&lt;br&gt;（2）如果有一个或多个模式pattern与频道channel相匹配，那么将消息message发送给pattern模式的订阅者。&lt;br&gt;下面是相关的源码。&lt;/message&gt;&lt;/channel&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int pubsubPublishMessage(robj* channel, robj* message) {
    int receives=0;
    dictEntry* de;
    listNode* ln;
    listIter li;

    de = dictFind(server.pubsub_channels, channel);    //查找channel
    if(de){
        list* list = dictGetVal(de);    //得到客户端链表
        listNode* ln;
        listIter* li;

        listRewind(list, &amp;amp;li);
        while(ln = listNext(&amp;amp;li)!=NULL){    //遍历客户端链表，将消息发送给他们
            redisClient* c = ln-&amp;gt;value;
            addReply(c,shared.mbulkhdr[3]);
            addReply(c,shared.messagebulk);
            addReplyBulk(c,channel);
            addReplyBulk(c,message);
            receives++;        //接收客户端计数
        }
    }

    //将消息发送给与频道匹配的模式
    if(listLength(server.pubsub_patterns)){
        listRewind(server.pubsub_patterns,&amp;amp;li);
        channel = getDecodedObject(channel);
        while ((ln = listNext(&amp;amp;li)) != NULL) {
            if (stringmatchlen((char*)pat-&amp;gt;pattern-&amp;gt;ptr,
                            sdslen(pat-&amp;gt;pattern-&amp;gt;ptr),
                            (char*)channel-&amp;gt;ptr,
                            sdslen(channel-&amp;gt;ptr),0)){    //如果模式和channel匹配
                //给所以订阅该模式的客户端发送消息
                addReply(pat-&amp;gt;client,shared.mbulkhdr[4]);
                addReply(pat-&amp;gt;client,shared.pmessagebulk);
                addReplyBulk(pat-&amp;gt;client,pat-&amp;gt;pattern);
                addReplyBulk(pat-&amp;gt;client,channel);
                addReplyBulk(pat-&amp;gt;client,message);

                receives++;        //接收客户端计数
            }
        }
    }
    return receives;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;查看订阅信息&quot;&gt;&lt;a href=&quot;#查看订阅信息&quot; class=&quot;headerlink&quot; title=&quot;查看订阅信息&quot;&gt;&lt;/a&gt;查看订阅信息&lt;/h3&gt;&lt;p&gt;此外，Redis还支持PUBSUB命令，客户端用以查看频道或者模式的相关信息，比如某个频道目前有多少订阅者、某个模式目前有多少订阅者等。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文分析下Redis的发布与订阅功能，该功能有点类似网络中的多播或者广播的感觉，即当一个客户端向某个频道发布消息时，频道的所有订阅者和与这个频道相匹配的模式的订阅者都会收到该消息。&lt;br&gt;Redis的发布与订阅功能分为频道的订阅和模式的订阅。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之启动过程分析</title>
    <link href="http://blog.dujiong.net/2016/11/10/Redis-start/"/>
    <id>http://blog.dujiong.net/2016/11/10/Redis-start/</id>
    <published>2016-11-10T01:49:28.000Z</published>
    <updated>2016-11-23T08:24:56.583Z</updated>
    
    <content type="html">&lt;p&gt;Redis服务器是典型的一对多服务器程序：一个服务器可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令，而服务器接收并处理客户端发送的命令请求，并向客户端返回命令回复。通过使用I/O多路复用技术实现的文件事件处理器，Redis服务器使用单进程单线程的方式来处理命令请求。&lt;br&gt;本文对Redis服务器的启动过程做简单分析。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一个Redis服务器从启动到能够接受客户端的命令请求，需要经过一系列的初始化和设置过程，比如初始化服务器状态，接受用户指定的服务器配置，创建相应的数据结构和网络连接等。&lt;/p&gt;
&lt;h3 id=&quot;初始化服务器状态结构&quot;&gt;&lt;a href=&quot;#初始化服务器状态结构&quot; class=&quot;headerlink&quot; title=&quot;初始化服务器状态结构&quot;&gt;&lt;/a&gt;初始化服务器状态结构&lt;/h3&gt;&lt;p&gt;初始化服务器的第一步是创建一个struct redisServer类型的实例变量作为服务器的状态，并为结构中的各个属性设置默认值，在Redis中，服务器所有属性都保存在struct redisServer类型全局变量server中。该部分工作由redis.c/initServerConfig函数完成。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void initServerConfig()
{
    ...
    getRandomHexChars(server.runid, REDIS_RUN_ID_SIZE);    //设置服务器的运行ID
    server.configfile = NULL;
    server.port = REDIS_SERVERPORT;
    server.tcp_backlog = REDIS_TCP_BACKLOG;
    ...
    server.lruclock = getLRUclock();    //
    server.commands = dictCreate(&amp;amp;commandTableDictType, NULL);
    server.orig_command = dictCreate(&amp;amp;commandTableDictType, NULL);
    populateCommandTable();
    ...
}   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，&lt;code&gt;server.lruclock = getLRUclock();&lt;/code&gt;用于保存服务器的LRU时钟，表示服务器最近一次使用时钟的时间。精度为秒。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//mstime()返回Unix时间毫秒数
//#define REDIS_LRU_BITS 24
//#define REDIS_LRU_CLOCK_MAX ((1&amp;lt;&amp;lt;REDIS_LRU_BITS)-1)    //Max value of obj-&amp;gt;lru
//#define REDIS_LRU_CLOCK_RESOLUTION 1000         //LRU clock resolution in ms
unsigned int getLRUClock(void){
    return (mstime()/REDIS_LRU_CLOCK_RESOLLUTION) &amp;amp; REDIS_LRU_CLOCK_MAX;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此外，每个Redis对象都会有一个LRU属性，保存了对象最后一次被命令访问的时间。    &lt;/p&gt;
&lt;h3 id=&quot;载入配置选项&quot;&gt;&lt;a href=&quot;#载入配置选项&quot; class=&quot;headerlink&quot; title=&quot;载入配置选项&quot;&gt;&lt;/a&gt;载入配置选项&lt;/h3&gt;&lt;p&gt;在启动服务器时，用户可以通过给定配置参数（终端命令输入）或者指定配置文件（redis.conf）来修改服务器的默认配置。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if(argc &amp;gt;= 2){
    int j=1;
    sds options = sdsempty();
    char* configfile = NULL;
    if(argv[j][0]!=&amp;apos;-&amp;apos; || argv[j][1] != &amp;apos;-&amp;apos;)       //配置文件
        configfile = argv[j++];
    while(j != argc){    //除了配置文件还有其余选项，由options保存,比如--port 6380会被分析为&amp;quot;port 6380\n&amp;quot;
        if(argv[j][0]==&amp;apos;-&amp;apos; &amp;amp;&amp;amp; argv[j][1]==&amp;apos;-&amp;apos;){
            if(sdslen(options)) options = sdscat(options, &amp;quot;\n&amp;quot;);
            options = sdscat(options, argv[j]+2);
            options = sdscat(options, &amp;quot; &amp;quot;);
        }else{
            options = sdscatrepr(options,argv[j],strlen(argv[j]));
            options = sdscat(options, &amp;quot; &amp;quot;);
        }
        j++;
    }    
    if(configfile) server.configfile = getAbsolutePath(configfile);
    resetServerSaveParams();
    loadServerConfig(configfile, options);    //载入配置文件，还有options
    sdsfree(options);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置文件只能再第二个参数（第一个为程序名称），然后跟着配置文件后面可以是各个配置选项，都存储在option字符串中。最后调用函数&lt;code&gt;loadServerConfig(configfile, options);&lt;/code&gt;将文件读进内存，并给server赋值。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void loadServerConfig(char* filename, char* options)
{
    sds config = sdsempty();
    char buf[REDIS_CONFIGFILE_MAX+1];

    if(filename){
        FILE* fp;

        if(filename[0]==&amp;apos;-&amp;apos; &amp;amp;&amp;amp; finename[1]==&amp;apos;\0&amp;apos;){
            fp = stdin;
        }else{
            if((fp=fopen(filename,&amp;quot;r&amp;quot;))==NULL){
                redisLog(REDIS_WARNING, &amp;quot;Fatal error, can&amp;apos;t open config file &amp;apos;%s&amp;apos;&amp;quot;, filename);
                exit(1);
            }
        }
        while(fgets(buf, REDIS_CONFIGFILE_MAX+1, fp)!=NULL)
            config = sdscat(config, buf);
        if(fp != stdin) fclose(fp);
    }
    if(options) {
        config = sdscat(config, &amp;quot;\n&amp;quot;);
        config = sdscat(config, options);
    }
    loadServerConfigFromString(config);
    sdsfree(config);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将配置文件和options的配置存入config中，然后调用loadServerConfigFromString(config)根据配置选项名称给server结构体赋值。&lt;/p&gt;
&lt;h3 id=&quot;初始化服务器数据结构&quot;&gt;&lt;a href=&quot;#初始化服务器数据结构&quot; class=&quot;headerlink&quot; title=&quot;初始化服务器数据结构&quot;&gt;&lt;/a&gt;初始化服务器数据结构&lt;/h3&gt;&lt;p&gt;在之前执行initServerConfig函数初始化server状态时，程序只创建了命令表一个数据结构，不过除了命令表之外，服务器状态还包含其他数据结构。比如：&lt;br&gt;(1) server.clients链表。该链表记录了所有与服务器相连的客户端的状态结构，链表的每一个节点都包含一个redisClient结构实例。&lt;br&gt;(2) server.db数组。该数组包含了服务器中的所有数组。&lt;br&gt;(3) 用于保存频道订阅信息的server.pubsub_channels字典，以及用于保存模式订阅信息的server.pubsub_patterns链表。&lt;br&gt;(4)…&lt;br&gt;当初始化服务器进行到这一步，服务器将调用initServer函数，为以上提到的数据结构分配内存，并在有需要时，为这些数据结构设置或关联初始化值。&lt;br&gt;因此，前面的initServerConfig函数中主要负责初始化一般属性，而initServer函数主要负责初始化数据结构。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void initServer()
{
    int j;

    server.current_client = NULL;
    server.clients = listCreate();
    server.clients_to_close = listCreate();
    server.slaves = listCreate();
    server.monitors = listCreate();

    createSharedObjects();    //创建共享对象
    server.el = aeCreateEventLoop(server.maxclients+REDIS_EVENTLOOP_FDSET_INCR);    //创建EventLoop实例
    server.db = zmalloc(sizeof(redisDb)*server.dbnum);

    if(server.port!=0 &amp;amp;&amp;amp; 
            listenToPort(server.port, server.ipfd, &amp;amp;server.ipfd_count)==REDIS_ERR)
        exit(1);
    ...
    if(acCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR){
        redisPanic(&amp;quot;can&amp;apos;t create the serverCron time event.&amp;quot;);
        exit(1);
    }

    for(j=0; j&amp;lt;server.ipfd_count; j++){
        //为TCP连接关联连接处理器
        if(aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler, NULL)==AE_ERR){
            redisPanic(&amp;quot;...&amp;quot;);
        }    
    }    
    //为本地套接字关联处理器
    if(server.sofd&amp;gt;0 &amp;amp;&amp;amp; aeCreateFileEvent(server.el, server.sofd, AE_READABLE, acceptUnixHandler, NULL)==AE_ERR){
        redisPanic(&amp;quot;...&amp;quot;);
    }
    //AOF文件
    //初始化脚本系统
    //初始化慢查询功能
    //...
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，listenToPort函数先判断用户是否提供监听地址，如果没有，则监听INADDR_ANY(0.0.0.0)地址，即所有地址，包括IPV4和IPV6，并设置为非阻塞。如果有设置监听地址，可以是一个地址队列，则只监听用户自己设置的ip地址队列。最后server.ipfd为监听套接字数组，server.ipfd_count为套接字数组个数。&lt;br&gt;然后创建了时间和文件描述符事件，主要是设置处理事件的回调函数。   &lt;/p&gt;
&lt;h3 id=&quot;serverCron函数&quot;&gt;&lt;a href=&quot;#serverCron函数&quot; class=&quot;headerlink&quot; title=&quot;serverCron函数&quot;&gt;&lt;/a&gt;serverCron函数&lt;/h3&gt;&lt;p&gt;Redis服务器中的serverCron函数默认每隔100（1000/server.hz）毫秒执行一次（第一次是1ms执行，后面是100ms），该函数负责管理服务器的资源，并保持服务器自身的良好运转。&lt;br&gt;(1)更新服务器时间缓存&lt;br&gt;Redis服务器中有不少功能需要获取系统的当前时间，而每次获取系统的当前时间都需要执行一次时间调用，为了减少系统调用的执行次数，服务器状态中的unixtime属性和mstime属性被当作当前时间的缓存，serverCron函数更新该域，这样就可以从这里获取时间。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//time_t unixtime;    //秒级精度的系统当前UNIX时间戳
//long long mstime;    //毫秒级精度的系统当前UNIX时间戳
void updateCachedTime(void){
    server.unixtime = time(NULL);
    server.mstime = mstime();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  服务器只会在打印日志、更新服务器的LRU时钟、决定是否执行初始化任务、计算服务器上线时间这类对时间精度要求不高的功能上“使用unixtime和mstime属性”。而对于为键设置过期时间、添加慢查询日志这种需要高精度时间的功能来说，服务器还是会再次执行系统调用，从而获得最准确的系统当前时间。&lt;br&gt;(2)更新LRU时钟；&lt;br&gt;(3)更新内存使用峰值&lt;br&gt;服务器状态中的stat_peak_memory属性记录了服务器的内存峰值大小。每次serverCron函数执行时，程序都会查看服务器当前使用的内存数量，并与stat_peak_memory保存的数值进行比较，如果当前使用的内存数量比stat_peak_memory属性记录的值要打，那么程序就将当前使用的内存数量记录到stat_peak_memory。&lt;br&gt;(4)处理SIGTERM信号&lt;br&gt;在启动服务器时，Redis会为服务器进程的SIGTERM信号关联处理器sigtermHandler函数，该信号处理器接到SIGTERM信号时，打开服务器状态的shutdown_asap标识。每次serverCron函数运行时，程序都会对服务器状态的shutdown_asap属性进行检查，以决定是否关闭服务器。&lt;br&gt;(5)管理客户端资源&lt;br&gt;serverCron函数每次执行都会调用clientsCron函数，clientsCron函数会对一定数量的客户端进行一下两个检查：&lt;br&gt;a. 如果客户端与服务器之间连接已经超时（很长时间没有互动），那么程序释放这个客户端，关闭连接。&lt;br&gt;b. 如果客户端在上一次执行命令请求之后，输入缓冲区的大小超过了一定的长度，那么程序会释放客户端当前的输入缓冲区，并重新创建一个默认大小的输入缓冲区，从而防止客户端的输入缓冲区耗费了过多的内存。&lt;br&gt;(6)管理数据库资源&lt;br&gt;serverCron函数每次执行都会调用databasesCron函数，该函数会对服务器中的一部分数据库进行检查，删除其中的过期键，并在有需要时，对字典进行收缩操作。&lt;br&gt;(7)调度aof或rdb读写子进程，复制同步，集群同步，sentinel定时器等；&lt;br&gt;总之，定时事件做的事情很多，可以说Redis充分利用了定时器，这样就少了很多线程。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Redis服务器是典型的一对多服务器程序：一个服务器可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令，而服务器接收并处理客户端发送的命令请求，并向客户端返回命令回复。通过使用I/O多路复用技术实现的文件事件处理器，Redis服务器使用单进程单线程的方式来处理命令请求。&lt;br&gt;本文对Redis服务器的启动过程做简单分析。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之事件驱动</title>
    <link href="http://blog.dujiong.net/2016/11/05/Redis-event/"/>
    <id>http://blog.dujiong.net/2016/11/05/Redis-event/</id>
    <published>2016-11-05T04:03:53.000Z</published>
    <updated>2016-11-15T05:52:30.834Z</updated>
    
    <content type="html">&lt;p&gt;事件处理是Redis的核心机制之一，通过在文件、网络和时间等类型的事件上进行多路复用，为Redis的高性能提供保证。事件驱动在Redis源码中主要涉及ae.h/ae.c，Ae_evport/epoll/kqueue/select.c等文件。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Redis事件驱动相关数据结构&quot;&gt;&lt;a href=&quot;#Redis事件驱动相关数据结构&quot; class=&quot;headerlink&quot; title=&quot;Redis事件驱动相关数据结构&quot;&gt;&lt;/a&gt;Redis事件驱动相关数据结构&lt;/h3&gt;&lt;p&gt;Redis事件驱动内部包含四个主要的数据结构(定义在ae.h中)，分别是：文件事件结构体、时间事件结构体、就绪事件结构体和循环结构体。&lt;/p&gt;
&lt;h4 id=&quot;文件事件&quot;&gt;&lt;a href=&quot;#文件事件&quot; class=&quot;headerlink&quot; title=&quot;文件事件&quot;&gt;&lt;/a&gt;文件事件&lt;/h4&gt;&lt;p&gt;文件事件定义在ae.h/aeFileEvent结构体中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeFileEvent {
    int mask;            //状态

    aeFileProc* rfileProc;        
    aeFileProc* wfileProc;
    void* clientData;    //多路复用库的私有数据
} aeFileEvent;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，rfileProc和wfileProc为aeFileProc类型函数指针，分别对应于读、写事件处理函数。其声明为：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef void aeFileProc(struct aeEventLoop *eventLoop, int fd, void *clientData, int mask);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;clientData保存执行命令时所需要的数据，每次处理事件时，它会作为参数被传入事件处理器。&lt;/p&gt;
&lt;h4 id=&quot;就绪事件&quot;&gt;&lt;a href=&quot;#就绪事件&quot; class=&quot;headerlink&quot; title=&quot;就绪事件&quot;&gt;&lt;/a&gt;就绪事件&lt;/h4&gt;&lt;p&gt;就绪事件定义在ae.h/aeFiredEvent结构体中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeFiredEvent {
    int fd;                //就绪文件描述符

    int mask;            //事件类型掩码
} aeFiredEvent;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就绪事件结构体将在IO多路复用（aeApiPoll函数）返回时设置。&lt;/p&gt;
&lt;h4 id=&quot;时间事件&quot;&gt;&lt;a href=&quot;#时间事件&quot; class=&quot;headerlink&quot; title=&quot;时间事件&quot;&gt;&lt;/a&gt;时间事件&lt;/h4&gt;&lt;p&gt;时间事件定义在ae.h/aeTimeEvent结构体中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeTimeEvent {
    long long id;        //时间事件的唯一标识

    long when_sec;
    long when_ms;

    aeTimeProc* timeProc;
    aeEventFinalizerProc* finalizerProc;     
    void* clientData;
    struct aeTimeEvent* next;        //指向下个时间事件结构，形成链表
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，id为时间事件的全局唯一标识号，其值按从小到大的顺序递增，新事件的id号比旧事件的id大。when为毫秒级的UNIX时间戳，记录时间事件的到达时间。next为指向下个时间事件结构的指针，Redis服务器将所有时间事件都放在一个无序（到达时间）链表中，每当时间事件执行器运行时，就遍历链表，查找所有已到达的时间事件，并调用相应的事件处理器。注意，Redis的时间事件链表是按id排序的链表，对于到达时间，它是无序的。&lt;br&gt;timeProc和finalizerProc分别为时间事件处理器和事件释放函数的函数指针。其声明为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef int aeTimeProc(struct aeEventLoop *eventLoop, long long id, void *clientData);
typedef void aeEventFinalizerProc(struct aeEventLoop *eventLoop, void *clientData);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此外，Redis的时间事件可以分为以下两类：&lt;br&gt;（1）定时事件：让一段程序在指定的时间之后执行一次；&lt;br&gt;（2）周期性事件：让一段程序每隔指定的时间就执行一次。&lt;br&gt;一个时间事件是定时事件还是周期性事件取决于时间事件处理器的返回值(ae.c/processTimeEvents/retval = te-&amp;gt;timeProc(eventLoop, id, te-&amp;gt;clientData))：&lt;br&gt;（1）如果事件处理器返回返回ae.h/AE_NOMORE,那么这个事件为定时事件，该事件在到达一次之后就会被删除。&lt;br&gt;（2）如果事件处理器返回一个非AE_NOMORE的整数值，那么这个事件为周期性事件，此时，服务器会对时间事件的when属性进行更新，让该事件在一段时间之后再次到达，并以这种方式更新、运行。   &lt;/p&gt;
&lt;h4 id=&quot;事件循环结构体&quot;&gt;&lt;a href=&quot;#事件循环结构体&quot; class=&quot;headerlink&quot; title=&quot;事件循环结构体&quot;&gt;&lt;/a&gt;事件循环结构体&lt;/h4&gt;&lt;p&gt;在事件驱动的实现中，需要有一个事件循环结构来监控调度所有的事件。在Redis中的事件驱动库中，事件循环结构结构定义在ae.h/aeEventLoop中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeEventLoop {
    int maxfd;                    //注册的最大的文件描述符
    int setsize;                //监听的文件描述符的最大个数

    long long timeEventNextId;    //生成时间事件id
    time_t lastTime;            //最后一次执行时间事件的时间

    aeFileEvent* events;        //注册的文件事件
    aeFilEvent* fired;            //就绪的文件事件
    aeTimeEvent* timeEventHead;    //时间事件
    int stop;
    void* apindata;                //多路复用库的私有数据
    aeBeforeSleepProc* beforesleep;
} aeEventLoop;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，events是aeFileEvent结构的数组，每个aeFileEvent结构表示一个注册的文件事件。setsize表示能处理的文件描述符的最大个数。beforesleep函数指针表示在监控事件触发之前，需要调用的函数。apindata表示底层多路复用的私有数据，比如对于select来说，该结构保存了读写描述符数组；对于epoll来说，该结构中保存了epoll描述符和epoll_event数组。       &lt;/p&gt;
&lt;h3 id=&quot;Redis事件的调度与执行&quot;&gt;&lt;a href=&quot;#Redis事件的调度与执行&quot; class=&quot;headerlink&quot; title=&quot;Redis事件的调度与执行&quot;&gt;&lt;/a&gt;Redis事件的调度与执行&lt;/h3&gt;&lt;p&gt;Redis的事件处理主循环在aeMain函数中进行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void aeMain(aeEventLoop* eventLoop){
    eventLoop-&amp;gt;stop = 0;
    while(!eventLoop-&amp;gt;stop){
        if(eventLoop-&amp;gt;beforesleep != NULL){
            eventLoop-&amp;gt;beforesleep(eventLoop);
        }
        aeProessEvents(eventLoop, AE_ALL_EVENTS);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该事件循环的流程图如下：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/5bUY0j1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;aeProcessEvents函数进行具体的事件处理，定义在ae.c文件下，其关键代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int aeProcessEvents(aeEventLoop* eventLoop, int flags) {
    ...
    if(eventLoop-&amp;gt;maxfd!=-1 || ((flags &amp;amp; AE_TIME_EVENTS) &amp;amp;&amp;amp; !(flags &amp;amp; AE_DONT_WAIT))) {
        shortest = aeSearchNearestTimer(eventLoop);  //获取最近的时间事件
        if(shortest){
            aeGetTime(&amp;amp;now_sec, &amp;amp;now_ms);
            //计算最近的时间事件距离到达还有多少毫秒
            tvp-&amp;gt;tv_usec = ((shortest-&amp;gt;when_ms+1000) - now_ms)*1000;
            tvp-&amp;gt;tv_sec --;
            ...
        }else{        //没有时间事件，根据AE_DONT_WAIT来设置是否阻塞，以及阻塞的事件长度
            if(flags &amp;amp; AE_DONT_WAIT) {        
                tv.tv_sec = tv.tv_usec = 0;
                tvp = &amp;amp;tv;
            }else{
                tvp = NULL;
            }
        }
        numevents = aeApiPoll(eventLoop, tvp);            //select,epoll...
        for(j=0; j&amp;lt;numevents;j++){
            aeFileEvent *fe = &amp;amp;eventLoop-&amp;gt;events[eventLoop-&amp;gt;fired[j].fd];
            int mask = eventLoop-&amp;gt;fired[j].mask;
            int fd = eventLoop-&amp;gt;fired[j].fd;
            int rfired = 0;
            if(fe-&amp;gt;mask &amp;amp; mask &amp;amp; AE_READABLE){
                rfired = 1;
                fe-&amp;gt;rfileProc(eventLoop, fd, fe-&amp;gt;clientData, mask);        //处理读事件
            }
        ...
        }
    }
    if(flags &amp;amp; AE_TIME_EVENTS)
        processed += processTimeEvents(eventLoop);        //处理时间事件
    return processed;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，aeApiPoll函数的最大阻塞时间(tvp结构)由到达时间最接近当前时间的时间事件(shortest)决定，这样既可以避免服务器对时间事件进行频繁的轮询（忙等待），也可以确保aeApiPoll函数不会阻塞过长时间。&lt;br&gt;因为文件事件是随机出现的，如果等待并处理完一次文件事件之后，仍未有任何时间事件到来，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这时服务器就可以开始处理到达的时间事件了。&lt;br&gt;对文件事件和时间事件的处理都是同步、有序、原子地执行的，服务器不会中途中断事件处理，也不会对事件进行抢占，因此，不管是文件事件的处理器，还是时间事件的处理器，它们都会尽可能地减少程序的阻塞时间，并在需要时让出执行权，从而降低造成事件饥饿的可能性。比如说，在命令回复处理器将一个命令回复写入到客户端套接字，如果写入的字节数超过了一个预设常量的话，命令回复处理器就会主动用break跳出写入循环，将余下的数据留到下次再写，另外，时间事件也会将非常耗时的持久化操作放到子线程或子进程中执行。&lt;br&gt;此外，由于时间事件放在文件事件之后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达时间稍晚一些。   &lt;/p&gt;
&lt;h3 id=&quot;Redis-IO复用函数选择&quot;&gt;&lt;a href=&quot;#Redis-IO复用函数选择&quot; class=&quot;headerlink&quot; title=&quot;Redis IO复用函数选择&quot;&gt;&lt;/a&gt;Redis IO复用函数选择&lt;/h3&gt;&lt;p&gt;最后提到的一点是，Redis提供了在多个IO库之间选择最佳的策略。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#ifdef HAVE_EVPORT
#include &amp;quot;ae_evport.c&amp;quot;
#else
    #ifdef HAVE_EPOLL
    #include &amp;quot;ae_epoll.c&amp;quot;
    #else
        #ifdef HAVE_KQUEUE
        #include &amp;quot;ae_kqueue.c&amp;quot;
        #else
        #include &amp;quot;ae_select.c&amp;quot;
        #endif
    #endif
#endif
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，在编译时，Redis可以根据平台自上而下选择最快的IO多路复用函数。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;事件处理是Redis的核心机制之一，通过在文件、网络和时间等类型的事件上进行多路复用，为Redis的高性能提供保证。事件驱动在Redis源码中主要涉及ae.h/ae.c，Ae_evport/epoll/kqueue/select.c等文件。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL之deque</title>
    <link href="http://blog.dujiong.net/2016/10/31/STL-deque/"/>
    <id>http://blog.dujiong.net/2016/10/31/STL-deque/</id>
    <published>2016-10-31T09:49:42.000Z</published>
    <updated>2016-10-31T11:48:49.896Z</updated>
    
    <content type="html">&lt;p&gt;C++标准模板库序列式容器中，使用最少的估计就是deque了。但是，了解下deque这种双向开口的连续线性空间容器的底层设计与实现仍是很有帮助的。此外，stack和queue这两种适配器容器（容器底层是调用其他容器）底层实现默认就是使用deque。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;与vector比较&quot;&gt;&lt;a href=&quot;#与vector比较&quot; class=&quot;headerlink&quot; title=&quot;与vector比较&quot;&gt;&lt;/a&gt;与vector比较&lt;/h3&gt;&lt;p&gt;deque和vector的最大差异，一是deque允许常熟时间内对起头端进行元素的插入或移除操作，二在于deque没有所谓容量观念，因为它是动态地以分段连续空间组合而成，随时可以增加一段新的空间并链接起来。即，像vector那样“因旧空间不足而重新配置一块更大空间，然后复制元素，再释放旧空间”这样的事情在deque是不会发生的。也因此，deque没有必要提供所谓的空间保留功能。&lt;br&gt;更具体的，array无法增长，vector虽可增长，却只能向尾端增长，而且所谓增长是个假象，事实上是（1）另觅更大空间；（2）将原数据复制过去；（3）释放原空间 三部曲。&lt;br&gt;deque是由一段一段的定量连续空间构成。一旦有必要在deque的前端或尾端增加新空间，便配置一段定量连续空间，串接在整个deque的头端或尾端。deque的最大任务，便是在这些分段的定量连续空间上，维护其整体连续的假象，并提供随机存取的接口。这样避开了“重新配置、复制、释放”的轮回，代价则是复杂的迭代器架构。    &lt;/p&gt;
&lt;h3 id=&quot;deque的中控器和迭代器&quot;&gt;&lt;a href=&quot;#deque的中控器和迭代器&quot; class=&quot;headerlink&quot; title=&quot;deque的中控器和迭代器&quot;&gt;&lt;/a&gt;deque的中控器和迭代器&lt;/h3&gt;&lt;p&gt;deque底层实现一个中控器，即一个指针数组，其中的每一个元素都是指针，指向另一段连续线性空间，称为缓冲区。缓冲区才是deque的存储空间主体。&lt;br&gt;迭代器由以下四个部分组成：&lt;br&gt;（1）cur：指向缓冲区当前元素。&lt;br&gt;（2）first：指向缓冲区的第一个位置。&lt;br&gt;（3）last：指向末节点，即最后一个元素的下一个位置。&lt;br&gt;（4）node：指向主控器相应的索引位置。&lt;br&gt;中控器、缓冲区、迭代器之间的关系如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/SsE0h85.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;以下是中控器和迭代器的相关源代码。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc, size_t BufSiz = 0&amp;gt;
class deque {
public:
    typedef T value_type;
    typedef value_type* pointer;        
    ...
protected:
    typedef pointer* map_pointer;        //指针的指针
    map_pointer map;        //map是指针数组，中控器
    size_type map_size;        //map内可容纳多少指针
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，中控器map其实是一个T**，即是指向指针的指针，T为元素型别。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Ref, class Ptr, size_t BufSiz&amp;gt;
struct __deque_iterator {
    typedef __deque_iterator&amp;lt;T, T&amp;amp;, T*, BufSiz&amp;gt; iterator;
    typedef __deque_iterator&amp;lt;T, const T&amp;amp;, const T*, BufSiz&amp;gt; const_iterator;
    static size_t buffer_size() { return __deque_buf_size(BufSiz, sizeof(T)); }
    typedef random_access_iterator_tag iterator_category;    //RandomAccess Iterator
    typedef T value_type; 
    typedef Ptr pointer;
    typedef Ref reference;
    typedef size_t size_type;
    typedef ptrdiff_t difference_type;
    typedef T** map_pointer;                //指向主控器的指针

    T* cur;
    T* first;
    T* last;
    map_pointer node;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;迭代器的四个主要组成：cur、first、last、node的定义。&lt;br&gt;接下来是构造函数和迭代器的重载运算因子。          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;__deque_iterator(T* x, map_pointer y)    //用T类型数据和指向中控器的指针初始化一个迭代器
    : cur(x), first(*y), last(*y+buffer_size()), node(y) {}
__deque_iterator() : cur(0), first(0), last(0), node(0) {}    //创建一个空的迭代器
__deque_iterator(const iterator&amp;amp; x) : cur(x.cur), first(x.first), last(x.last), node(x.node) {}    //复制构造函数

reference operator*() const { return *cur; }
pointer operator-&amp;gt;() const { return &amp;amp;(operator*()); }
difference_type operator-(const self&amp;amp; x) const {
    return difference_type(buffer_size())*(node-x.node-1)+(cur-first)+(x.last-x.cur);
}
...
self&amp;amp; operator+=(difference_type n){
    difference_type offset=n+(cur-first);
    if(offset&amp;gt;=0 &amp;amp;&amp;amp; offset&amp;lt;difference_type(buffer_size())){    //目标在同一个缓冲区内
        cur+=n;
    }else{            //目标位置不在同一个缓冲区内
        difference_type node_offset = offset&amp;gt;0 ? offset/difference_type(buffer_size()) : -difference_type((-offset-1) / buffer_size())-1;
        set_node(node + node_offset);
        cur = first+(offset-node_offset*difference_type(buffer_size()));
    }
    return *this;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在进行+=n运算时，要判断+n之后的索引是否还在当前缓冲区内，如果在，cur简单+n即可，如果不在，则要计算正确的缓存节点和正确的元素位置。其他+n，-=n，-运算都可以通过+=运算得出。&lt;/p&gt;
&lt;h3 id=&quot;deque的结构&quot;&gt;&lt;a href=&quot;#deque的结构&quot; class=&quot;headerlink&quot; title=&quot;deque的结构&quot;&gt;&lt;/a&gt;deque的结构&lt;/h3&gt;&lt;p&gt;deque除了维护一个指向map的指针外，还维护start、finish两个迭代器，分别指向第一缓冲区的第一个元素和最后缓冲区的最后一个元素（的下一个位置）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc, size_t BufSiz = 0&amp;gt;
class deque {
public:
    typedef T value_type;
    typedef value_type* pointer;
    typedef size_t size_type;
    typedef __deque_iterator&amp;lt;T, T&amp;amp;, T*, BufSiz&amp;gt; iterator;
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;
    typedef simple_alloc&amp;lt;pointer, Alloc&amp;gt; map_allocator;
    ...
protected:
    typedef pointer* map_pointer;
    iterator start;
    iterator finish;
    map_pointer map;
    size_type map_size;        //map容纳指针的个数    
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;默认构造函数&quot;&gt;&lt;a href=&quot;#默认构造函数&quot; class=&quot;headerlink&quot; title=&quot;默认构造函数&quot;&gt;&lt;/a&gt;默认构造函数&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;deque()
    : start(), finish(), map(0), map_size(0) {
    create_map_nodes(0);
} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;默认构造函数先初始化两个迭代器为空迭代器，然后设置map和map_size，接着调用create_map_and_nodes(size_type num_elements)来初始化一块内存。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Alloc, size_t BufSize&amp;gt;
void deque&amp;lt;T, Alloc, BufSize&amp;gt;::create_map_and_nodes(size_type num_elements) {
    size_type num_nodes = num_elements/buffer_size() + 1;    //    需要节点数
    map_size = max(initial_map_size(), num_nodes+2);    //一个map管理的节点数，最少8个，最多是“所需节点加2”
    map = map_allocator::allocate(map_size);

    map_pointer nstart = map+(map_size-num_nodes)/2;
    map_pointer nfinish = nstart+num_nodes-1;
    map_pointer cur;

    __STL_TRY {
        for(cur=nstart; cur&amp;lt;=nfinish; ++cur){
            *cur = allocate_node();
        }
    }catch(...){
        ...
    }
    //为deque内的两个迭代器设定正确的内容
    start.set_node(nstart);
    finish.set_node(nfinish);
    start.cur = start.first;
    finish.cur = finish.first + num_elements%buffer_size();
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;由n个value初始化的构造函数&quot;&gt;&lt;a href=&quot;#由n个value初始化的构造函数&quot; class=&quot;headerlink&quot; title=&quot;由n个value初始化的构造函数&quot;&gt;&lt;/a&gt;由n个value初始化的构造函数&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;deque(size_type n, const value_type&amp;amp; value)
    : start(), finish(), map(0), map_size(0) {
    fill_initialize(n, value);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该构造函数调用fill_initialize函数来初始化deque，fill_initialize函数负责产生并安排好deque的结构，并将元素的初值设定妥当。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc, size_t BufSize&amp;gt;
void deque&amp;lt;T, Alloc, BufSize&amp;gt;::fill_initialize(
    size_type n, const value_type&amp;amp; value) {
    create_map_and_nodes(n);
    map_pointer cur;
    __STL_TRY {
        //为每个节点的缓冲区设定初值
        for(cur=start.node; cur&amp;lt;finish.node;++cur){
            uninitialized_fill(*cur, *cur + buffer_size(), value);
        }
        uninitialized_fill(finish.first, finish.cur, value);    //最后一个节点单独对待
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;两个迭代器初始化的构造函数&quot;&gt;&lt;a href=&quot;#两个迭代器初始化的构造函数&quot; class=&quot;headerlink&quot; title=&quot;两个迭代器初始化的构造函数&quot;&gt;&lt;/a&gt;两个迭代器初始化的构造函数&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator&amp;gt;
deque(InputIterator first, InputIterator last)
    : start(), finish(), map(0), map_size(0) {
    range_initialize(first, last, iterator_category(first));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该构造函数调用range_initialize来用迭代器范围内的元素初始化deque.range_initialize，根据迭代器类型，调用对应的版本。&lt;/p&gt;
&lt;h4 id=&quot;析构函数&quot;&gt;&lt;a href=&quot;#析构函数&quot; class=&quot;headerlink&quot; title=&quot;析构函数&quot;&gt;&lt;/a&gt;析构函数&lt;/h4&gt;&lt;p&gt;deque的析构函数先是调用destroy析构缓冲区内的数据，然后调用destroy_map_and_nodes函数析构缓冲区和中控器内存。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~deque() {
    destroy(start, finish);
    destroy_map_and_nodes();
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;deque的一些常用操作&quot;&gt;&lt;a href=&quot;#deque的一些常用操作&quot; class=&quot;headerlink&quot; title=&quot;deque的一些常用操作&quot;&gt;&lt;/a&gt;deque的一些常用操作&lt;/h3&gt;&lt;p&gt;deque所提供的元素操作很多，如pop_back、pop_front、clear、erase、insert等，这里不再一一列举，在理解时，只需把握“deque是多个连续缓冲区组合在一起的分段线性空间”即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;C++标准模板库序列式容器中，使用最少的估计就是deque了。但是，了解下deque这种双向开口的连续线性空间容器的底层设计与实现仍是很有帮助的。此外，stack和queue这两种适配器容器（容器底层是调用其他容器）底层实现默认就是使用deque。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL之list</title>
    <link href="http://blog.dujiong.net/2016/10/28/STL-list/"/>
    <id>http://blog.dujiong.net/2016/10/28/STL-list/</id>
    <published>2016-10-28T11:33:14.000Z</published>
    <updated>2016-10-31T03:26:00.692Z</updated>
    
    <content type="html">&lt;p&gt;上一篇文章总结了vector的结构和实现原理，今天来看看STL中另一个重要的容器：list。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;相比于vector的连续线性空间，list显得复杂得多，它的好处是每次插入或删除一个元素，就配置或释放一个元素空间。因此，list对于空间的运用有绝对的精准，一点都不浪费。    &lt;/p&gt;
&lt;h3 id=&quot;list的节点&quot;&gt;&lt;a href=&quot;#list的节点&quot; class=&quot;headerlink&quot; title=&quot;list的节点&quot;&gt;&lt;/a&gt;list的节点&lt;/h3&gt;&lt;p&gt;我们知道，list本身和list的节点是不同的结构，需分开设计。以下是STL list的节点结构：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct __list_node {
    typedef void* void_pointer;
    void_pointer prev;
    void_pointer next;
    T data;    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，STL list是一个双向链表，有两个指针，分别指向前向节点和后向节点。  &lt;/p&gt;
&lt;h3 id=&quot;list的迭代器&quot;&gt;&lt;a href=&quot;#list的迭代器&quot; class=&quot;headerlink&quot; title=&quot;list的迭代器&quot;&gt;&lt;/a&gt;list的迭代器&lt;/h3&gt;&lt;p&gt;list不能够像vector一样以普通指针作为迭代器，因为其节点不保证在存储空间连续存在。并且，由于list提供的是一个双向链表，迭都代器必须具备前移、后移的能力，所以list提供的是Bidirectional Iterators.&lt;br&gt;list有一个重要的性质：插入操作和结合操作都不会造成原有的list迭代器失效。这在vector是不成立的，因为vector的插入操作可能造成记忆体重新配置，导致原有的迭代器全部失效。甚至list的元素删除操作，也只有“指向被删除元素”的那个迭代器失效，其他迭代器不受任何影响。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Ref, class Ptr&amp;gt;
struct __list_iterator {
    typedef __list_iterator&amp;lt;T, &amp;amp;T, T*&amp;gt; iterator;
    typedef __list_iterator&amp;lt;T, Ref, Ptr&amp;gt; self;

    typedef __list_node&amp;lt;T&amp;gt;* link_type;
    link_type node;                        //list的节点:node 

    //迭代器的构造函数
    __list_iterator(link_type x) : node(x) {}
      __list_iterator() {}
      __list_iterator(const iterator&amp;amp; x) : node(x.node) {}    

    reference operator*() const { return (*node).data; }
    pointer operator-&amp;gt;() const { return &amp;amp;(operator*()); }

    self&amp;amp; operator++() {                    //先加1，再返回，类似++i
        node = (link_type)((*node).next);
        return *this;
    }
    self operator++(int) {                    //类似于i++
        self tmp = *this;
        ++*this;
        return tmp;
    }
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上是list的迭代器的设计，只实现了迭代器的++，–，取值，成员调用四个基本操作，没有像vector迭代器那样的+n操作，主要是因为地址不连续。       &lt;/p&gt;
&lt;h3 id=&quot;list的结构&quot;&gt;&lt;a href=&quot;#list的结构&quot; class=&quot;headerlink&quot; title=&quot;list的结构&quot;&gt;&lt;/a&gt;list的结构&lt;/h3&gt;&lt;p&gt;list不仅是一个双向链表，而且还是一个环状双向链表。所以，只需要一个指针，便可以完整表现整个链表：   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;
class list {
protected:
    typedef __list_node&amp;lt;T&amp;gt; list_node;
public:
    typedef list_node* link_type;
protected:
    link_type node;        
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如下图所示，如果让指针node指向刻意置于尾端的一个空白节点，node便能符合STL对于“前闭后开”区间的要求，成为last迭代器。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/rClntKM.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;list的构造与内存管理&quot;&gt;&lt;a href=&quot;#list的构造与内存管理&quot; class=&quot;headerlink&quot; title=&quot;list的构造与内存管理&quot;&gt;&lt;/a&gt;list的构造与内存管理&lt;/h4&gt;&lt;p&gt;list提供了多种constructors，主要包括四种：默认构造函数、使用n个值来初始化list、将另一个list的部分数据来初始化以及复制构造函数。&lt;br&gt;以下是默认构造函数，就是创建一个节点，然后前后指向自己。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;list() { empty_initialize(); }
void empty_initialize() {
    node = get_node();
    node-&amp;gt;next = node;
    node-&amp;gt;prev = node;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;list缺省使用alloc作为空间配置器，并据此另外定义了一个list_node_allocator，方便以节点大小为配置单位。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef simple_alloc&amp;lt;list_node, Alloc&amp;gt; list_node_allocator;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是，list_node_allocator(n)表示配置n个节点空间，list提供四个函数分别用来配置、释放、构造和销毁一个节点。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;link_type get_node() { return list_node_allocator::allocate(); }
void put_node(link_type p) { list_node_allocator::deallocate(p); }

link_type create_node(const T&amp;amp; x) {    //配置并构造节点
    link_type p = get_node;
    construct(&amp;amp;p-&amp;gt;data, x);
    return p;
}  
void destroy_node(link_type p){        //析构并释放节点
    destroy(&amp;amp;p-&amp;gt;data);
    put_node(p);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外，当我们以push_back()将新元素插入于list尾端时，此函数内部调用insert():&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void push_back(const T&amp;amp; x) { insert(end(), x); }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;insert()是一个重载函数，有多种形式，其中最简单的一种如下，符合以上所需： 首先配置并构造一个节点，然后进行适当的指针操作，将新节点插入进去：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iterator insert(iterator position, const T&amp;amp; x){
    link_type tmp = create_node(x);
    tmp-&amp;gt;next = position.node;
    tmp-&amp;gt;prev = position.node-&amp;gt;prev;
    (link_type(position.node-&amp;gt;prev))-&amp;gt;next = tmp;
    position.node-&amp;gt;prev = tmp;
    return tmp;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;list的析构&quot;&gt;&lt;a href=&quot;#list的析构&quot; class=&quot;headerlink&quot; title=&quot;list的析构&quot;&gt;&lt;/a&gt;list的析构&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;~list() {
    clear();
    put_node(node);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;clear()清空链表所有数据，即只剩下node节点，然后put_node将最后的node节点回收。&lt;/p&gt;
&lt;h3 id=&quot;list常用操作函数&quot;&gt;&lt;a href=&quot;#list常用操作函数&quot; class=&quot;headerlink&quot; title=&quot;list常用操作函数&quot;&gt;&lt;/a&gt;list常用操作函数&lt;/h3&gt;&lt;h4 id=&quot;在链表头尾插入节点&quot;&gt;&lt;a href=&quot;#在链表头尾插入节点&quot; class=&quot;headerlink&quot; title=&quot;在链表头尾插入节点&quot;&gt;&lt;/a&gt;在链表头尾插入节点&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;void push_front(const T&amp;amp; x) { insert(begin(), x); }
void push_back(const T&amp;amp; x) { insert(end(), x); }
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;erase&quot;&gt;&lt;a href=&quot;#erase&quot; class=&quot;headerlink&quot; title=&quot;erase&quot;&gt;&lt;/a&gt;erase&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;iterator erase(iterator position){
    link_type next_node = link_type(position.node-&amp;gt;next);
    link_type prev_node = link_type(position.node-&amp;gt;prev);
    prev_node-&amp;gt;next = next_node;
    next_node-&amp;gt;prev = prev_node;
    destroy_node(position.node);
    return iterator(next_node);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改前后节点的指针指向，然后销毁position处的节点。&lt;/p&gt;
&lt;h4 id=&quot;remove&quot;&gt;&lt;a href=&quot;#remove&quot; class=&quot;headerlink&quot; title=&quot;remove&quot;&gt;&lt;/a&gt;remove&lt;/h4&gt;&lt;p&gt;将数值为value的所有元素移除：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc&amp;gt;
void list&amp;lt;T, Alloc&amp;gt;::remove(const T&amp;amp; value){
    iterator first = begin();
    iterator last = end();
    while(first != last){
        iterator next = first;
        ++next;
        if(*first == value) erase(first);
        first = next;
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的remove是真的移除了元素，而不像vector那样。&lt;/p&gt;
&lt;h4 id=&quot;transfer&quot;&gt;&lt;a href=&quot;#transfer&quot; class=&quot;headerlink&quot; title=&quot;transfer&quot;&gt;&lt;/a&gt;transfer&lt;/h4&gt;&lt;p&gt;list内部提供一个迁移操作transfer：将某连续范围的元素迁移到某个特定位置之前。技术上很简单，节点间的指针移动。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void transfer(iterator position, iterator first, iterator last) {
      if (position != last) {
        (*(link_type((*last.node).prev))).next = position.node;    　　　　// (1)
        (*(link_type((*first.node).prev))).next = last.node;           // (2)
        (*(link_type((*position.node).prev))).next = first.node;         // (3)
        link_type tmp = link_type((*position.node).prev);               // (4)
        (*position.node).prev = (*last.node).prev;                       // (5)
        (*last.node).prev = (*first.node).prev;                        // (6)
        (*first.node).prev = tmp;                                       // (7)
      }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;示意图如下所示。&lt;br&gt;    &lt;img src=&quot;http://i.imgur.com/nq2Qm5c.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;transfer并非公开接口。list公开提供的是接合操作splice：将某连续范围的元素从一个list移动到另一个（或同一个）list的某个定点。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//将x链表的所有元素插入到当前list的position处
void splice(iterator position, list&amp;amp; x) {
    if(!x.empty()){
        transfer(position, x.begin(), x.end());
    }
}
//将i处节点插到position之前，i和position可能来自同一个链表
void splice(iterator position, list&amp;amp;, iterator i) {
    iterator j = i;
    ++j;
    if(position == i || position == j) return;
    transfer(position, i, j);
}
//将[first, last)内的所有元素结合与position所指位置之前,position不能位于[first,last）之内
void splice(iterator position, list&amp;amp; iterator first, iterator last) {
    if(first!=last) {
        transfer(position, first, last);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;merge-reverse-sort&quot;&gt;&lt;a href=&quot;#merge-reverse-sort&quot; class=&quot;headerlink&quot; title=&quot;merge(), reverse(), sort()&quot;&gt;&lt;/a&gt;merge(), reverse(), sort()&lt;/h4&gt;&lt;p&gt;基于transfer操作，list提供了三个很有用的函数：&lt;br&gt;merge()：合并两个链表，要求两个链表必须有序，合并之后的链表也是有序的。merge之后，传入的list被清空。&lt;br&gt;reverse()：将链表数据反转。&lt;br&gt;sort()：由于list的迭代器为Bidirectional iterator，而STL的sort算法必须接受RamdonAccessIterator，所以list不能使用STL的sort算法。于是，基于quick sort，list实现了自身的sort。&lt;br&gt;三个函数的具体源码这里就不再详细列出。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;list是一种很常用的数据结构，我们不仅要熟练使用它，还要弄清其中的设计与实现。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇文章总结了vector的结构和实现原理，今天来看看STL中另一个重要的容器：list。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL之vector</title>
    <link href="http://blog.dujiong.net/2016/10/25/STL-vector/"/>
    <id>http://blog.dujiong.net/2016/10/25/STL-vector/</id>
    <published>2016-10-25T10:42:24.000Z</published>
    <updated>2016-10-25T07:29:30.196Z</updated>
    
    <content type="html">&lt;p&gt;“用C++开发，尽量用容器类+迭代器来代替数组+指针，因为数组+指针容易越界，或者内存泄露，而容器+迭代器已将底层封装好，使用安全简单”。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;vector是序列式容器里使用最广泛的容器之一，该容器被用来改善数组的缺点，vector是一个动态空间，随着元素的加入，它的内部机制会自行扩充以容纳新元素，因此，vector的运用对于内存的合理利用和灵活性都有很大的帮助，再也不必因为害怕空间不足一开始就配置一个大容量数组了。&lt;br&gt;所以，vector的实现技术，关键在于其对大小的控制以及重新配置时的数据移动效率。下面就一起详细地看看vetcor的设计。     &lt;/p&gt;
&lt;h3 id=&quot;vector成员变量&quot;&gt;&lt;a href=&quot;#vector成员变量&quot; class=&quot;headerlink&quot; title=&quot;vector成员变量&quot;&gt;&lt;/a&gt;vector成员变量&lt;/h3&gt;&lt;p&gt;vector的成员变量比较简单，主要由空间配置器和三个迭代器组成，三个迭代器分别指向目前使用空间的头、尾合目前可用空间的尾。其源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;   
class vector{
public:
    typedef T value_type;
    typedef value_type* pointer;
    typedef value_type* iterator;    //vector的迭代器是普通指针
    ...
protected:
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;

    iterator start;
    iterator finish;
    iterator end_of_storage;
...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;vector提供以下函数用于获取相关成员变量。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iterator begin() { return start; }
iterator end() { return finish; }

//返回vector当前对象的个数
size_type size() const { return size_type(end()-begin()); }
//返回目前可用空间的大小
size_type capacity() const { return size_type(end_of_storage-end()); }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;vector的构造函数&quot;&gt;&lt;a href=&quot;#vector的构造函数&quot; class=&quot;headerlink&quot; title=&quot;vector的构造函数&quot;&gt;&lt;/a&gt;vector的构造函数&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;vector() : start(0), finish(0), end_of_storage(0) { }
vector(size_type n, const T&amp;amp; value) { fill_initialize(n, value); }
vector(int n, const T&amp;amp; value) { fill_initialize(n, value); }
vector(long n, const T&amp;amp; value) { fill_initialize(n, value); }
explicit vector(size_type n) { fill_initialize(n, T()); }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;除了默认构造函数，四个带参构造函数都调用&lt;code&gt;fill_initialize(size_type n, const T&amp;amp; value)&lt;/code&gt;，这个函数调用&lt;code&gt;iterator allocate_and_fill(size_type n, const T&amp;amp; x)&lt;/code&gt;配置空间，并填充数据(&lt;code&gt;uninitialized_fill_n(size_type n, const T&amp;amp; x)&lt;/code&gt;)，并设置vector的三个迭代器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void fill_initialize(size_type n, const T&amp;amp; value){
    start = allocate+_and_fill(n, value);
    finish =  start + n;
    end_of_storage = finish;
}

iterator allocate_and_fill(size_type n, const T&amp;amp; x){
    iterator result = data_allocator::allocate(n);    //分配n个sizeof(T)大小的内存
    uninitialized_fill_n(result, n, x);        //全局函数，填充数据
    return result;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;uninitialized_fill_n是STL的内存基本处理函数，用于在申请的内存上填充数据，存放在stl_uninitialized.h中。该函数的逻辑是，首先萃取出迭代器result的value type，然后判断该型别是否为POD型别，POD指Plain Old Data，也就是标量型别或传统的C struct型别。POD型别必然拥有trival constructor/default constructor/copy/assignment函数，因此，可以对POD型别采用最有效率的初值填写手法，而对non-POD型别采取最保险的做法。&lt;br&gt;相关代码如下：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;
inline ForwardIterator uninitialized_fill_n(ForwardIterator first, 
                                                Size n, const T&amp;amp; x) {
      return __uninitialized_fill_n(first, n, x, value_type(first));
}

template &amp;lt;class ForwardIterator, class Size, class T, class T1&amp;gt;
inline ForwardIterator __uninitialized_fill_n(ForwardIterator first, 
                                                Size n, const T&amp;amp; x, T1*) {
    typedef typename __type_traits&amp;lt;T1&amp;gt;::is_POD_type is_POD;
      return __uninitialized_fill_n_aux(first, n, x, is_POD());                                
}

template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;    
inline ForwardIterator __uninitialized_fill_n_aux(ForwardIterator first, Size n, 
                                                const T&amp;amp; x, __true_type) {
      return fill_n(first, n, x);            //POD类型，直接用fill_n填充即可
}

template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;
ForwardIterator __uninitialized_fill_n_aux(ForwardIterator first, Size n,
                                                   const T&amp;amp; x, __false_type) {
      ForwardIterator cur = first;
      __STL_TRY {
        for ( ; n &amp;gt; 0; --n, ++cur)
              construct(&amp;amp;*cur, x);    //调用构造函数，这里用的是placement new来构造
        return cur;
      }
      __STL_UNWIND(destroy(first, cur));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同样的，在复制构造函数中，也是先分配内存，然后根据是否为POD型别调用不同的复制函数。    &lt;/p&gt;
&lt;h3 id=&quot;vector的析构函数&quot;&gt;&lt;a href=&quot;#vector的析构函数&quot; class=&quot;headerlink&quot; title=&quot;vector的析构函数&quot;&gt;&lt;/a&gt;vector的析构函数&lt;/h3&gt;&lt;p&gt;vector的析构函数比较简单，先析构[start, finish)，然后归还内存。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~vector() {
    destory(start, finish);
    deallocate();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同构造函数类似，destroy函数根据数据类型，如果是POD，则什么都不做，如果不是POD型别，则调用析构函数一个一个的析构。然后调用deallocate函数归还内存,如果大于128bytes，则归还给系统，小于128bytes，则还给内存池，后面还可使用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void deallocate() {
    if(start) data_allocator::deallocate(start, end_of_storage-start);
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;vector常用操作函数&quot;&gt;&lt;a href=&quot;#vector常用操作函数&quot; class=&quot;headerlink&quot; title=&quot;vector常用操作函数&quot;&gt;&lt;/a&gt;vector常用操作函数&lt;/h3&gt;&lt;h4 id=&quot;push-back&quot;&gt;&lt;a href=&quot;#push-back&quot; class=&quot;headerlink&quot; title=&quot;push_back&quot;&gt;&lt;/a&gt;push_back&lt;/h4&gt;&lt;p&gt;当我们以push_back()将新元素插入于vector尾端时，该函数首先检查是否还有备用空间，如果有，就直接在备用空间上构造函数，并调整迭代器finish，使vetcor变大，如果没有，就扩充空间（重新配置、移动数据、释放原空间）。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void push_back(const T&amp;amp; x){
    if(finish != end_of_storage){
        construct(finish, x);
        ++finish;        
    }else{
        insert_aux(end(), x);            //已无备用空间
    }
}

template &amp;lt;class T, class Alloc&amp;gt;
void vector&amp;lt;T, Alloc&amp;gt;::insert_aux(iterator position, const T&amp;amp;x){
    if(finish != end_of_storage){
        construct(finish, *(finish-1));    
        ++finish;
        T x_copy = x;
        copy_backward(position, finish-2, finish-1);
        *position = x_copy;
    }else{
        const size_type old_size = size();
        const size_type len = old_size!=0 ? 2 * old_size : 1;
        iterator new_start = data_Allocator::allocate(len);
        iterator new_finish = new_start;

        try{
            new_finish = uninitialized_copy(start, position, new_start);
            construct(new_finish, x);
            ++new_finish;
            new_finish = uninitialized_copy(position, finish, new_finish);
        }catch(...){
            destroy(new_start, new_finish);
            data_allocator::deallocate(new_start, len);
            throw;
        }

        destroy(begin(), end());        //析构
        deallocate();                    //释放原来的内存
        //调整三个迭代器
        start = new_start;
        finish = new_finish;
        end_of_storage = new_start + len;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;erase&quot;&gt;&lt;a href=&quot;#erase&quot; class=&quot;headerlink&quot; title=&quot;erase&quot;&gt;&lt;/a&gt;erase&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;iterator erase(iterator first, iterator last){
    iterator i = copy(last, finish, first);
    destroy(i, finish);
    finish = finish-(last-first);
    return first;
}

iterator erase(iterator position){
    if(position+1 != end()){
        copy(position+1, finish, position);
    }
    --finish;
    destroy(finish);
    return position;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以，调用erase()函数时，size()会变化，而capacity()不会发生变化。可以看出，erase()函数会涉及到元素的移动，可能会导致原有的迭代器失效，使用时需要注意。此外，remove()和erase()的区别：remove只是将待删除元素移动到vector的尾端，不是删除，erase才是真正的删除元素。一定不要误用。&lt;/p&gt;
&lt;h4 id=&quot;其他&quot;&gt;&lt;a href=&quot;#其他&quot; class=&quot;headerlink&quot; title=&quot;其他&quot;&gt;&lt;/a&gt;其他&lt;/h4&gt;&lt;p&gt;另外，还有一些常用的函数操作，如pop_back(), clear(), insert()等，这里就不再逐一介绍，方法和原理都和上述差不多，在日常编程中多使用，自然就熟了。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;“用C++开发，尽量用容器类+迭代器来代替数组+指针，因为数组+指针容易越界，或者内存泄露，而容器+迭代器已将底层封装好，使用安全简单”。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>字符串的排列与组合</title>
    <link href="http://blog.dujiong.net/2016/10/23/permutation/"/>
    <id>http://blog.dujiong.net/2016/10/23/permutation/</id>
    <published>2016-10-23T11:09:33.000Z</published>
    <updated>2016-10-21T14:09:27.309Z</updated>
    
    <content type="html">&lt;p&gt;很久没有深入研究数据结构和算法了…&lt;br&gt;这次换个套路，先不说那些干瘪瘪的理论，首先来看一道编程题。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h3 id=&quot;题目描述&quot;&gt;&lt;a href=&quot;#题目描述&quot; class=&quot;headerlink&quot; title=&quot;题目描述&quot;&gt;&lt;/a&gt;题目描述&lt;/h3&gt;&lt;p&gt;编写一个方法，确定某字符串的所有排列组合。&lt;br&gt;给定一个string A[]和一个int n，代表字符串和其长度，请返回所有该字符串字符的排列，保证字符串长度小于等于11且字符串中字符均为大写英文字符，排列中的字符串按字典序从大到小排序。&lt;br&gt;样例： “ABC”&lt;br&gt;返回：[“CBA”,”CAB”,”BCA”,”BAC”,”ACB”,”ABC”]&lt;/p&gt;
&lt;h3 id=&quot;思考&quot;&gt;&lt;a href=&quot;#思考&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h3&gt;&lt;p&gt;…&lt;/p&gt;
&lt;h3 id=&quot;分析&quot;&gt;&lt;a href=&quot;#分析&quot; class=&quot;headerlink&quot; title=&quot;分析&quot;&gt;&lt;/a&gt;分析&lt;/h3&gt;&lt;h4 id=&quot;next-permutation&quot;&gt;&lt;a href=&quot;#next-permutation&quot; class=&quot;headerlink&quot; title=&quot;next_permutation&quot;&gt;&lt;/a&gt;next_permutation&lt;/h4&gt;&lt;p&gt;很容易看出来这是一道排列的问题。由于自己最近对STL甚是着迷，却又没有掌握透彻，故先写出了下面的错误代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vector&amp;lt;string&amp;gt; getPermutation(string A){
    std::sort(A.begin(), A.end());
    vector&amp;lt;string&amp;gt; ret;
    do{
        ret.push_back(A);
    }while(next_permutation(A.begin(), A.end()));
    std::sort(ret.begin(), ret.end(), greater&amp;lt;string&amp;gt;());
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当我满怀欣喜地提交代码运行时，却被告知通过率只有13.3%，给出的错误分析表明，当字符串中含有两个及以上的相同字符时，所得结果错误，即原题的意思是字符串中的每一个字符都是独立的，即使它们相同。所以，得出的结果应该有n!个字符串。而算法next_permutation不能处理这样的情况。比如输入”AAB”，使用next_permutation得到的结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/40N1AVT.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;递归&quot;&gt;&lt;a href=&quot;#递归&quot; class=&quot;headerlink&quot; title=&quot;递归&quot;&gt;&lt;/a&gt;递归&lt;/h4&gt;&lt;p&gt;递归方法的思想很容易理解，即从串中依次选出每一个元素，作为排列的第一个元素，然后对剩余的元素递归的进行全排列。&lt;br&gt;以对字符串”abc”进行全排列为例：&lt;br&gt;（1）固定a，求后面bc的排列：abc、acb，求好后，b放在第一位置，得到bac；&lt;br&gt;（2）固定b，求后面ac的排列：bac、bca，求好后，c放在第一位置，得到cba；&lt;br&gt;（3）固定c，求后面ba的排列，cba、cab。&lt;br&gt;其过程如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/iqS7F6D.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;分析了算法思想后，就很容易写出代码了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void getPermutation(vector&amp;lt;string&amp;gt;&amp;amp; ret, string A, int start){
    int end = A.size()-1;
    if(start == end){
        ret.push_back(A);
        return;
    }else{
        for(int j=start; j&amp;lt;=end; ++j){
            std::swap(A[start], A[j]);        //轮流固定在第一个位置
            getPermutation(ret, A, start+1);
            std::swap(A[start], A[j]);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行上面的例子，结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/aVKXDCF.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;所以，其实STL算法next_permutation是去掉了重复的全排列。&lt;/p&gt;
&lt;h3 id=&quot;组合&quot;&gt;&lt;a href=&quot;#组合&quot; class=&quot;headerlink&quot; title=&quot;组合&quot;&gt;&lt;/a&gt;组合&lt;/h3&gt;&lt;p&gt;如果不是求字符的所有排列，而是求其所有组合呢？比如字符a、b、c，它们的组合有a,b,c,ab,ac,bc,abc。    &lt;/p&gt;
&lt;h4 id=&quot;基于位图的算法&quot;&gt;&lt;a href=&quot;#基于位图的算法&quot; class=&quot;headerlink&quot; title=&quot;基于位图的算法&quot;&gt;&lt;/a&gt;基于位图的算法&lt;/h4&gt;&lt;p&gt;简单的数学知识：假设原有n个字符，则最终组合结果是2^n-1个。采用位操作：假设有元素a、b、c三个，规定二进制1表示取该元素，0表示不取。故取a的二进制表示为001，ab为001，依次类推，000没有意义。&lt;br&gt;所以，这些结果与位图的对应关系：&lt;br&gt;001, 010, 011, 100, 101, 110, 111&lt;br&gt;a, b, ab, c, ac, bc, abc&lt;br&gt;因此，可以循环1~2^n-1，然后输出对应代表的组合即可。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Combination(string A){
    int n=1&amp;lt;&amp;lt;A.size();
    for(int i=1;i&amp;lt;n;++i){
        for(int j=0;j&amp;lt;A.size();++j){
            if((1&amp;gt;&amp;gt;j)&amp;amp;i)        //对应位上为1，则输出对应的字符
                cout &amp;lt;&amp;lt; A[j];
        }                        //每一个组合
        cout &amp;lt;&amp;lt; endl;
    }
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码运行结果如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/hJmuKDD.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;很久没有深入研究数据结构和算法了…&lt;br&gt;这次换个套路，先不说那些干瘪瘪的理论，首先来看一道编程题。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL仿函数</title>
    <link href="http://blog.dujiong.net/2016/10/21/STL-functor/"/>
    <id>http://blog.dujiong.net/2016/10/21/STL-functor/</id>
    <published>2016-10-21T12:10:17.000Z</published>
    <updated>2016-10-18T12:10:54.242Z</updated>
    
    <content type="html">&lt;p&gt;仿函数，又称为函数对象，即一种具有函数特质的对象，指的是那些可以被传入其他函数或是从其他函数返回的函数。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;函数指针与函数对象&quot;&gt;&lt;a href=&quot;#函数指针与函数对象&quot; class=&quot;headerlink&quot; title=&quot;函数指针与函数对象&quot;&gt;&lt;/a&gt;函数指针与函数对象&lt;/h3&gt;&lt;p&gt;我们知道，STL所提供的各种算法，往往有两个版本，其中一个版本表现出最常用（或最直观）的某种运算，第二个版本则表现出最泛化的演算流程，允许用户“以template参数来指定所要采取的策略”。以accumulate()为例，其第一版本是将指定范围内的所有元素相加，第二版本则允许你指定某种“操作”，取代第一版本的“相加”行为。所以，要将某种“操作”当做算法的参数，首先想到的办法就是先将该“操作”设计为一个函数，再将函数指针当做算法的一个参数；或者将该“操作”设计为一个仿函数（语言层面而言是个class），再以该仿函数产生一个对象，并以此对象作为算法的一个参数。      下面通过一个实际的例子说明这两种方法。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;

using namespace std;

int add_func(int a, int b){
    return a+b;
}

class AddClass{
public:
       int operator()(int a, int b) { return a+b; }
};

typedef int (*AddFunction)(int a, int b);

int main()
{
    {
        AddClass addClass;
        int sum = addClass(1,2);
        cout &amp;lt;&amp;lt; &amp;quot;addClass: &amp;quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    }

    {
        AddFunction addFunction = &amp;amp;add_func;
        int sum = addFunction(1,2);
        cout &amp;lt;&amp;lt; &amp;quot;addFunction: &amp;quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，函数对象实际上就是一个重载了operator()操作符的类，这就是函数对象与普通类的差别。另外，函数对象和函数指针在定义的方式不一样，但是调用的方式是一样的。那既然已经有了函数指针这个东西，为什么还要发明函数对象呢？其实很简单，函数对象可以将附加数据保存在成员变量中，从而实现携带附加数据，而函数指针就不行了。考虑下面一个应用场景，我们需要使用std::for_ecah将一个std::vector中的每一个值加上某个值然后输出，如果使用普通函数，则其声明应该为&lt;code&gt;void add_num(int value, int num);&lt;/code&gt;，其中value为容器中的元素，num为要加上的数。但是由于std::for_each函数的第三个参数要求传入接受一个参数的函数或函数对象，所以将add_num函数传入std::for_each是错误的，然而函数对象可以携带附加数据解决这个问题。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;algorithm&amp;gt;

using namespace std;

class Add
{
    public:
        void operator()(int value){
            cout &amp;lt;&amp;lt; value + num_ &amp;lt;&amp;lt; endl;
        }
    private:
        int num_;
}；

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    Add add(2);
    std::for_each(ivec.begin(), ivec.end(), add);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;仿函数的型别&quot;&gt;&lt;a href=&quot;#仿函数的型别&quot; class=&quot;headerlink&quot; title=&quot;仿函数的型别&quot;&gt;&lt;/a&gt;仿函数的型别&lt;/h3&gt;&lt;p&gt;仿函数的相应型别主要用来表现函数参数型别和传回值型别。为了方便起见，&lt;stl\_function.h&gt;定义了两个classes，分别代表一元仿函数和二元仿函数（STL不支持三元仿函数），其中没有任何data members或member functions，唯有一些型别定义，任何仿函数，只要依个人需求选择继承其中一个class，便自动拥有了那些相应型别，也就自动拥有了配接能力。&lt;br&gt;unary_function和binary_function分别用来呈现一元和二元函数的参数型别和返回值型别。用户可以继承它们，从而定义自己的仿函数。   &lt;/stl\_function.h&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct negate : public unary_function&amp;lt;T,T&amp;gt; {
    T operator() (const T&amp;amp; x) const { return -x; }
}

template &amp;lt;class T&amp;gt;
struct plus : public binary_function&amp;lt;T,T,T&amp;gt; {
    T operator() (const T&amp;amp; x, const T&amp;amp; y) const { return x + y; }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;STL仿函数的分类，若以操作数的个数划分，可分为一元和二元仿函数，若以功能划分，可分为算术运算、关系运算和逻辑运算三大类。     &lt;/p&gt;
&lt;h3 id=&quot;lambda&quot;&gt;&lt;a href=&quot;#lambda&quot; class=&quot;headerlink&quot; title=&quot;lambda&quot;&gt;&lt;/a&gt;lambda&lt;/h3&gt;&lt;p&gt;lambda是C++11中引入的新特性，使程序员能定义匿名对象，而不必定义独立的函数和函数对象，这样使代码更容易编写和理解，又能防止别人的访问(调用)。简而言之，一个lambda函数是一个可以内联在代码中的函数，且通常也会传递给另外的函数（类似于仿函数）。&lt;br&gt;下面用lambda来重写上面的for_each例子。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;algorithm&amp;gt;

using namespace std;    

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    std::for_each(ivec.begin(), ivec.end(),
                  [](int x) { cout &amp;lt;&amp;lt; x + x &amp;lt;&amp;lt; endl; });
    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;lambda表达式&lt;code&gt;[] (int x) { cout &amp;lt;&amp;lt; x + 2 &amp;lt;&amp;lt; endl; }&lt;/code&gt;会让编译器产生一个类似前面例子中Add的未命名函数对象类。相比于函数对象类，lambda表达式具有如下优点：（1）简洁，不需要自己去实现函数对象类；（2）不会为临时的使用而引入新的名字，所以不会导致名字污染；（3）函数对象类名不如它的实际代码表达能力强，把代码放在更靠近它的地方将提高代码的清晰度。    &lt;/p&gt;
&lt;h3 id=&quot;std-function&quot;&gt;&lt;a href=&quot;#std-function&quot; class=&quot;headerlink&quot; title=&quot;std::function&quot;&gt;&lt;/a&gt;std::function&lt;/h3&gt;&lt;p&gt;lambda产生的闭包类型可以转换成std::function。std::function对象是对C++中现有的可调用实体的一种类型安全的包裹。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;algorithm?
#include &amp;lt;vector&amp;gt;

using namespace std;

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    std::function&amp;lt;void(int)&amp;gt; func = [](int val) { std::cout &amp;lt;&amp;lt; val+2 &amp;lt;&amp;lt; endl; }
    std::for_each(ivec.begin(), ivec.end(), func);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;std::function是个类模板，可以对函数（普通函数、成员函数）、lambda表达式、std::bind的绑定表达式、函数对象等进行封装。std::function的实例可以对这些封装的目标进行存储、复制和调用等操作。  &lt;/p&gt;
&lt;h3 id=&quot;std-bind&quot;&gt;&lt;a href=&quot;#std-bind&quot; class=&quot;headerlink&quot; title=&quot;std::bind&quot;&gt;&lt;/a&gt;std::bind&lt;/h3&gt;&lt;p&gt;函数模板std::bind能对普通函数、成员函数、静态成员函数、公共成员变量、公共静态成员变量等进行包装，调用std::bind的包装相当与将函数名和参数绑定在函数内部。std::bind函数模板返回的函数对象的类型是不确定的，但是可以存储在std::function内。std::bind绑定的参数是通过传值的方式传递的，如果需要通过引用传递则参数先需要用std::ref、std::cref进行引用，然后在传递给std::bind 将std::bind函数模板的返回值保存在std::function后，调用时需要传递的参数个数由std::bind中的占位符（std::placeholders::1、std::placeholders::2、std::placeholders::_3等）个数决定，即有几个占位符调用时就需要几个参数。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;

int testFunc(int a, char c, float f){
    cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; f &amp;lt;&amp;lt; endl;

    return a;
}

int main()
{
    auto bindFunc1 = std::bind(testFunc, std::placeholders::_1, &amp;apos;A&amp;apos;, 100.1);
    bindFunc1(10);

    auto bindFunc2 = std::bind(testFunc, std::placeholders::_1, std::placeholders::_1, 100.1);
    bindFunc2(&amp;apos;B&amp;apos;, 10);

    auto bindFunc3 = bind(TestFunc, std::placeholders::_2, std::placeholders::_3, std::placeholders::_1);
    bindFunc3(100.1, 30, &amp;apos;C&amp;apos;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;本文从STL functor开始，研究了那些可以被传入其他函数或是从其他函数返回的函数，包括函数指针、函数对象、lambda、function和bind。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;仿函数，又称为函数对象，即一种具有函数特质的对象，指的是那些可以被传入其他函数或是从其他函数返回的函数。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Data Center Bridging</title>
    <link href="http://blog.dujiong.net/2016/10/18/DataCenterBridging/"/>
    <id>http://blog.dujiong.net/2016/10/18/DataCenterBridging/</id>
    <published>2016-10-18T04:34:17.000Z</published>
    <updated>2016-10-18T07:14:35.762Z</updated>
    
    <content type="html">&lt;p&gt;最近，在参与一个数据中心-云存储的项目，用到了DCB（Data Center Bridging，数据中心桥接）协议。现将学到的相关知识总结出来，以供同行交流，同时加深自己的理解。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;在企业中，传统数据中心通常会使用不同的技术来实现不同数据流量的传输，例如LAN（Local Area Network，以太网）技术用来实现IP流量的传输，SAN（Storage Area Network，存储网络）技术用来实现光纤通道存储流量的传输，除此之外，还会用InifiniBand技术来为高性能集群计算提供支持。此时，虽然通过不同的技术解决了数据中心业务需求，但是以上技术的结合使用也导致了企业将面临如下问题，并且随着数据中心规模的逐步增大，问题的严重性也日益增加；首先存在服务器兼容问题，不同的服务器需要多个专用适配器，同时也需要不同的布线系统；其次是设备统一管理问题，由于多套网络无法统一管理，因此需要不同的维护人员，这将导致设备的部署、配置、管理都会很困难。最后是设备成本问题，以上技术的结合使用导致机房需要支持更多的设备，随之而来的则是服务器的电费预算将上升，并且对于服务器的制冷要求也会增加。&lt;br&gt;以上只是硬件问题，不同的技术在满足QoS（Quality of Service，服务质量）的需求上也存在较大差异。例如，LAN流量允许丢包，只需要设备提供尽力而为的服务，丢包和乱序问题则由两端的主机来处理，不需要网络节点做过多的干预；SAN流量对丢包敏感，且要求报文在传输过程中是有序的；IPC（Inter-Process Communication，进程间通信）则对低延时要求很高。&lt;br&gt;多网融合是解决上述问题的方向，即将采用多种技术的网络整合成统一技术的网络。而随着以太网IP技术的高速发展，使用以太网来统一承载上述各种流量在数据中心得到了广泛应用；此外，为了进一步满足各种流量（尤其是SAN流量）的QoS需求，在传统以太网的基础上产生了DCB协议。&lt;br&gt;DCB协议是一组由IEEE 802.1工作组定义的以太网增强协议，广泛应用于现有的数据中心网络中。DCB协议充分利用了传统以太网的优势，通过增添多种关键扩展功能来为数据中心网络提供无损数据传输、低延时和物理链路带宽共享的功能。DCB协议的主要特性有：PFC（Priority-based Flow Control，基于优先级的流量控制）、ETS（Enhanced Transmission Selection，增强流量选择）、DCBX（Data Center Bridging Capabilities Exchange Protocol，数据中心桥接交换协议）和ECN（Explicit Congestion Notification，显示拥塞通告）。 &lt;/p&gt;
&lt;h3 id=&quot;PFC&quot;&gt;&lt;a href=&quot;#PFC&quot; class=&quot;headerlink&quot; title=&quot;PFC&quot;&gt;&lt;/a&gt;PFC&lt;/h3&gt;&lt;p&gt;PFC是一种对IEEE802.3定义的流控机制的增强技术，主要用于消除链路阻塞而导致的丢包。PFC属于DCB的一部分，适用于DCB网络中点到点的全双工链路。在传统的以太网流控机制中，当下游设备发现接收能力小于上游设备的发送能力时，会主动发一个Pause帧给上游设备，要求暂停流量的发送，上游设备等待一定时间后再继续发送数据。此时虽然能够解决流控问题，但是该机制是将链路上所有的流量都暂停，即流量暂停是针对整个接口，这与数据中心的链路共享机制发生了冲突。因为链路共享机制有两个要求：（1）一种类型的突发流量不能影响其他类型流量的转发；（2）一种类型的流量大量积压在队列中不能抢占其他类型的流量的缓存资源。所以，为了解决现有以太网流控机制和链路共享之间的冲突，产生了PFC机制。&lt;br&gt;PFC是一种基于优先级的流量控制机制。PFC可以在一条以太网物理链路上创建8个独立的虚拟通道，并为每条虚拟通道指定一个优先等级，允许单独暂停和重启其中任意一条虚拟通道，同时不影响其他通道的流量。其工作机制如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/1HVTK7q.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Device A发送接口分成了8个优先级队列，Device B接收接口分成了8个接收缓存，两者一一对应。当Device B的端口上某个接收缓存即将产生拥塞时，向Device A发送一个反压信号“STOP”，Device A收到该信号后停止发送对应优先级队列的报文。“反压信号”实际上就是PFC帧，其具体报文格式如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/PKAQ8Df.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;报文中各字段的定义如下表所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/yddhfp4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;由此可见，PFC机制下流量暂停只针对某一个或几个优先级队列，不针对整个端口进行中断。这样将会使得每个队列都能单独进行暂停或重启，而不影响其他队列上的流量，从而实现了多种流量对链路的共享。而对于非PFC控制的优先级队列，系统则不进行反压处理，在发生拥塞时直接丢弃报文。&lt;/p&gt;
&lt;h3 id=&quot;ETS&quot;&gt;&lt;a href=&quot;#ETS&quot; class=&quot;headerlink&quot; title=&quot;ETS&quot;&gt;&lt;/a&gt;ETS&lt;/h3&gt;&lt;p&gt;ETS是DCB的另一个重要组成部分，它主要是通过灵活的层次化调度来实现对QoS的高需求。ETS提供两级调度，分别为基于PG（Priority Group，优先级组）的调度和基于优先级的调度；ETS的调度流程如下图所示，即：首先，接口对PG进行第一级调度，然后针对PG内的不同优先级队列进行第二级调度。通过采用ETS技术，可以为网络中不同类型的流量提供不同的服务和带宽。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2KZIJgX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在ETS中定义了3个优先级组PG0、PG1和PG15，分别代表LAN流量、SAN流量和IPC流量。ETS协议根据不同流量的QoS需求规定了不同的调度方式。IEEE 802.1Qaz中定义了三种ETS调度算法：WRR（Weighted Round Robin，基于权重的轮询）算法、SP（Strict Priority，严格优先级）算法和CBS（Credit-Based Shaper，令牌整形调度）算法；ETS协议对三个优先级组PG0、PG1、PG15常见的调度方式是SP算法和WRR算法，其中PG15采用的是SP算法，主要是由于PG15承载的是IPC流量，对延时要求很高；PG0和PG1则采用了WRR算法，其主要承载的是LAN流量和SAN流量。同时，用户可以根据自身的实际需求对优先级组PG0、PG1、PG15等划分不同的带宽。&lt;br&gt;下面简要介绍SP算法和WRR算法。&lt;/p&gt;
&lt;h4 id=&quot;SP算法&quot;&gt;&lt;a href=&quot;#SP算法&quot; class=&quot;headerlink&quot; title=&quot;SP算法&quot;&gt;&lt;/a&gt;SP算法&lt;/h4&gt;&lt;p&gt;如图所示，SP算法要求严格按照优先级来发送队列中的报文，优先发送高优先级队列中的报文，当高优先级队列为空时，再发送低优先级队列中的报文，在图1-4中的8个队列中，队列7优先级最高，队列0优先级最低，所以先发送队列7中的报文，最后发送队列0的报文。根据以上原理，SP算法常用于通过将关键业务报文放入高优先级队列，从而保证这些业务的正常运行的场景。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/24sjzR3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;WRR算法&quot;&gt;&lt;a href=&quot;#WRR算法&quot; class=&quot;headerlink&quot; title=&quot;WRR算法&quot;&gt;&lt;/a&gt;WRR算法&lt;/h4&gt;&lt;p&gt;WRR算法是一种常用的轮询调度算法，该算法先给每个队列分配一定的权重，然后在队列之间进行轮流调度。每个队列的权重决定了调度到该队列时可以发送的数据量。通过轮询，WRR算法保证每个队列都能得到调度，避免出现低优先级队列饿死的情况。WRR算法的工作过程如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/TCA7P5g.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;DCBX&quot;&gt;&lt;a href=&quot;#DCBX&quot; class=&quot;headerlink&quot; title=&quot;DCBX&quot;&gt;&lt;/a&gt;DCBX&lt;/h3&gt;&lt;p&gt;在数据中心网络融合场景下，为实现上述以太网增强协议，链路两端的PFC和ETS的参数配置需要保持一致，因此对于PFC和ETS的参数需要进行配置。但是如果这些配置单纯依靠管理员手动设置，不仅工作量庞大而且极易出错。因此提出了DCBX协议，DCBX协议是一种链路发现协议，主要是为链路两端的设备发现并交换DCB配置信息提供了通信方式。&lt;br&gt;DCBX协议作为信息的载体，运行在点对点的链路上，用于通告本机的PFC、ETS等参数的配置信息，同时，它也期望接收对端发送的配置的信息用以引导本机配置。DCBX将需要交互的DCB配置信息封装到LLDP（Link Layer Discovery Protocol，链路层发现协议）中的TLV中，借由LLDP来进行链路两端设备的DCB配置交换。下面以DCB的PFC参数为例，简要说明LLDP承载DCBX的实现过程。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/yUXsCiR.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上图所示，端口Port A和Port B已经开启了LLDP功能和DCBX功能。主要信息交互流程如下：首先，Port A的LLDP模块根据自己的报文发送周期定期地向Port B发送携带DCBX TLV的LLDP报文；然后，Port B收到LLDP报文后解析出DCBX TLV，将Port A的PFC参数通知给DCBX模块；最后，DCBX模块将Port A参数和本地的PFC参数进行比较，协商一致后生成配置文件，保证两端配置一致。DCBX的TLV结构定义如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/j8iw750.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，Type字段固定为127，OUI字段固定为0x0080c2，Subtype字段为DCBX TLV承载的消息类型，包括ETS Configuration TLV、ETS Recommendation TLV和PFC Configuration TLV，其具体内容如下表所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/3sEu8Cp.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;h3 id=&quot;ECN&quot;&gt;&lt;a href=&quot;#ECN&quot; class=&quot;headerlink&quot; title=&quot;ECN&quot;&gt;&lt;/a&gt;ECN&lt;/h3&gt;&lt;p&gt;传统的TCP/IP网络中，网络拥塞控制算法都是用包丢失作为指示信息，通知端系统网络中发生了拥塞，进而通过降低发送方的发送速率来减轻拥塞程度。&lt;br&gt;而ECN则采用了一种完全不同的方法，其核心思想是通过路由器标记IP头部的特定比特位来反映网络拥塞状况。当标记报文到达目的地址后，接收方使用下一个ACK通知发送方有拥塞发生，最后，发送方做出响应，缩小拥塞窗口，降低发送速率。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/LFQRQa7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;根据上图IP首部信息可知，ECN拥塞控制主要用到了IP首部TOS域中的最后两位，称作为ECN域，其字段定义如下表所示。当一个支持ECN的主机发送数据包时首先将ECN域设置为01或10，如果在该数据包的传输路径上的路由器支持ECN并且监测到拥塞信息，它将会把ECN域设置为11，表示网络出现拥塞。而如果ECN域已经被标记为11，下游路由器不会修改其值。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/90Qe1wt.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此外，ECN仍然需要传输层协议的支持。TCP使用6位保留位的后两位来支持ECN。其字段定义如下图所示。其中，ECE（ECN-Echo）标志位有两个作用：（1）在TCP三次握手中表明TCP端是否支持ECN；（2）在传输数据时表明接收到的TCP段的IP首部的ECN被设置为11，即出现了拥塞。CWR标志位为发送端缩小拥塞窗口标志，用来通知接收端它已经收到设置了ECE标志的ACK，并减小了发送窗口。当接收端收到CWR标志的包时，停止在接下来的ACK中设置ECE标志。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2SXhQy4.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;DCB协议是一组由IEEE 802.1工作组定义的以太网增强协议，广泛应用于现有的数据中心网络中。DCB协议充分利用了传统以太网的优势，通过增添多种关键扩展功能来为数据中心网络提供无损数据传输、低延时和物理链路带宽共享的功能。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在参与一个数据中心-云存储的项目，用到了DCB（Data Center Bridging，数据中心桥接）协议。现将学到的相关知识总结出来，以供同行交流，同时加深自己的理解。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL迭代器</title>
    <link href="http://blog.dujiong.net/2016/10/14/STL-iterator/"/>
    <id>http://blog.dujiong.net/2016/10/14/STL-iterator/</id>
    <published>2016-10-14T09:49:12.000Z</published>
    <updated>2016-10-17T13:31:20.941Z</updated>
    
    <content type="html">&lt;p&gt;我们知道，STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一帖胶着剂将他们撮合在一起。容器和算法的泛型化，可分别通过C++的class templates和function templates达成目标，而如何设计出两者之间的良好胶着剂，是一个值得深究的问题。本文所要学习的迭代器（iterator）就是在STL中扮演粘胶的角色。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Traits编程手法&quot;&gt;&lt;a href=&quot;#Traits编程手法&quot; class=&quot;headerlink&quot; title=&quot;Traits编程手法&quot;&gt;&lt;/a&gt;Traits编程手法&lt;/h3&gt;&lt;p&gt;在迭代器的实现中，经常需要访问迭代器所指对象的类型，称之为该迭代器的value type。利用内嵌类型声明typedef可以轻松实现隐藏所指对象类型。如下迭代器的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct Iterator{
    typedef T value_type;
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;泛型算法就可以通过typename Iterator::value_type来获得value type。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
typename Iterator::value_type
getValue(Iterator iter){
    return *iter;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里，关键字typename必不可少，因为T是一个一个template参数，在它被实例化之前，编译器不知道T是一个类型还是一个其他的对象，typename用于告诉编译器这是一个类型，这样才能通过编译。&lt;br&gt;如此，可以解决“函数的template参数推导机制推导的只是参数，无法推导函数的返回值型别“的问题，但是有个问题，并不是所有迭代器都是class type，比如原生指针。如果不是class type，就无法为它定义内嵌型别。但STL（以及整个泛型思维）都必须接受原生指针作为一种迭代器，所以上面这样还不够。&lt;br&gt;所以，这里需要多一层的封装，即萃取编译技术。&lt;/p&gt;
&lt;h4 id=&quot;template-partial-specialization&quot;&gt;&lt;a href=&quot;#template-partial-specialization&quot; class=&quot;headerlink&quot; title=&quot;template partial specialization&quot;&gt;&lt;/a&gt;template partial specialization&lt;/h4&gt;&lt;p&gt;template partial specialization的大致意思是：如果class template拥有一个以上的template参数，我们可以针对其中某个（或数个，但非全部）template参数进行特化工作。换句话说，我们可以在泛化设计中提供一个特化版本。所以，所谓的partial specialization就是“针对（任何）template参数更进一步的条件限制所设计出来的一个特化版本”。&lt;br&gt;比如，面对以下的class template:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class C { ... };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后，有一个如下形式的partial specialization:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class C&amp;lt;T*&amp;gt; { ... };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个特化版本仅适用于“T为原生指针”的情况，即“T为原生指针”便是“T为任何型别”的一个更进一步的条件限制。&lt;br&gt;如此，我们便可以使用partial specialization解决“内嵌型别”未能解决的问题。即对“迭代器之template参数为指针”者，设计特定版的迭代器。&lt;br&gt;下面这个class template专门用来“萃取”迭代器的特性，而value_type正是迭代器的特性之一：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
struct iterator_traits {
    typedef typename Iterator::value_type value_type;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里所谓的traits，其意义是，如果Iterator定义有自己的value_type，那么通过这个traits的作用，萃取出来的value_type就是Iterator::value_type。&lt;br&gt;因此，先前的func可以改写成这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
typename iterator_traits&amp;lt;Iterator&amp;gt;::value_type
getValue(Iterator iter){
    return *iter;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如此，多了一层间接性，traits便可以拥有特化版本。令iterator_traits拥有一个partial specialization：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct iterator_traits&amp;lt;T*&amp;gt;{      //模板是一个原生指针
    typedef T value_type;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是，原生指针虽然不是一种class type，亦可通过traits取其value type。&lt;/p&gt;
&lt;h3 id=&quot;STL的五种迭代器&quot;&gt;&lt;a href=&quot;#STL的五种迭代器&quot; class=&quot;headerlink&quot; title=&quot;STL的五种迭代器&quot;&gt;&lt;/a&gt;STL的五种迭代器&lt;/h3&gt;&lt;p&gt;根据移动特性与施行操作，迭代器被分为五类：&lt;br&gt;（1）Input Iterator:这种迭代器所指的对象，不允许外界改变，客户只可读取它们所指的东西，且只能向前移动，一次一步。C++标准库中的istream_iterator是这一类的代表。&lt;br&gt;（2）Output Iterator：与Input Iterator类似，但一切只为输出，C++标准库中的ostream_iterator是这类的代表。&lt;br&gt;（3）Forward Iterator：这种迭代器可以做前述两种分类所做的每一件事，而且可以读或写所指物一次以上。&lt;br&gt;（4）Bidirectional Iterator：比上一个分类威力更大，它除了可以向前移动，还可以向后移动。STL的list迭代器就属于这一分类，set、multiset、map和multimap的迭代器也都是这一分类。&lt;br&gt;（5）最具威力的当属Random Access Iterator。这种迭代器比上一个分类威力更大的地方在于它可以执行“迭代器算术”，也就是可以在常量时间内向前或向后跳跃任意距离，这样的算术很类似指针算术，因为random access迭代器正是以内置（原始）指针为榜样，而内置指针也可被当做random access迭代器使用。 vector, deque和string提供的迭代器都是这一分类。&lt;br&gt;这些迭代器的分类与从属关系，如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/WSUJIqE.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;设计算法时，如果可能，我们尽量针对上图中的某种迭代器提供一个明确定义，并针对更强化的某种迭代器提供另一种定义，这样才能在不同情况下提供最大效率。假设有个算法可接受Forward Iterator，而传入Random Access Iterator，它当然也会接受，因为一个Random Access Iterator必然是一个Forward Iterator，但是并不是最佳。&lt;br&gt;以advance()为例说明使用函数重载机制来选择最佳的迭代器版本。advance()函数有两个参数，迭代器p和数值n，函数内部将p累进n次。下面有分别针对Input Iterator、Bidirectional Iterator和Random Access Iterator的三种函数定义版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_II(InputIterator&amp;amp; i, Distance n){
    while(n--) ++i;        
}

template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_BI(InputIterator&amp;amp; i, Distance n){
    if(n&amp;gt;=0)
        while(n--) ++i;
    else
        while(n++) ++i;
}    

template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_RAI(InputIterator&amp;amp; i, Distance n){
    i+=n;        
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在，当程序调用advance()时，应该选择跟自己最匹配的版本，所以，我们需要将三者合一。首先想到的是运用条件判断。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance(InputIterator&amp;amp; i, Distance n){
    if(is_random_access_iterator(i)){
        advance_RAI(i, n);
    }else if(is_bidirectional_iterator(i)){
        advance_BI(i, n);
    }else{
        advance_II(i, n);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是像这样在执行时期才决定使用哪一个版本，会影响程序效率。最好能在编译期就选择正确的版本，所以，采用函数重载机制。&lt;br&gt;前面三个advance_xx()都有两个函数参数，型别都未定（都是template参数），为了令其同名，形成重载函数，我们必须加上一个型别已确定的函数参数，使函数重载机制得以有效运作起来。&lt;br&gt;STL设计思想为：如果traits有能力萃取出迭代器的种类，我们便可利用这个“迭代器类型”相应型别作为advanced()的三个参数，这个相应型别一定必须是一个class type，因为编译器需要依赖它（一个型别）来进行重载决议。&lt;br&gt;定义五个class，代表五种迭代器类型：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct input_iterator_tag { };
struct output_iterator_tag { };
struct forward_iterator_tag : public input_iterator_tag｛｝；
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在重新设计__advance，并加上第三参数，使它们形成重载:   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
inline void __advance(InputIterator&amp;amp; i, Distance n,
                      input_iterator_tag){
    while(n--) ++i;
}

template &amp;lt;class BidirectionalIterator, class Distance n&amp;gt;
inline void __advance(BidirectionalIterator&amp;amp; i, Distance n,
                      bidirectional_iterator_tag){
    if(n&amp;gt;=0)
        while(n--) ++i;
    else
        while(n++) --i;
}
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个__advance()的最后一个参数都只声明型别，并未指定参数名称，因为它纯粹只是用来激活重载机制，函数之中根本不使用该参数。&lt;br&gt;最后，还需要一个对外开放的上层接口，调用上述各个重载的__advance()，这一上层接口只需要两个参数，当它准备将工作转给上述的__advance()时，才自行加上第三参数：迭代器类型。因此，这个上层函数必须有能力从它所能获得的迭代器中推导出其类型（traits机制）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
inline void advance(InputIterator&amp;amp; i, Distance n){
    __advance(i, n, 
                iterator_traits&amp;lt;InputIterator&amp;gt;::iterator_category());
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;iterator_traits&lt;inputiterator&gt;::iterator&lt;em&gt;category())将产生一个暂时对象，其型别应该隶属于前述四个迭代器类型，然后根据这个型别，编译器才决定调用哪一个\&lt;/em&gt;_advance()重载函数。&lt;br&gt;因此，为了满足上述行为，traits必须再增加一个相应的型别：&lt;/inputiterator&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
struct iterator_traits{
    ...
    typedef typename Iterator::iterator_category iterator_category;
};

//针对原生指针
template &amp;lt;class T&amp;gt;
struct iterator_traits&amp;lt;T*&amp;gt;{
    ...
    typedef typename random_access_iterator_tag iterator_category;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后一个问题，STL算法的命名规则：以算法所能接收之最低阶迭代器类型，来为其迭代器型别参数命名。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;我们知道，STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一帖胶着剂将他们撮合在一起。容器和算法的泛型化，可分别通过C++的class templates和function templates达成目标，而如何设计出两者之间的良好胶着剂，是一个值得深究的问题。本文所要学习的迭代器（iterator）就是在STL中扮演粘胶的角色。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL空间配置器</title>
    <link href="http://blog.dujiong.net/2016/10/09/STL-allocator/"/>
    <id>http://blog.dujiong.net/2016/10/09/STL-allocator/</id>
    <published>2016-10-09T05:54:15.000Z</published>
    <updated>2016-10-13T11:18:08.167Z</updated>
    
    <content type="html">&lt;p&gt;最近准备结合《STL源码剖析》把学习的STL知识整理一遍，加深自己的理解的同时，也方便以后需要的时候查看。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;首先总结的是STL中的内存分配—空间配置器，从STL的运用角度而言，空间配置器是最不需要介绍的东西，因为用户使用过程中不会直接与其打交道，但是，从STL的实现角度看，空间配置器又是最重要的知识点之一，因为整个STL的操作对象都存放在容器之内，而容器一定需要配置空间以放置数据。&lt;br&gt;C++ STL配置器分为两层配置器，当请求的内存大于128bytes时，视为“足够大”，用第一层配置器分配内存，当请求的内存小于128bytes时，视为“过小”，调用第二级配置器，第二级配置器采用复杂的内存池整理方式，而不再求助于第一级配置器。&lt;/p&gt;
&lt;h3 id=&quot;第一级配置器&quot;&gt;&lt;a href=&quot;#第一级配置器&quot; class=&quot;headerlink&quot; title=&quot;第一级配置器&quot;&gt;&lt;/a&gt;第一级配置器&lt;/h3&gt;&lt;p&gt;首先来看下主要的源代码：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;int inst&amp;gt;
class __malloc_alloc_template{
private:
    static void *oom_malloc(size_t);    //malloc调用内存不足
    static void *oom_realloc(void*, size_t);    //realloc调用内存不足
    static void (*__malloc_alloc_oom_handler)();    //错误处理函数
public:
    static void* allocate(size_t){
        void *result = malloc(n);        //第一级配置器直接调用malloc()
        if(0 == result) result = oom_malloc(n);
        return result;
    }
    static void* deallocate(void *p, size_t){
        free(p);            
    }
    static void *reallocate(void *p, size_t/* old_sz */, size_t new_sz){
        void *result = realloc(p, new_sz);    //第一级配置器直接调用realloc()
        if(0 == result) result = oom_realloc(p, new_sz);
        return result;    
    }
    static void (*set_malloc_handler(void (*f)()))(){    //设置错误处理函数
        void (* old)() = __malloc_alloc_oom_handler;
        __malloc_alloc_oom_handler = f;
        return(old);    
    }
};

template &amp;lt;int inst&amp;gt;
void* __malloc_alloc_template&amp;lt;inst&amp;gt;::oom_alloc(size_t n){
    void (* my_alloc_handler)();     //声明函数指针
    void *result;                     //返回的内存指针
    for(;;){                          //循环，直到成功
        my_alloc_handler = __malloc_alloc_oom_handler;    
        if(0 == my_alloc_handler){ __THROW_BAD_ALLOC; }        //抛出异常
        (*my_alloc_handler)();
        result = malloc(n);            //再重新分配内存
        if(result) return(result);        
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一级配置器相对简单，其使用malloc(), free(), realloc()等C函数执行实际的内存分配，释放，重新配置等操作。此外，这个配置器提供了当内存配置错误时的处理函数oom&lt;em&gt;malloc，这个函数会调用\&lt;/em&gt;_malloc_alloc_oom_handler()这个错误处理函数，去企图释放内存，然后重新调用malloc分配内存。如此循环，直到分配成功，返回指针。&lt;/p&gt;
&lt;h3 id=&quot;第二级配置器&quot;&gt;&lt;a href=&quot;#第二级配置器&quot; class=&quot;headerlink&quot; title=&quot;第二级配置器&quot;&gt;&lt;/a&gt;第二级配置器&lt;/h3&gt;&lt;p&gt;STL第二级配置器的做法是，如果区块够大，超过128bytes时，就移交第一级配置器处理。当区块小于128bytes时，则以内存池管理，即每次配置一大块内存，并维护对应之自由链表，下次若再有相同大小的内存需求，就直接从free lists中拔出，而如果客户端释还小额区块，就由配置器回收到free lists中。&lt;br&gt;为了方便管理，SGI第二级配置器会主动将任何小额区块的内存需求量上调至8的倍数（例如客端要求30bytes，就会自动调整为32bytes），并维护16个free lists，各自管理大小分别为8,16,24,32,40,48,56,64,72,80,88,96,104,112,120,128的小额区块。&lt;br&gt;free-lists的节点结构定义如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;union obj {
    union obj *free_list_link;     //指向下一个内存的地址
    char client_data[1];           //内存的首地址 
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据union的特性，obj的内存布局应该如下所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/IE7fZAU.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从起第一字段观之，obj被视为一个指针，指向相同形式的另一个obj，从其第二字段观之，obj可被视为一个指针，指向实际区块。这样一物二用的结果是，不会为了维护链表所必须的指针而造成内存的另一种浪费。&lt;br&gt;下面来看一下相关的源代码。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;enum {__ALIGN = 8}；
enum {__MAX_BYTES = 128};
enum {__NFREELISTS = __MAX_BYTES/__ALIGN};

template &amp;lt;bool threads, int inst&amp;gt;
class __default_alloc_template{
    ...
    static size_t ROUND_UP(size_t bytes){        //将bytes上调至8的倍数
        return (((bytes)+__ALIGN-1) &amp;amp; ~(__ALIGN-1));
    }
    static obj* volatile free_list[__NFREELISTS];    //内存池链表
    static size_t FREELIST_INDEX(size_t bytes){    
        return (((bytes)+__ALIGN-1)/__ALIGN-1);        //根据区块大小，决定使用第n号free-list
    }
    ...    
};

static void* allocate(size_t n){
    obj * volatile * my_free_list;
    obj * result;
    if(n &amp;gt; (size_t)__MAX_BYTES){
        return (malloc_alloc::allocate(n));
    }
    my_free_list = free_list + FREELIST_INDEX(n);    //寻找合适的那个free_list
    result = *my_free_list;
    if(result == 0){        //没找到可用的free_list,准备重新填充free_list
        void* r = refill(ROUND_UP(n));
        return r;
    }
    *my_free_list = result-&amp;gt;free_list_link;        //调整free_list
    return (result);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;具体操作如下图所示（摘自《STL源码剖析》）。当有内存请求到达时（第二级配置器），先找到负责这个内存大小的数据元素指向的内存链表，取出第一块内存，然后把数据元素(obj指针)指向第二块内存的首地址。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/VrO5VMA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此外，当程序释放这块内存时，第二级配置器还负责回收这块内存，等下次有请求时，可以直接使用这块内存。示意图（摘自《STL源码剖析》）如下：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/um5jnaS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;先计算这块内存属于哪个数组元素负责，然后将这块回收的内存放置链表的第一个位置，这块内存的下一块内存为这个链表原先的第一块内存。源代码如下；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void deallocate(void *p, size_t n){
    obj *q = (obj *)p;
    obj * volatile * my_free_list;

    if(n &amp;gt; (size_t)__MAX_BYTES) {    //大于128bytes,调用第一级配置器回收
        malloc_alloc::deallocate(p, n);
        return;
    }
    my_free_list = free_list + FREELIST_INDEX(n);    //找到负责这块内存的数据元素
    q -&amp;gt;free_list_link = *my_free_list;         
    *my_free_list = q;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;重新填充free-lists&quot;&gt;&lt;a href=&quot;#重新填充free-lists&quot; class=&quot;headerlink&quot; title=&quot;重新填充free lists&quot;&gt;&lt;/a&gt;重新填充free lists&lt;/h3&gt;&lt;p&gt;在上面的allocate()中，当发现free list中没有可用区块了时，就调用refill()，准备为free list重现填充空间。新的空间将取自内存池（经由chunk_alloc()完成）。缺省取得20个新节点（新区块），但万一内存池空间不足，获得的区块数可能小于20。例如，如果请求内存为32bytes，此时内存链表中没有足够的内存了，那么refill会分配20块32bytes的内存块，然后把第一块返回给程序，其他19块由数组相应链表管理。相应的源代码为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;bool threads, int inst&amp;gt;
void* __default_alloc_template&amp;lt;threads, inst&amp;gt;::refill(size_t n){
    int nobjs = 20;
    char *chunk = chunk_alloc(n, nobjs);   //nobjs: pass by reference
    obj * volatile * my_free_list;
    obj * result;
    obj * current_obj, next_obj;
    int i;

    if(1 == nodejs) return chunk;    //如果只返回一块内存，直接返回
    my_free_list = free_list + FREELIST_INDEX(n);

    result = (obj*)chunk;        //不止一块内存，取出第一块内存
    *my_free_list = next_obj = (obj *)(chunk + n );   //数组元素链表指针指向第二块内存
    for(i=1; ;i++){
        curent_obj = next_obj;
        next_obj = (*obj)((char*)next_obj+n);
        if(nobjs - 1 ==i){
            current_obj-&amp;gt;free_list_link = 0;
            break;
        }else{
            current_obj-&amp;gt;free_list_link = next_obj;
        }
    }
    return(result);
}            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;接下来分析真正从内存池获取内存的函数chunk_alloc。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;bool threads, int inst&amp;gt;
char* __default_alloc_template&amp;lt;threads, inst&amp;gt;::chunk_alloc(size_t size, int&amp;amp; nobjs){
    char* result;
    size_t total_bytes = size * nobjs;
    size_t bytes_left = end_free - start_free;        //内存池剩余的内存

    if(bytes_left &amp;gt;= total_bytes){        //当内存持内存足够时
        result = start_free;
        start_free += total_free;
        return(result);
    }else if(bytes_left &amp;gt;= size){        //内存池不能满足total，但是可以满足一块以上
        nobjs = bytes_left/size;
        total_bytes = size * nobjs;
        result = start_free;
        start_free += total_bytes;
        return(result);
    }else{                //试着让内存池的残余零头还有利用价值
        size_t bytes_to_get = 2*total_bytes + ROUND_UP(heap_size &amp;gt;&amp;gt; 4);
        if(bytes_left &amp;gt; 0){
            obj * volatile * my_free_list = free_list + FREELIST_INDEX(bytes_left);
            ((obj *)start_free) -&amp;gt; free_list_link = *my_free_list;    //调整free list，将内存池中的残余空间编入
            *my_free_list = (*obj)start_free;
        }
        //调用malloc从内存分配
        start_free = (char*)malloc(bytes_to_get);
        if(0 == start_free){                //当系统内存不足时
            int i;
            obj * volatile * my_free_list, *p;
            for(i=size;i&amp;lt;=__MAX_BYTES;i+=__ALIGN){
                my_free_list = free_list + FREELIST_INDEX(i);
                p = *my_free_list;
                if(0 != p){
                    *my_free_list = p-&amp;gt;free_list_link;
                    start_free = (char*)p;
                    end_free = start_free + i;
                    return(chunk_alloc(size, nobjs));
                }
            }
            end_free = 0;        //从其他链表也没获取到内存，到处都没内存可用了
            start_free = (char*)malloc_alloc::allocate(byte_to_get);        //调用第一级配置器，因为有错误处理函数，最后的补救办法了
        }
        heap_size += bytes_to_get;
        end_free = start_free + bytes_to_get;
        return(chunk_alloc(size, nobjs));
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;chunk_alloc()函数以end_free-start_free来判断内存池的水量，如果水量充足，就直接调出20个区块返回给free list，如果水量不足以提供20个区块，但还足够供应一个以上的区块，就拨出这不足20个区块的空间出去，这时候pass by reference的nobjs参数被修改为实际能够供应的区块数。如果内存池连一个区块空间都无法供应，此时便利用malloc()从heap中配置内存，为内存注入源头活水以应付需求。其过程如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/SCDG2Gu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;对象内容的构造与析构&quot;&gt;&lt;a href=&quot;#对象内容的构造与析构&quot; class=&quot;headerlink&quot; title=&quot;对象内容的构造与析构&quot;&gt;&lt;/a&gt;对象内容的构造与析构&lt;/h3&gt;&lt;p&gt;我们知道，C++中的new操作符包含两阶段的操作：（1）调用::operator new配置内存；（2）调用构造函数构造对象内容，所以，为了精密分工，STL allocator决定将这两阶段 操作区分开来，内存配置操作由alloc::allocate()负责，对象构造函数由::construct()负责。同理，对象的析构与内存释放也是由两部分操作组成。&lt;/p&gt;
&lt;h3 id=&quot;使用配置器&quot;&gt;&lt;a href=&quot;#使用配置器&quot; class=&quot;headerlink&quot; title=&quot;使用配置器&quot;&gt;&lt;/a&gt;使用配置器&lt;/h3&gt;&lt;p&gt;最后，来看下配置器是如何使用的。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Alloc&amp;gt;
class simple_alloc {
public:
    static T *allocate(size_t n)
        { return 0 == n ? 0 : (T*)Alloc::allocate(n * sizeof(T)); }
    static T *allocate(void)
        { return 0 == n ? 0 : (T*)Alloc::allocate(sizeof(T)); }
    static void deallocate(T* p, size_t n)
        { if(0 != n) Alloc::deallocate(p, n * sizeof(T)); }
    static void deallocate(T* p)
        { Alloc::deallocate(p, sizeof(T)); }
};        
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;simple_alloc类封装了Alloc的分配和回收内存函数，并提供了四个用于内存操作的函数接口。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;        //alloc被默认为第二级配置器
class vector{
public:
    typedef T value_type;
    ...
protected:
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，vector内嵌了data_allocator类型，当需要分配内存时，调用simple_alloc的成员方法即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近准备结合《STL源码剖析》把学习的STL知识整理一遍，加深自己的理解的同时，也方便以后需要的时候查看。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>浅谈tcp backlog</title>
    <link href="http://blog.dujiong.net/2016/09/28/tcp-backlog/"/>
    <id>http://blog.dujiong.net/2016/09/28/tcp-backlog/</id>
    <published>2016-09-28T13:42:51.000Z</published>
    <updated>2016-09-20T15:49:44.450Z</updated>
    
    <content type="html">&lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;backlog的两种实现&quot;&gt;&lt;a href=&quot;#backlog的两种实现&quot; class=&quot;headerlink&quot; title=&quot;backlog的两种实现&quot;&gt;&lt;/a&gt;backlog的两种实现&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Ymk1keA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;首先通过上图回顾一下TCP建立连接时的状态变化。由于TCP建立连接时使用三次握手，所以监听的服务端在回给客户端SYN+ACK之后，会进入SYN RECEIVED状态，这称之为半连接状态，而只有当收到客户端回送的ACK之后，才完成连接，进入ESTABLISHED状态，等待应用层处理。所以，TCP/IP协议栈有两种方式来实现这个连接队列：&lt;br&gt;（1）第一种是使用一个单一的队列，队列的大小由应用层listen函数的backlog参数确定，当收到一个SYN请求，服务端就回发给客户端SYN+ACK，并且将该连接加入到队列中。当客户端最后的ACK到来时，该连接的状态变为ESTABLISHED，并等待应用层处理。所以，这种实现方式下，队列中包含了两种状态的连接：SYN RECEIVED和ESTABLISHED。只有后一种状态的连接才可以从acception中返回，被应用层处理。&lt;br&gt;（2）另一种实现方式是使用两个队列，一个SYN队列（即半连接队列）和一个全连接队列（ACCEPT队列）。处于SYN RECEIVED状态的连接被加入到SYN队列中，当最后一个ACK到来时，改变状态并移动到全连接队列。所以，accept系统调用直接从全连接队列中取已完成的连接交给应用层处理。这时，listen函数中的backlog值决定了全连接队列的大小。&lt;br&gt;传统的基于BSD的TCP实现采用的是第一种方式，这种实现方式意味着，当队列满的时候，系统再收到SYN，将不会回发SYN+ACK。通常，TCP实现采用的是简单地丢弃SYN，让客户端重传，而不是回发RST。&lt;br&gt;在Linux系统中，backlog的实现形式分为两个阶段，在Linux2.2之前，内核采用的也是上述的方式，队列满之后，服务端再收到SYN时，将不会返回SYN/ACK，也不返回RST，让客户端重试。而在Linux2.2之后，内核选择第二种方式实现，SYN_RECEIVED队列的大小由/proc/sys/net/ipv4/tcp_max_syn_backlog系统参数指定，ESTABLISHED队列由backlog和/proc/sys/net/core/somaxconn中较小的指定。    &lt;/p&gt;
&lt;h3 id=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;a href=&quot;#SYN队列和ACCEPT队列&quot; class=&quot;headerlink&quot; title=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;/a&gt;SYN队列和ACCEPT队列&lt;/h3&gt;&lt;p&gt;以下是操作系统维护两种队列处理TCP连接的示意图。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/sGEPFN7.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;SYN队列和已完成队列是内核实现的，当服务器绑定、监听了某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。客户端使用connect向服务器发起TCP连接时，当SYN包到达服务器之后，内核会把这一报文放入SYN队列，同时回发一个SYN+ACK包给客户端。一段时间后，当三次握手最后的ACK到达服务器，内核会把连接从SYN队列中取出，再把这个连接放入ACCEPT队列（已完成队列）中。所以，服务器调用accept，其实就是直接从ACCEPT队列中取出已经建立成功的连接套接字。&lt;br&gt;当然，随之也产生了一些问题。因为SYN和ACCEPT队列都是有大小限制的，所以，二者都会存在队列满的时候。上图中，如果第一步执行的速度大于第二步执行的速度，SYN队列就会不断增大直到队列满；如果第二步执行的速度大于第三步执行的速度，ACCEPT队列同样会满。&lt;br&gt;当ACCEPT队列已满，这时SYN队列中的一个连接收到最后的ACK，需要移动到ACCEPT队列，会发生什么呢？&lt;br&gt;通过查看内核源码(net/ipv4/tcp_ipv4.c)可知，如果/proc/sys/net/ipv4/tcp_abort_on_overflow被置为1，内核将会回送RST包，否则，将会丢弃ACK，什么都不做。进一步地，当一定时间服务端还没有收到ACK（包括丢弃掉的ACK），将会重发SYN+ACK包（“指数退避”算法）。当客户端收到重发的SYN+ACK时，它便知道ACK包丢失了，需要重传。另一方面，当ACCEPT队列已满的时候，内核将会限制SYN队列的处理速度，如果收到太多的SYN队列，将会丢弃一些。这样，丢弃的SYN对应的客户端将会重发SYN包。&lt;br&gt;另一种情况，当SYN队列满的时候，会发生什么呢？上面已经阐述了，服务器端将会直接丢弃请求，即丢弃SYN网络包。       &lt;/p&gt;
&lt;h3 id=&quot;TCP连接的一些异常情况&quot;&gt;&lt;a href=&quot;#TCP连接的一些异常情况&quot; class=&quot;headerlink&quot; title=&quot;TCP连接的一些异常情况&quot;&gt;&lt;/a&gt;TCP连接的一些异常情况&lt;/h3&gt;&lt;p&gt;针对上述的两个连接队列，有一些常见的连接异常情况。下面做一个简单总结。     &lt;/p&gt;
&lt;h4 id=&quot;服务端SYN超时&quot;&gt;&lt;a href=&quot;#服务端SYN超时&quot; class=&quot;headerlink&quot; title=&quot;服务端SYN超时&quot;&gt;&lt;/a&gt;服务端SYN超时&lt;/h4&gt;&lt;p&gt;当客户端给服务端发送SYN报文时，如果服务端没有返回SYN+ACK报文，那么客户端会重发SYN报文给服务端，重发的次数由参数tcp_syn_retries参数设置，该值默认是5，超过5次服务端还是不返回SYN+ACK报文，那么本次连接失败。服务端没有返回SYN+ACK主要有两种情况，一种是由于网络问题SYN包丢失；另一种是服务端SYN队列满，导致SYN包被丢弃。                &lt;/p&gt;
&lt;h4 id=&quot;客户端ACK超时&quot;&gt;&lt;a href=&quot;#客户端ACK超时&quot; class=&quot;headerlink&quot; title=&quot;客户端ACK超时&quot;&gt;&lt;/a&gt;客户端ACK超时&lt;/h4&gt;&lt;p&gt;如果服务端接到了客户端发的SYN并回发SYN+ACK后，客户端掉线了，这时，服务端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功也没失败。于是，服务端端如果在一定时间内没有收到客户端端的ACK，那么服务端端会重发SYN+ACK。在Linux下，默认重试次数为5次，重发的间隔时间从1s开始每次都翻番（指数退避），5次的重发的时间间隔分别1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s+2s+4s+8s+16s+32s = 2^6-1 = 63s，TCP才会把断开这个连接。              &lt;/p&gt;
&lt;h4 id=&quot;SYN-Flood&quot;&gt;&lt;a href=&quot;#SYN-Flood&quot; class=&quot;headerlink&quot; title=&quot;SYN Flood&quot;&gt;&lt;/a&gt;SYN Flood&lt;/h4&gt;&lt;p&gt;这时一种恶意攻击。客户端给服务器发一个SYN后就下线，这样服务器需要默认等待63s才会断开连接，这样攻击者就可以把服务器的SYN连接队列耗尽，让正常的连接请求不能处理。为了应对SYN Flood攻击，Linux实现了一种称为SYN cookie的机制，通过net.ipv4.tcp_syncookies来设置。当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使不在SYN队列中）。&lt;/p&gt;
&lt;h3 id=&quot;TCP连接过程参数调优&quot;&gt;&lt;a href=&quot;#TCP连接过程参数调优&quot; class=&quot;headerlink&quot; title=&quot;TCP连接过程参数调优&quot;&gt;&lt;/a&gt;TCP连接过程参数调优&lt;/h3&gt;&lt;p&gt;下面罗列一些常用于TCP连接过程优化的参数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-max-syn-backlog&quot;&gt;&lt;a href=&quot;#tcp-max-syn-backlog&quot; class=&quot;headerlink&quot; title=&quot;tcp_max_syn_backlog&quot;&gt;&lt;/a&gt;tcp_max_syn_backlog&lt;/h4&gt;&lt;p&gt;SYN队列长度。如果服务器经常出现过载，可以尝试增加这个数字。   &lt;/p&gt;
&lt;h4 id=&quot;tcp-synack-retries&quot;&gt;&lt;a href=&quot;#tcp-synack-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_synack_retries&quot;&gt;&lt;/a&gt;tcp_synack_retries&lt;/h4&gt;&lt;p&gt;连接被动打开方的确认连接的应答最大重试次数。对于一个新建连接，内核要发送多少SYN连接请求才决定放弃。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syn-retries&quot;&gt;&lt;a href=&quot;#tcp-syn-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_syn_retries&quot;&gt;&lt;/a&gt;tcp_syn_retries&lt;/h4&gt;&lt;p&gt;连接主动打开方的syn尝试次数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syncookies&quot;&gt;&lt;a href=&quot;#tcp-syncookies&quot; class=&quot;headerlink&quot; title=&quot;tcp_syncookies&quot;&gt;&lt;/a&gt;tcp_syncookies&lt;/h4&gt;&lt;p&gt;防止SYN Flood攻击。    &lt;/p&gt;
&lt;h4 id=&quot;tcp-abort-on-overflos&quot;&gt;&lt;a href=&quot;#tcp-abort-on-overflos&quot; class=&quot;headerlink&quot; title=&quot;tcp_abort_on_overflos&quot;&gt;&lt;/a&gt;tcp_abort_on_overflos&lt;/h4&gt;&lt;p&gt;ACCEPT队列满，处理不过来的时候，如果设置了该参数，内核将会回发RST包。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>数据结构之线段树</title>
    <link href="http://blog.dujiong.net/2016/09/23/SegmentTree/"/>
    <id>http://blog.dujiong.net/2016/09/23/SegmentTree/</id>
    <published>2016-09-23T13:28:16.000Z</published>
    <updated>2016-09-17T02:46:29.535Z</updated>
    
    <content type="html">&lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;线段树具有如下性质：&lt;br&gt;（1）线段树是一棵平衡树，使用线段树可以快速地查找某一个节点在若干条线段中出现的次数，时间复杂度为O(logN)。&lt;br&gt;（2）线段树同一层的节点所代表的区间，相互不会重叠。&lt;br&gt;（3）线段树任两节点要么是包含关系要么是没有公共部分，不可能部分重叠。&lt;br&gt;（4）给定一个叶子l，从根到l路径上所有节点代表的区间都包含l，且其他节点代表的区间都不包含l。&lt;br&gt;一棵[1,10]的线段树表示如下。注意，线段树的构造在各区间的端点处的处理方式不一样，会导致线段树最终的表示有些差别，但是本质上是一样的。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/JEkWmlu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;线段树的基本操作&quot;&gt;&lt;a href=&quot;#线段树的基本操作&quot; class=&quot;headerlink&quot; title=&quot;线段树的基本操作&quot;&gt;&lt;/a&gt;线段树的基本操作&lt;/h3&gt;&lt;p&gt;线段树的基本操作和普通二叉树很类似，只不过线段树的节点上存储的是一个区间（左右端点值）。下面以线段树的建立、插入线段和删除线段为例简要说明线段树的基本操作。&lt;/p&gt;
&lt;h4 id=&quot;线段树的构建&quot;&gt;&lt;a href=&quot;#线段树的构建&quot; class=&quot;headerlink&quot; title=&quot;线段树的构建&quot;&gt;&lt;/a&gt;线段树的构建&lt;/h4&gt;&lt;p&gt;首先定义线段树的结构，这里采用链表的方式组织。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Node
{
    int left,right;
    int cover;            
    Node* leftChild;
    Node* rightChild;    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，cover字段用于计算一条线段被覆盖的次数。接下来，以递归的方式构建线段树。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Node* build(int l, int r)
{
    Node* root = new Node();
    root-&amp;gt;left = l;
    root-&amp;gt;right = r;
    root-&amp;gt;cover = 0;
    root-&amp;gt;leftChild = NULL;
    root-&amp;gt;rightChild = NULL;
    if(r-l &amp;gt; 1)
    {
        int mid = (l+r) &amp;gt;&amp;gt; 1;
        root-&amp;gt;leftChild = build(l,mid);
        root-&amp;gt;rightChild = build(mid,r);        //build(mid+1,r)
    }
    return root;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;线段插入与删除&quot;&gt;&lt;a href=&quot;#线段插入与删除&quot; class=&quot;headerlink&quot; title=&quot;线段插入与删除&quot;&gt;&lt;/a&gt;线段插入与删除&lt;/h4&gt;&lt;p&gt;如上所述，通过cover字段来计算一条线段被覆盖的次数。插入与删除时更新相应线段的cover。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Insert(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover++;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Insert(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Insert(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Insert(start,mid,root-&amp;gt;leftChild);
        Insert(mid,end,root-&amp;gt;rightChild); 
    }
}

void Delete(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover--;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Delete(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Delete(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Delete(start,mid,root-&amp;gt;leftChild);
        Delete(mid,end,root-&amp;gt;rightChild);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;线段树的应用&quot;&gt;&lt;a href=&quot;#线段树的应用&quot; class=&quot;headerlink&quot; title=&quot;线段树的应用&quot;&gt;&lt;/a&gt;线段树的应用&lt;/h3&gt;&lt;p&gt;TODO&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Spin lock与Mutex</title>
    <link href="http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/"/>
    <id>http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/</id>
    <published>2016-09-18T13:34:32.000Z</published>
    <updated>2016-09-16T13:26:29.859Z</updated>
    
    <content type="html">&lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Pthreads提供了多种线程同步锁机制：&lt;br&gt;（1）Mutex（互斥量）：pthread_mutex_xxx&lt;br&gt;（2）Spin lock(自旋锁)：pthread_spin_xxx&lt;br&gt;（3）Condition Variable（条件变量）：pthread_cond_xxx&lt;br&gt;（4）Read/Write lock（读写锁）：pthread_rwlock_xxx&lt;br&gt;本文主要讲解Spin lock和其与Mutex（Mutex的用法很常见、也很简单，若还不熟悉，可参考&lt;a href=&quot;http://blog.dujiong.net/2016/07/08/muduo-5/&quot;&gt;muduo中的封装&lt;/a&gt;）之间的区别。     &lt;/p&gt;
&lt;h3 id=&quot;Spin-lock&quot;&gt;&lt;a href=&quot;#Spin-lock&quot; class=&quot;headerlink&quot; title=&quot;Spin lock&quot;&gt;&lt;/a&gt;Spin lock&lt;/h3&gt;&lt;p&gt;Spin lock又称自旋锁，线程通过busy-wait-loop的方式来获取锁，任何时刻都只有一个线程能够获得锁，其他线程忙等待直到获得锁。Spin lock在多处理器多线程环境的场景中有很广泛的使用。   &lt;/p&gt;
&lt;h4 id=&quot;Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;Spin lock和Mutex&quot;&gt;&lt;/a&gt;Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;Spin lock有如下特点：&lt;br&gt;（1）Spin lock是一种死等的锁机制。当发生访问资源冲突的时候，可以有两种机制：一个是死等，一个是挂起当前进程，调度其他线程执行（Mutex）。线程会一直进行忙等待而不停的进行锁清秋，直到得到这个锁为止。&lt;br&gt;（2）执行时间短。由于Spin lock死等这种特性，因此它使用在那些代码不是非常复杂的临界区（当然也不能太简单，否则使用原子操作或者其他适用简单场景的同步机制就可以了），如果临界区执行时间太长，那么不断在临界区门口进行死等的线程十分浪费CPU资源。&lt;br&gt;（3）可以在中断上下文执行。由于不睡眠，因此Spin lock可以在中断上下文中使用。&lt;br&gt;从上述总结的Spin lock的特点，已经可以看出其与Mutex的不同之处了，下面再以一个实例进行说明。&lt;br&gt;例如在一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core 0和Core 1上，假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，Core 0会在此时进行上下文切换将线程A置于等待队列中，此时Core 0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待。而Spin lock则不然，它属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，那么线程A就会一直在Core 0上进行忙等待并不停的进行锁请求，直到得到这个锁为止。&lt;/p&gt;
&lt;h4 id=&quot;使用Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#使用Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;使用Spin lock和Mutex&quot;&gt;&lt;/a&gt;使用Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;下面通过实际的代码来进一步比较说明Spin lock和Mutex。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;list&amp;gt;

using namespace std;

const int LOOPS = 50000000;

list&amp;lt;int&amp;gt; ilist;

#ifdef USE_SPINLOCK
    pthread_spinlock_t spinlock;
#else
    pthread_mutex_t mutex;
#endif

pid_t gettid() 
{
    return syscall( __NR_gettid );
}

void *consumer(void *ptr)
{
    int i;

    printf(&amp;quot;Consumer TID %lun&amp;quot;, (unsigned long)gettid());

    while (1)
    {
#ifdef USE_SPINLOCK
        pthread_spin_lock(&amp;amp;spinlock);
#else
        pthread_mutex_lock(&amp;amp;mutex);
#endif

        if (ilist.empty())
        {
#ifdef USE_SPINLOCK
            pthread_spin_unlock(&amp;amp;spinlock);
#else
            pthread_mutex_unlock(&amp;amp;mutex);
#endif
            break;
        }

        i = ilist.front();
        ilist.pop_front();

#ifdef USE_SPINLOCK
        pthread_spin_unlock(&amp;amp;spinlock);
#else
        pthread_mutex_unlock(&amp;amp;mutex);
#endif
      }

    return NULL;
}

int main()
{
    int i;
       pthread_t thr1, thr2;
    struct timeval tv1, tv2;

#ifdef USE_SPINLOCK
    pthread_spin_init(&amp;amp;spinlock, 0);
#else
    pthread_mutex_init(&amp;amp;mutex, NULL);
#endif

    for (i = 0; i &amp;lt; LOOPS; i++)
        ilist.push_back(i);

    gettimeofday(&amp;amp;tv1, NULL);

    pthread_create(&amp;amp;thr1, NULL, consumer, NULL);
    pthread_create(&amp;amp;thr2, NULL, consumer, NULL);

    pthread_join(thr1, NULL);
    pthread_join(thr2, NULL);

    gettimeofday(&amp;amp;tv2, NULL);

    if (tv1.tv_usec &amp;gt; tv2.tv_usec)
    {
        tv2.tv_sec--;
        tv2.tv_usec += 1000000;
    }
    printf(&amp;quot;Result - %ld.%ld\n&amp;quot;, tv2.tv_sec - tv1.tv_sec,
    tv2.tv_usec - tv1.tv_usec);

#ifdef USE_SPINLOCK
    pthread_spin_destroy(&amp;amp;spinlock);
#else
    pthread_mutex_destroy(&amp;amp;mutex);
#endif

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该程序的逻辑是：主线程先初始化一个list结构，并根据LOOPS的值将对应数量的i插入该list，之后创建两个新线程，它们都执行consumer()这个任务。两个被创建的新线程同时对这个list进行pop()操作。主线程会计算从创建两个新线程到新线程结束之间所用的时间。&lt;br&gt;代码执行平台参数：&lt;br&gt;Ubuntu14.04 X86&lt;br&gt;Inter i5-2430M @ 2.40GHz, Dual Core&lt;br&gt;4.0GB Memory&lt;br&gt;下面是代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/7dmwgzS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果中可以看出Spin lock表现出的性能更好，另外，sys时间是所花费的系统掉头时间，可以看出，Mutex将消耗更多的系统调用时间，这是因为Mutex会在锁冲突时调用System Wait造成的。&lt;br&gt;但是，当临界区很大时，两个线程的锁进程会非常的激烈。这时，Spin lock的“死等”策略效率将会急剧下降。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;

using namespace std;

const int THREAD_NUM = 2;

pthread_t g_thread[THREAD_NUM];
#ifdef USE_SPINLOCK
pthread_spinlock_t g_spin;
#else
pthread_mutex_t g_mutex;
#endif

__uint64_t g_count;

pid_t gettid()
{
    return syscall(SYS_gettid);
}

void* run_amuck(void* arg)
{
   int i, j;

   printf(&amp;quot;Thread %lu started.n&amp;quot;, (unsigned long)gettid());

   for (i = 0; i &amp;lt; 10000; i++) 
   {
#ifdef USE_SPINLOCK
       pthread_spin_lock(&amp;amp;g_spin);
#else
       pthread_mutex_lock(&amp;amp;g_mutex);
#endif
       for (j = 0; j &amp;lt; 100000; j++) 
       {
           if (g_count++ == 123456789)
              printf(&amp;quot;Thread %lu wins!n&amp;quot;, (unsigned long)gettid());
       }
#ifdef USE_SPINLOCK
       pthread_spin_unlock(&amp;amp;g_spin);
#else
       pthread_mutex_unlock(&amp;amp;g_mutex);
#endif
   }
   printf(&amp;quot;Thread %lu finished!n&amp;quot;, (unsigned long)gettid());

   return NULL;
}

int main(int argc, char *argv[])
{
   int i, threads = THREAD_NUM;
   printf(&amp;quot;Creating %d threads...n&amp;quot;, threads);
#ifdef USE_SPINLOCK
   pthread_spin_init(&amp;amp;g_spin, 0);
#else
   pthread_mutex_init(&amp;amp;g_mutex, NULL);
#endif
   for (i = 0; i &amp;lt; threads; i++)
           pthread_create(&amp;amp;g_thread[i], NULL, run_amuck, (void *) i);
   for (i = 0; i &amp;lt; threads; i++)
           pthread_join(g_thread[i], NULL);

   return 0;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/mZQYF49.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;果然，在我们选择使临界区变得很大时，锁竞争也变得很激烈。这样，Spin lock的性能急剧下降，Mutex的性能更好。同样地，可以看出，这种情况下，Spin lock消耗了很多的user time。原因是两个线程分别运行在两个核上，大部分时间只有一个线程能拿到锁，所以另一个线程就一直在它运行的core上进行忙等待，CPU占有率一直是100%；Mutex则不同，当对锁的请求失败后，上下文切换就会发生，这样就能空出一个核来运行别的计算任务。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;根据以上的分析和测试：&lt;br&gt;（1）Mutex适合对锁操作非常频繁的场景，并且具有更好的适应性。尽管相比Spin lock会花费更多的开销（上下文切换），但是它能适合实际开发中复杂的应用场景，在保证一定性能的前提下提供更大的灵活度。&lt;br&gt;（2）spin lock的lock/unlock性能更好(花费更少的cpu指令)，但是它只适应用于临界区运行时间很短的场景。而在实际软件开发中，除非程序员对自己的程序的锁操作行为非常的了解，否则使用spin lock不是一个好主意，实际中的多线程程序对锁的操作一般会很多。&lt;br&gt;（3）最好的方式是先使用Mutex，然后如果对性能还有进一步的需求，可以尝试使用spin lock进行调优。毕竟，需要先保证程序的正确性，再考虑提升性能。    &lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;&lt;a href=&quot;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&lt;/a&gt;  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;
    
    </summary>
    
    
      <category term="多线程" scheme="http://blog.dujiong.net/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>C++引用剖析</title>
    <link href="http://blog.dujiong.net/2016/09/14/cplusplusReference/"/>
    <id>http://blog.dujiong.net/2016/09/14/cplusplusReference/</id>
    <published>2016-09-14T11:58:41.000Z</published>
    <updated>2016-09-14T15:17:56.403Z</updated>
    
    <content type="html">&lt;p&gt;引用是C++对于C语言的一个强有力的补充，它是对象的别名，这里的对象是指广义的，不仅是用类、结构体等复杂类型来声明的变量，还包括用int，float等简单类型声明的变量。引用在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命期是不能被改变的，即自始至终只能依附于同一个变量。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;C-引用的本质&quot;&gt;&lt;a href=&quot;#C-引用的本质&quot; class=&quot;headerlink&quot; title=&quot;C++引用的本质&quot;&gt;&lt;/a&gt;C++引用的本质&lt;/h3&gt;&lt;p&gt;C++引用的本质是指针常量。&lt;br&gt;引用是个常量，不同于指针，其在声明时必须初始化。此外，引用其实也是一种指针，绑定于自身的指针。只不过二者的接口并不相同，引用的接口有一定的限制，下述。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct A
{
    char name_;
    int num_;
    A&amp;amp; a_;
};    

struct B
{
    int num_;
    B&amp;amp; b_;
};

int main()
{
    cout &amp;lt;&amp;lt; sizeof(A) &amp;lt;&amp;lt; endl;        //12
    cout &amp;lt;&amp;lt; sizeof(B) &amp;lt;&amp;lt; endl;        //8
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;32位平台下，运行上述测试代码，可以看出两个结构中对自身的引用占四个字节，是与对象的一种绑定关系，通过引用可以获得对象。&lt;/p&gt;
&lt;h3 id=&quot;指针和引用的区别&quot;&gt;&lt;a href=&quot;#指针和引用的区别&quot; class=&quot;headerlink&quot; title=&quot;指针和引用的区别&quot;&gt;&lt;/a&gt;指针和引用的区别&lt;/h3&gt;&lt;p&gt;虽然引用很多时候表现出指针的特性，但是二者是有很大区别的。&lt;br&gt;首先，引用不可以为空，但指针可以为空。前面说过，引用是对象的别名，若对象不存在，怎么可能有别名？所以，定义一个引用的时候，必须初始化。而如果有一个变量是用于指向另一个对象，但是它可能为空，这时应该使用指针。因此，在实际代码编写中，使用指针之前必须做判空操作(&lt;code&gt;if(!p==NULL)&lt;/code&gt;)，而引用就不必。&lt;br&gt;其次，引用不可以改变指向，始终绑定同一个对象，这也正是上述常量指针的表现。而指针可以改变指向。需要注意的是，虽然引用不可以改变指向，但是可以改变初始化对象的内容。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int i = 10;
int&amp;amp; ref = i;
ref++;
cout &amp;lt;&amp;lt; &amp;quot;i &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; ref &amp;quot; &amp;lt;&amp;lt; ref &amp;lt;&amp;lt; endl;

int j = 20;
ref = j;
ref++;
cout &amp;lt;&amp;lt; &amp;quot;i &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; ref &amp;quot; &amp;lt;&amp;lt; ref &amp;lt;&amp;lt; &amp;quot; j &amp;quot; &amp;lt;&amp;lt; j &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;输出为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/qgy7FOO.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以看出，对ref的++操作是直接反应到所绑定变量之上，所以，第一个cout之后i和ref都变为了11，对ref重新赋值并不影响它的指向。，它仍然指向的是i，而不是j，只是其绑定变量的值变为了j的值20，然后再对ref++，最终，i和ref都变为了21，而j，仍然是20。&lt;br&gt;第三，引用的大小是所绑定的变量的大小，因为引用只是一个别名而已；而指针对应的是指针本身的大小，4个字节（32bits）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct    A
{
    char name_;
    int num_;
    int sum_
};    

int main()
{
    A a;
    A&amp;amp; ref = a;
    cout &amp;lt;&amp;lt; sizeof(ref) &amp;lt;&amp;lt; endl;  //12
    A* p = new A();
    cout &amp;lt;&amp;lt; sizeof(p) &amp;lt;&amp;lt; endl;    //4
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，引用比指针更安全。因为不存在空引用，并且引用一旦被初始化为指向一个对象，它就不能被改变为另一个对象的引用，因此引用很安全。而对于指针来说，它可以随时指向别的对象，并且可以不被初始化，或为NULL，所以不安全。&lt;br&gt;总而言之—指针指向一块内存，它的内容是指向内存的地址；而引用则是某块内存的别名，引用不改变指向。&lt;/p&gt;
&lt;h3 id=&quot;const&quot;&gt;&lt;a href=&quot;#const&quot; class=&quot;headerlink&quot; title=&quot;const&quot;&gt;&lt;/a&gt;const&lt;/h3&gt;&lt;p&gt;很多C++程序员一提到const就头疼，特别是对常量指针、指针常量、常量指针常量等概念，现在还要加上引用…&lt;br&gt;首先总结下如何判定const是修饰指针，还是修饰指针所指向的数据。有一个简单的规则，画一条垂直穿过指针声明星号(*)的线，如果const出现在线的左边，则指针指向的数据位常量；如果const出现在右边，指针本身为常量。   &lt;/p&gt;
&lt;h4 id=&quot;常量指针和常量引用&quot;&gt;&lt;a href=&quot;#常量指针和常量引用&quot; class=&quot;headerlink&quot; title=&quot;常量指针和常量引用&quot;&gt;&lt;/a&gt;常量指针和常量引用&lt;/h4&gt;&lt;p&gt;常量指针：指向常量的指针，表示指向的对象是常量。比如&lt;code&gt;const int* p = &amp;amp;a&lt;/code&gt;，即告诉编译器*p是常量，不能将*p作为左值进行操作。&lt;br&gt;常量引用：指向常量的引用，表示指向的对象是常量。和指针一样不能利用引用对指向的变量进行重新赋值操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int main()
{   
    int i = 10;    
    const int&amp;amp; ref = i;      
    ref = 20;             //error    
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;指针常量和引用常量&quot;&gt;&lt;a href=&quot;#指针常量和引用常量&quot; class=&quot;headerlink&quot; title=&quot;指针常量和引用常量&quot;&gt;&lt;/a&gt;指针常量和引用常量&lt;/h4&gt;&lt;p&gt;指针常量：表示指针本身是常量，所以，在定义指针常量时必须进行初始化。比如&lt;code&gt;int* const p = &amp;amp;b&lt;/code&gt;，即告诉编译器，p是常量，不能作为左值进行操作，但是允许修改间接访问值，即*p可以修改。&lt;br&gt;引用常量：这是引用天生俱来的属性，不用再引用const来定义。   &lt;/p&gt;
&lt;h4 id=&quot;常量指针常量和常量引用常量&quot;&gt;&lt;a href=&quot;#常量指针常量和常量引用常量&quot; class=&quot;headerlink&quot; title=&quot;常量指针常量和常量引用常量&quot;&gt;&lt;/a&gt;常量指针常量和常量引用常量&lt;/h4&gt;&lt;p&gt;常量指针常量：指向常量的指针常量，如&lt;code&gt;const int* const p = &amp;amp;c&lt;/code&gt;，告诉编译器，p和*p都是常量，他们都不能作为左值进行操作。&lt;br&gt;不存在所谓的“常量引用常量”，因为跟上面讲的一样，引用变量就是引用常量。C++不区分变量的const引用和const变量的引用。绝不能给引用本身重新赋值，使它指向另一个变量，因此引用总是const的。如果对引用应用关键字const，起作用就是使其目标成为const变量。即没有：&lt;code&gt;const int const&amp;amp; a = 1&lt;/code&gt;,只有&lt;code&gt;const int&amp;amp; a = 1&lt;/code&gt;。     &lt;/p&gt;
&lt;h3 id=&quot;指针传递和引用传递&quot;&gt;&lt;a href=&quot;#指针传递和引用传递&quot; class=&quot;headerlink&quot; title=&quot;指针传递和引用传递&quot;&gt;&lt;/a&gt;指针传递和引用传递&lt;/h3&gt;&lt;p&gt;最后，介绍一下指针传递参数和引用传递参数的区别。&lt;br&gt;指针传递参数本质上是值传递方式，它所传递的是一个地址值。值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，即在栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。&lt;br&gt;引用传递的过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量。所以，被调函数对形参做的任何操作都影响了主调函数中的实参变量。&lt;br&gt;所以，对于指针传递的参数，如果改变被调函数中的指针地址，它影响不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关指针变量，那就得使用指向指针的指针，或者指针引用。&lt;br&gt;下面以一个代码来说明指针传递和引用传递的区别。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void func1(int x)
{
    x = x + 1;
}

void func2(int *x)
{
    (*x) = (*x) + 1;
}

void func3(int&amp;amp; x)
{
    x = x + 1;
}

int main()
{
    int a = 0;
    func1(a);
    cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;    //0
    int b = 0;
    func2(&amp;amp;b);            
    cout &amp;lt;&amp;lt; b &amp;lt;&amp;lt; endl;    //1
    int c = 0;
    func(c);        
    cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;    //1
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;三个函数分别对应值传递、指针传递和引用传递，值传递中，函数体内的x是外部变量的一份拷贝，改变x不会影响a。而指针传递中，函数体内的x是指向外部b的指针，改变该指针的内容将导致b值改变。引用传递中，函数体内的x是外部变量的引用，即二值是同一个东西，改变x等于改变c。&lt;br&gt;但是，要通过指针参数传递来改变主调函数中的相关指针变量，那就得使用指向指针的指针，或者指针引用。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;引用是C++对于C语言的一个强有力的补充，它是对象的别名，这里的对象是指广义的，不仅是用类、结构体等复杂类型来声明的变量，还包括用int，float等简单类型声明的变量。引用在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命期是不能被改变的，即自始至终只能依附于同一个变量。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>线性排序算法：计数排序、基数排序和桶排序</title>
    <link href="http://blog.dujiong.net/2016/09/07/LinearSort/"/>
    <id>http://blog.dujiong.net/2016/09/07/LinearSort/</id>
    <published>2016-09-07T12:43:51.000Z</published>
    <updated>2016-09-16T11:48:04.705Z</updated>
    
    <content type="html">&lt;p&gt;在计算机科学中，排序是一个非常基础的算法。不同的排序算法有不同的时间和空间开销。在这么多的排序算法中，根据在排序的最终结果中，各元素的次序是否依赖于它们之间的比较，可以将排序算法分为两大类：基于比较的排序和非基于比较的排序。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;基于比较的排序需要对序列中的数据进行比较，如我们最常用的快速排序、堆排序和归并排序。根据决策树模型可以证明：基于比较的排序算法的时间复杂度是不能突破O(NlogN)的。（《算法导论》8.1）&lt;br&gt;而非基于比较的排序，如本文将要介绍的计数排序、基数排序和桶排序，则可以突破O(NlogN)的时间下限。当然，这样的非比较的排序的使用会有一些条件的限制，比如元素的大小，所以，在一般在特定场合下，非基于比较的排序算法能够巧妙地解决一些问题。     &lt;/p&gt;
&lt;h3 id=&quot;计数排序&quot;&gt;&lt;a href=&quot;#计数排序&quot; class=&quot;headerlink&quot; title=&quot;计数排序&quot;&gt;&lt;/a&gt;计数排序&lt;/h3&gt;&lt;p&gt;首先介绍计数排序。&lt;br&gt;计数排序假设n个输入元素的每一个都是在0到K区间内的一个整数，其中K为某个正整数。计数排序的基本思想是，对每一个输入元素x，确定小于x的元素个数。利用这一信息，就可以直接把x放到它在输出数组的位置上了。比如，如果有17个元素小于x，则x就应该放在第18（或17，看数组a[0]怎么处理）个输出位置上。&lt;br&gt;按照这个思想，可以写出计数排序的伪代码：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;COUNTING-SORT(A,B,k)
    let C[0,k] be a new array
    for i=0 to k
        C[i]=0
    for j=0 to A.length-1
        C[A[j]]=C[A[j]]+1
    for i=1 to k
        C[i]=C[i]+C[i-1]
    for j=A.length-1 to 0
        B[C[A[j]]-1]=A[j]
        C[A[j]]=C[A[J]]-1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;说明一下，《算法导论》中的伪代码采用的是输入数组为A[1..n],输出数组为B[1..n]。这里没有这样做，而是采用传统的0~n-1的数组下标作为输入输出，本质是一样的。     &lt;/p&gt;
&lt;p&gt;下面以数据2 5 3 0 2 3 0 3为例说明计数排序的执行过程。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/pgoZnNn.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/Yz80C5w.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/hvHJ4Lx.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;容易看出，第一个for循环所花时间为Θ(k)，第二个for循环所花时间为Θ(n)，第三个for循环所花时间为Θ(k)，最后一个循环所花时间为Θ(n)。这样，总的时间代价就是Θ(n+k)。所以，当k=O(n)时，一般可以采用计数排序，这时运行时间为Θ(n)。          &lt;/p&gt;
&lt;h3 id=&quot;桶排序&quot;&gt;&lt;a href=&quot;#桶排序&quot; class=&quot;headerlink&quot; title=&quot;桶排序&quot;&gt;&lt;/a&gt;桶排序&lt;/h3&gt;&lt;p&gt;桶排序假设输入数据服从均匀分布，平均情况下它的时间代价为O(n)。与计数排序类似，因为对输入数据做了某种假设，桶排序的速度也很快。具体来说，计数排序假设输入数据都属于一个小区间内的整数，而桶排序则假设输入是由一个随机过程产生，该过程将元素均匀、独立地分布在[0,1)区间上。我们把区间[0,1)划分成n个相同大小的子区间，称为桶。将n个记录分布到各个桶中去。如果有多于一个记录分到同一个桶中，需要进行桶内排序。&lt;br&gt;在桶排序的代码中，假设输入是一个包含n个元素的数组A，且每个元素A[i]满足0&amp;lt;=A[i]&amp;lt;1。此外，算法还需要一个临时数组B[0..n-1]来存放链表（即桶），并假设存在一种用于维护这些链表的机制。在分完桶后，对每个桶进行排序，然后合并最后的结果。&lt;br&gt;桶排序用伪代码表示如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;BUCKET-SORT(A)
    n=A.length
    let B[0..n-1] to be a new array
    for i=0 to n-1
        make B[i] an empty list
    for i=1 to n
        insert A[i] to list B[nA[i]]
    for i=0 to n-1
        sort list B[i] with insertion sort
    concatenate the list B[0],B[1],...,B[n-1] together in order
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;例如，要对大小为[1..1000]范围内的n个整数A[1,n]排序，可以把桶设为大小为10的范围，具体而言，设集合B[0]存储[1..10)的整数，集合B[2]存储(10,20]的整数…依次，总共有100个桶。然后对A[1,n]从头到尾扫描一遍，把每个A[i]放入对应的桶B[j]中。然后再对这100个桶中每个桶里的数字进行排序。最后依次输出每个桶里面的数字，这样得到的就是排好序的序列了。&lt;br&gt;桶排序的平均时间复杂度为线性的O(N+C)，其中C为桶内快排的时间复杂度，如果对于同样的N，桶数量M越大，其效率越大，最好的时间复杂度达到O(N)。但是，桶排序的空间复杂度为O(N+M)，如果输入数据很庞大，而桶的数量也非常多，则空间代价是昂贵的。 &lt;/p&gt;
&lt;h3 id=&quot;基数排序&quot;&gt;&lt;a href=&quot;#基数排序&quot; class=&quot;headerlink&quot; title=&quot;基数排序&quot;&gt;&lt;/a&gt;基数排序&lt;/h3&gt;&lt;p&gt;另外一种线性排序方式是基数排序。下面通过一个例子来说明基数排序的思想。&lt;br&gt;假设有待排序的数据序列如下：&lt;br&gt;73 22 93 43 55 14 28 65 39 81&lt;br&gt;首先根据个位数的数值，在遍历数据时将它们各自分到编号为0-9的桶中，分配的结果如下图所示：&lt;br&gt; &lt;img src=&quot;http://i.imgur.com/eOVN7vZ.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;分配结束后，接下来将所有桶中所盛数据按照桶号由小到大依次重新收集起来，得到下列仍然无序的数据序列：&lt;br&gt;81 22 73 93 43 14 55 65 28 39&lt;br&gt;接着，再进行一次分配，这次根据十位数值来分配（原理同上），分配结构如下所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/sLQPdaX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样，原来无序的数据序列已经排序完毕。如果排序的位数大于2，则重复以上动作至最后一位。&lt;br&gt;当然，上面的排序过程中有一个还需探究的问题，即在原来的序列中的73 93 43（个位数相同）三个数的顺序，在经过第一次分配之后，在桶中的顺序由底至上应该为73 93 43（即装的迟的在最上面），但是在3号桶中刚好相反。这正是基数排序稳定的原因，分配时是从预排数据序列的末尾开始进行，逐次分配至首位。&lt;br&gt;所以，不难看出，基数排序原理类似于桶排序，只是这里总是需要十个桶，多次使用。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/*
 * getdigit(arr[i],k)用于获得arr[i]第k位上的数字
 */

void lsdRadixSort(int arr[], int begin, int end, int d)
{
    const int radix = 10;
    int count[radix];
    int i,j;

    int *bucket = (int*)malloc((end-start+1)*sizeof(int));
    for(int k=1;k&amp;lt;=d;k++)
    {
        for(i=0;i&amp;lt;radix;i++)
        {
            count[i]=0;
        }
        for(i=begin;i&amp;lt;=end;i++)
        {
            count[getdigit(arr[i], k)]++;    
        }    
        for(i=1;i&amp;lt;radix;i++)
        {
            count[i] = count[i] + count[i-1];
        }
        for(i=end;i&amp;gt;=end;--i)
        {
            j = getdigit(arr[i], k);
            bucket[count[j]-1] = arr[i];
            --count[j];
        }
        for(i=begin,j=0;i&amp;lt;=end;++i,++j)
        {
            arr[i] = bucket[j];
        }
    }
    free(bucket);    
}            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以，给定n个d位数，其中每一个数位有k个可能的取值，所以，每一轮排序耗时Θ(n+k)，那么整个基数排序的总时间为Θ(d(n+k))，当d为常数且k=O(n)时，基数排序具有线性的时间代价。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;以上三种线性时间排序方法突破了基于比较排序的O(NlogN)的时间下界，这样的非比较排序的方法会有一些使用场景的限制，比如元素的大小，所以，在特定的条件下，会体现出较好的性能。&lt;br&gt;本质上，都体现了用空间换时间的理念。        &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在计算机科学中，排序是一个非常基础的算法。不同的排序算法有不同的时间和空间开销。在这么多的排序算法中，根据在排序的最终结果中，各元素的次序是否依赖于它们之间的比较，可以将排序算法分为两大类：基于比较的排序和非基于比较的排序。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>从BlockingQueue再探线程同步</title>
    <link href="http://blog.dujiong.net/2016/08/26/muduo-7/"/>
    <id>http://blog.dujiong.net/2016/08/26/muduo-7/</id>
    <published>2016-08-26T05:18:11.000Z</published>
    <updated>2016-08-26T07:49:10.062Z</updated>
    
    <content type="html">&lt;p&gt;BlockingQueue（阻塞队列）在程序中被大量使用，特别是在多线程程序中，譬如需要提高吞吐量时采用将请求直接扔到阻塞队列中，然后返回，由其他线程从阻塞队列中获取请求再进一步处理。而经典的生产者-消费者模型，正是阻塞队列大放光彩之处。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Java中java.util.concurrent包便提供了BlockingQueue接口和其几种实现方式。muduo中也实现了无大小限制的BlockingQueue和固定大小的BoundedBlockingQueue。下面以BlockingQueue为例进行说明。     &lt;/p&gt;
&lt;h3 id=&quot;BlockingQueue的实现&quot;&gt;&lt;a href=&quot;#BlockingQueue的实现&quot; class=&quot;headerlink&quot; title=&quot;BlockingQueue的实现&quot;&gt;&lt;/a&gt;BlockingQueue的实现&lt;/h3&gt;&lt;p&gt;muduo中BlockingQueue的实现非常简单，队列采用C++标准库中的deque，无大小限制，唯一需要注意的是使用互斥锁和条件变量做好线程同步。&lt;br&gt;BlockingQueue实现时运用了模板。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class BlockingQueue : boost::noncopyable
{
    public:
        BlockingQueue() : mutex_(), notEmpty_(mutex_), queue_() {}

        void put(const T&amp;amp; x)
        {
            MutexLockGuard lock(mutex_);
            queue_.push_back(x);
            notEmpty_.notift();
        }    

        T take()
        {
            MutexLockGuard lock(mutex_);
            while(queue_.empty())    
            {
                notEmpty_.wait();
            }
            assert(!queue_.empty());
            T front(queue_.front());
            queue_.pop_front();
            return front;
        }

        size_t size() const
        {
            MutexLockGuard lock(mutex_);
            return queue_.size();
        }
    private:
        mutable MutexLock mutex_;
        Condition notEmpty_;
        std::deque&amp;lt;T&amp;gt; queue_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BlockingQueue提供了取元素(take)、放入元素(put)和取得队列大小(size)三个public成员函数完成对阻塞队列的操作。&lt;/p&gt;
&lt;h3 id=&quot;线程同步的一些细究&quot;&gt;&lt;a href=&quot;#线程同步的一些细究&quot; class=&quot;headerlink&quot; title=&quot;线程同步的一些细究&quot;&gt;&lt;/a&gt;线程同步的一些细究&lt;/h3&gt;&lt;p&gt;细究BlockingQueue的实现，可以总结并学习一些问题。&lt;/p&gt;
&lt;h4 id=&quot;spurious-wakeup&quot;&gt;&lt;a href=&quot;#spurious-wakeup&quot; class=&quot;headerlink&quot; title=&quot;spurious wakeup&quot;&gt;&lt;/a&gt;spurious wakeup&lt;/h4&gt;&lt;p&gt;首先是大名鼎鼎的spurious wakeup（虚假唤醒）。即对应代码中&lt;code&gt;while(queue_.empty())&lt;/code&gt;循环，可否改为&lt;code&gt;if(queue_.empty())&lt;/code&gt;？&lt;br&gt;答案是不能，否则会导致虚假唤醒，因为&lt;code&gt;notEmpty_.wait()&lt;/code&gt;封装的&lt;code&gt;pthread_cond_wait()&lt;/code&gt;不仅能被&lt;code&gt;pthread_cond_signal()/pthread_cond_broadcast()&lt;/code&gt;唤醒，而且还可能会被其他的信号唤醒，后者便是虚假唤醒，这时条件并不满足。所以，不仅要在&lt;code&gt;pthread_cond_wait()&lt;/code&gt;前检查条件是否成立，在&lt;code&gt;pthread_cond_wait()&lt;/code&gt;之后也要检查。 &lt;/p&gt;
&lt;h4 id=&quot;unlock和signal的顺序&quot;&gt;&lt;a href=&quot;#unlock和signal的顺序&quot; class=&quot;headerlink&quot; title=&quot;unlock和signal的顺序&quot;&gt;&lt;/a&gt;unlock和signal的顺序&lt;/h4&gt;&lt;p&gt;muduo中采用RAII手法封装了互斥器，所以，在进行put操作时，是先notify其他线程，再释放锁。那么反过来呢，先释放锁，再notify其他线程？这二者有什么差别呢？&lt;br&gt;先notify，再释放锁，在某些平台下存在性能问题，原因是，假设线程1阻塞在条件变量上wait，线程2将其唤醒（notify），系统执行上下文切换，但是线程2仍持有锁，导致线程1不能从&lt;code&gt;pthread_cond_wait()&lt;/code&gt;(需要持有锁)返回，所以线程1又阻塞在互斥锁上，直到线程2释放锁，线程1才可以运行。&lt;br&gt;福音是，对于此问题，Glibc中使用的线程库NPTL对此进行了优化。&lt;br&gt;另一种情况是先释放锁，再notify，这样可以避免上述问题，但是，这样可能会唤醒其他阻塞在此mutex上的线程，而不是处于wait条件变量的线程，所以，这种情况下，在唤醒之后，最好还得再check下predicate（类似于spurious wakeup）。&lt;br&gt;所以，Pthreads实现平台下，建议使用第一种方法，可以避免一些&lt;a href=&quot;http://www.domaigne.com/blog/computing/condvars-signal-with-mutex-locked-or-not/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;obscure bugs&lt;/a&gt;,除非采用第二种有较明显的性能的提升。&lt;/p&gt;
&lt;h4 id=&quot;Linux快速同步机制（Futex）&quot;&gt;&lt;a href=&quot;#Linux快速同步机制（Futex）&quot; class=&quot;headerlink&quot; title=&quot;Linux快速同步机制（Futex）&quot;&gt;&lt;/a&gt;Linux快速同步机制（Futex）&lt;/h4&gt;&lt;p&gt;Futex（Fast Userspace mutexes，快速用户空间互斥体），是在Linux上实现锁定和构建高级抽象锁如信号量和POSIX互斥的基本工具，首先出现在Linux 2.5.7版。&lt;br&gt;在传统的Unix系统中，System V IPC，如消息队列，信号量，socket等进程间同步机制都是对一个内核对象操作来完成的，这个内核对象对于要同步的进程都是可见的，其提供了共享的状态信息和原子操作。当进程间要同步的时候必须要通过系统调用在内核中完成。可是研究发现，很多同步状态是无竞争的，即某个进程进入互斥去，到从互斥区出来这段时间，常常是没有进程进也要进入这个互斥区或者请求同一个同步变量的。而这种情况下，进程也要陷入到内核去看有没有竞争者，退出的时候还要陷入内核去看有没有进程等待在同一变量上。这些不必要的系统调用（陷入内核）造成了大量的性能开销。&lt;br&gt;而Futex就是在这样的背景下被提出的，以减少不必要的系统调用（内核陷入）。Funtex是一种用户态和内核态混合的同步机制。首先，同步的进程间通过mmap共享一段内存，Futex变量就位于这段共享的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex，而不用再执行系统调用了。当通过访问futex变量告诉进程有竞争发生，再去执行系统调用以完成相应的处理。futex通过这样的机制，大大提高了low-contention时的效率。     &lt;/p&gt;
&lt;h5 id=&quot;Futex机制&quot;&gt;&lt;a href=&quot;#Futex机制&quot; class=&quot;headerlink&quot; title=&quot;Futex机制&quot;&gt;&lt;/a&gt;Futex机制&lt;/h5&gt;&lt;p&gt;所有的Futex同步操作都从用户空间开始，首先创建一个futex同步变量，也就是位于共享内存的一个整型计数器。&lt;br&gt;当进程尝试持有锁或者要进入互斥区的时候，对futex执行”down”操作，即原子性的给futex同步变量减1。如果同步变量变为0，则没有竞争发生，进程照常执行。如果同步变量是个负数，则意味着有竞争发生，需要调用futex系统调用的futex_wait操作休眠当前进程。&lt;br&gt;当进程释放锁或者要离开互斥区的时候，对futex进行”up”操作，即原子性的给futex同步变量加1。如果同步变量由0变成1，则没有竞争发生，进程照常执行。如果加之前同步变量是负数，则意味着有竞争发生，需要调用futex系统调用的futex_wake操作唤醒一个或者多个等待进程。&lt;br&gt;这里的原子性加减通常是用CAS(Compare and Swap)完成的，与平台相关。CAS的基本形式是：CAS(addr,old,new),当addr中存放的值等于old时，用new对其替换。在x86平台上有专门的一条指令来完成它: cmpxchg。    &lt;/p&gt;
&lt;h5 id=&quot;Linux下使用glibc开发&quot;&gt;&lt;a href=&quot;#Linux下使用glibc开发&quot; class=&quot;headerlink&quot; title=&quot;Linux下使用glibc开发&quot;&gt;&lt;/a&gt;Linux下使用glibc开发&lt;/h5&gt;&lt;p&gt;上面讲了很多关于Futex的机制，重点是弄清楚其中的原理和思想，我们在实际的多线程程序开发中却没有必要去实现自己的futex同步原语。&lt;br&gt;因为NPTL库实现了POSIX标准定义的线程同步机制，他们都构造与futex之上，而glibc又使用NPTL作为自己的线程库。所以，在日常程序开发中，只需要正确地使用glibc所提供的同步方式，并在使用它们的过程中，意识到它们是利用futex机制和linux配合完成同步操作，重点是思想。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;BlockingQueue（阻塞队列）在程序中被大量使用，特别是在多线程程序中，譬如需要提高吞吐量时采用将请求直接扔到阻塞队列中，然后返回，由其他线程从阻塞队列中获取请求再进一步处理。而经典的生产者-消费者模型，正是阻塞队列大放光彩之处。&lt;br&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
      <category term="多线程" scheme="http://blog.dujiong.net/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>单例模式</title>
    <link href="http://blog.dujiong.net/2016/08/21/Singleton/"/>
    <id>http://blog.dujiong.net/2016/08/21/Singleton/</id>
    <published>2016-08-21T13:57:13.000Z</published>
    <updated>2016-08-26T08:23:05.770Z</updated>
    
    <content type="html">&lt;p&gt;单例（Singleton）模式可能是被使用最广泛的一个设计模式之一，也可能是面试中被问到或被要求书写最多的一个设计模式了。该设计模式的主要目的是要求在整个系统中只出现一个类的实例。&lt;br&gt;下面采用Java语言描述单例模式的几种实现方式。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h3 id=&quot;懒汉-amp-amp-线程不安全&quot;&gt;&lt;a href=&quot;#懒汉-amp-amp-线程不安全&quot; class=&quot;headerlink&quot; title=&quot;懒汉&amp;amp;&amp;amp;线程不安全&quot;&gt;&lt;/a&gt;懒汉&amp;amp;&amp;amp;线程不安全&lt;/h3&gt;&lt;p&gt;懒汉式单例在调用取得实例方法的时候实例化对象。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton{
    private staic Singleton singleton = null;
    private Singleton()　{ }
    public static Singleton getInstance(){
        if(singleton == null){
            singleton = new Singleton();
        }
        return singleton;        
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从代码中可以看出，采用私有的构造函数，表明这个类是不可能形成实例了，这样可以防止类出现多个实例。所以，采用一个静态的方式（getInstance()）来让其形成实例。在getInstance()方法中，先判断是否已经形成实例，如果已经形成则直接返回，否则创建实例，保存在自己类的私有成员中。&lt;br&gt;但是，问题来了，因为是全局性的实例，这种方式最大的问题就是不支持多线程，在多线程情况下，多个线程同时调用getInstance()的话，那么，可能会有多个线程同时通过(singleton == null)的条件检查，最终创建出多个实例。所以，应加入同步机制以适应多线程环境。    &lt;/p&gt;
&lt;h3 id=&quot;懒汉-amp-amp-线程安全&quot;&gt;&lt;a href=&quot;#懒汉-amp-amp-线程安全&quot; class=&quot;headerlink&quot; title=&quot;懒汉&amp;amp;&amp;amp;线程安全&quot;&gt;&lt;/a&gt;懒汉&amp;amp;&amp;amp;线程安全&lt;/h3&gt;&lt;p&gt;所以，加入synchronized做同步。得到如下所示的线程安全版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton{
    private static Singleton singleton = null;
    private Singleton() { }
    public static synchronized Singleton getInstance(){
        if(singleton == null){
            singleton = new Singleton();
        }
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;饿汉&quot;&gt;&lt;a href=&quot;#饿汉&quot; class=&quot;headerlink&quot; title=&quot;饿汉&quot;&gt;&lt;/a&gt;饿汉&lt;/h3&gt;&lt;p&gt;饿汉式单例在单例类被加载的时候，就实例化一个对象交给自己的引用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton {
    private static final Singleton singleton = new Singleton();
    private Singleton(){ } 
    public static Singleton getInstance(){
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这种方式在实际中比较常用，基于classloader机制避免了多线程的同步问题，没有加锁，执行效率较高。但是，仍美中不足的是：singleton在类加载的时候就实例化，这样就算是getInstance()没有被调用，类也被初始化了。这样的话，有时会与我们想要的行为不一样，比如，在类的构造函数中，有一些事需要依赖于别的类，我们希望它能在第一次getInstance()时才被真正创建。这样，可以自己控制真正的类创建的时刻，而不是把类的创建委托给类装载器。&lt;br&gt;所以又出现了下面这种方式。&lt;/p&gt;
&lt;h3 id=&quot;静态内部类&quot;&gt;&lt;a href=&quot;#静态内部类&quot; class=&quot;headerlink&quot; title=&quot;静态内部类&quot;&gt;&lt;/a&gt;静态内部类&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public class Singleton{
    private static class SingletonHolder{
        private static Singleton singleton = new Singleton();
    }        
    private Singleton() { }
    public static Singleton getInstance(){
        return SingletonHolder.singleton;
    } 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样的话，由于SingletonHolder是私有的，除了getInstance()之外没有方法访问它，因此只有在getInstance()被调用时才会真正创建。&lt;/p&gt;
&lt;h3 id=&quot;双重锁校验锁&quot;&gt;&lt;a href=&quot;#双重锁校验锁&quot; class=&quot;headerlink&quot; title=&quot;双重锁校验锁&quot;&gt;&lt;/a&gt;双重锁校验锁&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public class Singleton{
    private volatile static Singleton singleton = null;
    private Singleton() { }
    public static Singleton getInstance(){
        if(singleton == null){
            synchronized(Singleton.class){
                if(singleton == null){
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一个if判定是说，如果实例创建了，就不需要同步了，直接return singleton就可以了。不然的话，就开始同步线程。第二个if判定是说，如果被同步的线程中，已经创建了对象，那么就不用创建了。这样，保证了多线程条件下的安全。&lt;br&gt;此外，由于&lt;code&gt;singleton = new Singleton();&lt;/code&gt;不是原子操作，所以使用volatile关键字禁止指令重排序优化。&lt;/p&gt;
&lt;h3 id=&quot;枚举&quot;&gt;&lt;a href=&quot;#枚举&quot; class=&quot;headerlink&quot; title=&quot;枚举&quot;&gt;&lt;/a&gt;枚举&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public enum Singleton{
    INSTANCE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，简直不要太简单哦！是的，虽然他可能还包含实例变量和实例方法。默认枚举实例的创建是线程安全的，所以不需要担心线程安全的问题。当然，需要自行负责枚举中的其他任何方法的线程安全。&lt;br&gt;这样，通过Singleton.INSTANCE来访问，这比上述的getInstance()方法简单多了。而且，更重要的是，枚举单例，JVM对序列化有保证。 &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;总结一下上述的单例模式实现，一般情况下，不建议使用两种懒汉方式，建议使用饿汉方式。当要求延迟加载时，使用静态内部类形式。而如果涉及到反序列化创建对象时，可以尝试用枚举方式。   &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;单例（Singleton）模式可能是被使用最广泛的一个设计模式之一，也可能是面试中被问到或被要求书写最多的一个设计模式了。该设计模式的主要目的是要求在整个系统中只出现一个类的实例。&lt;br&gt;下面采用Java语言描述单例模式的几种实现方式。&lt;br&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="http://blog.dujiong.net/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>shared_ptr的注意事项</title>
    <link href="http://blog.dujiong.net/2016/08/08/shared-ptr/"/>
    <id>http://blog.dujiong.net/2016/08/08/shared-ptr/</id>
    <published>2016-08-08T13:38:44.000Z</published>
    <updated>2016-08-27T13:24:49.329Z</updated>
    
    <content type="html">&lt;p&gt;前面在&lt;a href=&quot;http://blog.dujiong.net/2016/05/15/cplusplus-sematics/&quot;&gt;浅谈C++值语义和对象语义&lt;/a&gt;一文中简要的阐述了一下智能指针shared_ptr的作用和用法，作为C++11中最为广泛使用的智能指针，shared_ptr虽然解决了裸指针的诸多问题，但是它并非完美、无懈可击，所以，本文就shared_ptr使用过程中需要注意的一些问题做一下总结。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;循环引用&quot;&gt;&lt;a href=&quot;#循环引用&quot; class=&quot;headerlink&quot; title=&quot;循环引用&quot;&gt;&lt;/a&gt;循环引用&lt;/h3&gt;&lt;p&gt;首当其冲的便是shared_ptr造成的循环引用。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class BaseClass;
class DerivedClass;

typedef std::shared_ptr&amp;lt;BaseClass&amp;gt; BaseClassPtr;
typedef std::shared_ptr&amp;lt;DerivedClass&amp;gt; DerivedClassPtr;

class BaseClass
{
    public:
        DerivedClassPtr derivedPtr;
        ~BaseClass()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~BaseClass()&amp;quot; &amp;lt;&amp;lt; endl;
        }
};

class DerivedClass
{
    public:
        BaseClassPtr basePtr;
        ~DerivedClass()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~DerivedClass()&amp;quot; &amp;lt;&amp;lt; endl;
        }
};

int main()
{
    BaseClassPtr base(new BaseClass());
    DerivedClassPtr derived(new DerivedClass());

    base-&amp;gt;derivedPtr = derived;
    derived-&amp;gt;basePtr = base;

    cout &amp;lt;&amp;lt; base.use_count() &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; derived.use_count() &amp;lt;&amp;lt; endl;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;程序运行结果如下。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/dqHRq8F.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果可以看出，堆上的BaseClass和DerivedClass都没有被析构，因为二者的引用都为1，并形成了循环引用，类似于“放开我的引用”，“你先放开我的我就放你的”的恶性循环，所以，造成了内存泄露。&lt;br&gt;解决方法是使用弱智能指针weak_ptr，让BaseClass和DerivedClass分别持有对方的weak_ptr，而不是shared_ptr，weak_ptr也是一个引用计数型智能指针，但是它不增加对象的引用计数。这样，就可以保证内存正常释放。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/cG2fmZx.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;h3 id=&quot;线程安全&quot;&gt;&lt;a href=&quot;#线程安全&quot; class=&quot;headerlink&quot; title=&quot;线程安全&quot;&gt;&lt;/a&gt;线程安全&lt;/h3&gt;&lt;p&gt;shared_ptr是引用计数型智能指针，几乎所有的实现都采用在堆上存放计数值的方法。具体来说，shared_ptr&lt;foo&gt;包含两个成员，一个是指向Foo的指针ptr，另一个是ref_count指针（不一定是原始指针），指向堆上的ref_count对象。ref_count对象有多个成员。&lt;/foo&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/WZNNAPg.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以，如果执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shared_ptr&amp;lt;Foo&amp;gt; x(new Foo);
shared_ptr&amp;lt;Foo&amp;gt; y = x;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;y=x将会涉及两个成员的拷贝,ptr和ref_count指针。这两步不是原子的，所以在多线程中会有race condition，需要加锁保护。     &lt;/p&gt;
&lt;h3 id=&quot;内存多次释放&quot;&gt;&lt;a href=&quot;#内存多次释放&quot; class=&quot;headerlink&quot; title=&quot;内存多次释放&quot;&gt;&lt;/a&gt;内存多次释放&lt;/h3&gt;&lt;p&gt;shared_ptr多次引用同一数据会导致内存多次释放。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

int main()
{
    int* ptr = new int(100);
    std::shared_ptr sptr1(ptr);
    ...
    std::shared_ptr sptr2(ptr);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只分配了一次内存，却两次释放。&lt;/p&gt;
&lt;h3 id=&quot;enable-shared-from-this&quot;&gt;&lt;a href=&quot;#enable-shared-from-this&quot; class=&quot;headerlink&quot; title=&quot;enable_shared_from_this&quot;&gt;&lt;/a&gt;enable_shared_from_this&lt;/h3&gt;&lt;p&gt;当使用智能指针时，类的某些成员函数需要返回的是管理自身的shared_ptr，这时就需要使A继承自enable_shared_from_this（顾名思义，将this指针变身为shared_ptr），然后通过其成员函数shared_from_this()返回指向自身的shared_ptr。      &lt;/p&gt;
&lt;p&gt;首先看没有使用它会发生什么？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class A
{
    public:
        ~A()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~A()&amp;quot; &amp;lt;&amp;lt; endl;
        }
        shared_ptr&amp;lt;A&amp;gt; get_sptr()
        {
            return shared_ptr&amp;lt;A&amp;gt;(this);
        }
};

int main()
{
    shared_ptr&amp;lt;A&amp;gt; a(new A());
    shared_ptr&amp;lt;A&amp;gt; b = a-&amp;gt;get_sptr();

    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/21rnuTE.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以看出，只new了一个A对象，但是却调用了两次析构函数。产生这个错误的原因get_sptr()成员函数中将shared_ptr中的引用计数器的值加了1。所以，需要解决的是，怎样通过一个类的成员函数获取当前对象的shared_ptr？&lt;br&gt;方法就是使类继承enable_shared_from_this，然后在需要shared_ptr的地方调用其成员函数shared_from_this()即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class A : public enable_shared_from_this&amp;lt;A&amp;gt;
{
    public:
        ~A()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~A()&amp;quot; &amp;lt;&amp;lt; endl;
        }
        shared_ptr&amp;lt;A&amp;gt; get_sptr()
        {
            return shared_from_this();
        }
};

int main()
{
    shared_ptr&amp;lt;A&amp;gt; a(new A());
    shared_ptr&amp;lt;A&amp;gt; b = a-&amp;gt;get_sptr();

    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/ZuA23y9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;需要注意的是，不能在构造函数中使用&lt;code&gt;shared_from_this()&lt;/code&gt;，因为虽然对象的基类&lt;code&gt;enable_shared_from_this&lt;/code&gt;的构造函数已经调用，但是&lt;code&gt;shared_ptr&lt;/code&gt;的构造函数并没有调用，所以这个时候调用&lt;code&gt;shared_from_this()&lt;/code&gt;是错的。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;智能指针虽好，但也并非完美，在使用的过程中还是需要注意。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;前面在&lt;a href=&quot;http://blog.dujiong.net/2016/05/15/cplusplus-sematics/&quot;&gt;浅谈C++值语义和对象语义&lt;/a&gt;一文中简要的阐述了一下智能指针shared_ptr的作用和用法，作为C++11中最为广泛使用的智能指针，shared_ptr虽然解决了裸指针的诸多问题，但是它并非完美、无懈可击，所以，本文就shared_ptr使用过程中需要注意的一些问题做一下总结。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
</feed>
