<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一期一会</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.dujiong.net/"/>
  <updated>2016-11-30T13:21:20.180Z</updated>
  <id>http://blog.dujiong.net/</id>
  
  <author>
    <name>dujiong</name>
    <email>dujiong.uestc@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>协程</title>
    <link href="http://blog.dujiong.net/2016/12/03/Coroutine/"/>
    <id>http://blog.dujiong.net/2016/12/03/Coroutine/</id>
    <published>2016-12-03T10:41:42.000Z</published>
    <updated>2016-11-30T13:21:20.180Z</updated>
    
    <content type="html">&lt;p&gt;协程，顾名思义，是“协作的例程”。跟具有操作系统概念的线程不一样，协程是在用户空间利用程序语言的语法语义就能实现逻辑上类似多任务的编程技巧。协程可以在运行期间的某个点上暂停执行，并在恢复运行时从暂停的点上继续执行。协程已经被证明是一种非常有用的程序组件，不仅被Python、lua、ruby等脚本语言广泛语言，还被新一代面多核的编程语言如golang等作为并发的基本单位。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;   &lt;/p&gt;
&lt;h3 id=&quot;协程的特点&quot;&gt;&lt;a href=&quot;#协程的特点&quot; class=&quot;headerlink&quot; title=&quot;协程的特点&quot;&gt;&lt;/a&gt;协程的特点&lt;/h3&gt;&lt;p&gt;协程的调度完全由用户控制，一个线程可以有多个协程，每个协程都是循环按照指定的任务清单顺序完成不同的任务，当任务被阻塞的时候执行下一个任务，当恢复的时候再回来执行这个任务，任务之间的切换只需要保存每个任务的上下文内容，就像直接操作栈一样，这样就完全没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。&lt;br&gt;因此，与传统的抢占式线程相比，协程主要具有以下两个优点：&lt;br&gt;（1）与线程不同，线程是自己主动让出CPU，并交付它期望的下一个协程运行，而不是在任何时候都有可能被系统调度打断。因此协程的使用更加清晰易懂，并且大多数情况下不需要锁机制。&lt;br&gt;（2）与线程相比，协程的切换由程序控制，发生在用户空间而非内核空间，因此切换的代价非常小。    &lt;/p&gt;
&lt;h3 id=&quot;进程与线程&quot;&gt;&lt;a href=&quot;#进程与线程&quot; class=&quot;headerlink&quot; title=&quot;进程与线程&quot;&gt;&lt;/a&gt;进程与线程&lt;/h3&gt;&lt;p&gt;下面简单回顾下进程与线程的概念。   &lt;/p&gt;
&lt;h4 id=&quot;进程&quot;&gt;&lt;a href=&quot;#进程&quot; class=&quot;headerlink&quot; title=&quot;进程&quot;&gt;&lt;/a&gt;进程&lt;/h4&gt;&lt;p&gt;进程是具有一定独立功能的程序关于某个数据集合上的一次活动，进程是系统进行资源分配和调度的单位。&lt;br&gt;进程之间不共享任何状态，进程的调度由操作系统完成，每个进程都有自己的独立的内存空间，而进程间的通信主要是通过信号传递的方式来实现的，实现的方式有多种，如信号量、管道等，但是任何一种方式的通信都需要通过内核，因此效率比较低。同时，由于进程拥有的是独立的内存空间，所以在进行上下文切换的时候需要先保存调用栈的信息，CPU各寄存器的信息，虚拟内存以及打开的句柄等信息，所以导致进程间切换开销很大。&lt;/p&gt;
&lt;h4 id=&quot;线程&quot;&gt;&lt;a href=&quot;#线程&quot; class=&quot;headerlink&quot; title=&quot;线程&quot;&gt;&lt;/a&gt;线程&lt;/h4&gt;&lt;p&gt;线程是进程的一个实体，是CPU调度的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点再运行中比不可少的资源（如程序计数器、一些寄存器和栈），它与同一个进程的其他线程共享所拥有的全部资源。&lt;br&gt;线程之间共享变量，解决了通信麻烦的问题，但同时，多个线程对变量的访问需要进行同步与互斥操作。线程的调度也主要由操作系统完成，一个进程可以拥有多个线程，每个线程会共享父进程向操作系统申请的资源，包括虚拟内存，文件等，因此创建线程所需的资源要比进程小很多，相应的可创建的线程数量也变得多很多。线程之间的通信除了可以使用进程之间通信的方式之外还可以通过共享内存的方式，此外，在线程调度方面，由于线程间共享进程的资源，所以上下文切换的时候需要保存的东西相对少些，上下文也因此高效一些。     &lt;/p&gt;
&lt;h3 id=&quot;构建C协程&quot;&gt;&lt;a href=&quot;#构建C协程&quot; class=&quot;headerlink&quot; title=&quot;构建C协程&quot;&gt;&lt;/a&gt;构建C协程&lt;/h3&gt;&lt;p&gt;C/C++不直接支持协程语义，但目前已有不少开源的协程库，本文以其中最常用的使用glibc的ucontext组件的实现方式进行说明。&lt;/p&gt;
&lt;h4 id=&quot;ucontext组件&quot;&gt;&lt;a href=&quot;#ucontext组件&quot; class=&quot;headerlink&quot; title=&quot;ucontext组件&quot;&gt;&lt;/a&gt;ucontext组件&lt;/h4&gt;&lt;p&gt;ucontext组件是GNU C库提供的一组用于创建、保存、切换用户态执行”上下文”的API。主要包括以下两个结构体和四个函数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//mcontest_t类型与机器相关，并且不透明
typedef struct ucontext {
    struct ucontext* uc_link;    //链接下一个执行的上下文
    sigset_t uc_sigmask;    //阻塞信号集合
    stack_t uc_stack;        //该上下文中使用的栈
    mcontext_t uc_mcontest;
    ...
} ucontext_t;

//初始化一个ucontext_t类型的结构，即用户执行上下文。
//函数指针func指明了该context的入口函数，argc指入口参数个数    
void makecontext(ucontext_t *ucp, void (*func)(), int argc, ...);
//&amp;quot;原子&amp;quot;地完成旧状态的保存和切换到新状态的工作
int swapcontext(ucontext_t *oucp, ucontext_t *ucp);
//将当前执行上下文保存到ucp中，若后续调用setcontext或swapcontext恢复状态，
//则程序会沿着getcontext调用点之后继续执行，看起来好像刚从getcontext函数返回一样。
int getcontext(ucontext_t *ucp);
//将当前程序执行线索切换到ucp所指向的上下文状态，
//在执行正确的情况下，该函数直接切入到新的执行状态，不再回返回
int setcontext(const ucontext_t *ucp);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;来看一个简单的实例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;ucontext.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

int main()
{
    ucontext_t context;

    getcontext(&amp;amp;context);    
    puts(&amp;quot;hello world&amp;quot;);
    sleep(1);
    setcontext(&amp;amp;context);
    return 0;
}         
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果如下：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/SvtkRI7.png&quot; alt=&quot;&quot;&gt;               &lt;/p&gt;
&lt;p&gt;程序通过getcontext保存了一个上下文，然后输出”hello world”，睡一秒后执行到setcontext，恢复上下文到getcontext之后，重新执行代码，所以程序不断输出“hello world”。   &lt;/p&gt;
&lt;h4 id=&quot;使用ucontext实现线程切换&quot;&gt;&lt;a href=&quot;#使用ucontext实现线程切换&quot; class=&quot;headerlink&quot; title=&quot;使用ucontext实现线程切换&quot;&gt;&lt;/a&gt;使用ucontext实现线程切换&lt;/h4&gt;&lt;p&gt;虽然我们称协程是一个用户态的轻量级线程，但实际上多个协程同属于一个线程。任意一个时刻，同一个线程不可能同时运行两个协程。&lt;br&gt;接下来通过一个实例说明协程与主函数的切换，即实现协程的调度。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;ucontext.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

void func1(void *arg)
{
    puts(&amp;quot;1&amp;quot;);
    puts(&amp;quot;11&amp;quot;);
    puts(&amp;quot;111&amp;quot;);
    puts(&amp;quot;1111&amp;quot;);
}

void context_test()
{
    char stack[1024*128];
    ucontext_t child, main;
    getcontext(&amp;amp;child);
    child.uc_stack.ss_sp = stack;
    child.uc_stack.ss_size = sizeof(stack);
    child.uc_link = &amp;amp;main;
    makecontext(&amp;amp;child, (void (*)(void))func1, 0);
    swapcontext(&amp;amp;main, &amp;amp;child);
    puts(&amp;quot;main&amp;quot;);
}

int main()
{
    context_test();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/FbFrKKW.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在context_test中，创建了一个用户线程（协程）child，其运行的函数为func1，指定后继上下文为main，当func1返回后激活后继上下文，继续执行main函数。&lt;/p&gt;
&lt;h3 id=&quot;开源C-C-协程库&quot;&gt;&lt;a href=&quot;#开源C-C-协程库&quot; class=&quot;headerlink&quot; title=&quot;开源C/C++协程库&quot;&gt;&lt;/a&gt;开源C/C++协程库&lt;/h3&gt;&lt;p&gt;最后，罗列几个比较出名的开源C/C++协程库，后面争取再深入学习下。&lt;br&gt;libco： &lt;a href=&quot;http://code.tencent.com/libco.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;腾讯的开源协程库&lt;/a&gt;&lt;br&gt;coroutine: &lt;a href=&quot;https://github.com/cloudwu/coroutine/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;云风大牛的作品&lt;/a&gt;&lt;br&gt;Protothreads: &lt;a href=&quot;http://coolshell.cn/articles/10975.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;一个”蝇量级”C语言协程库&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;协程，顾名思义，是“协作的例程”。跟具有操作系统概念的线程不一样，协程是在用户空间利用程序语言的语法语义就能实现逻辑上类似多任务的编程技巧。协程可以在运行期间的某个点上暂停执行，并在恢复运行时从暂停的点上继续执行。协程已经被证明是一种非常有用的程序组件，不仅被Python、lua、ruby等脚本语言广泛语言，还被新一代面多核的编程语言如golang等作为并发的基本单位。&lt;br&gt;
    
    </summary>
    
    
      <category term="进程/线程/并发" scheme="http://blog.dujiong.net/tags/%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B-%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Redis两种持久化方式比较</title>
    <link href="http://blog.dujiong.net/2016/11/30/Redis-RDB-AOF/"/>
    <id>http://blog.dujiong.net/2016/11/30/Redis-RDB-AOF/</id>
    <published>2016-11-30T09:14:03.000Z</published>
    <updated>2016-12-05T09:10:53.872Z</updated>
    
    <content type="html">&lt;p&gt;本文对前面所述的Redis两种持久化方式RDB和AOF做简单总结和比较。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;RDB和AOF简单总结&quot;&gt;&lt;a href=&quot;#RDB和AOF简单总结&quot; class=&quot;headerlink&quot; title=&quot;RDB和AOF简单总结&quot;&gt;&lt;/a&gt;RDB和AOF简单总结&lt;/h3&gt;&lt;p&gt;RDB持久化可以在指定的时间间隔内生成数据集的时间点快照，保存的是该时间点Redis在内存中的数据库状态。&lt;br&gt;AOF持久化记录的是服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾。Redis还可以在后台对AOF文件进行重写，使得AOF文件的体积不会超出保存数据集状态所需的实际大小。Redis可以同时使用AOF持久化和RDB持久化，在这种情况下，当Redis重启下，它会优先使用AOF来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。           &lt;/p&gt;
&lt;h3 id=&quot;RDB&quot;&gt;&lt;a href=&quot;#RDB&quot; class=&quot;headerlink&quot; title=&quot;RDB&quot;&gt;&lt;/a&gt;RDB&lt;/h3&gt;&lt;h4 id=&quot;RDB的优点&quot;&gt;&lt;a href=&quot;#RDB的优点&quot; class=&quot;headerlink&quot; title=&quot;RDB的优点&quot;&gt;&lt;/a&gt;RDB的优点&lt;/h4&gt;&lt;p&gt;RDB是一个非常紧凑的文件，它保存了Redis在某个时间点上的数据集，这种文件非常适合进行备份。比如，可以在一天内，每小时备份RDB文件，并在每月的每一天，也备份一个RDB文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB非常适用于灾难恢复，它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。RDB可以最大化Redis的性能：父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/O操作。RDB在恢复大数据集时的速度比AOF的恢复速度要快。          &lt;/p&gt;
&lt;h4 id=&quot;RDB的缺点&quot;&gt;&lt;a href=&quot;#RDB的缺点&quot; class=&quot;headerlink&quot; title=&quot;RDB的缺点&quot;&gt;&lt;/a&gt;RDB的缺点&lt;/h4&gt;&lt;p&gt;如果需要尽量避免在服务器故障时丢失数据，那么RDB不适合。因为，虽然Redis允许设置不同的保存点来控制保存RDB文件的频率，但是，因为RDB文件需要保存整个数据集的状态，所以它并不是一个轻松的操作。因此，可能会至少需要5分钟才保存一次RDB文件。这种情况下，一旦出现故障停机，那么便会丢失几分钟的数据。此外，每次保存RDB的时候，Redis都要fork出一个子进程，并由子进程来进行实际的持久化工作。当数据集比较庞大的时候，fork过程会非常耗时，造成服务器端在短时间内停止处理客户端。虽然AOF重写也需要进行fork，但无论fork重写的执行间隔有多长，数据的耐久性都不会有任何损失。&lt;/p&gt;
&lt;h3 id=&quot;AOF&quot;&gt;&lt;a href=&quot;#AOF&quot; class=&quot;headerlink&quot; title=&quot;AOF&quot;&gt;&lt;/a&gt;AOF&lt;/h3&gt;&lt;h4 id=&quot;AOF的优点&quot;&gt;&lt;a href=&quot;#AOF的优点&quot; class=&quot;headerlink&quot; title=&quot;AOF的优点&quot;&gt;&lt;/a&gt;AOF的优点&lt;/h4&gt;&lt;p&gt;使用AOF持久化会让Redis变得非常耐久，AOF支持设置不同的fsync策略，比如每秒钟fsync、每次执行写命令时fsync。AOF的默认策略为每秒钟fsync一次，在这种配置下，Redis仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（fsync会在后台进程执行，所以主进程可以继续处理命令请求）。另外，AOF文件是一个只进行追加操作的日志文件，因此对AOF文件的写入不需要进行seek，即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机），redis-check-aof工具也可以轻易地修复这种问题。Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写，重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建AOF文件的过程中，会继续将命令追加到现有的AOF文件里面，即使重写过程中发生停机，现有的AOF文件也不会丢失。而一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。AOF文件有序地保存了对数据库执行的所有写操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很轻松。比如，如果不小心执行了FLUSHALL命令，但只要AOF文件未被重写，那么只要停止服务器，移除AOF文件末尾的FLUSHALL命令，并重启Redis，就可以将数据集恢复到执行FLUSHALL之前的状态。           &lt;/p&gt;
&lt;h4 id=&quot;AOF的缺点&quot;&gt;&lt;a href=&quot;#AOF的缺点&quot; class=&quot;headerlink&quot; title=&quot;AOF的缺点&quot;&gt;&lt;/a&gt;AOF的缺点&lt;/h4&gt;&lt;p&gt;对同样的数据集，AOF文件通常要大于等价的RDB文件。&lt;br&gt;AOF可能比RDB慢，这取决于具体的fsync策略。&lt;br&gt;另外，Redis AOF是通过递增地更新一个已经存在的状态，而RDB快照则是一次又一次地从头开始创造一切，概念上更健壮。&lt;/p&gt;
&lt;h3 id=&quot;二者的使用&quot;&gt;&lt;a href=&quot;#二者的使用&quot; class=&quot;headerlink&quot; title=&quot;二者的使用&quot;&gt;&lt;/a&gt;二者的使用&lt;/h3&gt;&lt;p&gt;一般来说，如果想达到很高的数据安全性，那么应该同时使用两种持久化功能。如果可以承受数分钟以内的数据丢失，那么可以只使用RDB持久化。但是不建议只是用AOF持久化：因为定时生成RDB快照非常便于进行数据库备份，并且RDB恢复数据集的速度也要比AOF恢复的速度要快。&lt;/p&gt;
&lt;h3 id=&quot;其他一些问题&quot;&gt;&lt;a href=&quot;#其他一些问题&quot; class=&quot;headerlink&quot; title=&quot;其他一些问题&quot;&gt;&lt;/a&gt;其他一些问题&lt;/h3&gt;&lt;h4 id=&quot;RDB设置&quot;&gt;&lt;a href=&quot;#RDB设置&quot; class=&quot;headerlink&quot; title=&quot;RDB设置&quot;&gt;&lt;/a&gt;RDB设置&lt;/h4&gt;&lt;p&gt;在默认情况下，Redis将数据库快照保存dump.rdb的二进制文件中。可以对Redis进行设置，让它在“N秒内数据集至少有M个改动”这样的条件满足时，自动保存一次数据集。此外，还可以使用SAVE或BGSAVE手动对Redis进行数据集保存操作。&lt;/p&gt;
&lt;h4 id=&quot;AOF文件出错&quot;&gt;&lt;a href=&quot;#AOF文件出错&quot; class=&quot;headerlink&quot; title=&quot;AOF文件出错&quot;&gt;&lt;/a&gt;AOF文件出错&lt;/h4&gt;&lt;p&gt;服务器可能在程序正在对AOF文件进行写入时停机，如果停机造成了AOF文件出错，那么Redis在重启时会拒绝载入这个AOF文件，从而确保数据的一致性不会被破坏。&lt;br&gt;当发生这种情况时，可以为现有的AOF文件创建一个备份，然后使用Redis附带的redis-check-aof程序，对原来的AOF文件进行修复，并查看两个文件的不同之处，最后重启Redis服务器，等待服务器载入修复后的AOF文件，并进行数据恢复。&lt;/p&gt;
&lt;h4 id=&quot;RDB和AOF之间的相互作用&quot;&gt;&lt;a href=&quot;#RDB和AOF之间的相互作用&quot; class=&quot;headerlink&quot; title=&quot;RDB和AOF之间的相互作用&quot;&gt;&lt;/a&gt;RDB和AOF之间的相互作用&lt;/h4&gt;&lt;p&gt;在版本大于等于2.4的Redis中，BGSAVE执行的过程中，不可以执行BGREWRITEAOF。同样，在执行BGREWRITEAOF的过程中，也不可执行BGSAVE。这样主要是防止两个Redis后台进程同时对磁盘进行大量的I/O操作。&lt;br&gt;如果BGSAVE正在执行，并且用户显示地调用BGREWRITEAOF命令， 那么服务器将向用户回复一个OK状态，并告知用户，BGREWRITEAOF已经被预定执行：一旦BGSAVE执行完毕，BGREWRITEAOF就会正式开始。&lt;br&gt;当Redis启动时，如果RDB持久化和AOF持久化都打开了，那么程序会优先使用AOF文件来恢复数据集，因为AOF文件所保存的数据通常是最完整的。&lt;/p&gt;
&lt;h4 id=&quot;RDB备份数据&quot;&gt;&lt;a href=&quot;#RDB备份数据&quot; class=&quot;headerlink&quot; title=&quot;RDB备份数据&quot;&gt;&lt;/a&gt;RDB备份数据&lt;/h4&gt;&lt;p&gt;Redis对于数据备份是非常友好的，可以在服务器运行的时候对 RDB 文件进行复制：RDB文件一旦被创建，就不会进行任何修改。当服务器要创建一个新的RDB文件时，它先将文件的内容保存在一个临时文件里，当临时文件写入完毕时，程序才原子地使用临时文件替换原来的RDB文件。即，无论何时，复制RDB文件都是绝对安全的。&lt;/p&gt;
&lt;p&gt;参考： &lt;a href=&quot;https://segmentfault.com/a/1190000005052628&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Redis持久化&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文对前面所述的Redis两种持久化方式RDB和AOF做简单总结和比较。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之AOF持久化</title>
    <link href="http://blog.dujiong.net/2016/11/27/Redis-AOF/"/>
    <id>http://blog.dujiong.net/2016/11/27/Redis-AOF/</id>
    <published>2016-11-27T12:17:07.000Z</published>
    <updated>2016-11-28T11:47:43.686Z</updated>
    
    <content type="html">&lt;p&gt;除了RDB持久化功能之外，Redis还提供了AOF（Append Only File）持久化功能。与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;AOF持久化的实现&quot;&gt;&lt;a href=&quot;#AOF持久化的实现&quot; class=&quot;headerlink&quot; title=&quot;AOF持久化的实现&quot;&gt;&lt;/a&gt;AOF持久化的实现&lt;/h3&gt;&lt;p&gt;AOF持久化功能的实现可以分为命令追加、文件写入、文件同步三个步骤。&lt;/p&gt;
&lt;h4 id=&quot;命令追加&quot;&gt;&lt;a href=&quot;#命令追加&quot; class=&quot;headerlink&quot; title=&quot;命令追加&quot;&gt;&lt;/a&gt;命令追加&lt;/h4&gt;&lt;p&gt;当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct redisServer {
    sds aof_buf;        //AOF缓冲区
    ...
};    
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;AOF文件的写入与同步&quot;&gt;&lt;a href=&quot;#AOF文件的写入与同步&quot; class=&quot;headerlink&quot; title=&quot;AOF文件的写入与同步&quot;&gt;&lt;/a&gt;AOF文件的写入与同步&lt;/h4&gt;&lt;p&gt;Redis的服务器进程是一个事件循环，这个循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复，而时间事件则负责执行像serverCron函数这样需要定时运行的函数。&lt;br&gt;因为服务器在处理文件事件时可能会执行写命令，使得一些内容被追加到aof_buf缓冲区，所以在服务器每次结束一个事件循环之前，它都会调用flushAppendOnlyFile函数，考虑是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件中。&lt;br&gt;因为程序需要在回复客户端之前对AOF执行写操作，而客户端能执行写操作的唯一机会就是在事件loop中，因此，程序将所有AOF写累计到缓存中，并在重新事件之前，将缓存写入到文件中。下面是flushAppendOnlyFile函数的关键代码。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void flushAppendOnlyFile(int force) {
    ssize_t nwritten;
    int sync_int_progress = 0;
    if(sdslen(server.aof_buf) == 0) return;        //缓冲区没有内容

    //当fsync策略为每秒一次时，如果后台线程仍然有fsync在执行，那么可能会延迟执行冲洗（flush）操作，因为Linux上的write会被后台的fsync阻塞。
    //当这种情况下，说明需要尽快冲洗aof缓存，程序会尝试在serverCron函数中对缓存进行冲洗。
    //但是，当force为1时，不管后台是否在fsync，程序都直接进行写入
    if(server.aof_fsync == AOF_FSYNC_EVERYSEC)    //每秒同步
        sync_in_progress = bioPendingJobsOfType(REDIS_BIO_AOF_FSYNC) != 0;
    if(server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;amp;&amp;amp; !force){
        if(sync_in_progress){    //后台正在执行FSYNC
            if(server.aof_flush_postponed_start == 0){
                server.aof_flush_postponed_start = server.unixtime;     //前面没有推迟过write操作，记录推迟写操作的时间
                return；
            }
            else if(server.unixtime-server.aof_flush_postponed_start &amp;lt; 2){    //推迟时间小于2秒
                return；
            }
            server.aof_delayed_fsync++;
            redisLog(REDIS_NOTICE, &amp;quot;...&amp;quot;);
        }
    }
    //程序对AOF文件进行写入
    server.aof_flush_postponed_start = 0;
    //如果写入设备是物理的话，这个操作应该是原子的
    //若出现电源中断这样的不可抗现象，AOF文件也是可能出现问题的，这时就需要使用redis-check-aof程序来修复
    nwritten = write(server.aof_fd, server.aof_buf, sdslen(server.aof_buf));
    if(nwritten != (signed)sdslen(server.aof_buf)){
        //不成功处理
        ...
    }else{
        if(server.aof_last_write_status == REDIS_ERR){
            redisLog(REDIS_WARNING, &amp;quot;...&amp;quot;);
            server.aof_last_write_status = REDIS_OK;
        }
    }
    server.aof_current_size += nwritten;    //更新写入后的AOF文件大小
    if(sdslen(server.aof_buf)+sdsavail(server.aof_buf) &amp;lt; 4000){
        sdsclear(server.aof_buf);    //清除缓存内容，等待重用
    }else{
        //释放缓存
        sdsfree(server.aof_buf);
        server.aof_buf = sdsempty();
    }

    if(server.aof_fsync == AOF_FSYNC_ALWAYS) {        //策略为总是执行fsync
        aof_fsync(server.aof_fd);
        server.aof_last_fsync = server.unixtime;
    }else if(server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;amp;&amp;amp;
            server.unixtime &amp;gt; server.aof_last_fsync){        //策略为每秒fsync, 并且距离上次fsync已经超过1秒
        if (!sync_in_progress) aof_background_fsync(server.aof_fd);
        server.aof_last_fsync = server.unixtime;
    }
}       
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;服务器配置appendfsync选项的值直接决定AOF持久化功能的效率和安全性。&lt;br&gt;当appendfsync的值为always时，服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件，并且同步AOF文件，所有always的效率是appendfsync三个选项值中最慢的一个，但从安全性来看，always也是最安全的，因为即使出现故障停机，AOF持久化也只会丢失一个事件循环中所产生的命令数据。&lt;br&gt;当appendfsync的值为everysec时，服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件，并且每隔一秒就要在子线程中对AOF文件进行一次同步。从效率上来讲，everysec模式足够快，并且即使出现故障停机，也只丢失一秒钟的命令数据。&lt;br&gt;当appendfsync的值为no时，服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件，至于何时对AOF文件进行同步，则由操作系统决定。所以该模式的单次同步时长通常是三种模式中时间最长的，并且在出现故障时，将丢失上次同步AOF文件之后的所有写命令数据。     &lt;/p&gt;
&lt;h3 id=&quot;AOF文件的载入与数据还原&quot;&gt;&lt;a href=&quot;#AOF文件的载入与数据还原&quot; class=&quot;headerlink&quot; title=&quot;AOF文件的载入与数据还原&quot;&gt;&lt;/a&gt;AOF文件的载入与数据还原&lt;/h3&gt;&lt;p&gt;因为AOF文件里面包含了重建数据库状态所需的所有写命令，所有服务器只要读入并重新执行一遍AOF文件里面保存的命令，就可以还原服务器关闭之前的数据库状态。Redis读取AOF文件并还原数据库状态的详细步骤如下：&lt;br&gt;（1）创建一个不带网络连接的伪客户端：因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时所使用的命令直接来源于AOF文件而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端来执行AOF文件保存的写命令，伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样。&lt;br&gt;（2）从AOF文件中分析并读出一条写命令。&lt;br&gt;（3）使用伪客户端执行被读出的写命令。&lt;br&gt;（4）重复执行步骤2和步骤3，直到AOF文件中的所有写命令都被处理完毕为止。      &lt;/p&gt;
&lt;h4 id=&quot;AOF重写&quot;&gt;&lt;a href=&quot;#AOF重写&quot; class=&quot;headerlink&quot; title=&quot;AOF重写&quot;&gt;&lt;/a&gt;AOF重写&lt;/h4&gt;&lt;p&gt;因为AOF持久化是通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF文件中的内容会越来越多，文件的体积也会越来越大，如果不加以控制的话，体积过大的AOF文件很可能对Redis服务器、甚至整个宿主计算机造成影响，并且AOF文件的体积越大，使用AOF文件来进行数据还原所需的时间就越多。&lt;br&gt;为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写功能。通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积要小得多。&lt;/p&gt;
&lt;h4 id=&quot;实现&quot;&gt;&lt;a href=&quot;#实现&quot; class=&quot;headerlink&quot; title=&quot;实现&quot;&gt;&lt;/a&gt;实现&lt;/h4&gt;&lt;p&gt;AOF文件重写是通过读取服务器当前的数据库状态来实现的，并不需要对现有的AOF文件进行任何读取、分析或者写入操作。即首先从数据库状态中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。&lt;br&gt;下面是相关的源代码实现。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int rewriteAppendOnlyFile(char* filename)
{
    dictIterator *di = NULL;
    dictEntry *de;
    rio aof;
    FILE *fp;
    char tmpfile[256];
    int j;
    long long now = mstime();

    snprintf(tmpfile, 256, &amp;quot;temp-rewriteaof-%d.aof&amp;quot;, (int)getpid());
    fp = fopen(tmpfile, &amp;quot;w&amp;quot;);

    rioInitWithFile(&amp;amp;aof, fp);
    //设置每写入REDIS_AOF_AUTOSYNC_BYTES字节，就执行一次FSYNC
    //防止缓存中积累太多命令内容，造成I/O阻塞时间过长
    if(server.aof_rewrite_incremental_fsync){
        rioSetAutoSync(&amp;amp;aof, REDIS_AOF_AUTOSYNC_BYTES);
    }
    //遍历所有数据库
    for(j=0; j&amp;lt;server.dbnum; j++){
        char selectcmd[] = &amp;quot;*2\r\n$6\r\nSELECT\r\n&amp;quot;;
        redisDb *db = server.db+j;
        dict *d = db-&amp;gt;dict;
        if (dictSize(d) == 0) continue;
        di = dictGetSafeIterator(d);        //键空间迭代器
        if(!di) {
            fclose(fp);    
            return REDIS_ERR;
        }
        //写入SELECT命令
        if(rioWrite(&amp;amp;aof, selectcmd, sizeof(selectcmd)-1) ==0 ) goto werr;
        if (rioWriteBulkLongLong(&amp;amp;aof,j) == 0) goto werr;

        //遍历数据库所有键
        while((de = dictNext(di)) != NULL) {
            robj key, *o;
            long long expiretime;    
            sds keystr = dictGetKey(de);

            o = dictGetVal(de);        //取出键
            initStaticStringObject(key, keystr);
            expiretime = getExpire(db, &amp;amp;key);
            if(expiretime != -1 &amp;amp;&amp;amp; expiretime &amp;lt; now) continue;
            //根据值的类型，选择适当的命令来保存
            if(o-&amp;gt;type == REDIS_STRING){
                char cmd[]=&amp;quot;*3\r\n$3\r\nSET\r\n&amp;quot;;
                if (rioWrite(&amp;amp;aof,cmd,sizeof(cmd)-1) == 0) goto werr;
                if (rioWriteBulkObject(&amp;amp;aof,&amp;amp;key) == 0) goto werr;
                if (rioWriteBulkObject(&amp;amp;aof,o) == 0) goto werr;
            } else if(o-&amp;gt;type == REDIS_LIST){
                if (rewriteListObject(&amp;amp;aof,&amp;amp;key,o) == 0) goto werr;
            } else if(o-&amp;gt;type == REDIS_SET){
                if (rewriteSetObject(&amp;amp;aof,&amp;amp;key,o) == 0) goto werr;
            }
            ...
            //写入键的过期时间
            if(expiretime != -1) {
                char cmd[]=&amp;quot;*3\r\n$9\r\nPEXPIREAT\r\n&amp;quot;;
                if (rioWrite(&amp;amp;aof,cmd,sizeof(cmd)-1) == 0) goto werr;
                if (rioWriteBulkObject(&amp;amp;aof,&amp;amp;key) == 0) goto werr;
                if (rioWriteBulkLongLong(&amp;amp;aof,expiretime) == 0) goto werr;
            }
        }
        dictReleaseIterator(di);    //释放迭代器
    }
    if(fflush(fp)==EOF) goto werr;    
    if(aof_fsync(fileno(fp))==-1) goto werr;
    if(fclose(fp)==EOF) goto werr;
    //重命名
    if (rename(tmpfile,filename)==-1){
        ...
    }

    return REDIS_OK;
werr:
    fclose(fp);
    unlink(tmpfile);
    if(di) dictReleaseIterator(di);
    return REDIS_ERR;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因为rewriteAppendOnlyFile函数生成的新AOF文件只包含还原当前数据库状态所必须的命令，所以新AOF文件不会浪费任何硬盘空间。&lt;/p&gt;
&lt;h4 id=&quot;后台重写&quot;&gt;&lt;a href=&quot;#后台重写&quot; class=&quot;headerlink&quot; title=&quot;后台重写&quot;&gt;&lt;/a&gt;后台重写&lt;/h4&gt;&lt;p&gt;rewriteAppendOnlyFile函数虽然可以很好地完成一个新的AOF文件的任务，但是，该函数会进行大量的写入操作，所以调用这个函数的线程将被长时间阻塞，因为Redis服务器使用单个线程来处理命令请求，所以如果服务器直接调用rewriteAppendOnlyFile函数的话，那么在重写AOF文件期间，服务器将无法处理客户端发来的命令请求。&lt;br&gt;所以Redis将AOF重写程序放到子进程里执行，这样做可以同时满足：（1）子进程在处理AOF重写的同时，服务器进程（父进程）可以继续处理命令请求。 （2）子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。当然，使用子进程也有一个问题，即子进程在进行AOF重写期间，服务器进程还需要继续处理命令请求，而新的命令可能会对现有的数据库状态进行修改，从而使得服务器当前的数据状态和重写后的AOF文件所保存的数据库状态不一致。&lt;br&gt;为此，Redis服务器设置了一个AOF重写缓冲区，该缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到信号后，会调用一个信号处理函数：（1）将AOF重写缓冲区中的所有内容写入到新AOF文件中，这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致；（2）对新的AOF文件进行改名，原子地覆盖现有的AOF文件，完成新旧两个AOF文件的替换。&lt;br&gt;因此，在整个AOF后台重写的过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，在其他时候，AOF后台重写都不会阻塞父进程，这将AOF重写对服务器性能造成的影响降到了最低。&lt;br&gt;下面是相关的源代码实现。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int rewriteAppendOnlyFileBackground(void) {
    pid_t childpid;
    long long start;

    if(server.aof_child_pid != -1) return REDIS_ERR;

    start = ustime();
    if(childpid=fork()==0) {    //子进程
        char tmpfile[256];
        closeListeningSockets(0);    //关闭网络连接fd
        redisSetProcTitle(&amp;quot;redis-aof-rewrite&amp;quot;);        //为进程设置名字
        //创建临时文件，并进行AOF重写
        snprintf(tmpfile, 256, &amp;quot;temp-rewriteaof-bg-%d.aof&amp;quot;, (int) getpid());
        if(rewriteAppendOnlyFile(tmpfile) == REDIS_OK){
            exitFromChild(0);    //发送重写成功信号
        } else{
            exitFromChild(1);
        }
    } else{                    //父进程
        server.stat_fork_time = ustime()-start;
        ...
        server.aof_selected_db = -1;            //feedAppendOnlyFile()
        replicationScriptCacheFlush();
        return REDIS_OK;
    }
    return REDIS_OK;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;待续&quot;&gt;&lt;a href=&quot;#待续&quot; class=&quot;headerlink&quot; title=&quot;待续&quot;&gt;&lt;/a&gt;待续&lt;/h3&gt;&lt;p&gt;Redis提供了RDB和AOF两种持久化方式，对于二者各自的优缺点和使用的场景，还有待分析。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;除了RDB持久化功能之外，Redis还提供了AOF（Append Only File）持久化功能。与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之RDB持久化</title>
    <link href="http://blog.dujiong.net/2016/11/25/Redis-RDB/"/>
    <id>http://blog.dujiong.net/2016/11/25/Redis-RDB/</id>
    <published>2016-11-25T06:22:16.000Z</published>
    <updated>2016-11-25T08:21:30.775Z</updated>
    
    <content type="html">&lt;p&gt;Redis是内存数据库，它将自己的数据库状态储存在内存里面，所以，如果不想办法将储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Redis提供了RDB持久化功能，该功能可以将Redis在内存中的数据库状态保存到磁盘里面，避免数据意外丢失。RDB持久化可以手动执行，也可以根据服务器配置选项定期执行。RDB文件是一个压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态。      &lt;/p&gt;
&lt;h3 id=&quot;RDB文件的创建与载入&quot;&gt;&lt;a href=&quot;#RDB文件的创建与载入&quot; class=&quot;headerlink&quot; title=&quot;RDB文件的创建与载入&quot;&gt;&lt;/a&gt;RDB文件的创建与载入&lt;/h3&gt;&lt;p&gt;有两个命令Redis命令可以用于生成RDB文件，一个是SAVE（rdb.c/rdbSave），另一个是BGSAVE(rdb.c/rdbSaveBackground)。&lt;br&gt;SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求。而BGSAVE命令会派生一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求。&lt;br&gt;创建RDB文件的实际工作由rdb.c/rdbSave函数完成，SAVE命令和BGSAVE命令以不同的方式调用这个函数，关键代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int rdbSave(char* filename) {
    dictIterator *di = NULL;
    dictEntry *de;
    char tmpfile[256];
    char magic[10];
    int j;
    long long now = mstime();
    FILE *fp;
    rio rdb;
    uint64_t cksum;

    snprintf(tmpfile, 256, &amp;quot;temp-%d.rdb&amp;quot;, (int)getpid());    //创建临时文件，pid为标识
    fp = fopen(tmpfile, &amp;quot;w&amp;quot;);
    if(!fp) {
        redisLog(REDIS_WARNING, &amp;quot;Failed opening .rdb for saving : %s&amp;quot;, strerror(errno));
        return REDIS_ERR;
    }

    rioInitWithFile(&amp;amp;rdb, fp);        //初始化I/O

    if(server.rdb_checksum)            //设置校验和函数
        rdb.update_cksum = rioGenericUpdateChecksum;
    snprintf(magic, sizeof(magic), &amp;quot;REDIS%04d&amp;quot;, REDIS_RDB_VERSION);
    if(rdbWriteRaw(&amp;amp;rdb, magic, 0)==-1) goto err;    //写入RDB版本号

    for(j=0; j&amp;lt;server.dbnum; j++){
        redisDb *db = server.db+j;    //指向数据库
        dict *d = db-&amp;gt;dict;            //数据库键空间
        if(dictSize(d) == 0) continue;    //跳过空数据库
        di = dictGetSafeIterator(d);
        if(!di){
            fclose(fp);            
            return REDIS_ERR;
        }
        //写入SELECTDB
        if (rdbSaveType(&amp;amp;rdb,REDIS_RDB_OPCODE_SELECTDB) == -1) goto werr;
        //对数据库ID编码后写入
        if (rdbSaveLen(&amp;amp;rdb,j) == -1) goto werr;
        //遍历数据库，写入每个键值对数据
        while((de = dictNext(di)) != NULL){
            sds keystr = dictGetKey(de);
            robj key, *o = dictGetValue(de);
            long long expire;

            initStaticStringObject(key, keystr);
            expire = getExpire(db, &amp;amp;key);
            if(rdbSaveKeyValuePair(&amp;amp;rdb, &amp;amp;key, o, expire, now)==-1) goto err;
        }
        dictReleaseIterator(di);
    }
    di = NULL;
    if (rdbSaveType(&amp;amp;rdb,REDIS_RDB_OPCODE_EOF) == -1) goto werr;        //写入EOF
    //校验和
    cksum = rdb.cksum;
    memrev64ifbe(&amp;amp;cksum);
    rioWrite(&amp;amp;rdb,&amp;amp;cksum,8);
    //冲洗缓存
    if (fflush(fp) == EOF) goto werr;
    if (fsync(fileno(fp)) == -1) goto werr;
    if (fclose(fp) == EOF) goto werr;
    //命名
    if (rename(tmpfile,filename) == -1) {
        redisLog(REDIS_WARNING,&amp;quot;Error moving temp DB file on the final destination: %s&amp;quot;, strerror(errno));
        unlink(tmpfile);
        return REDIS_ERR;
    }
    //清零数据库脏状态
    server.dirty = 0;
    //记录最后一次完成 SAVE 的时间
    server.lastsave = time(NULL);
    //记录最后一次执行 SAVE 的状态
    server.lastbgsave_status = REDIS_OK;

    return REDIS_OK;

werr:
    fclose(fp);
    unlink(tmpfile);
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;RDB文件的结构&quot;&gt;&lt;a href=&quot;#RDB文件的结构&quot; class=&quot;headerlink&quot; title=&quot;RDB文件的结构&quot;&gt;&lt;/a&gt;RDB文件的结构&lt;/h3&gt;&lt;p&gt;从上文的代码分析中可以看出RDB文件的结构。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/fnagdgd.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;RDB文件的最开头部分是REDIS，通过这五个字符，程序可以在载入文件时，快速检查所载入的文件是否是RDB文件。&lt;br&gt;db_version长度为4字节，它的值是一个字符串表示的整数，该整数记录了RDB文件的版本号，比如“0006”代表RDB文件的版本为第六版。  &lt;/p&gt;
&lt;h4 id=&quot;databases部分&quot;&gt;&lt;a href=&quot;#databases部分&quot; class=&quot;headerlink&quot; title=&quot;databases部分&quot;&gt;&lt;/a&gt;databases部分&lt;/h4&gt;&lt;p&gt;一个RDB文件的databases部分可以保存任意多个非空数据库。每个非空数据库在RDB文件中都可以保存为SELECTDB、db_number、key_value_pairs三个部分，如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/vjF6XaN.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/8NLANJY.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;SELECTDB常量的长度为1字节，当读入程序遇到这个值的时候，它知道接下来要读入的将是一个数据库号码。db_number保存着一个数据库号码，根据号码的大小不同，该部分的长度可以是1、2或者5字节。key_value_pairs部分保存了数据库中的所有键值对数据，如果键值对带有过期时间，那么过期时间也会和键值对保存在一起。&lt;/p&gt;
&lt;h5 id=&quot;key-value-pairs部分&quot;&gt;&lt;a href=&quot;#key-value-pairs部分&quot; class=&quot;headerlink&quot; title=&quot;key_value_pairs部分&quot;&gt;&lt;/a&gt;key_value_pairs部分&lt;/h5&gt;&lt;p&gt;RDB文件中的每个key_value_pairs部分都保存了一个或以上数量的键值对，如果键值对带有过期时间的话，那么键值对的过期时间也会被保存在内。&lt;br&gt;不带过期时间的键值对在RDB文件中由TYPE、key、value三部分组成。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/NYbtrsP.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;TYPE记录了value的类型，长度为1字节。可能的取值包括REDIS_RDB_TYPE_STRING、REDIS_RDB_TYPE_LIST、REDIS_RDB_TYPE_SET、REDIS_RDB_TYPE_HASH等，每个TYPE常量代表了一种对象类型或者底层编码，当服务器读入RDB文件中的键值对数据时，程序会根据TYPE的值来决定如何读入和解释value的数据。&lt;br&gt;带有过期时间的键值对在RDB文件中的结构如图10-17所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/vI9BEm5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;带有过期时间的键值对中的TYPE、key、value三部分的意义和前面不带过期时间键值对三部分的意义完全相同，新增的EXPIRETIME_\MS常量的长度为1字节，它的作用是告知程序，接下来要读入的将是一个以毫秒为单位的过期时间；ms是一个8字节长的带符号整数，记录着以ms为单位的时间戳，即过期时间。  &lt;/p&gt;
&lt;h3 id=&quot;自动间隔性保存&quot;&gt;&lt;a href=&quot;#自动间隔性保存&quot; class=&quot;headerlink&quot; title=&quot;自动间隔性保存&quot;&gt;&lt;/a&gt;自动间隔性保存&lt;/h3&gt;&lt;p&gt;因为BGSAVE命令可以在不阻塞服务器进程的情况下执行，所以Redis允许用户通过设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令。用户可以通过save选项设置多个保存条件，但只要其中任意一个条件满足，服务器就会执行BGSAVE命令。&lt;br&gt;当Redis服务器启动时，用户可以通过指定配置文件或者传入启动参数的方式设置save选项，如果用户没有主动设置save选项，那么服务器会为save选项设置默认条件：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;save 900 1
save 300 10
save 60 10000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;接着，服务器程序会根据save选项所设置的保存条件，设置服务器状态redisServer结构的saveparams属性。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct redisServer {
    struct saveparam *saveparams;
    ...
}
struct saveparams {
    time_t seconds;        //秒数
    int changes;        //修改数
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;RDB文件的载入&quot;&gt;&lt;a href=&quot;#RDB文件的载入&quot; class=&quot;headerlink&quot; title=&quot;RDB文件的载入&quot;&gt;&lt;/a&gt;RDB文件的载入&lt;/h3&gt;&lt;p&gt;RDB文件的载入工作(rdb.c/rdbLoad)是在服务器启动时自动执行的，所以Redis并没有专门用于载入RDB文件的命令，只要Redis服务器在启动时监测到RDB文件存在，它就会自动载入RDB文件。&lt;br&gt;另外，因为AOF文件（见下文分析）的更新频率通常比RDB文件的更新频率高，所以：&lt;br&gt;（1）如果服务器开启了AOF持久化功能，那么服务器会优先使用AOF文件来还原数据库状态；&lt;br&gt;（2）只有在AOF持久化功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Redis是内存数据库，它将自己的数据库状态储存在内存里面，所以，如果不想办法将储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>最短路问题</title>
    <link href="http://blog.dujiong.net/2016/11/20/shortest-path/"/>
    <id>http://blog.dujiong.net/2016/11/20/shortest-path/</id>
    <published>2016-11-20T12:03:09.000Z</published>
    <updated>2016-11-25T01:45:32.826Z</updated>
    
    <content type="html">&lt;p&gt;最短路问题是图论中最基础的问题。最短路是给定两个顶点，在以这两个点为起点和终点的路径中，边的权值和最小的路径。如果把权值当做距离，考虑最短距离就很容易理解了。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;单源最短路问题&quot;&gt;&lt;a href=&quot;#单源最短路问题&quot; class=&quot;headerlink&quot; title=&quot;单源最短路问题&quot;&gt;&lt;/a&gt;单源最短路问题&lt;/h3&gt;&lt;p&gt;单源最短路问题是固定一个起点，求它到其他所有点的最短路的问题。如果终点也固定，这样的问题叫做两点之间的最短路问题。        &lt;/p&gt;
&lt;h4 id=&quot;Bellman-Ford算法&quot;&gt;&lt;a href=&quot;#Bellman-Ford算法&quot; class=&quot;headerlink&quot; title=&quot;Bellman-Ford算法&quot;&gt;&lt;/a&gt;Bellman-Ford算法&lt;/h4&gt;&lt;p&gt;记从起点s出发到顶点i的最短距离为d[i]。则下列等式成立：&lt;br&gt; &lt;img src=&quot;http://i.imgur.com/sZLfLxF.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如果给定的图是一个有向无环图，可以按拓扑排序给顶点编号，并利用这条递推关系式计算出d。但是，如果图中有圈，就无法依赖这样的顺序进行排序。这种情况下，记当前到顶点i的最短路长度为d[i]，并设初值d[s]=0，d[i]=INF，再不断使用这条关系式更新d的值，就可以算出新的d。只要图中不存在负圈，这样的更新操作是有限的。结束之后的d就是所求的最短距离。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct edge {
    int from, to;
    int cost;
}

edge es[MAX_E];        //边

int d[MAX_V];        //最短距离
int V, E;            //顶点数和边数

void shortest_path(int s) {
    for(int i=0;i&amp;lt;V;i++){
        d[i]=INF;    //初始化为INF
    }
    d[s]=0;
    while(true){
        bool update =false;
        for(int i=0;i&amp;lt;E;i++){
            edge e = es[i];        //边
            if(d[e.from]!=INF &amp;amp;&amp;amp; d[e.to]&amp;gt;d[e.from]+e.cost){
                d[e.to] = d[e.from]+cost;    
                update = true;
            }
        }
        if(!update) break;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该算法叫做Bellman-Ford算法。如果在图中不存在从s可达的负圈，那么最短路不会经过同一顶点两次（即最多通过|V-1|条边），while循环最多执行|V|-1次。因此，复杂度是O(|V|x|E|)。反之，如果存在从s到达的负圈，那么在第|V|次循环中也会更新d的值，因此可以利用这个性质来检查负圈。&lt;/p&gt;
&lt;h4 id=&quot;Dijkstra算法&quot;&gt;&lt;a href=&quot;#Dijkstra算法&quot; class=&quot;headerlink&quot; title=&quot;Dijkstra算法&quot;&gt;&lt;/a&gt;Dijkstra算法&lt;/h4&gt;&lt;p&gt;考虑一下Bellman-Ford算法没有负边的情况。如果d[i]还不是最短距离的话，那么即使进行d[j]=d[i]+(从i到j的边的权值)的更新，d[j]也不会变成最短距离。而且，即使d[i]没有变化，每一次循环也要检查一遍从i出发的所有边，这是很浪费时间的。因此可以对算法做如下修改：&lt;br&gt;（1）找到最短距离已经确定的顶点，从它出发更新相邻的最短距离；&lt;br&gt;（2）此后不需要再关心（1）中“最短距离已经确定的顶点”。&lt;br&gt;得到上述提到的“最短距离已经确定的顶点“是问题的关键。在最开始时，只有起点的最短距离是确定的。而在尚未使用过的顶点中，距离d[i]最小的顶点就是最短距离已经确定的顶点。因为不存在负边，所以d[i]不会在后面的更新中变小。该算法称为Dijkstra算法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int cost[MAX_V][MAX_V];        //cost[u][v]表示边e=(u,v)的权值
int d[MAX_V];                //顶点s出发的最短距离
bool used[MAX_V];            //已经使用过的图
int V;

void dijkstra(int s){
    fill(d, d+V, INF);        //初始距离设为无穷大
    d[s]=0;

    while(true){
        int v=-1;
        for(int u=0;u&amp;lt;V;u++){
            if(!used[u] &amp;amp;&amp;amp; (v==-1 || d[u]&amp;lt;d[v])) v=u;    //从尚未使过的顶点中选择一个距离最小的顶点
        }
        if(v==-1) break;
        used[v]=true;
        for(int u=0;u&amp;lt;V;u++){
            d[u] = min(d[u], d[v]+cost[v][u]);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用邻接矩阵实现的Dijkstra算法的复杂度是O(|V|^2)。使用邻接表的话，更新最短距离只需要访问每条边一次即可，因此这部分的复杂度是O(|E|)。但是每次要枚举所有的顶点来查找下一个使用的顶点，因此最终复杂度还是O(|V|^2)。在|E|比较小时，大部分时间花在了查找下一个使用的顶点上，因此需要使用合适的数据结构对其进行优化。&lt;br&gt;使用堆就可以了，把每个顶点当前的最短距离用堆维护，在更新最短距离时，把对应的元素往根的方向移动以满足堆的性质。而每次从堆中取出的最小值就是下一次要使用的顶点。这样堆中元素共有O(|V|)个，更新和取出数值的操作有O(|E|)次，因此整个算法的复杂度是O(|E|log|V|)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct edge {
    int to, cost;    
}

typedef pair&amp;lt;int, int&amp;gt; P;        //first是最短距离，second是顶点的编号

int V;
vector&amp;lt;edge&amp;gt; G[MAX_V];

int d[MAX_V];

void dijkstra(int s) {
    priority_queue&amp;lt;P, vector&amp;lt;P&amp;gt;, greater&amp;lt;P&amp;gt; &amp;gt; que;
    fill(d, d+V, INF);
    d[s]=0;
    que.push(P(0, s));

    while(!que.empty()){
        P p=que.top();
        que.pop();
        int v=p.second;        //顶点
        if(d[v]&amp;lt;p.first) continue;
        for(int i=0;i&amp;lt;G[v].size();i++){        //找距离最短的邻点
            edge e=G[v][i];
            if(d[e.to]&amp;gt;d[v]+e.cost){            //更新
                d[e.to]=d[v]+e.cost;
                que.push(P(d[e.to], e.to));        //把最近的节点和距离放入堆中
            }
        }    

    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;任意两点间的最短路问题&quot;&gt;&lt;a href=&quot;#任意两点间的最短路问题&quot; class=&quot;headerlink&quot; title=&quot;任意两点间的最短路问题&quot;&gt;&lt;/a&gt;任意两点间的最短路问题&lt;/h3&gt;&lt;p&gt;求解所有两点间的最短路问题叫做任意两点间的最短路问题，可以尝试使用动态规划。只使用顶点0~k和i,j的情况下，记i到j的最短路长度为d[k+1][i][j]。k=-1时，认为只使用i和j，所以d[0][i][j]=cost[i][j]。接下来把只使用顶点0~k的问题归约到只使用0~k-1的问题上。&lt;br&gt;只使用0~k时，我们分i到j的最短路正好经过顶点k一次和完全不经过顶点k两种情况来讨论。不经过顶点k的情况，d[k][i][j]=d[k-1][i][j]。通过顶点k的情况下，d[k][i][j]=d[k-1][i][k]+d[k-1][k][j]。合起来，就得到了d[k][i][j]=min(d[k-1][i][j], d[k-1][i][k]+d[k-1][k][j])。这个DP也可以使用同一个数组，不断进行d[i][j]=d[i][k]+d[k][j]的更新来实现。&lt;br&gt;该算法叫做Floyd-Warshall算法，可以在O(|V|^3)时间里求得所有两点间的最短路长度。该算法可以处理边是负数的情况。而判断图中是否有负圈，只需检查是否存在d[i][i]是负数的顶点i即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int d[MAX_V][MAX_V];    //边不存在为INF，d[i][i]=0
int V;

void warshall_floyd() {
    for(int k=0;k&amp;lt;V;k++){
        for(int i=0;i&amp;lt;V;i++){
            for(int j=0;j&amp;lt;V;j++){
                dp[i][j]=min(d[i][j], d[i][k]+d[k][j]);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样通过三重循环非常简单地就可以求出所有两点间的最短路长度。实现起来简单，复杂度也在可以承受的范围之内。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最短路问题是图论中最基础的问题。最短路是给定两个顶点，在以这两个点为起点和终点的路径中，边的权值和最小的路径。如果把权值当做距离，考虑最短距离就很容易理解了。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Redis之数据库的实现</title>
    <link href="http://blog.dujiong.net/2016/11/17/Redis-db/"/>
    <id>http://blog.dujiong.net/2016/11/17/Redis-db/</id>
    <published>2016-11-17T11:46:03.000Z</published>
    <updated>2016-11-24T07:49:39.294Z</updated>
    
    <content type="html">&lt;p&gt;本文对Redis服务器的数据库实现进行说明，包括服务器保存数据库的方法，数据库保存键值对的方法，以及针对数据库的添加、删除、查看等操作的实现方法，最后，会对服务器保存键的过期时间的方法和服务器自动删除过期键的方法进行分析。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;服务器中的数据库结构&quot;&gt;&lt;a href=&quot;#服务器中的数据库结构&quot; class=&quot;headerlink&quot; title=&quot;服务器中的数据库结构&quot;&gt;&lt;/a&gt;服务器中的数据库结构&lt;/h3&gt;&lt;p&gt;Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中，db数组的每个项都是一个redis.h/redisDb结构，每个redisDb结构代表一个数据库。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct redisServer {
    redisDb* db;    //    保存着服务器中的所有数据库
    int dbnum;        //服务器的数据库数量
    ...    
}

typedef struct {
    dict *dict;            //保存着数据库中的所有键值对    
    dict *expires;        //键的过期时间，键为数据库键，值为过期事件
    dict *blocking_keys;    //正处于阻塞状态的键和相应的client
    dict *ready_keys;        //可以解除阻塞的键和相应的client
    dict *watched_keys;        //正在被WATCH命令监视的键和相应的client
    struct evictionPoolEntry *eviction_pool;
    int id;        //数据库ID
    long long avg_ttl;        //数据库键的平均TTL，统计信息
} redisDb;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在初始化服务器时，程序会根据服务器状态的dbnum属性（配置文件database选项）来决定应该创建多少个数据库，默认情况下，该选项的值为16。&lt;/p&gt;
&lt;h3 id=&quot;切换数据库&quot;&gt;&lt;a href=&quot;#切换数据库&quot; class=&quot;headerlink&quot; title=&quot;切换数据库&quot;&gt;&lt;/a&gt;切换数据库&lt;/h3&gt;&lt;p&gt;每个Redis客户端都有自己的目标数据库，默认情况下，Redis客户端的目标数据库为0号数据库，客户端可以通过执行SELECT命令来切换目标数据库。&lt;br&gt;客户端redisClient结构的db属性记录了客户端当前的目标数据库，该属性是一个指向redisDb结构的指针，该指针指向redisServer.db数组的其中一个元素，即客户端的目标数据库。&lt;br&gt;用户执行SELECT命令切换数据库，Redis便修改redisClient.db指针，让它指向服务器中的不同数据库。 &lt;/p&gt;
&lt;h3 id=&quot;数据库键空间&quot;&gt;&lt;a href=&quot;#数据库键空间&quot; class=&quot;headerlink&quot; title=&quot;数据库键空间&quot;&gt;&lt;/a&gt;数据库键空间&lt;/h3&gt;&lt;p&gt;如前文所述，redisDb结构化的dict字典保存了数据库中的所有键值对，该字典被称为键空间。&lt;br&gt;键空间和用户所见的数据库是直接对应的：&lt;br&gt;（1）键空间的键也就是数据库的键，每个键都是一个字符串对象；&lt;br&gt;（2）键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任何一种Redis对象。&lt;br&gt;因为数据库的键空间是一个字典，所以所有针对数据库的操作，比如添加一个键值对，删除一个键值对，或者在数据库中获取某个键值对等，实际上都是通过对键空间字典进行操作来实现的。&lt;/p&gt;
&lt;h4 id=&quot;读写键空间的维护操作&quot;&gt;&lt;a href=&quot;#读写键空间的维护操作&quot; class=&quot;headerlink&quot; title=&quot;读写键空间的维护操作&quot;&gt;&lt;/a&gt;读写键空间的维护操作&lt;/h4&gt;&lt;p&gt;当使用Redis命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，包括：&lt;br&gt;（1）在读取一个键后，服务器会根据键是否存在来更新服务器的键空间命中(hit)次数或键空间不命中次数（miss）次数，这两个值可以在INFO status命令的keyspace_hits属性和keyspace_misses属性中查看；&lt;br&gt;（2）在读取一个键后,服务器会更新键的LRU事件，这个值可以用来计算键的闲置时间；&lt;br&gt;（3）如果服务器在读取一个键时发现该键已经过期，那么服务器会先删除这个过期键，再执行余下的其他操作；&lt;br&gt;（4）如果有客户端使用WATCH命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将这个键标记为脏，从而让食物程序注意到这个键已经被修改过；&lt;br&gt;（5）…&lt;/p&gt;
&lt;h3 id=&quot;设置键的生存时间或过期时间&quot;&gt;&lt;a href=&quot;#设置键的生存时间或过期时间&quot; class=&quot;headerlink&quot; title=&quot;设置键的生存时间或过期时间&quot;&gt;&lt;/a&gt;设置键的生存时间或过期时间&lt;/h3&gt;&lt;p&gt;客户端可以使用EXPIRE或PEXPIRE命令以秒或者毫秒精度为数据库中的某个键设置生存时间，在经过指定的秒数或者毫秒数之后，服务器就会自动删除生存时间为0的键。&lt;br&gt;客户端可以使用EXPIREAT或PEXPIREAT命令以秒或者毫秒精度为数据库中的某个键设置过期时间，过期时间是一个UNIX时间戳，当键的过期时间来临时，服务器就会自动从数据库中删除这个键。&lt;br&gt;下面是部分源代码(db.c)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//下面四个函数对应文中四个命令，最终都调用expireGenericCommand函数
void expireCommand(redisClient *c) {
    expireGenericCommand(c,mstime(),UNIT_SECONDS);
}    

void expireatCommand(redisClient *c) {
    expireGenericCommand(c,0,UNIT_SECONDS);
}

void pexpireCommand(redisClient *c) {
    expireGenericCommand(c,mstime(),UNIT_MILLISECONDS);
}

void pexpireatCommand(redisClient *c) {
    expireGenericCommand(c,0,UNIT_MILLISECONDS);
}

void expireGenericCommand(redisClient *c, long long basetime, int unit) {
    robj *key=c-&amp;gt;argv[1],*param=c-&amp;gt;argv[2];
    long long when;

    if(getLongLongFromObjectOrReply(c, param, &amp;amp;when, NULL)!=REDIS_OK)        //取出when参数
        return;
    if(unit == UNIT_SECONDS) when *= 1000;    //传入的时间是以秒为单位的
    when += basetime;

    if(lookupKeyRead(c-&amp;gt;db, key) == NULL) {    //取出键
        addReply(c, shared.czero);
        return;
    }

    // 在载入数据时，如果服务器为附属节点时，即使EXPIRE的TTL为负数，或者EXPIREAT提供的时间戳已经过期，服务器也不会主动删除这个键，而是等待主节点发来显示的DEL命令
    if(when &amp;lt;= mstime() &amp;amp;&amp;amp; !server.loading &amp;amp;&amp;amp; !server.masterhost) {
        robj *aux;
        redisAssertWithInfo(c, key, dbDelete(c-&amp;gt;db, key));
        server.dirty++;

        aux = createStringObject(&amp;quot;DEL&amp;quot;, 3);
        rewriteClientCommandVector(c,2,aux,key);
           decrRefCount(aux);

        signalModifiedKey(c-&amp;gt;db,key);
        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&amp;quot;del&amp;quot;,key,c-&amp;gt;db-&amp;gt;id);

        addReply(c, shared.cone);
        return;
    }else {            //设置键的过期事件
        setExpire(c-&amp;gt;db, key, when);
        addReply(c, shared.cone);
        signalModifiedKey(c-&amp;gt;db, key);
        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC, &amp;quot;expire&amp;quot;, key, c-&amp;gt;db-&amp;gt;id);

        server.dirty++;
        return;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;过期键删除策略&quot;&gt;&lt;a href=&quot;#过期键删除策略&quot; class=&quot;headerlink&quot; title=&quot;过期键删除策略&quot;&gt;&lt;/a&gt;过期键删除策略&lt;/h3&gt;&lt;h4 id=&quot;三种删除策略&quot;&gt;&lt;a href=&quot;#三种删除策略&quot; class=&quot;headerlink&quot; title=&quot;三种删除策略&quot;&gt;&lt;/a&gt;三种删除策略&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;定时删除：定时删除对内存是最友好的，在设置键的过期时间的同时，创建一个定时器，让定时器在键过期时间来临时，立即执行对键的删除操作。定时删除的问题是对CPU时间不友好，在过期键较多的情况下，删除过期键这一行为可能会占用相当一部分CPU时间，这样会对服务器的响应时间和吞吐量造成影响。     &lt;/li&gt;
&lt;li&gt;惰性删除：惰性删除策略对CPU时间来说是最友好的，因为程序只会在取出键时才会对键进行过期检查，这样确保删除过期键的操作只会在非做不可的情况下进行，不会在删除其他无关的过期键上花费任何时间。但惰性删除的缺点是对内存时最不友好的，如果数据库中有很多的过期键，而这些键又恰好没有访问到，那么它们也许永远也不会被删除，这样无用的垃圾数据占用了大量的内存。       &lt;/li&gt;
&lt;li&gt;定期删除：定期删除策略是前两种策略的一种折中，每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行时长和频率来减少删除操作对CPU时间的影响。但是定期策略的难点也正是在于确定操作执行的时长和频率。   &lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Redis的过期键删除策略&quot;&gt;&lt;a href=&quot;#Redis的过期键删除策略&quot; class=&quot;headerlink&quot; title=&quot;Redis的过期键删除策略&quot;&gt;&lt;/a&gt;Redis的过期键删除策略&lt;/h4&gt;&lt;p&gt;Redis服务器采用的是惰性删除和定期删除两种策略，通过配合这两种删除策略，服务器可以很好地在合理使用CPU时间和避免内存浪费之间取得平衡。&lt;br&gt;Redis过期键的惰性删除策略由db.c/expireIfNedded函数实现，所有读写数据库的Redis命令在执行之前都会调用expireIfNedded函数对输入键进行检查：如果输入键已经过期，那么该函数将输入键从数据库中删除。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int expireIfNeeded(redisDb *db, robj *key) {
    mstime_t when = getExpire(db, key);        //键的过期时间
    mstime_t now;
    if(when &amp;lt; 0) return 0;
    if(server.loading) return 0;    //服务器正在进行载入，返回

    now = server.lua_caller ? server.lua_time_start : mstime();
    //当服务器运行在replication模式时，附属节点并不主动删除 key，它只返回一个逻辑上正确的返回值，真正的删除操作要等待主节点发来删除命令时才执行 
    if (server.masterhost != NULL) return now &amp;gt; when;
    if(now &amp;lt;= when) return 0;        //未过期

    server.stat_expiredkeys++;
    propagateExpire(db, key);        //向AOF文件和附属节点传播过期信息
    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED, &amp;quot;expired&amp;quot;, key, db-&amp;gt;id);

    return dbDelete(db, key);        //从数据库中删除键
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;expireIfNeeded函数就像一个过滤器，它可以在命令真正执行之前，过期掉过期的输入键，从而避免命令接触到过期键。&lt;br&gt;Redis过期键的定时删除策略由redis.c/activeExpireCycle函数实现，该函数在redis.c/beforesleep和redis.c/serverCron两个函数中调用，且分别对应ACTIVE_EXPIRE_CYCLE_FAST（快速过期）和ACTIVE_EXPIRE_CYCLE_SLOW(正常过期)两种处理模式。以下是关键部分源码。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void activeExpireCycle(int type) {
    //静态变量，累计函数连续执行时的数据
    static unsigned int current_db = 0;
    static int timelimit_exit = 0;
    static long long last_fast_cycle = 0;
    //默认每次处理的数据库数量
    unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;
    long long start=ustime(), timelimit;

    if(type == ACTIVE_EXPIRE_CYCLE_FAST) {         //快速模式
        if (!timelimit_exit) return;
        if (start &amp;lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;
        last_fast_cycle = start;        //执行快速处理
    }
    if (dbs_per_call &amp;gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    //处理的时间上限
    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;    
    timelimit_exit = 0;
    if (timelimit &amp;lt;= 0) timelimit = 1;
    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION;

    for(j=0; j&amp;lt;dbs_per_call, j++) {
        int expired;
        redisDb *db = server.db+(current_db % server.dbnum); //当前要处理的数据库
        current_db++;
        do {
            ...
            if ((num = dictSize(db-&amp;gt;expires)) == 0) {    //数据库中带过期时间的键的数量
                db-&amp;gt;avg_ttl = 0;
                break;
            }
            slots = dictSlots(db-&amp;gt;expires);        //数据库键值对的数量
            if (num &amp;amp;&amp;amp; slots &amp;gt; DICT_HT_INITIAL_SIZE &amp;amp;&amp;amp; (num*100/slots &amp;lt; 1))  //数据库的使用率低于1%，跳过
                break;
            while(num--){
                dictEntry *de;
                long long ttl;
                //随机取出一个带过期时间的键
                if ((de = dictGetRandomKey(db-&amp;gt;expires)) == NULL) break;
                ttl = dictGetSignedIntegerVal(de)-now;        //计算TTL
                if (activeExpireCycleTryExpire(db,de,now)) //如果键过期，则删除它，并将expired计数器加1
                    expired++;
                ...
            }
            ...
        } while (expired &amp;gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);

    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;其他&quot;&gt;&lt;a href=&quot;#其他&quot; class=&quot;headerlink&quot; title=&quot;其他&quot;&gt;&lt;/a&gt;其他&lt;/h3&gt;&lt;p&gt;Redis的数据库功能很强大，也比较复杂，本文只是对其中的一些基本功能做了简单说明和分析，其他的一些功能和实现，比如持久化方式和复制功能对过期键的处理，将在后面的文章中继续学习。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文对Redis服务器的数据库实现进行说明，包括服务器保存数据库的方法，数据库保存键值对的方法，以及针对数据库的添加、删除、查看等操作的实现方法，最后，会对服务器保存键的过期时间的方法和服务器自动删除过期键的方法进行分析。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之发布与订阅</title>
    <link href="http://blog.dujiong.net/2016/11/13/Redis-pubsub/"/>
    <id>http://blog.dujiong.net/2016/11/13/Redis-pubsub/</id>
    <published>2016-11-13T10:13:33.000Z</published>
    <updated>2016-11-23T12:03:19.622Z</updated>
    
    <content type="html">&lt;p&gt;本文分析下Redis的发布与订阅功能，该功能有点类似网络中的多播或者广播的感觉，即当一个客户端向某个频道发布消息时，频道的所有订阅者和与这个频道相匹配的模式的订阅者都会收到该消息。&lt;br&gt;Redis的发布与订阅功能分为频道的订阅和模式的订阅。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;   &lt;/p&gt;
&lt;h3 id=&quot;相关的数据结构&quot;&gt;&lt;a href=&quot;#相关的数据结构&quot; class=&quot;headerlink&quot; title=&quot;相关的数据结构&quot;&gt;&lt;/a&gt;相关的数据结构&lt;/h3&gt;&lt;p&gt;首先看一下服务器和客户端与发布/订阅相关的属性。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct redisServer {
    ...
    dict* pubsub_channels;    //字典，键为频道，值为链表，记录所有订阅这个频道的客户端
    list* pubsub_patterns;    //订阅模式列表，为pubsubPattern结构
    ...
}
typedef struct redisClient {
    ...
    dict* pubsub_channels;    //该客户端感兴趣的频道列表
    list* pubsub_patterns;    //该客户端感兴趣的模式
    ...
}redisClient;

typedef struct pubsubPattern {
    redisClient* client;            //订阅模式的客户端
    robj* pattern;                    //被订阅的模式
}pubsubPattern;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;频道的订阅与退订&quot;&gt;&lt;a href=&quot;#频道的订阅与退订&quot; class=&quot;headerlink&quot; title=&quot;频道的订阅与退订&quot;&gt;&lt;/a&gt;频道的订阅与退订&lt;/h3&gt;&lt;p&gt;频道的订阅与退订在Redis中对应的命令分别为SUBSCRIBE和UNSUBSCRIBE。&lt;br&gt;首先学习SUBSCRIBE相关的源码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void subscribeCommand(redisClient* c){
    int j;
    for(j=1; j&amp;lt;c-&amp;gt;argc; j++){
        pubsubSubscribeChannel(c, c-&amp;gt;argv[j]);    //第二个参数开始的都是要订阅的频道
    }
}

int pubsubSubscribeChannel(redisClient* c, robj* channel){
    dictEntry* de;
    list* client=NULL;
    int retval=0;
    //将channels放入客户端c-&amp;gt;pubsub_channels的集合中
    if(dictAdd(c-&amp;gt;pubsub_channels, channel, NULL) == DICT_OK){
        retval=1;
        incrRefCount(channel);        //与该channel关联的引用计数加1
        //在server中查找这个频道的客户端链表是否存在
        de = dictFind(server.pubsub_channels, channel);
        if(de==NULL){    //不存在创建一个
            clients = listCreate();
            dictAdd(server.pubsub_channels, channel, clients);    //添加进字典
            increRefCount(channel);
        }else{
            clients = dictGetVal(de);    //如果已经存在，则直接获取频道所对应的客户端链表
        }

        listaddNodeTail(clients, c);    //将客户端添加到链表的末尾
    }
    //回复客户端
    addReply(c, shared.mbulkhdr[3]);
    addReply(c, shared.subscribebulk);
    addReply(c, channel);    
    addReplyLongLong(c,dictSize(c-&amp;gt;pubsub_channels)+listLength(c-&amp;gt;pubsub_patterns));

    return retval; 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，客户端就订阅了频道。&lt;br&gt;UNSUBSCRIBE命令的行为和SUBSCRIBE的行为正好相反，当一个客户端退订某个或某些频道的时候，服务器将从pubsub_channels中解除客户端与被退订频道之间的关联。&lt;/p&gt;
&lt;h3 id=&quot;模式的订阅与退订&quot;&gt;&lt;a href=&quot;#模式的订阅与退订&quot; class=&quot;headerlink&quot; title=&quot;模式的订阅与退订&quot;&gt;&lt;/a&gt;模式的订阅与退订&lt;/h3&gt;&lt;p&gt;如前文所述，服务器将所有模式的订阅关系都保存在服务器状态的pubsub_patterns属性里面。&lt;br&gt;模式的订阅与退订在Redis中对应的命令分别为PSUBSCRIBE和PUNSUBSCRIBE。&lt;br&gt;下面是PSUBSCRIBE相关的源代码。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int pubsubSubscribePattern(redisClient* c, robj* pattern){
    int retval=0;

    //看客户端是否已经订阅了这个模式
    if(listSearchKey(c-&amp;gt;pubsub_patterns, pattern)==NULL){    //没有
        retval=1;
        pubsubPattern* pat;
        listAddNodeTail(c-&amp;gt;pubsub_patterns, pattern);
        incrRefCount(pattern);

        //创建并设置新的pubsubPattern结构
        pat = zmalloc(sizeof(*pat));
        pat-&amp;gt;pattern = getDecodedObject(pattern);
        pat-&amp;gt;client = c;

        listAddNodeTail(server.pubsub_patterns, pat);
    }
    //回复客户端
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同频道订阅操作类似，只是在数据结构上有些许差异。&lt;br&gt;模式的退订命令PUNSUBSCRIBE是PSUBSCRIBE命令的反操作：当一个客户端退订某个或某些模式的时候，服务器将在pubsub_patterns链表查找并删除那些pattern属性为被退订模式，并且client属性为执行退订命令的客户端的pubsubPattern结构。&lt;/p&gt;
&lt;h3 id=&quot;发送消息&quot;&gt;&lt;a href=&quot;#发送消息&quot; class=&quot;headerlink&quot; title=&quot;发送消息&quot;&gt;&lt;/a&gt;发送消息&lt;/h3&gt;&lt;p&gt;当一个Redis客户端执行PUBLISH &lt;channel&gt; &lt;message&gt;命令将消息message发送给频道channel的时候，服务器需要执行以下两个动作：&lt;br&gt;（1）将消息message发送给channel频道的所有订阅者；&lt;br&gt;（2）如果有一个或多个模式pattern与频道channel相匹配，那么将消息message发送给pattern模式的订阅者。&lt;br&gt;下面是相关的源码。&lt;/message&gt;&lt;/channel&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int pubsubPublishMessage(robj* channel, robj* message) {
    int receives=0;
    dictEntry* de;
    listNode* ln;
    listIter li;

    de = dictFind(server.pubsub_channels, channel);    //查找channel
    if(de){
        list* list = dictGetVal(de);    //得到客户端链表
        listNode* ln;
        listIter* li;

        listRewind(list, &amp;amp;li);
        while(ln = listNext(&amp;amp;li)!=NULL){    //遍历客户端链表，将消息发送给他们
            redisClient* c = ln-&amp;gt;value;
            addReply(c,shared.mbulkhdr[3]);
            addReply(c,shared.messagebulk);
            addReplyBulk(c,channel);
            addReplyBulk(c,message);
            receives++;        //接收客户端计数
        }
    }

    //将消息发送给与频道匹配的模式
    if(listLength(server.pubsub_patterns)){
        listRewind(server.pubsub_patterns,&amp;amp;li);
        channel = getDecodedObject(channel);
        while ((ln = listNext(&amp;amp;li)) != NULL) {
            if (stringmatchlen((char*)pat-&amp;gt;pattern-&amp;gt;ptr,
                            sdslen(pat-&amp;gt;pattern-&amp;gt;ptr),
                            (char*)channel-&amp;gt;ptr,
                            sdslen(channel-&amp;gt;ptr),0)){    //如果模式和channel匹配
                //给所以订阅该模式的客户端发送消息
                addReply(pat-&amp;gt;client,shared.mbulkhdr[4]);
                addReply(pat-&amp;gt;client,shared.pmessagebulk);
                addReplyBulk(pat-&amp;gt;client,pat-&amp;gt;pattern);
                addReplyBulk(pat-&amp;gt;client,channel);
                addReplyBulk(pat-&amp;gt;client,message);

                receives++;        //接收客户端计数
            }
        }
    }
    return receives;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;查看订阅信息&quot;&gt;&lt;a href=&quot;#查看订阅信息&quot; class=&quot;headerlink&quot; title=&quot;查看订阅信息&quot;&gt;&lt;/a&gt;查看订阅信息&lt;/h3&gt;&lt;p&gt;此外，Redis还支持PUBSUB命令，客户端用以查看频道或者模式的相关信息，比如某个频道目前有多少订阅者、某个模式目前有多少订阅者等。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文分析下Redis的发布与订阅功能，该功能有点类似网络中的多播或者广播的感觉，即当一个客户端向某个频道发布消息时，频道的所有订阅者和与这个频道相匹配的模式的订阅者都会收到该消息。&lt;br&gt;Redis的发布与订阅功能分为频道的订阅和模式的订阅。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之启动过程分析</title>
    <link href="http://blog.dujiong.net/2016/11/10/Redis-start/"/>
    <id>http://blog.dujiong.net/2016/11/10/Redis-start/</id>
    <published>2016-11-10T01:49:28.000Z</published>
    <updated>2016-11-23T08:24:56.583Z</updated>
    
    <content type="html">&lt;p&gt;Redis服务器是典型的一对多服务器程序：一个服务器可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令，而服务器接收并处理客户端发送的命令请求，并向客户端返回命令回复。通过使用I/O多路复用技术实现的文件事件处理器，Redis服务器使用单进程单线程的方式来处理命令请求。&lt;br&gt;本文对Redis服务器的启动过程做简单分析。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一个Redis服务器从启动到能够接受客户端的命令请求，需要经过一系列的初始化和设置过程，比如初始化服务器状态，接受用户指定的服务器配置，创建相应的数据结构和网络连接等。&lt;/p&gt;
&lt;h3 id=&quot;初始化服务器状态结构&quot;&gt;&lt;a href=&quot;#初始化服务器状态结构&quot; class=&quot;headerlink&quot; title=&quot;初始化服务器状态结构&quot;&gt;&lt;/a&gt;初始化服务器状态结构&lt;/h3&gt;&lt;p&gt;初始化服务器的第一步是创建一个struct redisServer类型的实例变量作为服务器的状态，并为结构中的各个属性设置默认值，在Redis中，服务器所有属性都保存在struct redisServer类型全局变量server中。该部分工作由redis.c/initServerConfig函数完成。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void initServerConfig()
{
    ...
    getRandomHexChars(server.runid, REDIS_RUN_ID_SIZE);    //设置服务器的运行ID
    server.configfile = NULL;
    server.port = REDIS_SERVERPORT;
    server.tcp_backlog = REDIS_TCP_BACKLOG;
    ...
    server.lruclock = getLRUclock();    //
    server.commands = dictCreate(&amp;amp;commandTableDictType, NULL);
    server.orig_command = dictCreate(&amp;amp;commandTableDictType, NULL);
    populateCommandTable();
    ...
}   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，&lt;code&gt;server.lruclock = getLRUclock();&lt;/code&gt;用于保存服务器的LRU时钟，表示服务器最近一次使用时钟的时间。精度为秒。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//mstime()返回Unix时间毫秒数
//#define REDIS_LRU_BITS 24
//#define REDIS_LRU_CLOCK_MAX ((1&amp;lt;&amp;lt;REDIS_LRU_BITS)-1)    //Max value of obj-&amp;gt;lru
//#define REDIS_LRU_CLOCK_RESOLUTION 1000         //LRU clock resolution in ms
unsigned int getLRUClock(void){
    return (mstime()/REDIS_LRU_CLOCK_RESOLLUTION) &amp;amp; REDIS_LRU_CLOCK_MAX;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此外，每个Redis对象都会有一个LRU属性，保存了对象最后一次被命令访问的时间。    &lt;/p&gt;
&lt;h3 id=&quot;载入配置选项&quot;&gt;&lt;a href=&quot;#载入配置选项&quot; class=&quot;headerlink&quot; title=&quot;载入配置选项&quot;&gt;&lt;/a&gt;载入配置选项&lt;/h3&gt;&lt;p&gt;在启动服务器时，用户可以通过给定配置参数（终端命令输入）或者指定配置文件（redis.conf）来修改服务器的默认配置。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if(argc &amp;gt;= 2){
    int j=1;
    sds options = sdsempty();
    char* configfile = NULL;
    if(argv[j][0]!=&amp;apos;-&amp;apos; || argv[j][1] != &amp;apos;-&amp;apos;)       //配置文件
        configfile = argv[j++];
    while(j != argc){    //除了配置文件还有其余选项，由options保存,比如--port 6380会被分析为&amp;quot;port 6380\n&amp;quot;
        if(argv[j][0]==&amp;apos;-&amp;apos; &amp;amp;&amp;amp; argv[j][1]==&amp;apos;-&amp;apos;){
            if(sdslen(options)) options = sdscat(options, &amp;quot;\n&amp;quot;);
            options = sdscat(options, argv[j]+2);
            options = sdscat(options, &amp;quot; &amp;quot;);
        }else{
            options = sdscatrepr(options,argv[j],strlen(argv[j]));
            options = sdscat(options, &amp;quot; &amp;quot;);
        }
        j++;
    }    
    if(configfile) server.configfile = getAbsolutePath(configfile);
    resetServerSaveParams();
    loadServerConfig(configfile, options);    //载入配置文件，还有options
    sdsfree(options);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置文件只能再第二个参数（第一个为程序名称），然后跟着配置文件后面可以是各个配置选项，都存储在option字符串中。最后调用函数&lt;code&gt;loadServerConfig(configfile, options);&lt;/code&gt;将文件读进内存，并给server赋值。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void loadServerConfig(char* filename, char* options)
{
    sds config = sdsempty();
    char buf[REDIS_CONFIGFILE_MAX+1];

    if(filename){
        FILE* fp;

        if(filename[0]==&amp;apos;-&amp;apos; &amp;amp;&amp;amp; finename[1]==&amp;apos;\0&amp;apos;){
            fp = stdin;
        }else{
            if((fp=fopen(filename,&amp;quot;r&amp;quot;))==NULL){
                redisLog(REDIS_WARNING, &amp;quot;Fatal error, can&amp;apos;t open config file &amp;apos;%s&amp;apos;&amp;quot;, filename);
                exit(1);
            }
        }
        while(fgets(buf, REDIS_CONFIGFILE_MAX+1, fp)!=NULL)
            config = sdscat(config, buf);
        if(fp != stdin) fclose(fp);
    }
    if(options) {
        config = sdscat(config, &amp;quot;\n&amp;quot;);
        config = sdscat(config, options);
    }
    loadServerConfigFromString(config);
    sdsfree(config);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将配置文件和options的配置存入config中，然后调用loadServerConfigFromString(config)根据配置选项名称给server结构体赋值。&lt;/p&gt;
&lt;h3 id=&quot;初始化服务器数据结构&quot;&gt;&lt;a href=&quot;#初始化服务器数据结构&quot; class=&quot;headerlink&quot; title=&quot;初始化服务器数据结构&quot;&gt;&lt;/a&gt;初始化服务器数据结构&lt;/h3&gt;&lt;p&gt;在之前执行initServerConfig函数初始化server状态时，程序只创建了命令表一个数据结构，不过除了命令表之外，服务器状态还包含其他数据结构。比如：&lt;br&gt;(1) server.clients链表。该链表记录了所有与服务器相连的客户端的状态结构，链表的每一个节点都包含一个redisClient结构实例。&lt;br&gt;(2) server.db数组。该数组包含了服务器中的所有数组。&lt;br&gt;(3) 用于保存频道订阅信息的server.pubsub_channels字典，以及用于保存模式订阅信息的server.pubsub_patterns链表。&lt;br&gt;(4)…&lt;br&gt;当初始化服务器进行到这一步，服务器将调用initServer函数，为以上提到的数据结构分配内存，并在有需要时，为这些数据结构设置或关联初始化值。&lt;br&gt;因此，前面的initServerConfig函数中主要负责初始化一般属性，而initServer函数主要负责初始化数据结构。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void initServer()
{
    int j;

    server.current_client = NULL;
    server.clients = listCreate();
    server.clients_to_close = listCreate();
    server.slaves = listCreate();
    server.monitors = listCreate();

    createSharedObjects();    //创建共享对象
    server.el = aeCreateEventLoop(server.maxclients+REDIS_EVENTLOOP_FDSET_INCR);    //创建EventLoop实例
    server.db = zmalloc(sizeof(redisDb)*server.dbnum);

    if(server.port!=0 &amp;amp;&amp;amp; 
            listenToPort(server.port, server.ipfd, &amp;amp;server.ipfd_count)==REDIS_ERR)
        exit(1);
    ...
    if(acCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR){
        redisPanic(&amp;quot;can&amp;apos;t create the serverCron time event.&amp;quot;);
        exit(1);
    }

    for(j=0; j&amp;lt;server.ipfd_count; j++){
        //为TCP连接关联连接处理器
        if(aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE, acceptTcpHandler, NULL)==AE_ERR){
            redisPanic(&amp;quot;...&amp;quot;);
        }    
    }    
    //为本地套接字关联处理器
    if(server.sofd&amp;gt;0 &amp;amp;&amp;amp; aeCreateFileEvent(server.el, server.sofd, AE_READABLE, acceptUnixHandler, NULL)==AE_ERR){
        redisPanic(&amp;quot;...&amp;quot;);
    }
    //AOF文件
    //初始化脚本系统
    //初始化慢查询功能
    //...
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，listenToPort函数先判断用户是否提供监听地址，如果没有，则监听INADDR_ANY(0.0.0.0)地址，即所有地址，包括IPV4和IPV6，并设置为非阻塞。如果有设置监听地址，可以是一个地址队列，则只监听用户自己设置的ip地址队列。最后server.ipfd为监听套接字数组，server.ipfd_count为套接字数组个数。&lt;br&gt;然后创建了时间和文件描述符事件，主要是设置处理事件的回调函数。   &lt;/p&gt;
&lt;h3 id=&quot;serverCron函数&quot;&gt;&lt;a href=&quot;#serverCron函数&quot; class=&quot;headerlink&quot; title=&quot;serverCron函数&quot;&gt;&lt;/a&gt;serverCron函数&lt;/h3&gt;&lt;p&gt;Redis服务器中的serverCron函数默认每隔100（1000/server.hz）毫秒执行一次（第一次是1ms执行，后面是100ms），该函数负责管理服务器的资源，并保持服务器自身的良好运转。&lt;br&gt;(1)更新服务器时间缓存&lt;br&gt;Redis服务器中有不少功能需要获取系统的当前时间，而每次获取系统的当前时间都需要执行一次时间调用，为了减少系统调用的执行次数，服务器状态中的unixtime属性和mstime属性被当作当前时间的缓存，serverCron函数更新该域，这样就可以从这里获取时间。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//time_t unixtime;    //秒级精度的系统当前UNIX时间戳
//long long mstime;    //毫秒级精度的系统当前UNIX时间戳
void updateCachedTime(void){
    server.unixtime = time(NULL);
    server.mstime = mstime();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  服务器只会在打印日志、更新服务器的LRU时钟、决定是否执行初始化任务、计算服务器上线时间这类对时间精度要求不高的功能上“使用unixtime和mstime属性”。而对于为键设置过期时间、添加慢查询日志这种需要高精度时间的功能来说，服务器还是会再次执行系统调用，从而获得最准确的系统当前时间。&lt;br&gt;(2)更新LRU时钟；&lt;br&gt;(3)更新内存使用峰值&lt;br&gt;服务器状态中的stat_peak_memory属性记录了服务器的内存峰值大小。每次serverCron函数执行时，程序都会查看服务器当前使用的内存数量，并与stat_peak_memory保存的数值进行比较，如果当前使用的内存数量比stat_peak_memory属性记录的值要打，那么程序就将当前使用的内存数量记录到stat_peak_memory。&lt;br&gt;(4)处理SIGTERM信号&lt;br&gt;在启动服务器时，Redis会为服务器进程的SIGTERM信号关联处理器sigtermHandler函数，该信号处理器接到SIGTERM信号时，打开服务器状态的shutdown_asap标识。每次serverCron函数运行时，程序都会对服务器状态的shutdown_asap属性进行检查，以决定是否关闭服务器。&lt;br&gt;(5)管理客户端资源&lt;br&gt;serverCron函数每次执行都会调用clientsCron函数，clientsCron函数会对一定数量的客户端进行一下两个检查：&lt;br&gt;a. 如果客户端与服务器之间连接已经超时（很长时间没有互动），那么程序释放这个客户端，关闭连接。&lt;br&gt;b. 如果客户端在上一次执行命令请求之后，输入缓冲区的大小超过了一定的长度，那么程序会释放客户端当前的输入缓冲区，并重新创建一个默认大小的输入缓冲区，从而防止客户端的输入缓冲区耗费了过多的内存。&lt;br&gt;(6)管理数据库资源&lt;br&gt;serverCron函数每次执行都会调用databasesCron函数，该函数会对服务器中的一部分数据库进行检查，删除其中的过期键，并在有需要时，对字典进行收缩操作。&lt;br&gt;(7)调度aof或rdb读写子进程，复制同步，集群同步，sentinel定时器等；&lt;br&gt;总之，定时事件做的事情很多，可以说Redis充分利用了定时器，这样就少了很多线程。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Redis服务器是典型的一对多服务器程序：一个服务器可以与多个客户端建立网络连接，每个客户端可以向服务器发送命令，而服务器接收并处理客户端发送的命令请求，并向客户端返回命令回复。通过使用I/O多路复用技术实现的文件事件处理器，Redis服务器使用单进程单线程的方式来处理命令请求。&lt;br&gt;本文对Redis服务器的启动过程做简单分析。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis之事件驱动</title>
    <link href="http://blog.dujiong.net/2016/11/05/Redis-event/"/>
    <id>http://blog.dujiong.net/2016/11/05/Redis-event/</id>
    <published>2016-11-05T04:03:53.000Z</published>
    <updated>2016-11-15T05:52:30.834Z</updated>
    
    <content type="html">&lt;p&gt;事件处理是Redis的核心机制之一，通过在文件、网络和时间等类型的事件上进行多路复用，为Redis的高性能提供保证。事件驱动在Redis源码中主要涉及ae.h/ae.c，Ae_evport/epoll/kqueue/select.c等文件。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Redis事件驱动相关数据结构&quot;&gt;&lt;a href=&quot;#Redis事件驱动相关数据结构&quot; class=&quot;headerlink&quot; title=&quot;Redis事件驱动相关数据结构&quot;&gt;&lt;/a&gt;Redis事件驱动相关数据结构&lt;/h3&gt;&lt;p&gt;Redis事件驱动内部包含四个主要的数据结构(定义在ae.h中)，分别是：文件事件结构体、时间事件结构体、就绪事件结构体和循环结构体。&lt;/p&gt;
&lt;h4 id=&quot;文件事件&quot;&gt;&lt;a href=&quot;#文件事件&quot; class=&quot;headerlink&quot; title=&quot;文件事件&quot;&gt;&lt;/a&gt;文件事件&lt;/h4&gt;&lt;p&gt;文件事件定义在ae.h/aeFileEvent结构体中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeFileEvent {
    int mask;            //状态

    aeFileProc* rfileProc;        
    aeFileProc* wfileProc;
    void* clientData;    //多路复用库的私有数据
} aeFileEvent;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，rfileProc和wfileProc为aeFileProc类型函数指针，分别对应于读、写事件处理函数。其声明为：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef void aeFileProc(struct aeEventLoop *eventLoop, int fd, void *clientData, int mask);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;clientData保存执行命令时所需要的数据，每次处理事件时，它会作为参数被传入事件处理器。&lt;/p&gt;
&lt;h4 id=&quot;就绪事件&quot;&gt;&lt;a href=&quot;#就绪事件&quot; class=&quot;headerlink&quot; title=&quot;就绪事件&quot;&gt;&lt;/a&gt;就绪事件&lt;/h4&gt;&lt;p&gt;就绪事件定义在ae.h/aeFiredEvent结构体中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeFiredEvent {
    int fd;                //就绪文件描述符

    int mask;            //事件类型掩码
} aeFiredEvent;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就绪事件结构体将在IO多路复用（aeApiPoll函数）返回时设置。&lt;/p&gt;
&lt;h4 id=&quot;时间事件&quot;&gt;&lt;a href=&quot;#时间事件&quot; class=&quot;headerlink&quot; title=&quot;时间事件&quot;&gt;&lt;/a&gt;时间事件&lt;/h4&gt;&lt;p&gt;时间事件定义在ae.h/aeTimeEvent结构体中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeTimeEvent {
    long long id;        //时间事件的唯一标识

    long when_sec;
    long when_ms;

    aeTimeProc* timeProc;
    aeEventFinalizerProc* finalizerProc;     
    void* clientData;
    struct aeTimeEvent* next;        //指向下个时间事件结构，形成链表
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，id为时间事件的全局唯一标识号，其值按从小到大的顺序递增，新事件的id号比旧事件的id大。when为毫秒级的UNIX时间戳，记录时间事件的到达时间。next为指向下个时间事件结构的指针，Redis服务器将所有时间事件都放在一个无序（到达时间）链表中，每当时间事件执行器运行时，就遍历链表，查找所有已到达的时间事件，并调用相应的事件处理器。注意，Redis的时间事件链表是按id排序的链表，对于到达时间，它是无序的。&lt;br&gt;timeProc和finalizerProc分别为时间事件处理器和事件释放函数的函数指针。其声明为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef int aeTimeProc(struct aeEventLoop *eventLoop, long long id, void *clientData);
typedef void aeEventFinalizerProc(struct aeEventLoop *eventLoop, void *clientData);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此外，Redis的时间事件可以分为以下两类：&lt;br&gt;（1）定时事件：让一段程序在指定的时间之后执行一次；&lt;br&gt;（2）周期性事件：让一段程序每隔指定的时间就执行一次。&lt;br&gt;一个时间事件是定时事件还是周期性事件取决于时间事件处理器的返回值(ae.c/processTimeEvents/retval = te-&amp;gt;timeProc(eventLoop, id, te-&amp;gt;clientData))：&lt;br&gt;（1）如果事件处理器返回返回ae.h/AE_NOMORE,那么这个事件为定时事件，该事件在到达一次之后就会被删除。&lt;br&gt;（2）如果事件处理器返回一个非AE_NOMORE的整数值，那么这个事件为周期性事件，此时，服务器会对时间事件的when属性进行更新，让该事件在一段时间之后再次到达，并以这种方式更新、运行。   &lt;/p&gt;
&lt;h4 id=&quot;事件循环结构体&quot;&gt;&lt;a href=&quot;#事件循环结构体&quot; class=&quot;headerlink&quot; title=&quot;事件循环结构体&quot;&gt;&lt;/a&gt;事件循环结构体&lt;/h4&gt;&lt;p&gt;在事件驱动的实现中，需要有一个事件循环结构来监控调度所有的事件。在Redis中的事件驱动库中，事件循环结构结构定义在ae.h/aeEventLoop中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef struct aeEventLoop {
    int maxfd;                    //注册的最大的文件描述符
    int setsize;                //监听的文件描述符的最大个数

    long long timeEventNextId;    //生成时间事件id
    time_t lastTime;            //最后一次执行时间事件的时间

    aeFileEvent* events;        //注册的文件事件
    aeFilEvent* fired;            //就绪的文件事件
    aeTimeEvent* timeEventHead;    //时间事件
    int stop;
    void* apindata;                //多路复用库的私有数据
    aeBeforeSleepProc* beforesleep;
} aeEventLoop;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，events是aeFileEvent结构的数组，每个aeFileEvent结构表示一个注册的文件事件。setsize表示能处理的文件描述符的最大个数。beforesleep函数指针表示在监控事件触发之前，需要调用的函数。apindata表示底层多路复用的私有数据，比如对于select来说，该结构保存了读写描述符数组；对于epoll来说，该结构中保存了epoll描述符和epoll_event数组。       &lt;/p&gt;
&lt;h3 id=&quot;Redis事件的调度与执行&quot;&gt;&lt;a href=&quot;#Redis事件的调度与执行&quot; class=&quot;headerlink&quot; title=&quot;Redis事件的调度与执行&quot;&gt;&lt;/a&gt;Redis事件的调度与执行&lt;/h3&gt;&lt;p&gt;Redis的事件处理主循环在aeMain函数中进行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void aeMain(aeEventLoop* eventLoop){
    eventLoop-&amp;gt;stop = 0;
    while(!eventLoop-&amp;gt;stop){
        if(eventLoop-&amp;gt;beforesleep != NULL){
            eventLoop-&amp;gt;beforesleep(eventLoop);
        }
        aeProessEvents(eventLoop, AE_ALL_EVENTS);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该事件循环的流程图如下：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/5bUY0j1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;aeProcessEvents函数进行具体的事件处理，定义在ae.c文件下，其关键代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int aeProcessEvents(aeEventLoop* eventLoop, int flags) {
    ...
    if(eventLoop-&amp;gt;maxfd!=-1 || ((flags &amp;amp; AE_TIME_EVENTS) &amp;amp;&amp;amp; !(flags &amp;amp; AE_DONT_WAIT))) {
        shortest = aeSearchNearestTimer(eventLoop);  //获取最近的时间事件
        if(shortest){
            aeGetTime(&amp;amp;now_sec, &amp;amp;now_ms);
            //计算最近的时间事件距离到达还有多少毫秒
            tvp-&amp;gt;tv_usec = ((shortest-&amp;gt;when_ms+1000) - now_ms)*1000;
            tvp-&amp;gt;tv_sec --;
            ...
        }else{        //没有时间事件，根据AE_DONT_WAIT来设置是否阻塞，以及阻塞的事件长度
            if(flags &amp;amp; AE_DONT_WAIT) {        
                tv.tv_sec = tv.tv_usec = 0;
                tvp = &amp;amp;tv;
            }else{
                tvp = NULL;
            }
        }
        numevents = aeApiPoll(eventLoop, tvp);            //select,epoll...
        for(j=0; j&amp;lt;numevents;j++){
            aeFileEvent *fe = &amp;amp;eventLoop-&amp;gt;events[eventLoop-&amp;gt;fired[j].fd];
            int mask = eventLoop-&amp;gt;fired[j].mask;
            int fd = eventLoop-&amp;gt;fired[j].fd;
            int rfired = 0;
            if(fe-&amp;gt;mask &amp;amp; mask &amp;amp; AE_READABLE){
                rfired = 1;
                fe-&amp;gt;rfileProc(eventLoop, fd, fe-&amp;gt;clientData, mask);        //处理读事件
            }
        ...
        }
    }
    if(flags &amp;amp; AE_TIME_EVENTS)
        processed += processTimeEvents(eventLoop);        //处理时间事件
    return processed;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，aeApiPoll函数的最大阻塞时间(tvp结构)由到达时间最接近当前时间的时间事件(shortest)决定，这样既可以避免服务器对时间事件进行频繁的轮询（忙等待），也可以确保aeApiPoll函数不会阻塞过长时间。&lt;br&gt;因为文件事件是随机出现的，如果等待并处理完一次文件事件之后，仍未有任何时间事件到来，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间逐渐向时间事件所设置的到达时间逼近，并最终来到到达时间，这时服务器就可以开始处理到达的时间事件了。&lt;br&gt;对文件事件和时间事件的处理都是同步、有序、原子地执行的，服务器不会中途中断事件处理，也不会对事件进行抢占，因此，不管是文件事件的处理器，还是时间事件的处理器，它们都会尽可能地减少程序的阻塞时间，并在需要时让出执行权，从而降低造成事件饥饿的可能性。比如说，在命令回复处理器将一个命令回复写入到客户端套接字，如果写入的字节数超过了一个预设常量的话，命令回复处理器就会主动用break跳出写入循环，将余下的数据留到下次再写，另外，时间事件也会将非常耗时的持久化操作放到子线程或子进程中执行。&lt;br&gt;此外，由于时间事件放在文件事件之后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达时间稍晚一些。   &lt;/p&gt;
&lt;h3 id=&quot;Redis-IO复用函数选择&quot;&gt;&lt;a href=&quot;#Redis-IO复用函数选择&quot; class=&quot;headerlink&quot; title=&quot;Redis IO复用函数选择&quot;&gt;&lt;/a&gt;Redis IO复用函数选择&lt;/h3&gt;&lt;p&gt;最后提到的一点是，Redis提供了在多个IO库之间选择最佳的策略。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#ifdef HAVE_EVPORT
#include &amp;quot;ae_evport.c&amp;quot;
#else
    #ifdef HAVE_EPOLL
    #include &amp;quot;ae_epoll.c&amp;quot;
    #else
        #ifdef HAVE_KQUEUE
        #include &amp;quot;ae_kqueue.c&amp;quot;
        #else
        #include &amp;quot;ae_select.c&amp;quot;
        #endif
    #endif
#endif
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，在编译时，Redis可以根据平台自上而下选择最快的IO多路复用函数。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;事件处理是Redis的核心机制之一，通过在文件、网络和时间等类型的事件上进行多路复用，为Redis的高性能提供保证。事件驱动在Redis源码中主要涉及ae.h/ae.c，Ae_evport/epoll/kqueue/select.c等文件。&lt;br&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://blog.dujiong.net/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL之deque</title>
    <link href="http://blog.dujiong.net/2016/10/31/STL-deque/"/>
    <id>http://blog.dujiong.net/2016/10/31/STL-deque/</id>
    <published>2016-10-31T09:49:42.000Z</published>
    <updated>2016-10-31T11:48:49.896Z</updated>
    
    <content type="html">&lt;p&gt;C++标准模板库序列式容器中，使用最少的估计就是deque了。但是，了解下deque这种双向开口的连续线性空间容器的底层设计与实现仍是很有帮助的。此外，stack和queue这两种适配器容器（容器底层是调用其他容器）底层实现默认就是使用deque。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;与vector比较&quot;&gt;&lt;a href=&quot;#与vector比较&quot; class=&quot;headerlink&quot; title=&quot;与vector比较&quot;&gt;&lt;/a&gt;与vector比较&lt;/h3&gt;&lt;p&gt;deque和vector的最大差异，一是deque允许常熟时间内对起头端进行元素的插入或移除操作，二在于deque没有所谓容量观念，因为它是动态地以分段连续空间组合而成，随时可以增加一段新的空间并链接起来。即，像vector那样“因旧空间不足而重新配置一块更大空间，然后复制元素，再释放旧空间”这样的事情在deque是不会发生的。也因此，deque没有必要提供所谓的空间保留功能。&lt;br&gt;更具体的，array无法增长，vector虽可增长，却只能向尾端增长，而且所谓增长是个假象，事实上是（1）另觅更大空间；（2）将原数据复制过去；（3）释放原空间 三部曲。&lt;br&gt;deque是由一段一段的定量连续空间构成。一旦有必要在deque的前端或尾端增加新空间，便配置一段定量连续空间，串接在整个deque的头端或尾端。deque的最大任务，便是在这些分段的定量连续空间上，维护其整体连续的假象，并提供随机存取的接口。这样避开了“重新配置、复制、释放”的轮回，代价则是复杂的迭代器架构。    &lt;/p&gt;
&lt;h3 id=&quot;deque的中控器和迭代器&quot;&gt;&lt;a href=&quot;#deque的中控器和迭代器&quot; class=&quot;headerlink&quot; title=&quot;deque的中控器和迭代器&quot;&gt;&lt;/a&gt;deque的中控器和迭代器&lt;/h3&gt;&lt;p&gt;deque底层实现一个中控器，即一个指针数组，其中的每一个元素都是指针，指向另一段连续线性空间，称为缓冲区。缓冲区才是deque的存储空间主体。&lt;br&gt;迭代器由以下四个部分组成：&lt;br&gt;（1）cur：指向缓冲区当前元素。&lt;br&gt;（2）first：指向缓冲区的第一个位置。&lt;br&gt;（3）last：指向末节点，即最后一个元素的下一个位置。&lt;br&gt;（4）node：指向主控器相应的索引位置。&lt;br&gt;中控器、缓冲区、迭代器之间的关系如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/SsE0h85.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;以下是中控器和迭代器的相关源代码。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc, size_t BufSiz = 0&amp;gt;
class deque {
public:
    typedef T value_type;
    typedef value_type* pointer;        
    ...
protected:
    typedef pointer* map_pointer;        //指针的指针
    map_pointer map;        //map是指针数组，中控器
    size_type map_size;        //map内可容纳多少指针
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，中控器map其实是一个T**，即是指向指针的指针，T为元素型别。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Ref, class Ptr, size_t BufSiz&amp;gt;
struct __deque_iterator {
    typedef __deque_iterator&amp;lt;T, T&amp;amp;, T*, BufSiz&amp;gt; iterator;
    typedef __deque_iterator&amp;lt;T, const T&amp;amp;, const T*, BufSiz&amp;gt; const_iterator;
    static size_t buffer_size() { return __deque_buf_size(BufSiz, sizeof(T)); }
    typedef random_access_iterator_tag iterator_category;    //RandomAccess Iterator
    typedef T value_type; 
    typedef Ptr pointer;
    typedef Ref reference;
    typedef size_t size_type;
    typedef ptrdiff_t difference_type;
    typedef T** map_pointer;                //指向主控器的指针

    T* cur;
    T* first;
    T* last;
    map_pointer node;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;迭代器的四个主要组成：cur、first、last、node的定义。&lt;br&gt;接下来是构造函数和迭代器的重载运算因子。          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;__deque_iterator(T* x, map_pointer y)    //用T类型数据和指向中控器的指针初始化一个迭代器
    : cur(x), first(*y), last(*y+buffer_size()), node(y) {}
__deque_iterator() : cur(0), first(0), last(0), node(0) {}    //创建一个空的迭代器
__deque_iterator(const iterator&amp;amp; x) : cur(x.cur), first(x.first), last(x.last), node(x.node) {}    //复制构造函数

reference operator*() const { return *cur; }
pointer operator-&amp;gt;() const { return &amp;amp;(operator*()); }
difference_type operator-(const self&amp;amp; x) const {
    return difference_type(buffer_size())*(node-x.node-1)+(cur-first)+(x.last-x.cur);
}
...
self&amp;amp; operator+=(difference_type n){
    difference_type offset=n+(cur-first);
    if(offset&amp;gt;=0 &amp;amp;&amp;amp; offset&amp;lt;difference_type(buffer_size())){    //目标在同一个缓冲区内
        cur+=n;
    }else{            //目标位置不在同一个缓冲区内
        difference_type node_offset = offset&amp;gt;0 ? offset/difference_type(buffer_size()) : -difference_type((-offset-1) / buffer_size())-1;
        set_node(node + node_offset);
        cur = first+(offset-node_offset*difference_type(buffer_size()));
    }
    return *this;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在进行+=n运算时，要判断+n之后的索引是否还在当前缓冲区内，如果在，cur简单+n即可，如果不在，则要计算正确的缓存节点和正确的元素位置。其他+n，-=n，-运算都可以通过+=运算得出。&lt;/p&gt;
&lt;h3 id=&quot;deque的结构&quot;&gt;&lt;a href=&quot;#deque的结构&quot; class=&quot;headerlink&quot; title=&quot;deque的结构&quot;&gt;&lt;/a&gt;deque的结构&lt;/h3&gt;&lt;p&gt;deque除了维护一个指向map的指针外，还维护start、finish两个迭代器，分别指向第一缓冲区的第一个元素和最后缓冲区的最后一个元素（的下一个位置）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc, size_t BufSiz = 0&amp;gt;
class deque {
public:
    typedef T value_type;
    typedef value_type* pointer;
    typedef size_t size_type;
    typedef __deque_iterator&amp;lt;T, T&amp;amp;, T*, BufSiz&amp;gt; iterator;
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;
    typedef simple_alloc&amp;lt;pointer, Alloc&amp;gt; map_allocator;
    ...
protected:
    typedef pointer* map_pointer;
    iterator start;
    iterator finish;
    map_pointer map;
    size_type map_size;        //map容纳指针的个数    
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;默认构造函数&quot;&gt;&lt;a href=&quot;#默认构造函数&quot; class=&quot;headerlink&quot; title=&quot;默认构造函数&quot;&gt;&lt;/a&gt;默认构造函数&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;deque()
    : start(), finish(), map(0), map_size(0) {
    create_map_nodes(0);
} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;默认构造函数先初始化两个迭代器为空迭代器，然后设置map和map_size，接着调用create_map_and_nodes(size_type num_elements)来初始化一块内存。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Alloc, size_t BufSize&amp;gt;
void deque&amp;lt;T, Alloc, BufSize&amp;gt;::create_map_and_nodes(size_type num_elements) {
    size_type num_nodes = num_elements/buffer_size() + 1;    //    需要节点数
    map_size = max(initial_map_size(), num_nodes+2);    //一个map管理的节点数，最少8个，最多是“所需节点加2”
    map = map_allocator::allocate(map_size);

    map_pointer nstart = map+(map_size-num_nodes)/2;
    map_pointer nfinish = nstart+num_nodes-1;
    map_pointer cur;

    __STL_TRY {
        for(cur=nstart; cur&amp;lt;=nfinish; ++cur){
            *cur = allocate_node();
        }
    }catch(...){
        ...
    }
    //为deque内的两个迭代器设定正确的内容
    start.set_node(nstart);
    finish.set_node(nfinish);
    start.cur = start.first;
    finish.cur = finish.first + num_elements%buffer_size();
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;由n个value初始化的构造函数&quot;&gt;&lt;a href=&quot;#由n个value初始化的构造函数&quot; class=&quot;headerlink&quot; title=&quot;由n个value初始化的构造函数&quot;&gt;&lt;/a&gt;由n个value初始化的构造函数&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;deque(size_type n, const value_type&amp;amp; value)
    : start(), finish(), map(0), map_size(0) {
    fill_initialize(n, value);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该构造函数调用fill_initialize函数来初始化deque，fill_initialize函数负责产生并安排好deque的结构，并将元素的初值设定妥当。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc, size_t BufSize&amp;gt;
void deque&amp;lt;T, Alloc, BufSize&amp;gt;::fill_initialize(
    size_type n, const value_type&amp;amp; value) {
    create_map_and_nodes(n);
    map_pointer cur;
    __STL_TRY {
        //为每个节点的缓冲区设定初值
        for(cur=start.node; cur&amp;lt;finish.node;++cur){
            uninitialized_fill(*cur, *cur + buffer_size(), value);
        }
        uninitialized_fill(finish.first, finish.cur, value);    //最后一个节点单独对待
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;两个迭代器初始化的构造函数&quot;&gt;&lt;a href=&quot;#两个迭代器初始化的构造函数&quot; class=&quot;headerlink&quot; title=&quot;两个迭代器初始化的构造函数&quot;&gt;&lt;/a&gt;两个迭代器初始化的构造函数&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator&amp;gt;
deque(InputIterator first, InputIterator last)
    : start(), finish(), map(0), map_size(0) {
    range_initialize(first, last, iterator_category(first));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该构造函数调用range_initialize来用迭代器范围内的元素初始化deque.range_initialize，根据迭代器类型，调用对应的版本。&lt;/p&gt;
&lt;h4 id=&quot;析构函数&quot;&gt;&lt;a href=&quot;#析构函数&quot; class=&quot;headerlink&quot; title=&quot;析构函数&quot;&gt;&lt;/a&gt;析构函数&lt;/h4&gt;&lt;p&gt;deque的析构函数先是调用destroy析构缓冲区内的数据，然后调用destroy_map_and_nodes函数析构缓冲区和中控器内存。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~deque() {
    destroy(start, finish);
    destroy_map_and_nodes();
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;deque的一些常用操作&quot;&gt;&lt;a href=&quot;#deque的一些常用操作&quot; class=&quot;headerlink&quot; title=&quot;deque的一些常用操作&quot;&gt;&lt;/a&gt;deque的一些常用操作&lt;/h3&gt;&lt;p&gt;deque所提供的元素操作很多，如pop_back、pop_front、clear、erase、insert等，这里不再一一列举，在理解时，只需把握“deque是多个连续缓冲区组合在一起的分段线性空间”即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;C++标准模板库序列式容器中，使用最少的估计就是deque了。但是，了解下deque这种双向开口的连续线性空间容器的底层设计与实现仍是很有帮助的。此外，stack和queue这两种适配器容器（容器底层是调用其他容器）底层实现默认就是使用deque。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL之list</title>
    <link href="http://blog.dujiong.net/2016/10/28/STL-list/"/>
    <id>http://blog.dujiong.net/2016/10/28/STL-list/</id>
    <published>2016-10-28T11:33:14.000Z</published>
    <updated>2016-10-31T03:26:00.692Z</updated>
    
    <content type="html">&lt;p&gt;上一篇文章总结了vector的结构和实现原理，今天来看看STL中另一个重要的容器：list。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;相比于vector的连续线性空间，list显得复杂得多，它的好处是每次插入或删除一个元素，就配置或释放一个元素空间。因此，list对于空间的运用有绝对的精准，一点都不浪费。    &lt;/p&gt;
&lt;h3 id=&quot;list的节点&quot;&gt;&lt;a href=&quot;#list的节点&quot; class=&quot;headerlink&quot; title=&quot;list的节点&quot;&gt;&lt;/a&gt;list的节点&lt;/h3&gt;&lt;p&gt;我们知道，list本身和list的节点是不同的结构，需分开设计。以下是STL list的节点结构：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct __list_node {
    typedef void* void_pointer;
    void_pointer prev;
    void_pointer next;
    T data;    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，STL list是一个双向链表，有两个指针，分别指向前向节点和后向节点。  &lt;/p&gt;
&lt;h3 id=&quot;list的迭代器&quot;&gt;&lt;a href=&quot;#list的迭代器&quot; class=&quot;headerlink&quot; title=&quot;list的迭代器&quot;&gt;&lt;/a&gt;list的迭代器&lt;/h3&gt;&lt;p&gt;list不能够像vector一样以普通指针作为迭代器，因为其节点不保证在存储空间连续存在。并且，由于list提供的是一个双向链表，迭都代器必须具备前移、后移的能力，所以list提供的是Bidirectional Iterators.&lt;br&gt;list有一个重要的性质：插入操作和结合操作都不会造成原有的list迭代器失效。这在vector是不成立的，因为vector的插入操作可能造成记忆体重新配置，导致原有的迭代器全部失效。甚至list的元素删除操作，也只有“指向被删除元素”的那个迭代器失效，其他迭代器不受任何影响。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Ref, class Ptr&amp;gt;
struct __list_iterator {
    typedef __list_iterator&amp;lt;T, &amp;amp;T, T*&amp;gt; iterator;
    typedef __list_iterator&amp;lt;T, Ref, Ptr&amp;gt; self;

    typedef __list_node&amp;lt;T&amp;gt;* link_type;
    link_type node;                        //list的节点:node 

    //迭代器的构造函数
    __list_iterator(link_type x) : node(x) {}
      __list_iterator() {}
      __list_iterator(const iterator&amp;amp; x) : node(x.node) {}    

    reference operator*() const { return (*node).data; }
    pointer operator-&amp;gt;() const { return &amp;amp;(operator*()); }

    self&amp;amp; operator++() {                    //先加1，再返回，类似++i
        node = (link_type)((*node).next);
        return *this;
    }
    self operator++(int) {                    //类似于i++
        self tmp = *this;
        ++*this;
        return tmp;
    }
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上是list的迭代器的设计，只实现了迭代器的++，–，取值，成员调用四个基本操作，没有像vector迭代器那样的+n操作，主要是因为地址不连续。       &lt;/p&gt;
&lt;h3 id=&quot;list的结构&quot;&gt;&lt;a href=&quot;#list的结构&quot; class=&quot;headerlink&quot; title=&quot;list的结构&quot;&gt;&lt;/a&gt;list的结构&lt;/h3&gt;&lt;p&gt;list不仅是一个双向链表，而且还是一个环状双向链表。所以，只需要一个指针，便可以完整表现整个链表：   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;
class list {
protected:
    typedef __list_node&amp;lt;T&amp;gt; list_node;
public:
    typedef list_node* link_type;
protected:
    link_type node;        
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如下图所示，如果让指针node指向刻意置于尾端的一个空白节点，node便能符合STL对于“前闭后开”区间的要求，成为last迭代器。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/rClntKM.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;list的构造与内存管理&quot;&gt;&lt;a href=&quot;#list的构造与内存管理&quot; class=&quot;headerlink&quot; title=&quot;list的构造与内存管理&quot;&gt;&lt;/a&gt;list的构造与内存管理&lt;/h4&gt;&lt;p&gt;list提供了多种constructors，主要包括四种：默认构造函数、使用n个值来初始化list、将另一个list的部分数据来初始化以及复制构造函数。&lt;br&gt;以下是默认构造函数，就是创建一个节点，然后前后指向自己。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;list() { empty_initialize(); }
void empty_initialize() {
    node = get_node();
    node-&amp;gt;next = node;
    node-&amp;gt;prev = node;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;list缺省使用alloc作为空间配置器，并据此另外定义了一个list_node_allocator，方便以节点大小为配置单位。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef simple_alloc&amp;lt;list_node, Alloc&amp;gt; list_node_allocator;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是，list_node_allocator(n)表示配置n个节点空间，list提供四个函数分别用来配置、释放、构造和销毁一个节点。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;link_type get_node() { return list_node_allocator::allocate(); }
void put_node(link_type p) { list_node_allocator::deallocate(p); }

link_type create_node(const T&amp;amp; x) {    //配置并构造节点
    link_type p = get_node;
    construct(&amp;amp;p-&amp;gt;data, x);
    return p;
}  
void destroy_node(link_type p){        //析构并释放节点
    destroy(&amp;amp;p-&amp;gt;data);
    put_node(p);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外，当我们以push_back()将新元素插入于list尾端时，此函数内部调用insert():&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void push_back(const T&amp;amp; x) { insert(end(), x); }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;insert()是一个重载函数，有多种形式，其中最简单的一种如下，符合以上所需： 首先配置并构造一个节点，然后进行适当的指针操作，将新节点插入进去：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iterator insert(iterator position, const T&amp;amp; x){
    link_type tmp = create_node(x);
    tmp-&amp;gt;next = position.node;
    tmp-&amp;gt;prev = position.node-&amp;gt;prev;
    (link_type(position.node-&amp;gt;prev))-&amp;gt;next = tmp;
    position.node-&amp;gt;prev = tmp;
    return tmp;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;list的析构&quot;&gt;&lt;a href=&quot;#list的析构&quot; class=&quot;headerlink&quot; title=&quot;list的析构&quot;&gt;&lt;/a&gt;list的析构&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;~list() {
    clear();
    put_node(node);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;clear()清空链表所有数据，即只剩下node节点，然后put_node将最后的node节点回收。&lt;/p&gt;
&lt;h3 id=&quot;list常用操作函数&quot;&gt;&lt;a href=&quot;#list常用操作函数&quot; class=&quot;headerlink&quot; title=&quot;list常用操作函数&quot;&gt;&lt;/a&gt;list常用操作函数&lt;/h3&gt;&lt;h4 id=&quot;在链表头尾插入节点&quot;&gt;&lt;a href=&quot;#在链表头尾插入节点&quot; class=&quot;headerlink&quot; title=&quot;在链表头尾插入节点&quot;&gt;&lt;/a&gt;在链表头尾插入节点&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;void push_front(const T&amp;amp; x) { insert(begin(), x); }
void push_back(const T&amp;amp; x) { insert(end(), x); }
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;erase&quot;&gt;&lt;a href=&quot;#erase&quot; class=&quot;headerlink&quot; title=&quot;erase&quot;&gt;&lt;/a&gt;erase&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;iterator erase(iterator position){
    link_type next_node = link_type(position.node-&amp;gt;next);
    link_type prev_node = link_type(position.node-&amp;gt;prev);
    prev_node-&amp;gt;next = next_node;
    next_node-&amp;gt;prev = prev_node;
    destroy_node(position.node);
    return iterator(next_node);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改前后节点的指针指向，然后销毁position处的节点。&lt;/p&gt;
&lt;h4 id=&quot;remove&quot;&gt;&lt;a href=&quot;#remove&quot; class=&quot;headerlink&quot; title=&quot;remove&quot;&gt;&lt;/a&gt;remove&lt;/h4&gt;&lt;p&gt;将数值为value的所有元素移除：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc&amp;gt;
void list&amp;lt;T, Alloc&amp;gt;::remove(const T&amp;amp; value){
    iterator first = begin();
    iterator last = end();
    while(first != last){
        iterator next = first;
        ++next;
        if(*first == value) erase(first);
        first = next;
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的remove是真的移除了元素，而不像vector那样。&lt;/p&gt;
&lt;h4 id=&quot;transfer&quot;&gt;&lt;a href=&quot;#transfer&quot; class=&quot;headerlink&quot; title=&quot;transfer&quot;&gt;&lt;/a&gt;transfer&lt;/h4&gt;&lt;p&gt;list内部提供一个迁移操作transfer：将某连续范围的元素迁移到某个特定位置之前。技术上很简单，节点间的指针移动。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void transfer(iterator position, iterator first, iterator last) {
      if (position != last) {
        (*(link_type((*last.node).prev))).next = position.node;    　　　　// (1)
        (*(link_type((*first.node).prev))).next = last.node;           // (2)
        (*(link_type((*position.node).prev))).next = first.node;         // (3)
        link_type tmp = link_type((*position.node).prev);               // (4)
        (*position.node).prev = (*last.node).prev;                       // (5)
        (*last.node).prev = (*first.node).prev;                        // (6)
        (*first.node).prev = tmp;                                       // (7)
      }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;示意图如下所示。&lt;br&gt;    &lt;img src=&quot;http://i.imgur.com/nq2Qm5c.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;transfer并非公开接口。list公开提供的是接合操作splice：将某连续范围的元素从一个list移动到另一个（或同一个）list的某个定点。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//将x链表的所有元素插入到当前list的position处
void splice(iterator position, list&amp;amp; x) {
    if(!x.empty()){
        transfer(position, x.begin(), x.end());
    }
}
//将i处节点插到position之前，i和position可能来自同一个链表
void splice(iterator position, list&amp;amp;, iterator i) {
    iterator j = i;
    ++j;
    if(position == i || position == j) return;
    transfer(position, i, j);
}
//将[first, last)内的所有元素结合与position所指位置之前,position不能位于[first,last）之内
void splice(iterator position, list&amp;amp; iterator first, iterator last) {
    if(first!=last) {
        transfer(position, first, last);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;merge-reverse-sort&quot;&gt;&lt;a href=&quot;#merge-reverse-sort&quot; class=&quot;headerlink&quot; title=&quot;merge(), reverse(), sort()&quot;&gt;&lt;/a&gt;merge(), reverse(), sort()&lt;/h4&gt;&lt;p&gt;基于transfer操作，list提供了三个很有用的函数：&lt;br&gt;merge()：合并两个链表，要求两个链表必须有序，合并之后的链表也是有序的。merge之后，传入的list被清空。&lt;br&gt;reverse()：将链表数据反转。&lt;br&gt;sort()：由于list的迭代器为Bidirectional iterator，而STL的sort算法必须接受RamdonAccessIterator，所以list不能使用STL的sort算法。于是，基于quick sort，list实现了自身的sort。&lt;br&gt;三个函数的具体源码这里就不再详细列出。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;list是一种很常用的数据结构，我们不仅要熟练使用它，还要弄清其中的设计与实现。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇文章总结了vector的结构和实现原理，今天来看看STL中另一个重要的容器：list。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL之vector</title>
    <link href="http://blog.dujiong.net/2016/10/25/STL-vector/"/>
    <id>http://blog.dujiong.net/2016/10/25/STL-vector/</id>
    <published>2016-10-25T10:42:24.000Z</published>
    <updated>2016-10-25T07:29:30.196Z</updated>
    
    <content type="html">&lt;p&gt;“用C++开发，尽量用容器类+迭代器来代替数组+指针，因为数组+指针容易越界，或者内存泄露，而容器+迭代器已将底层封装好，使用安全简单”。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;vector是序列式容器里使用最广泛的容器之一，该容器被用来改善数组的缺点，vector是一个动态空间，随着元素的加入，它的内部机制会自行扩充以容纳新元素，因此，vector的运用对于内存的合理利用和灵活性都有很大的帮助，再也不必因为害怕空间不足一开始就配置一个大容量数组了。&lt;br&gt;所以，vector的实现技术，关键在于其对大小的控制以及重新配置时的数据移动效率。下面就一起详细地看看vetcor的设计。     &lt;/p&gt;
&lt;h3 id=&quot;vector成员变量&quot;&gt;&lt;a href=&quot;#vector成员变量&quot; class=&quot;headerlink&quot; title=&quot;vector成员变量&quot;&gt;&lt;/a&gt;vector成员变量&lt;/h3&gt;&lt;p&gt;vector的成员变量比较简单，主要由空间配置器和三个迭代器组成，三个迭代器分别指向目前使用空间的头、尾合目前可用空间的尾。其源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;   
class vector{
public:
    typedef T value_type;
    typedef value_type* pointer;
    typedef value_type* iterator;    //vector的迭代器是普通指针
    ...
protected:
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;

    iterator start;
    iterator finish;
    iterator end_of_storage;
...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;vector提供以下函数用于获取相关成员变量。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iterator begin() { return start; }
iterator end() { return finish; }

//返回vector当前对象的个数
size_type size() const { return size_type(end()-begin()); }
//返回目前可用空间的大小
size_type capacity() const { return size_type(end_of_storage-end()); }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;vector的构造函数&quot;&gt;&lt;a href=&quot;#vector的构造函数&quot; class=&quot;headerlink&quot; title=&quot;vector的构造函数&quot;&gt;&lt;/a&gt;vector的构造函数&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;vector() : start(0), finish(0), end_of_storage(0) { }
vector(size_type n, const T&amp;amp; value) { fill_initialize(n, value); }
vector(int n, const T&amp;amp; value) { fill_initialize(n, value); }
vector(long n, const T&amp;amp; value) { fill_initialize(n, value); }
explicit vector(size_type n) { fill_initialize(n, T()); }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;除了默认构造函数，四个带参构造函数都调用&lt;code&gt;fill_initialize(size_type n, const T&amp;amp; value)&lt;/code&gt;，这个函数调用&lt;code&gt;iterator allocate_and_fill(size_type n, const T&amp;amp; x)&lt;/code&gt;配置空间，并填充数据(&lt;code&gt;uninitialized_fill_n(size_type n, const T&amp;amp; x)&lt;/code&gt;)，并设置vector的三个迭代器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void fill_initialize(size_type n, const T&amp;amp; value){
    start = allocate+_and_fill(n, value);
    finish =  start + n;
    end_of_storage = finish;
}

iterator allocate_and_fill(size_type n, const T&amp;amp; x){
    iterator result = data_allocator::allocate(n);    //分配n个sizeof(T)大小的内存
    uninitialized_fill_n(result, n, x);        //全局函数，填充数据
    return result;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;uninitialized_fill_n是STL的内存基本处理函数，用于在申请的内存上填充数据，存放在stl_uninitialized.h中。该函数的逻辑是，首先萃取出迭代器result的value type，然后判断该型别是否为POD型别，POD指Plain Old Data，也就是标量型别或传统的C struct型别。POD型别必然拥有trival constructor/default constructor/copy/assignment函数，因此，可以对POD型别采用最有效率的初值填写手法，而对non-POD型别采取最保险的做法。&lt;br&gt;相关代码如下：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;
inline ForwardIterator uninitialized_fill_n(ForwardIterator first, 
                                                Size n, const T&amp;amp; x) {
      return __uninitialized_fill_n(first, n, x, value_type(first));
}

template &amp;lt;class ForwardIterator, class Size, class T, class T1&amp;gt;
inline ForwardIterator __uninitialized_fill_n(ForwardIterator first, 
                                                Size n, const T&amp;amp; x, T1*) {
    typedef typename __type_traits&amp;lt;T1&amp;gt;::is_POD_type is_POD;
      return __uninitialized_fill_n_aux(first, n, x, is_POD());                                
}

template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;    
inline ForwardIterator __uninitialized_fill_n_aux(ForwardIterator first, Size n, 
                                                const T&amp;amp; x, __true_type) {
      return fill_n(first, n, x);            //POD类型，直接用fill_n填充即可
}

template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;
ForwardIterator __uninitialized_fill_n_aux(ForwardIterator first, Size n,
                                                   const T&amp;amp; x, __false_type) {
      ForwardIterator cur = first;
      __STL_TRY {
        for ( ; n &amp;gt; 0; --n, ++cur)
              construct(&amp;amp;*cur, x);    //调用构造函数，这里用的是placement new来构造
        return cur;
      }
      __STL_UNWIND(destroy(first, cur));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同样的，在复制构造函数中，也是先分配内存，然后根据是否为POD型别调用不同的复制函数。    &lt;/p&gt;
&lt;h3 id=&quot;vector的析构函数&quot;&gt;&lt;a href=&quot;#vector的析构函数&quot; class=&quot;headerlink&quot; title=&quot;vector的析构函数&quot;&gt;&lt;/a&gt;vector的析构函数&lt;/h3&gt;&lt;p&gt;vector的析构函数比较简单，先析构[start, finish)，然后归还内存。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~vector() {
    destory(start, finish);
    deallocate();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同构造函数类似，destroy函数根据数据类型，如果是POD，则什么都不做，如果不是POD型别，则调用析构函数一个一个的析构。然后调用deallocate函数归还内存,如果大于128bytes，则归还给系统，小于128bytes，则还给内存池，后面还可使用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void deallocate() {
    if(start) data_allocator::deallocate(start, end_of_storage-start);
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;vector常用操作函数&quot;&gt;&lt;a href=&quot;#vector常用操作函数&quot; class=&quot;headerlink&quot; title=&quot;vector常用操作函数&quot;&gt;&lt;/a&gt;vector常用操作函数&lt;/h3&gt;&lt;h4 id=&quot;push-back&quot;&gt;&lt;a href=&quot;#push-back&quot; class=&quot;headerlink&quot; title=&quot;push_back&quot;&gt;&lt;/a&gt;push_back&lt;/h4&gt;&lt;p&gt;当我们以push_back()将新元素插入于vector尾端时，该函数首先检查是否还有备用空间，如果有，就直接在备用空间上构造函数，并调整迭代器finish，使vetcor变大，如果没有，就扩充空间（重新配置、移动数据、释放原空间）。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void push_back(const T&amp;amp; x){
    if(finish != end_of_storage){
        construct(finish, x);
        ++finish;        
    }else{
        insert_aux(end(), x);            //已无备用空间
    }
}

template &amp;lt;class T, class Alloc&amp;gt;
void vector&amp;lt;T, Alloc&amp;gt;::insert_aux(iterator position, const T&amp;amp;x){
    if(finish != end_of_storage){
        construct(finish, *(finish-1));    
        ++finish;
        T x_copy = x;
        copy_backward(position, finish-2, finish-1);
        *position = x_copy;
    }else{
        const size_type old_size = size();
        const size_type len = old_size!=0 ? 2 * old_size : 1;
        iterator new_start = data_Allocator::allocate(len);
        iterator new_finish = new_start;

        try{
            new_finish = uninitialized_copy(start, position, new_start);
            construct(new_finish, x);
            ++new_finish;
            new_finish = uninitialized_copy(position, finish, new_finish);
        }catch(...){
            destroy(new_start, new_finish);
            data_allocator::deallocate(new_start, len);
            throw;
        }

        destroy(begin(), end());        //析构
        deallocate();                    //释放原来的内存
        //调整三个迭代器
        start = new_start;
        finish = new_finish;
        end_of_storage = new_start + len;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;erase&quot;&gt;&lt;a href=&quot;#erase&quot; class=&quot;headerlink&quot; title=&quot;erase&quot;&gt;&lt;/a&gt;erase&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;iterator erase(iterator first, iterator last){
    iterator i = copy(last, finish, first);
    destroy(i, finish);
    finish = finish-(last-first);
    return first;
}

iterator erase(iterator position){
    if(position+1 != end()){
        copy(position+1, finish, position);
    }
    --finish;
    destroy(finish);
    return position;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以，调用erase()函数时，size()会变化，而capacity()不会发生变化。可以看出，erase()函数会涉及到元素的移动，可能会导致原有的迭代器失效，使用时需要注意。此外，remove()和erase()的区别：remove只是将待删除元素移动到vector的尾端，不是删除，erase才是真正的删除元素。一定不要误用。&lt;/p&gt;
&lt;h4 id=&quot;其他&quot;&gt;&lt;a href=&quot;#其他&quot; class=&quot;headerlink&quot; title=&quot;其他&quot;&gt;&lt;/a&gt;其他&lt;/h4&gt;&lt;p&gt;另外，还有一些常用的函数操作，如pop_back(), clear(), insert()等，这里就不再逐一介绍，方法和原理都和上述差不多，在日常编程中多使用，自然就熟了。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;“用C++开发，尽量用容器类+迭代器来代替数组+指针，因为数组+指针容易越界，或者内存泄露，而容器+迭代器已将底层封装好，使用安全简单”。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>字符串的排列与组合</title>
    <link href="http://blog.dujiong.net/2016/10/23/permutation/"/>
    <id>http://blog.dujiong.net/2016/10/23/permutation/</id>
    <published>2016-10-23T11:09:33.000Z</published>
    <updated>2016-12-02T02:55:05.318Z</updated>
    
    <content type="html">&lt;p&gt;很久没有深入研究数据结构和算法了…&lt;br&gt;这次换个套路，先不说那些干瘪瘪的理论，首先来看一道编程题。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h3 id=&quot;题目描述&quot;&gt;&lt;a href=&quot;#题目描述&quot; class=&quot;headerlink&quot; title=&quot;题目描述&quot;&gt;&lt;/a&gt;题目描述&lt;/h3&gt;&lt;p&gt;编写一个方法，确定某字符串的所有排列组合。&lt;br&gt;给定一个string A[]和一个int n，代表字符串和其长度，请返回所有该字符串字符的排列，保证字符串长度小于等于11且字符串中字符均为大写英文字符，排列中的字符串按字典序从大到小排序。&lt;br&gt;样例： “ABC”&lt;br&gt;返回：[“CBA”,”CAB”,”BCA”,”BAC”,”ACB”,”ABC”]&lt;/p&gt;
&lt;h3 id=&quot;思考&quot;&gt;&lt;a href=&quot;#思考&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h3&gt;&lt;p&gt;…&lt;/p&gt;
&lt;h3 id=&quot;分析&quot;&gt;&lt;a href=&quot;#分析&quot; class=&quot;headerlink&quot; title=&quot;分析&quot;&gt;&lt;/a&gt;分析&lt;/h3&gt;&lt;h4 id=&quot;next-permutation&quot;&gt;&lt;a href=&quot;#next-permutation&quot; class=&quot;headerlink&quot; title=&quot;next_permutation&quot;&gt;&lt;/a&gt;next_permutation&lt;/h4&gt;&lt;p&gt;很容易看出来这是一道排列的问题。由于自己最近对STL甚是着迷，却又没有掌握透彻，故先写出了下面的错误代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vector&amp;lt;string&amp;gt; getPermutation(string A){
    std::sort(A.begin(), A.end());
    vector&amp;lt;string&amp;gt; ret;
    do{
        ret.push_back(A);
    }while(next_permutation(A.begin(), A.end()));
    std::sort(ret.begin(), ret.end(), greater&amp;lt;string&amp;gt;());
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当我满怀欣喜地提交代码运行时，却被告知通过率只有13.3%，给出的错误分析表明，当字符串中含有两个及以上的相同字符时，所得结果错误，即原题的意思是字符串中的每一个字符都是独立的，即使它们相同。所以，得出的结果应该有n!个字符串。而算法next_permutation不能处理这样的情况。比如输入”AAB”，使用next_permutation得到的结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/40N1AVT.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;递归&quot;&gt;&lt;a href=&quot;#递归&quot; class=&quot;headerlink&quot; title=&quot;递归&quot;&gt;&lt;/a&gt;递归&lt;/h4&gt;&lt;p&gt;递归方法的思想很容易理解，即从串中依次选出每一个元素，作为排列的第一个元素，然后对剩余的元素递归的进行全排列。&lt;br&gt;以对字符串”abc”进行全排列为例：&lt;br&gt;（1）固定a，求后面bc的排列：abc、acb，求好后，b放在第一位置，得到bac；&lt;br&gt;（2）固定b，求后面ac的排列：bac、bca，求好后，c放在第一位置，得到cba；&lt;br&gt;（3）固定c，求后面ba的排列，cba、cab。&lt;br&gt;其过程如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/iqS7F6D.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;分析了算法思想后，就很容易写出代码了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void getPermutation(vector&amp;lt;string&amp;gt;&amp;amp; ret, string A, int start){
    int end = A.size()-1;
    if(start == end){
        ret.push_back(A);
        return;
    }else{
        for(int j=start; j&amp;lt;=end; ++j){
            std::swap(A[start], A[j]);        //轮流固定在第一个位置
            getPermutation(ret, A, start+1);
            std::swap(A[start], A[j]);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行上面的例子，结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/aVKXDCF.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;所以，其实STL算法next_permutation是去掉了重复的全排列。&lt;/p&gt;
&lt;h3 id=&quot;组合&quot;&gt;&lt;a href=&quot;#组合&quot; class=&quot;headerlink&quot; title=&quot;组合&quot;&gt;&lt;/a&gt;组合&lt;/h3&gt;&lt;p&gt;如果不是求字符的所有排列，而是求其所有组合呢？比如字符a、b、c，它们的组合有a,b,c,ab,ac,bc,abc。    &lt;/p&gt;
&lt;h4 id=&quot;基于位图的算法&quot;&gt;&lt;a href=&quot;#基于位图的算法&quot; class=&quot;headerlink&quot; title=&quot;基于位图的算法&quot;&gt;&lt;/a&gt;基于位图的算法&lt;/h4&gt;&lt;p&gt;简单的数学知识：假设原有n个字符，则最终组合结果是2^n-1个。采用位操作：假设有元素a、b、c三个，规定二进制1表示取该元素，0表示不取。故取a的二进制表示为001，ab为011，依次类推，000没有意义。&lt;br&gt;所以，这些结果与位图的对应关系：&lt;br&gt;001, 010, 011, 100, 101, 110, 111&lt;br&gt;a, b, ab, c, ac, bc, abc&lt;br&gt;因此，可以循环1~2^n-1，然后输出对应代表的组合即可。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Combination(string A){
    int n=1&amp;lt;&amp;lt;A.size();
    for(int i=1;i&amp;lt;n;++i){
        for(int j=0;j&amp;lt;A.size();++j){
            if((1&amp;gt;&amp;gt;j)&amp;amp;i)        //对应位上为1，则输出对应的字符
                cout &amp;lt;&amp;lt; A[j];
        }                        //每一个组合
        cout &amp;lt;&amp;lt; endl;
    }
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码运行结果如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/hJmuKDD.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;很久没有深入研究数据结构和算法了…&lt;br&gt;这次换个套路，先不说那些干瘪瘪的理论，首先来看一道编程题。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL仿函数</title>
    <link href="http://blog.dujiong.net/2016/10/21/STL-functor/"/>
    <id>http://blog.dujiong.net/2016/10/21/STL-functor/</id>
    <published>2016-10-21T12:10:17.000Z</published>
    <updated>2016-10-18T12:10:54.242Z</updated>
    
    <content type="html">&lt;p&gt;仿函数，又称为函数对象，即一种具有函数特质的对象，指的是那些可以被传入其他函数或是从其他函数返回的函数。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;函数指针与函数对象&quot;&gt;&lt;a href=&quot;#函数指针与函数对象&quot; class=&quot;headerlink&quot; title=&quot;函数指针与函数对象&quot;&gt;&lt;/a&gt;函数指针与函数对象&lt;/h3&gt;&lt;p&gt;我们知道，STL所提供的各种算法，往往有两个版本，其中一个版本表现出最常用（或最直观）的某种运算，第二个版本则表现出最泛化的演算流程，允许用户“以template参数来指定所要采取的策略”。以accumulate()为例，其第一版本是将指定范围内的所有元素相加，第二版本则允许你指定某种“操作”，取代第一版本的“相加”行为。所以，要将某种“操作”当做算法的参数，首先想到的办法就是先将该“操作”设计为一个函数，再将函数指针当做算法的一个参数；或者将该“操作”设计为一个仿函数（语言层面而言是个class），再以该仿函数产生一个对象，并以此对象作为算法的一个参数。      下面通过一个实际的例子说明这两种方法。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;

using namespace std;

int add_func(int a, int b){
    return a+b;
}

class AddClass{
public:
       int operator()(int a, int b) { return a+b; }
};

typedef int (*AddFunction)(int a, int b);

int main()
{
    {
        AddClass addClass;
        int sum = addClass(1,2);
        cout &amp;lt;&amp;lt; &amp;quot;addClass: &amp;quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    }

    {
        AddFunction addFunction = &amp;amp;add_func;
        int sum = addFunction(1,2);
        cout &amp;lt;&amp;lt; &amp;quot;addFunction: &amp;quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，函数对象实际上就是一个重载了operator()操作符的类，这就是函数对象与普通类的差别。另外，函数对象和函数指针在定义的方式不一样，但是调用的方式是一样的。那既然已经有了函数指针这个东西，为什么还要发明函数对象呢？其实很简单，函数对象可以将附加数据保存在成员变量中，从而实现携带附加数据，而函数指针就不行了。考虑下面一个应用场景，我们需要使用std::for_ecah将一个std::vector中的每一个值加上某个值然后输出，如果使用普通函数，则其声明应该为&lt;code&gt;void add_num(int value, int num);&lt;/code&gt;，其中value为容器中的元素，num为要加上的数。但是由于std::for_each函数的第三个参数要求传入接受一个参数的函数或函数对象，所以将add_num函数传入std::for_each是错误的，然而函数对象可以携带附加数据解决这个问题。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;algorithm&amp;gt;

using namespace std;

class Add
{
    public:
        void operator()(int value){
            cout &amp;lt;&amp;lt; value + num_ &amp;lt;&amp;lt; endl;
        }
    private:
        int num_;
}；

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    Add add(2);
    std::for_each(ivec.begin(), ivec.end(), add);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;仿函数的型别&quot;&gt;&lt;a href=&quot;#仿函数的型别&quot; class=&quot;headerlink&quot; title=&quot;仿函数的型别&quot;&gt;&lt;/a&gt;仿函数的型别&lt;/h3&gt;&lt;p&gt;仿函数的相应型别主要用来表现函数参数型别和传回值型别。为了方便起见，&lt;stl\_function.h&gt;定义了两个classes，分别代表一元仿函数和二元仿函数（STL不支持三元仿函数），其中没有任何data members或member functions，唯有一些型别定义，任何仿函数，只要依个人需求选择继承其中一个class，便自动拥有了那些相应型别，也就自动拥有了配接能力。&lt;br&gt;unary_function和binary_function分别用来呈现一元和二元函数的参数型别和返回值型别。用户可以继承它们，从而定义自己的仿函数。   &lt;/stl\_function.h&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct negate : public unary_function&amp;lt;T,T&amp;gt; {
    T operator() (const T&amp;amp; x) const { return -x; }
}

template &amp;lt;class T&amp;gt;
struct plus : public binary_function&amp;lt;T,T,T&amp;gt; {
    T operator() (const T&amp;amp; x, const T&amp;amp; y) const { return x + y; }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;STL仿函数的分类，若以操作数的个数划分，可分为一元和二元仿函数，若以功能划分，可分为算术运算、关系运算和逻辑运算三大类。     &lt;/p&gt;
&lt;h3 id=&quot;lambda&quot;&gt;&lt;a href=&quot;#lambda&quot; class=&quot;headerlink&quot; title=&quot;lambda&quot;&gt;&lt;/a&gt;lambda&lt;/h3&gt;&lt;p&gt;lambda是C++11中引入的新特性，使程序员能定义匿名对象，而不必定义独立的函数和函数对象，这样使代码更容易编写和理解，又能防止别人的访问(调用)。简而言之，一个lambda函数是一个可以内联在代码中的函数，且通常也会传递给另外的函数（类似于仿函数）。&lt;br&gt;下面用lambda来重写上面的for_each例子。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;algorithm&amp;gt;

using namespace std;    

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    std::for_each(ivec.begin(), ivec.end(),
                  [](int x) { cout &amp;lt;&amp;lt; x + x &amp;lt;&amp;lt; endl; });
    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;lambda表达式&lt;code&gt;[] (int x) { cout &amp;lt;&amp;lt; x + 2 &amp;lt;&amp;lt; endl; }&lt;/code&gt;会让编译器产生一个类似前面例子中Add的未命名函数对象类。相比于函数对象类，lambda表达式具有如下优点：（1）简洁，不需要自己去实现函数对象类；（2）不会为临时的使用而引入新的名字，所以不会导致名字污染；（3）函数对象类名不如它的实际代码表达能力强，把代码放在更靠近它的地方将提高代码的清晰度。    &lt;/p&gt;
&lt;h3 id=&quot;std-function&quot;&gt;&lt;a href=&quot;#std-function&quot; class=&quot;headerlink&quot; title=&quot;std::function&quot;&gt;&lt;/a&gt;std::function&lt;/h3&gt;&lt;p&gt;lambda产生的闭包类型可以转换成std::function。std::function对象是对C++中现有的可调用实体的一种类型安全的包裹。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;algorithm?
#include &amp;lt;vector&amp;gt;

using namespace std;

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    std::function&amp;lt;void(int)&amp;gt; func = [](int val) { std::cout &amp;lt;&amp;lt; val+2 &amp;lt;&amp;lt; endl; }
    std::for_each(ivec.begin(), ivec.end(), func);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;std::function是个类模板，可以对函数（普通函数、成员函数）、lambda表达式、std::bind的绑定表达式、函数对象等进行封装。std::function的实例可以对这些封装的目标进行存储、复制和调用等操作。  &lt;/p&gt;
&lt;h3 id=&quot;std-bind&quot;&gt;&lt;a href=&quot;#std-bind&quot; class=&quot;headerlink&quot; title=&quot;std::bind&quot;&gt;&lt;/a&gt;std::bind&lt;/h3&gt;&lt;p&gt;函数模板std::bind能对普通函数、成员函数、静态成员函数、公共成员变量、公共静态成员变量等进行包装，调用std::bind的包装相当与将函数名和参数绑定在函数内部。std::bind函数模板返回的函数对象的类型是不确定的，但是可以存储在std::function内。std::bind绑定的参数是通过传值的方式传递的，如果需要通过引用传递则参数先需要用std::ref、std::cref进行引用，然后在传递给std::bind 将std::bind函数模板的返回值保存在std::function后，调用时需要传递的参数个数由std::bind中的占位符（std::placeholders::1、std::placeholders::2、std::placeholders::_3等）个数决定，即有几个占位符调用时就需要几个参数。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;

int testFunc(int a, char c, float f){
    cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; f &amp;lt;&amp;lt; endl;

    return a;
}

int main()
{
    auto bindFunc1 = std::bind(testFunc, std::placeholders::_1, &amp;apos;A&amp;apos;, 100.1);
    bindFunc1(10);

    auto bindFunc2 = std::bind(testFunc, std::placeholders::_1, std::placeholders::_1, 100.1);
    bindFunc2(&amp;apos;B&amp;apos;, 10);

    auto bindFunc3 = bind(TestFunc, std::placeholders::_2, std::placeholders::_3, std::placeholders::_1);
    bindFunc3(100.1, 30, &amp;apos;C&amp;apos;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;本文从STL functor开始，研究了那些可以被传入其他函数或是从其他函数返回的函数，包括函数指针、函数对象、lambda、function和bind。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;仿函数，又称为函数对象，即一种具有函数特质的对象，指的是那些可以被传入其他函数或是从其他函数返回的函数。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Data Center Bridging</title>
    <link href="http://blog.dujiong.net/2016/10/18/DataCenterBridging/"/>
    <id>http://blog.dujiong.net/2016/10/18/DataCenterBridging/</id>
    <published>2016-10-18T04:34:17.000Z</published>
    <updated>2016-10-18T07:14:35.762Z</updated>
    
    <content type="html">&lt;p&gt;最近，在参与一个数据中心-云存储的项目，用到了DCB（Data Center Bridging，数据中心桥接）协议。现将学到的相关知识总结出来，以供同行交流，同时加深自己的理解。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;在企业中，传统数据中心通常会使用不同的技术来实现不同数据流量的传输，例如LAN（Local Area Network，以太网）技术用来实现IP流量的传输，SAN（Storage Area Network，存储网络）技术用来实现光纤通道存储流量的传输，除此之外，还会用InifiniBand技术来为高性能集群计算提供支持。此时，虽然通过不同的技术解决了数据中心业务需求，但是以上技术的结合使用也导致了企业将面临如下问题，并且随着数据中心规模的逐步增大，问题的严重性也日益增加；首先存在服务器兼容问题，不同的服务器需要多个专用适配器，同时也需要不同的布线系统；其次是设备统一管理问题，由于多套网络无法统一管理，因此需要不同的维护人员，这将导致设备的部署、配置、管理都会很困难。最后是设备成本问题，以上技术的结合使用导致机房需要支持更多的设备，随之而来的则是服务器的电费预算将上升，并且对于服务器的制冷要求也会增加。&lt;br&gt;以上只是硬件问题，不同的技术在满足QoS（Quality of Service，服务质量）的需求上也存在较大差异。例如，LAN流量允许丢包，只需要设备提供尽力而为的服务，丢包和乱序问题则由两端的主机来处理，不需要网络节点做过多的干预；SAN流量对丢包敏感，且要求报文在传输过程中是有序的；IPC（Inter-Process Communication，进程间通信）则对低延时要求很高。&lt;br&gt;多网融合是解决上述问题的方向，即将采用多种技术的网络整合成统一技术的网络。而随着以太网IP技术的高速发展，使用以太网来统一承载上述各种流量在数据中心得到了广泛应用；此外，为了进一步满足各种流量（尤其是SAN流量）的QoS需求，在传统以太网的基础上产生了DCB协议。&lt;br&gt;DCB协议是一组由IEEE 802.1工作组定义的以太网增强协议，广泛应用于现有的数据中心网络中。DCB协议充分利用了传统以太网的优势，通过增添多种关键扩展功能来为数据中心网络提供无损数据传输、低延时和物理链路带宽共享的功能。DCB协议的主要特性有：PFC（Priority-based Flow Control，基于优先级的流量控制）、ETS（Enhanced Transmission Selection，增强流量选择）、DCBX（Data Center Bridging Capabilities Exchange Protocol，数据中心桥接交换协议）和ECN（Explicit Congestion Notification，显示拥塞通告）。 &lt;/p&gt;
&lt;h3 id=&quot;PFC&quot;&gt;&lt;a href=&quot;#PFC&quot; class=&quot;headerlink&quot; title=&quot;PFC&quot;&gt;&lt;/a&gt;PFC&lt;/h3&gt;&lt;p&gt;PFC是一种对IEEE802.3定义的流控机制的增强技术，主要用于消除链路阻塞而导致的丢包。PFC属于DCB的一部分，适用于DCB网络中点到点的全双工链路。在传统的以太网流控机制中，当下游设备发现接收能力小于上游设备的发送能力时，会主动发一个Pause帧给上游设备，要求暂停流量的发送，上游设备等待一定时间后再继续发送数据。此时虽然能够解决流控问题，但是该机制是将链路上所有的流量都暂停，即流量暂停是针对整个接口，这与数据中心的链路共享机制发生了冲突。因为链路共享机制有两个要求：（1）一种类型的突发流量不能影响其他类型流量的转发；（2）一种类型的流量大量积压在队列中不能抢占其他类型的流量的缓存资源。所以，为了解决现有以太网流控机制和链路共享之间的冲突，产生了PFC机制。&lt;br&gt;PFC是一种基于优先级的流量控制机制。PFC可以在一条以太网物理链路上创建8个独立的虚拟通道，并为每条虚拟通道指定一个优先等级，允许单独暂停和重启其中任意一条虚拟通道，同时不影响其他通道的流量。其工作机制如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/1HVTK7q.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Device A发送接口分成了8个优先级队列，Device B接收接口分成了8个接收缓存，两者一一对应。当Device B的端口上某个接收缓存即将产生拥塞时，向Device A发送一个反压信号“STOP”，Device A收到该信号后停止发送对应优先级队列的报文。“反压信号”实际上就是PFC帧，其具体报文格式如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/PKAQ8Df.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;报文中各字段的定义如下表所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/yddhfp4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;由此可见，PFC机制下流量暂停只针对某一个或几个优先级队列，不针对整个端口进行中断。这样将会使得每个队列都能单独进行暂停或重启，而不影响其他队列上的流量，从而实现了多种流量对链路的共享。而对于非PFC控制的优先级队列，系统则不进行反压处理，在发生拥塞时直接丢弃报文。&lt;/p&gt;
&lt;h3 id=&quot;ETS&quot;&gt;&lt;a href=&quot;#ETS&quot; class=&quot;headerlink&quot; title=&quot;ETS&quot;&gt;&lt;/a&gt;ETS&lt;/h3&gt;&lt;p&gt;ETS是DCB的另一个重要组成部分，它主要是通过灵活的层次化调度来实现对QoS的高需求。ETS提供两级调度，分别为基于PG（Priority Group，优先级组）的调度和基于优先级的调度；ETS的调度流程如下图所示，即：首先，接口对PG进行第一级调度，然后针对PG内的不同优先级队列进行第二级调度。通过采用ETS技术，可以为网络中不同类型的流量提供不同的服务和带宽。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2KZIJgX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在ETS中定义了3个优先级组PG0、PG1和PG15，分别代表LAN流量、SAN流量和IPC流量。ETS协议根据不同流量的QoS需求规定了不同的调度方式。IEEE 802.1Qaz中定义了三种ETS调度算法：WRR（Weighted Round Robin，基于权重的轮询）算法、SP（Strict Priority，严格优先级）算法和CBS（Credit-Based Shaper，令牌整形调度）算法；ETS协议对三个优先级组PG0、PG1、PG15常见的调度方式是SP算法和WRR算法，其中PG15采用的是SP算法，主要是由于PG15承载的是IPC流量，对延时要求很高；PG0和PG1则采用了WRR算法，其主要承载的是LAN流量和SAN流量。同时，用户可以根据自身的实际需求对优先级组PG0、PG1、PG15等划分不同的带宽。&lt;br&gt;下面简要介绍SP算法和WRR算法。&lt;/p&gt;
&lt;h4 id=&quot;SP算法&quot;&gt;&lt;a href=&quot;#SP算法&quot; class=&quot;headerlink&quot; title=&quot;SP算法&quot;&gt;&lt;/a&gt;SP算法&lt;/h4&gt;&lt;p&gt;如图所示，SP算法要求严格按照优先级来发送队列中的报文，优先发送高优先级队列中的报文，当高优先级队列为空时，再发送低优先级队列中的报文，在图1-4中的8个队列中，队列7优先级最高，队列0优先级最低，所以先发送队列7中的报文，最后发送队列0的报文。根据以上原理，SP算法常用于通过将关键业务报文放入高优先级队列，从而保证这些业务的正常运行的场景。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/24sjzR3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;WRR算法&quot;&gt;&lt;a href=&quot;#WRR算法&quot; class=&quot;headerlink&quot; title=&quot;WRR算法&quot;&gt;&lt;/a&gt;WRR算法&lt;/h4&gt;&lt;p&gt;WRR算法是一种常用的轮询调度算法，该算法先给每个队列分配一定的权重，然后在队列之间进行轮流调度。每个队列的权重决定了调度到该队列时可以发送的数据量。通过轮询，WRR算法保证每个队列都能得到调度，避免出现低优先级队列饿死的情况。WRR算法的工作过程如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/TCA7P5g.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;DCBX&quot;&gt;&lt;a href=&quot;#DCBX&quot; class=&quot;headerlink&quot; title=&quot;DCBX&quot;&gt;&lt;/a&gt;DCBX&lt;/h3&gt;&lt;p&gt;在数据中心网络融合场景下，为实现上述以太网增强协议，链路两端的PFC和ETS的参数配置需要保持一致，因此对于PFC和ETS的参数需要进行配置。但是如果这些配置单纯依靠管理员手动设置，不仅工作量庞大而且极易出错。因此提出了DCBX协议，DCBX协议是一种链路发现协议，主要是为链路两端的设备发现并交换DCB配置信息提供了通信方式。&lt;br&gt;DCBX协议作为信息的载体，运行在点对点的链路上，用于通告本机的PFC、ETS等参数的配置信息，同时，它也期望接收对端发送的配置的信息用以引导本机配置。DCBX将需要交互的DCB配置信息封装到LLDP（Link Layer Discovery Protocol，链路层发现协议）中的TLV中，借由LLDP来进行链路两端设备的DCB配置交换。下面以DCB的PFC参数为例，简要说明LLDP承载DCBX的实现过程。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/yUXsCiR.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上图所示，端口Port A和Port B已经开启了LLDP功能和DCBX功能。主要信息交互流程如下：首先，Port A的LLDP模块根据自己的报文发送周期定期地向Port B发送携带DCBX TLV的LLDP报文；然后，Port B收到LLDP报文后解析出DCBX TLV，将Port A的PFC参数通知给DCBX模块；最后，DCBX模块将Port A参数和本地的PFC参数进行比较，协商一致后生成配置文件，保证两端配置一致。DCBX的TLV结构定义如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/j8iw750.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，Type字段固定为127，OUI字段固定为0x0080c2，Subtype字段为DCBX TLV承载的消息类型，包括ETS Configuration TLV、ETS Recommendation TLV和PFC Configuration TLV，其具体内容如下表所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/3sEu8Cp.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;h3 id=&quot;ECN&quot;&gt;&lt;a href=&quot;#ECN&quot; class=&quot;headerlink&quot; title=&quot;ECN&quot;&gt;&lt;/a&gt;ECN&lt;/h3&gt;&lt;p&gt;传统的TCP/IP网络中，网络拥塞控制算法都是用包丢失作为指示信息，通知端系统网络中发生了拥塞，进而通过降低发送方的发送速率来减轻拥塞程度。&lt;br&gt;而ECN则采用了一种完全不同的方法，其核心思想是通过路由器标记IP头部的特定比特位来反映网络拥塞状况。当标记报文到达目的地址后，接收方使用下一个ACK通知发送方有拥塞发生，最后，发送方做出响应，缩小拥塞窗口，降低发送速率。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/LFQRQa7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;根据上图IP首部信息可知，ECN拥塞控制主要用到了IP首部TOS域中的最后两位，称作为ECN域，其字段定义如下表所示。当一个支持ECN的主机发送数据包时首先将ECN域设置为01或10，如果在该数据包的传输路径上的路由器支持ECN并且监测到拥塞信息，它将会把ECN域设置为11，表示网络出现拥塞。而如果ECN域已经被标记为11，下游路由器不会修改其值。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/90Qe1wt.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此外，ECN仍然需要传输层协议的支持。TCP使用6位保留位的后两位来支持ECN。其字段定义如下图所示。其中，ECE（ECN-Echo）标志位有两个作用：（1）在TCP三次握手中表明TCP端是否支持ECN；（2）在传输数据时表明接收到的TCP段的IP首部的ECN被设置为11，即出现了拥塞。CWR标志位为发送端缩小拥塞窗口标志，用来通知接收端它已经收到设置了ECE标志的ACK，并减小了发送窗口。当接收端收到CWR标志的包时，停止在接下来的ACK中设置ECE标志。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2SXhQy4.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;DCB协议是一组由IEEE 802.1工作组定义的以太网增强协议，广泛应用于现有的数据中心网络中。DCB协议充分利用了传统以太网的优势，通过增添多种关键扩展功能来为数据中心网络提供无损数据传输、低延时和物理链路带宽共享的功能。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在参与一个数据中心-云存储的项目，用到了DCB（Data Center Bridging，数据中心桥接）协议。现将学到的相关知识总结出来，以供同行交流，同时加深自己的理解。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL迭代器</title>
    <link href="http://blog.dujiong.net/2016/10/14/STL-iterator/"/>
    <id>http://blog.dujiong.net/2016/10/14/STL-iterator/</id>
    <published>2016-10-14T09:49:12.000Z</published>
    <updated>2016-10-17T13:31:20.941Z</updated>
    
    <content type="html">&lt;p&gt;我们知道，STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一帖胶着剂将他们撮合在一起。容器和算法的泛型化，可分别通过C++的class templates和function templates达成目标，而如何设计出两者之间的良好胶着剂，是一个值得深究的问题。本文所要学习的迭代器（iterator）就是在STL中扮演粘胶的角色。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Traits编程手法&quot;&gt;&lt;a href=&quot;#Traits编程手法&quot; class=&quot;headerlink&quot; title=&quot;Traits编程手法&quot;&gt;&lt;/a&gt;Traits编程手法&lt;/h3&gt;&lt;p&gt;在迭代器的实现中，经常需要访问迭代器所指对象的类型，称之为该迭代器的value type。利用内嵌类型声明typedef可以轻松实现隐藏所指对象类型。如下迭代器的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct Iterator{
    typedef T value_type;
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;泛型算法就可以通过typename Iterator::value_type来获得value type。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
typename Iterator::value_type
getValue(Iterator iter){
    return *iter;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里，关键字typename必不可少，因为T是一个一个template参数，在它被实例化之前，编译器不知道T是一个类型还是一个其他的对象，typename用于告诉编译器这是一个类型，这样才能通过编译。&lt;br&gt;如此，可以解决“函数的template参数推导机制推导的只是参数，无法推导函数的返回值型别“的问题，但是有个问题，并不是所有迭代器都是class type，比如原生指针。如果不是class type，就无法为它定义内嵌型别。但STL（以及整个泛型思维）都必须接受原生指针作为一种迭代器，所以上面这样还不够。&lt;br&gt;所以，这里需要多一层的封装，即萃取编译技术。&lt;/p&gt;
&lt;h4 id=&quot;template-partial-specialization&quot;&gt;&lt;a href=&quot;#template-partial-specialization&quot; class=&quot;headerlink&quot; title=&quot;template partial specialization&quot;&gt;&lt;/a&gt;template partial specialization&lt;/h4&gt;&lt;p&gt;template partial specialization的大致意思是：如果class template拥有一个以上的template参数，我们可以针对其中某个（或数个，但非全部）template参数进行特化工作。换句话说，我们可以在泛化设计中提供一个特化版本。所以，所谓的partial specialization就是“针对（任何）template参数更进一步的条件限制所设计出来的一个特化版本”。&lt;br&gt;比如，面对以下的class template:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class C { ... };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后，有一个如下形式的partial specialization:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class C&amp;lt;T*&amp;gt; { ... };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个特化版本仅适用于“T为原生指针”的情况，即“T为原生指针”便是“T为任何型别”的一个更进一步的条件限制。&lt;br&gt;如此，我们便可以使用partial specialization解决“内嵌型别”未能解决的问题。即对“迭代器之template参数为指针”者，设计特定版的迭代器。&lt;br&gt;下面这个class template专门用来“萃取”迭代器的特性，而value_type正是迭代器的特性之一：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
struct iterator_traits {
    typedef typename Iterator::value_type value_type;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里所谓的traits，其意义是，如果Iterator定义有自己的value_type，那么通过这个traits的作用，萃取出来的value_type就是Iterator::value_type。&lt;br&gt;因此，先前的func可以改写成这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
typename iterator_traits&amp;lt;Iterator&amp;gt;::value_type
getValue(Iterator iter){
    return *iter;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如此，多了一层间接性，traits便可以拥有特化版本。令iterator_traits拥有一个partial specialization：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct iterator_traits&amp;lt;T*&amp;gt;{      //模板是一个原生指针
    typedef T value_type;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是，原生指针虽然不是一种class type，亦可通过traits取其value type。&lt;/p&gt;
&lt;h3 id=&quot;STL的五种迭代器&quot;&gt;&lt;a href=&quot;#STL的五种迭代器&quot; class=&quot;headerlink&quot; title=&quot;STL的五种迭代器&quot;&gt;&lt;/a&gt;STL的五种迭代器&lt;/h3&gt;&lt;p&gt;根据移动特性与施行操作，迭代器被分为五类：&lt;br&gt;（1）Input Iterator:这种迭代器所指的对象，不允许外界改变，客户只可读取它们所指的东西，且只能向前移动，一次一步。C++标准库中的istream_iterator是这一类的代表。&lt;br&gt;（2）Output Iterator：与Input Iterator类似，但一切只为输出，C++标准库中的ostream_iterator是这类的代表。&lt;br&gt;（3）Forward Iterator：这种迭代器可以做前述两种分类所做的每一件事，而且可以读或写所指物一次以上。&lt;br&gt;（4）Bidirectional Iterator：比上一个分类威力更大，它除了可以向前移动，还可以向后移动。STL的list迭代器就属于这一分类，set、multiset、map和multimap的迭代器也都是这一分类。&lt;br&gt;（5）最具威力的当属Random Access Iterator。这种迭代器比上一个分类威力更大的地方在于它可以执行“迭代器算术”，也就是可以在常量时间内向前或向后跳跃任意距离，这样的算术很类似指针算术，因为random access迭代器正是以内置（原始）指针为榜样，而内置指针也可被当做random access迭代器使用。 vector, deque和string提供的迭代器都是这一分类。&lt;br&gt;这些迭代器的分类与从属关系，如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/WSUJIqE.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;设计算法时，如果可能，我们尽量针对上图中的某种迭代器提供一个明确定义，并针对更强化的某种迭代器提供另一种定义，这样才能在不同情况下提供最大效率。假设有个算法可接受Forward Iterator，而传入Random Access Iterator，它当然也会接受，因为一个Random Access Iterator必然是一个Forward Iterator，但是并不是最佳。&lt;br&gt;以advance()为例说明使用函数重载机制来选择最佳的迭代器版本。advance()函数有两个参数，迭代器p和数值n，函数内部将p累进n次。下面有分别针对Input Iterator、Bidirectional Iterator和Random Access Iterator的三种函数定义版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_II(InputIterator&amp;amp; i, Distance n){
    while(n--) ++i;        
}

template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_BI(InputIterator&amp;amp; i, Distance n){
    if(n&amp;gt;=0)
        while(n--) ++i;
    else
        while(n++) ++i;
}    

template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_RAI(InputIterator&amp;amp; i, Distance n){
    i+=n;        
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在，当程序调用advance()时，应该选择跟自己最匹配的版本，所以，我们需要将三者合一。首先想到的是运用条件判断。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance(InputIterator&amp;amp; i, Distance n){
    if(is_random_access_iterator(i)){
        advance_RAI(i, n);
    }else if(is_bidirectional_iterator(i)){
        advance_BI(i, n);
    }else{
        advance_II(i, n);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是像这样在执行时期才决定使用哪一个版本，会影响程序效率。最好能在编译期就选择正确的版本，所以，采用函数重载机制。&lt;br&gt;前面三个advance_xx()都有两个函数参数，型别都未定（都是template参数），为了令其同名，形成重载函数，我们必须加上一个型别已确定的函数参数，使函数重载机制得以有效运作起来。&lt;br&gt;STL设计思想为：如果traits有能力萃取出迭代器的种类，我们便可利用这个“迭代器类型”相应型别作为advanced()的三个参数，这个相应型别一定必须是一个class type，因为编译器需要依赖它（一个型别）来进行重载决议。&lt;br&gt;定义五个class，代表五种迭代器类型：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct input_iterator_tag { };
struct output_iterator_tag { };
struct forward_iterator_tag : public input_iterator_tag｛｝；
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在重新设计__advance，并加上第三参数，使它们形成重载:   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
inline void __advance(InputIterator&amp;amp; i, Distance n,
                      input_iterator_tag){
    while(n--) ++i;
}

template &amp;lt;class BidirectionalIterator, class Distance n&amp;gt;
inline void __advance(BidirectionalIterator&amp;amp; i, Distance n,
                      bidirectional_iterator_tag){
    if(n&amp;gt;=0)
        while(n--) ++i;
    else
        while(n++) --i;
}
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个__advance()的最后一个参数都只声明型别，并未指定参数名称，因为它纯粹只是用来激活重载机制，函数之中根本不使用该参数。&lt;br&gt;最后，还需要一个对外开放的上层接口，调用上述各个重载的__advance()，这一上层接口只需要两个参数，当它准备将工作转给上述的__advance()时，才自行加上第三参数：迭代器类型。因此，这个上层函数必须有能力从它所能获得的迭代器中推导出其类型（traits机制）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
inline void advance(InputIterator&amp;amp; i, Distance n){
    __advance(i, n, 
                iterator_traits&amp;lt;InputIterator&amp;gt;::iterator_category());
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;iterator_traits&lt;inputiterator&gt;::iterator&lt;em&gt;category())将产生一个暂时对象，其型别应该隶属于前述四个迭代器类型，然后根据这个型别，编译器才决定调用哪一个\&lt;/em&gt;_advance()重载函数。&lt;br&gt;因此，为了满足上述行为，traits必须再增加一个相应的型别：&lt;/inputiterator&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
struct iterator_traits{
    ...
    typedef typename Iterator::iterator_category iterator_category;
};

//针对原生指针
template &amp;lt;class T&amp;gt;
struct iterator_traits&amp;lt;T*&amp;gt;{
    ...
    typedef typename random_access_iterator_tag iterator_category;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后一个问题，STL算法的命名规则：以算法所能接收之最低阶迭代器类型，来为其迭代器型别参数命名。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;我们知道，STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一帖胶着剂将他们撮合在一起。容器和算法的泛型化，可分别通过C++的class templates和function templates达成目标，而如何设计出两者之间的良好胶着剂，是一个值得深究的问题。本文所要学习的迭代器（iterator）就是在STL中扮演粘胶的角色。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL空间配置器</title>
    <link href="http://blog.dujiong.net/2016/10/09/STL-allocator/"/>
    <id>http://blog.dujiong.net/2016/10/09/STL-allocator/</id>
    <published>2016-10-09T05:54:15.000Z</published>
    <updated>2016-10-13T11:18:08.167Z</updated>
    
    <content type="html">&lt;p&gt;最近准备结合《STL源码剖析》把学习的STL知识整理一遍，加深自己的理解的同时，也方便以后需要的时候查看。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;首先总结的是STL中的内存分配—空间配置器，从STL的运用角度而言，空间配置器是最不需要介绍的东西，因为用户使用过程中不会直接与其打交道，但是，从STL的实现角度看，空间配置器又是最重要的知识点之一，因为整个STL的操作对象都存放在容器之内，而容器一定需要配置空间以放置数据。&lt;br&gt;C++ STL配置器分为两层配置器，当请求的内存大于128bytes时，视为“足够大”，用第一层配置器分配内存，当请求的内存小于128bytes时，视为“过小”，调用第二级配置器，第二级配置器采用复杂的内存池整理方式，而不再求助于第一级配置器。&lt;/p&gt;
&lt;h3 id=&quot;第一级配置器&quot;&gt;&lt;a href=&quot;#第一级配置器&quot; class=&quot;headerlink&quot; title=&quot;第一级配置器&quot;&gt;&lt;/a&gt;第一级配置器&lt;/h3&gt;&lt;p&gt;首先来看下主要的源代码：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;int inst&amp;gt;
class __malloc_alloc_template{
private:
    static void *oom_malloc(size_t);    //malloc调用内存不足
    static void *oom_realloc(void*, size_t);    //realloc调用内存不足
    static void (*__malloc_alloc_oom_handler)();    //错误处理函数
public:
    static void* allocate(size_t){
        void *result = malloc(n);        //第一级配置器直接调用malloc()
        if(0 == result) result = oom_malloc(n);
        return result;
    }
    static void* deallocate(void *p, size_t){
        free(p);            
    }
    static void *reallocate(void *p, size_t/* old_sz */, size_t new_sz){
        void *result = realloc(p, new_sz);    //第一级配置器直接调用realloc()
        if(0 == result) result = oom_realloc(p, new_sz);
        return result;    
    }
    static void (*set_malloc_handler(void (*f)()))(){    //设置错误处理函数
        void (* old)() = __malloc_alloc_oom_handler;
        __malloc_alloc_oom_handler = f;
        return(old);    
    }
};

template &amp;lt;int inst&amp;gt;
void* __malloc_alloc_template&amp;lt;inst&amp;gt;::oom_alloc(size_t n){
    void (* my_alloc_handler)();     //声明函数指针
    void *result;                     //返回的内存指针
    for(;;){                          //循环，直到成功
        my_alloc_handler = __malloc_alloc_oom_handler;    
        if(0 == my_alloc_handler){ __THROW_BAD_ALLOC; }        //抛出异常
        (*my_alloc_handler)();
        result = malloc(n);            //再重新分配内存
        if(result) return(result);        
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一级配置器相对简单，其使用malloc(), free(), realloc()等C函数执行实际的内存分配，释放，重新配置等操作。此外，这个配置器提供了当内存配置错误时的处理函数oom&lt;em&gt;malloc，这个函数会调用\&lt;/em&gt;_malloc_alloc_oom_handler()这个错误处理函数，去企图释放内存，然后重新调用malloc分配内存。如此循环，直到分配成功，返回指针。&lt;/p&gt;
&lt;h3 id=&quot;第二级配置器&quot;&gt;&lt;a href=&quot;#第二级配置器&quot; class=&quot;headerlink&quot; title=&quot;第二级配置器&quot;&gt;&lt;/a&gt;第二级配置器&lt;/h3&gt;&lt;p&gt;STL第二级配置器的做法是，如果区块够大，超过128bytes时，就移交第一级配置器处理。当区块小于128bytes时，则以内存池管理，即每次配置一大块内存，并维护对应之自由链表，下次若再有相同大小的内存需求，就直接从free lists中拔出，而如果客户端释还小额区块，就由配置器回收到free lists中。&lt;br&gt;为了方便管理，SGI第二级配置器会主动将任何小额区块的内存需求量上调至8的倍数（例如客端要求30bytes，就会自动调整为32bytes），并维护16个free lists，各自管理大小分别为8,16,24,32,40,48,56,64,72,80,88,96,104,112,120,128的小额区块。&lt;br&gt;free-lists的节点结构定义如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;union obj {
    union obj *free_list_link;     //指向下一个内存的地址
    char client_data[1];           //内存的首地址 
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据union的特性，obj的内存布局应该如下所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/IE7fZAU.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从起第一字段观之，obj被视为一个指针，指向相同形式的另一个obj，从其第二字段观之，obj可被视为一个指针，指向实际区块。这样一物二用的结果是，不会为了维护链表所必须的指针而造成内存的另一种浪费。&lt;br&gt;下面来看一下相关的源代码。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;enum {__ALIGN = 8}；
enum {__MAX_BYTES = 128};
enum {__NFREELISTS = __MAX_BYTES/__ALIGN};

template &amp;lt;bool threads, int inst&amp;gt;
class __default_alloc_template{
    ...
    static size_t ROUND_UP(size_t bytes){        //将bytes上调至8的倍数
        return (((bytes)+__ALIGN-1) &amp;amp; ~(__ALIGN-1));
    }
    static obj* volatile free_list[__NFREELISTS];    //内存池链表
    static size_t FREELIST_INDEX(size_t bytes){    
        return (((bytes)+__ALIGN-1)/__ALIGN-1);        //根据区块大小，决定使用第n号free-list
    }
    ...    
};

static void* allocate(size_t n){
    obj * volatile * my_free_list;
    obj * result;
    if(n &amp;gt; (size_t)__MAX_BYTES){
        return (malloc_alloc::allocate(n));
    }
    my_free_list = free_list + FREELIST_INDEX(n);    //寻找合适的那个free_list
    result = *my_free_list;
    if(result == 0){        //没找到可用的free_list,准备重新填充free_list
        void* r = refill(ROUND_UP(n));
        return r;
    }
    *my_free_list = result-&amp;gt;free_list_link;        //调整free_list
    return (result);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;具体操作如下图所示（摘自《STL源码剖析》）。当有内存请求到达时（第二级配置器），先找到负责这个内存大小的数据元素指向的内存链表，取出第一块内存，然后把数据元素(obj指针)指向第二块内存的首地址。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/VrO5VMA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此外，当程序释放这块内存时，第二级配置器还负责回收这块内存，等下次有请求时，可以直接使用这块内存。示意图（摘自《STL源码剖析》）如下：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/um5jnaS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;先计算这块内存属于哪个数组元素负责，然后将这块回收的内存放置链表的第一个位置，这块内存的下一块内存为这个链表原先的第一块内存。源代码如下；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void deallocate(void *p, size_t n){
    obj *q = (obj *)p;
    obj * volatile * my_free_list;

    if(n &amp;gt; (size_t)__MAX_BYTES) {    //大于128bytes,调用第一级配置器回收
        malloc_alloc::deallocate(p, n);
        return;
    }
    my_free_list = free_list + FREELIST_INDEX(n);    //找到负责这块内存的数据元素
    q -&amp;gt;free_list_link = *my_free_list;         
    *my_free_list = q;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;重新填充free-lists&quot;&gt;&lt;a href=&quot;#重新填充free-lists&quot; class=&quot;headerlink&quot; title=&quot;重新填充free lists&quot;&gt;&lt;/a&gt;重新填充free lists&lt;/h3&gt;&lt;p&gt;在上面的allocate()中，当发现free list中没有可用区块了时，就调用refill()，准备为free list重现填充空间。新的空间将取自内存池（经由chunk_alloc()完成）。缺省取得20个新节点（新区块），但万一内存池空间不足，获得的区块数可能小于20。例如，如果请求内存为32bytes，此时内存链表中没有足够的内存了，那么refill会分配20块32bytes的内存块，然后把第一块返回给程序，其他19块由数组相应链表管理。相应的源代码为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;bool threads, int inst&amp;gt;
void* __default_alloc_template&amp;lt;threads, inst&amp;gt;::refill(size_t n){
    int nobjs = 20;
    char *chunk = chunk_alloc(n, nobjs);   //nobjs: pass by reference
    obj * volatile * my_free_list;
    obj * result;
    obj * current_obj, next_obj;
    int i;

    if(1 == nodejs) return chunk;    //如果只返回一块内存，直接返回
    my_free_list = free_list + FREELIST_INDEX(n);

    result = (obj*)chunk;        //不止一块内存，取出第一块内存
    *my_free_list = next_obj = (obj *)(chunk + n );   //数组元素链表指针指向第二块内存
    for(i=1; ;i++){
        curent_obj = next_obj;
        next_obj = (*obj)((char*)next_obj+n);
        if(nobjs - 1 ==i){
            current_obj-&amp;gt;free_list_link = 0;
            break;
        }else{
            current_obj-&amp;gt;free_list_link = next_obj;
        }
    }
    return(result);
}            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;接下来分析真正从内存池获取内存的函数chunk_alloc。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;bool threads, int inst&amp;gt;
char* __default_alloc_template&amp;lt;threads, inst&amp;gt;::chunk_alloc(size_t size, int&amp;amp; nobjs){
    char* result;
    size_t total_bytes = size * nobjs;
    size_t bytes_left = end_free - start_free;        //内存池剩余的内存

    if(bytes_left &amp;gt;= total_bytes){        //当内存持内存足够时
        result = start_free;
        start_free += total_free;
        return(result);
    }else if(bytes_left &amp;gt;= size){        //内存池不能满足total，但是可以满足一块以上
        nobjs = bytes_left/size;
        total_bytes = size * nobjs;
        result = start_free;
        start_free += total_bytes;
        return(result);
    }else{                //试着让内存池的残余零头还有利用价值
        size_t bytes_to_get = 2*total_bytes + ROUND_UP(heap_size &amp;gt;&amp;gt; 4);
        if(bytes_left &amp;gt; 0){
            obj * volatile * my_free_list = free_list + FREELIST_INDEX(bytes_left);
            ((obj *)start_free) -&amp;gt; free_list_link = *my_free_list;    //调整free list，将内存池中的残余空间编入
            *my_free_list = (*obj)start_free;
        }
        //调用malloc从内存分配
        start_free = (char*)malloc(bytes_to_get);
        if(0 == start_free){                //当系统内存不足时
            int i;
            obj * volatile * my_free_list, *p;
            for(i=size;i&amp;lt;=__MAX_BYTES;i+=__ALIGN){
                my_free_list = free_list + FREELIST_INDEX(i);
                p = *my_free_list;
                if(0 != p){
                    *my_free_list = p-&amp;gt;free_list_link;
                    start_free = (char*)p;
                    end_free = start_free + i;
                    return(chunk_alloc(size, nobjs));
                }
            }
            end_free = 0;        //从其他链表也没获取到内存，到处都没内存可用了
            start_free = (char*)malloc_alloc::allocate(byte_to_get);        //调用第一级配置器，因为有错误处理函数，最后的补救办法了
        }
        heap_size += bytes_to_get;
        end_free = start_free + bytes_to_get;
        return(chunk_alloc(size, nobjs));
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;chunk_alloc()函数以end_free-start_free来判断内存池的水量，如果水量充足，就直接调出20个区块返回给free list，如果水量不足以提供20个区块，但还足够供应一个以上的区块，就拨出这不足20个区块的空间出去，这时候pass by reference的nobjs参数被修改为实际能够供应的区块数。如果内存池连一个区块空间都无法供应，此时便利用malloc()从heap中配置内存，为内存注入源头活水以应付需求。其过程如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/SCDG2Gu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;对象内容的构造与析构&quot;&gt;&lt;a href=&quot;#对象内容的构造与析构&quot; class=&quot;headerlink&quot; title=&quot;对象内容的构造与析构&quot;&gt;&lt;/a&gt;对象内容的构造与析构&lt;/h3&gt;&lt;p&gt;我们知道，C++中的new操作符包含两阶段的操作：（1）调用::operator new配置内存；（2）调用构造函数构造对象内容，所以，为了精密分工，STL allocator决定将这两阶段 操作区分开来，内存配置操作由alloc::allocate()负责，对象构造函数由::construct()负责。同理，对象的析构与内存释放也是由两部分操作组成。&lt;/p&gt;
&lt;h3 id=&quot;使用配置器&quot;&gt;&lt;a href=&quot;#使用配置器&quot; class=&quot;headerlink&quot; title=&quot;使用配置器&quot;&gt;&lt;/a&gt;使用配置器&lt;/h3&gt;&lt;p&gt;最后，来看下配置器是如何使用的。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Alloc&amp;gt;
class simple_alloc {
public:
    static T *allocate(size_t n)
        { return 0 == n ? 0 : (T*)Alloc::allocate(n * sizeof(T)); }
    static T *allocate(void)
        { return 0 == n ? 0 : (T*)Alloc::allocate(sizeof(T)); }
    static void deallocate(T* p, size_t n)
        { if(0 != n) Alloc::deallocate(p, n * sizeof(T)); }
    static void deallocate(T* p)
        { Alloc::deallocate(p, sizeof(T)); }
};        
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;simple_alloc类封装了Alloc的分配和回收内存函数，并提供了四个用于内存操作的函数接口。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;        //alloc被默认为第二级配置器
class vector{
public:
    typedef T value_type;
    ...
protected:
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，vector内嵌了data_allocator类型，当需要分配内存时，调用simple_alloc的成员方法即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近准备结合《STL源码剖析》把学习的STL知识整理一遍，加深自己的理解的同时，也方便以后需要的时候查看。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>浅谈tcp backlog</title>
    <link href="http://blog.dujiong.net/2016/09/28/tcp-backlog/"/>
    <id>http://blog.dujiong.net/2016/09/28/tcp-backlog/</id>
    <published>2016-09-28T13:42:51.000Z</published>
    <updated>2016-09-20T15:49:44.450Z</updated>
    
    <content type="html">&lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;backlog的两种实现&quot;&gt;&lt;a href=&quot;#backlog的两种实现&quot; class=&quot;headerlink&quot; title=&quot;backlog的两种实现&quot;&gt;&lt;/a&gt;backlog的两种实现&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Ymk1keA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;首先通过上图回顾一下TCP建立连接时的状态变化。由于TCP建立连接时使用三次握手，所以监听的服务端在回给客户端SYN+ACK之后，会进入SYN RECEIVED状态，这称之为半连接状态，而只有当收到客户端回送的ACK之后，才完成连接，进入ESTABLISHED状态，等待应用层处理。所以，TCP/IP协议栈有两种方式来实现这个连接队列：&lt;br&gt;（1）第一种是使用一个单一的队列，队列的大小由应用层listen函数的backlog参数确定，当收到一个SYN请求，服务端就回发给客户端SYN+ACK，并且将该连接加入到队列中。当客户端最后的ACK到来时，该连接的状态变为ESTABLISHED，并等待应用层处理。所以，这种实现方式下，队列中包含了两种状态的连接：SYN RECEIVED和ESTABLISHED。只有后一种状态的连接才可以从acception中返回，被应用层处理。&lt;br&gt;（2）另一种实现方式是使用两个队列，一个SYN队列（即半连接队列）和一个全连接队列（ACCEPT队列）。处于SYN RECEIVED状态的连接被加入到SYN队列中，当最后一个ACK到来时，改变状态并移动到全连接队列。所以，accept系统调用直接从全连接队列中取已完成的连接交给应用层处理。这时，listen函数中的backlog值决定了全连接队列的大小。&lt;br&gt;传统的基于BSD的TCP实现采用的是第一种方式，这种实现方式意味着，当队列满的时候，系统再收到SYN，将不会回发SYN+ACK。通常，TCP实现采用的是简单地丢弃SYN，让客户端重传，而不是回发RST。&lt;br&gt;在Linux系统中，backlog的实现形式分为两个阶段，在Linux2.2之前，内核采用的也是上述的方式，队列满之后，服务端再收到SYN时，将不会返回SYN/ACK，也不返回RST，让客户端重试。而在Linux2.2之后，内核选择第二种方式实现，SYN_RECEIVED队列的大小由/proc/sys/net/ipv4/tcp_max_syn_backlog系统参数指定，ESTABLISHED队列由backlog和/proc/sys/net/core/somaxconn中较小的指定。    &lt;/p&gt;
&lt;h3 id=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;a href=&quot;#SYN队列和ACCEPT队列&quot; class=&quot;headerlink&quot; title=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;/a&gt;SYN队列和ACCEPT队列&lt;/h3&gt;&lt;p&gt;以下是操作系统维护两种队列处理TCP连接的示意图。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/sGEPFN7.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;SYN队列和已完成队列是内核实现的，当服务器绑定、监听了某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。客户端使用connect向服务器发起TCP连接时，当SYN包到达服务器之后，内核会把这一报文放入SYN队列，同时回发一个SYN+ACK包给客户端。一段时间后，当三次握手最后的ACK到达服务器，内核会把连接从SYN队列中取出，再把这个连接放入ACCEPT队列（已完成队列）中。所以，服务器调用accept，其实就是直接从ACCEPT队列中取出已经建立成功的连接套接字。&lt;br&gt;当然，随之也产生了一些问题。因为SYN和ACCEPT队列都是有大小限制的，所以，二者都会存在队列满的时候。上图中，如果第一步执行的速度大于第二步执行的速度，SYN队列就会不断增大直到队列满；如果第二步执行的速度大于第三步执行的速度，ACCEPT队列同样会满。&lt;br&gt;当ACCEPT队列已满，这时SYN队列中的一个连接收到最后的ACK，需要移动到ACCEPT队列，会发生什么呢？&lt;br&gt;通过查看内核源码(net/ipv4/tcp_ipv4.c)可知，如果/proc/sys/net/ipv4/tcp_abort_on_overflow被置为1，内核将会回送RST包，否则，将会丢弃ACK，什么都不做。进一步地，当一定时间服务端还没有收到ACK（包括丢弃掉的ACK），将会重发SYN+ACK包（“指数退避”算法）。当客户端收到重发的SYN+ACK时，它便知道ACK包丢失了，需要重传。另一方面，当ACCEPT队列已满的时候，内核将会限制SYN队列的处理速度，如果收到太多的SYN队列，将会丢弃一些。这样，丢弃的SYN对应的客户端将会重发SYN包。&lt;br&gt;另一种情况，当SYN队列满的时候，会发生什么呢？上面已经阐述了，服务器端将会直接丢弃请求，即丢弃SYN网络包。       &lt;/p&gt;
&lt;h3 id=&quot;TCP连接的一些异常情况&quot;&gt;&lt;a href=&quot;#TCP连接的一些异常情况&quot; class=&quot;headerlink&quot; title=&quot;TCP连接的一些异常情况&quot;&gt;&lt;/a&gt;TCP连接的一些异常情况&lt;/h3&gt;&lt;p&gt;针对上述的两个连接队列，有一些常见的连接异常情况。下面做一个简单总结。     &lt;/p&gt;
&lt;h4 id=&quot;服务端SYN超时&quot;&gt;&lt;a href=&quot;#服务端SYN超时&quot; class=&quot;headerlink&quot; title=&quot;服务端SYN超时&quot;&gt;&lt;/a&gt;服务端SYN超时&lt;/h4&gt;&lt;p&gt;当客户端给服务端发送SYN报文时，如果服务端没有返回SYN+ACK报文，那么客户端会重发SYN报文给服务端，重发的次数由参数tcp_syn_retries参数设置，该值默认是5，超过5次服务端还是不返回SYN+ACK报文，那么本次连接失败。服务端没有返回SYN+ACK主要有两种情况，一种是由于网络问题SYN包丢失；另一种是服务端SYN队列满，导致SYN包被丢弃。                &lt;/p&gt;
&lt;h4 id=&quot;客户端ACK超时&quot;&gt;&lt;a href=&quot;#客户端ACK超时&quot; class=&quot;headerlink&quot; title=&quot;客户端ACK超时&quot;&gt;&lt;/a&gt;客户端ACK超时&lt;/h4&gt;&lt;p&gt;如果服务端接到了客户端发的SYN并回发SYN+ACK后，客户端掉线了，这时，服务端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功也没失败。于是，服务端端如果在一定时间内没有收到客户端端的ACK，那么服务端端会重发SYN+ACK。在Linux下，默认重试次数为5次，重发的间隔时间从1s开始每次都翻番（指数退避），5次的重发的时间间隔分别1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s+2s+4s+8s+16s+32s = 2^6-1 = 63s，TCP才会把断开这个连接。              &lt;/p&gt;
&lt;h4 id=&quot;SYN-Flood&quot;&gt;&lt;a href=&quot;#SYN-Flood&quot; class=&quot;headerlink&quot; title=&quot;SYN Flood&quot;&gt;&lt;/a&gt;SYN Flood&lt;/h4&gt;&lt;p&gt;这时一种恶意攻击。客户端给服务器发一个SYN后就下线，这样服务器需要默认等待63s才会断开连接，这样攻击者就可以把服务器的SYN连接队列耗尽，让正常的连接请求不能处理。为了应对SYN Flood攻击，Linux实现了一种称为SYN cookie的机制，通过net.ipv4.tcp_syncookies来设置。当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使不在SYN队列中）。&lt;/p&gt;
&lt;h3 id=&quot;TCP连接过程参数调优&quot;&gt;&lt;a href=&quot;#TCP连接过程参数调优&quot; class=&quot;headerlink&quot; title=&quot;TCP连接过程参数调优&quot;&gt;&lt;/a&gt;TCP连接过程参数调优&lt;/h3&gt;&lt;p&gt;下面罗列一些常用于TCP连接过程优化的参数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-max-syn-backlog&quot;&gt;&lt;a href=&quot;#tcp-max-syn-backlog&quot; class=&quot;headerlink&quot; title=&quot;tcp_max_syn_backlog&quot;&gt;&lt;/a&gt;tcp_max_syn_backlog&lt;/h4&gt;&lt;p&gt;SYN队列长度。如果服务器经常出现过载，可以尝试增加这个数字。   &lt;/p&gt;
&lt;h4 id=&quot;tcp-synack-retries&quot;&gt;&lt;a href=&quot;#tcp-synack-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_synack_retries&quot;&gt;&lt;/a&gt;tcp_synack_retries&lt;/h4&gt;&lt;p&gt;连接被动打开方的确认连接的应答最大重试次数。对于一个新建连接，内核要发送多少SYN连接请求才决定放弃。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syn-retries&quot;&gt;&lt;a href=&quot;#tcp-syn-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_syn_retries&quot;&gt;&lt;/a&gt;tcp_syn_retries&lt;/h4&gt;&lt;p&gt;连接主动打开方的syn尝试次数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syncookies&quot;&gt;&lt;a href=&quot;#tcp-syncookies&quot; class=&quot;headerlink&quot; title=&quot;tcp_syncookies&quot;&gt;&lt;/a&gt;tcp_syncookies&lt;/h4&gt;&lt;p&gt;防止SYN Flood攻击。    &lt;/p&gt;
&lt;h4 id=&quot;tcp-abort-on-overflos&quot;&gt;&lt;a href=&quot;#tcp-abort-on-overflos&quot; class=&quot;headerlink&quot; title=&quot;tcp_abort_on_overflos&quot;&gt;&lt;/a&gt;tcp_abort_on_overflos&lt;/h4&gt;&lt;p&gt;ACCEPT队列满，处理不过来的时候，如果设置了该参数，内核将会回发RST包。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>数据结构之线段树</title>
    <link href="http://blog.dujiong.net/2016/09/23/SegmentTree/"/>
    <id>http://blog.dujiong.net/2016/09/23/SegmentTree/</id>
    <published>2016-09-23T13:28:16.000Z</published>
    <updated>2016-09-17T02:46:29.535Z</updated>
    
    <content type="html">&lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;线段树具有如下性质：&lt;br&gt;（1）线段树是一棵平衡树，使用线段树可以快速地查找某一个节点在若干条线段中出现的次数，时间复杂度为O(logN)。&lt;br&gt;（2）线段树同一层的节点所代表的区间，相互不会重叠。&lt;br&gt;（3）线段树任两节点要么是包含关系要么是没有公共部分，不可能部分重叠。&lt;br&gt;（4）给定一个叶子l，从根到l路径上所有节点代表的区间都包含l，且其他节点代表的区间都不包含l。&lt;br&gt;一棵[1,10]的线段树表示如下。注意，线段树的构造在各区间的端点处的处理方式不一样，会导致线段树最终的表示有些差别，但是本质上是一样的。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/JEkWmlu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;线段树的基本操作&quot;&gt;&lt;a href=&quot;#线段树的基本操作&quot; class=&quot;headerlink&quot; title=&quot;线段树的基本操作&quot;&gt;&lt;/a&gt;线段树的基本操作&lt;/h3&gt;&lt;p&gt;线段树的基本操作和普通二叉树很类似，只不过线段树的节点上存储的是一个区间（左右端点值）。下面以线段树的建立、插入线段和删除线段为例简要说明线段树的基本操作。&lt;/p&gt;
&lt;h4 id=&quot;线段树的构建&quot;&gt;&lt;a href=&quot;#线段树的构建&quot; class=&quot;headerlink&quot; title=&quot;线段树的构建&quot;&gt;&lt;/a&gt;线段树的构建&lt;/h4&gt;&lt;p&gt;首先定义线段树的结构，这里采用链表的方式组织。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Node
{
    int left,right;
    int cover;            
    Node* leftChild;
    Node* rightChild;    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，cover字段用于计算一条线段被覆盖的次数。接下来，以递归的方式构建线段树。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Node* build(int l, int r)
{
    Node* root = new Node();
    root-&amp;gt;left = l;
    root-&amp;gt;right = r;
    root-&amp;gt;cover = 0;
    root-&amp;gt;leftChild = NULL;
    root-&amp;gt;rightChild = NULL;
    if(r-l &amp;gt; 1)
    {
        int mid = (l+r) &amp;gt;&amp;gt; 1;
        root-&amp;gt;leftChild = build(l,mid);
        root-&amp;gt;rightChild = build(mid,r);        //build(mid+1,r)
    }
    return root;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;线段插入与删除&quot;&gt;&lt;a href=&quot;#线段插入与删除&quot; class=&quot;headerlink&quot; title=&quot;线段插入与删除&quot;&gt;&lt;/a&gt;线段插入与删除&lt;/h4&gt;&lt;p&gt;如上所述，通过cover字段来计算一条线段被覆盖的次数。插入与删除时更新相应线段的cover。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Insert(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover++;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Insert(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Insert(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Insert(start,mid,root-&amp;gt;leftChild);
        Insert(mid,end,root-&amp;gt;rightChild); 
    }
}

void Delete(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover--;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Delete(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Delete(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Delete(start,mid,root-&amp;gt;leftChild);
        Delete(mid,end,root-&amp;gt;rightChild);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;线段树的应用&quot;&gt;&lt;a href=&quot;#线段树的应用&quot; class=&quot;headerlink&quot; title=&quot;线段树的应用&quot;&gt;&lt;/a&gt;线段树的应用&lt;/h3&gt;&lt;p&gt;TODO&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Spin lock与Mutex</title>
    <link href="http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/"/>
    <id>http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/</id>
    <published>2016-09-18T13:34:32.000Z</published>
    <updated>2016-11-30T10:38:14.506Z</updated>
    
    <content type="html">&lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Pthreads提供了多种线程同步锁机制：&lt;br&gt;（1）Mutex（互斥量）：pthread_mutex_xxx&lt;br&gt;（2）Spin lock(自旋锁)：pthread_spin_xxx&lt;br&gt;（3）Condition Variable（条件变量）：pthread_cond_xxx&lt;br&gt;（4）Read/Write lock（读写锁）：pthread_rwlock_xxx&lt;br&gt;本文主要讲解Spin lock和其与Mutex（Mutex的用法很常见、也很简单，若还不熟悉，可参考&lt;a href=&quot;http://blog.dujiong.net/2016/07/08/muduo-5/&quot;&gt;muduo中的封装&lt;/a&gt;）之间的区别。     &lt;/p&gt;
&lt;h3 id=&quot;Spin-lock&quot;&gt;&lt;a href=&quot;#Spin-lock&quot; class=&quot;headerlink&quot; title=&quot;Spin lock&quot;&gt;&lt;/a&gt;Spin lock&lt;/h3&gt;&lt;p&gt;Spin lock又称自旋锁，线程通过busy-wait-loop的方式来获取锁，任何时刻都只有一个线程能够获得锁，其他线程忙等待直到获得锁。Spin lock在多处理器多线程环境的场景中有很广泛的使用。   &lt;/p&gt;
&lt;h4 id=&quot;Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;Spin lock和Mutex&quot;&gt;&lt;/a&gt;Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;Spin lock有如下特点：&lt;br&gt;（1）Spin lock是一种死等的锁机制。当发生访问资源冲突的时候，可以有两种机制：一个是死等，一个是挂起当前进程，调度其他线程执行（Mutex）。线程会一直进行忙等待而不停的进行锁清秋，直到得到这个锁为止。&lt;br&gt;（2）执行时间短。由于Spin lock死等这种特性，因此它使用在那些代码不是非常复杂的临界区（当然也不能太简单，否则使用原子操作或者其他适用简单场景的同步机制就可以了），如果临界区执行时间太长，那么不断在临界区门口进行死等的线程十分浪费CPU资源。&lt;br&gt;（3）可以在中断上下文执行。由于不睡眠，因此Spin lock可以在中断上下文中使用。&lt;br&gt;从上述总结的Spin lock的特点，已经可以看出其与Mutex的不同之处了，下面再以一个实例进行说明。&lt;br&gt;例如在一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core 0和Core 1上，假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，Core 0会在此时进行上下文切换将线程A置于等待队列中，此时Core 0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待。而Spin lock则不然，它属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，那么线程A就会一直在Core 0上进行忙等待并不停的进行锁请求，直到得到这个锁为止。&lt;/p&gt;
&lt;h4 id=&quot;使用Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#使用Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;使用Spin lock和Mutex&quot;&gt;&lt;/a&gt;使用Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;下面通过实际的代码来进一步比较说明Spin lock和Mutex。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;list&amp;gt;

using namespace std;

const int LOOPS = 50000000;

list&amp;lt;int&amp;gt; ilist;

#ifdef USE_SPINLOCK
    pthread_spinlock_t spinlock;
#else
    pthread_mutex_t mutex;
#endif

pid_t gettid() 
{
    return syscall( __NR_gettid );
}

void *consumer(void *ptr)
{
    int i;

    printf(&amp;quot;Consumer TID %lun&amp;quot;, (unsigned long)gettid());

    while (1)
    {
#ifdef USE_SPINLOCK
        pthread_spin_lock(&amp;amp;spinlock);
#else
        pthread_mutex_lock(&amp;amp;mutex);
#endif

        if (ilist.empty())
        {
#ifdef USE_SPINLOCK
            pthread_spin_unlock(&amp;amp;spinlock);
#else
            pthread_mutex_unlock(&amp;amp;mutex);
#endif
            break;
        }

        i = ilist.front();
        ilist.pop_front();

#ifdef USE_SPINLOCK
        pthread_spin_unlock(&amp;amp;spinlock);
#else
        pthread_mutex_unlock(&amp;amp;mutex);
#endif
      }

    return NULL;
}

int main()
{
    int i;
       pthread_t thr1, thr2;
    struct timeval tv1, tv2;

#ifdef USE_SPINLOCK
    pthread_spin_init(&amp;amp;spinlock, 0);
#else
    pthread_mutex_init(&amp;amp;mutex, NULL);
#endif

    for (i = 0; i &amp;lt; LOOPS; i++)
        ilist.push_back(i);

    gettimeofday(&amp;amp;tv1, NULL);

    pthread_create(&amp;amp;thr1, NULL, consumer, NULL);
    pthread_create(&amp;amp;thr2, NULL, consumer, NULL);

    pthread_join(thr1, NULL);
    pthread_join(thr2, NULL);

    gettimeofday(&amp;amp;tv2, NULL);

    if (tv1.tv_usec &amp;gt; tv2.tv_usec)
    {
        tv2.tv_sec--;
        tv2.tv_usec += 1000000;
    }
    printf(&amp;quot;Result - %ld.%ld\n&amp;quot;, tv2.tv_sec - tv1.tv_sec,
    tv2.tv_usec - tv1.tv_usec);

#ifdef USE_SPINLOCK
    pthread_spin_destroy(&amp;amp;spinlock);
#else
    pthread_mutex_destroy(&amp;amp;mutex);
#endif

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该程序的逻辑是：主线程先初始化一个list结构，并根据LOOPS的值将对应数量的i插入该list，之后创建两个新线程，它们都执行consumer()这个任务。两个被创建的新线程同时对这个list进行pop()操作。主线程会计算从创建两个新线程到新线程结束之间所用的时间。&lt;br&gt;代码执行平台参数：&lt;br&gt;Ubuntu14.04 X86&lt;br&gt;Inter i5-2430M @ 2.40GHz, Dual Core&lt;br&gt;4.0GB Memory&lt;br&gt;下面是代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/7dmwgzS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果中可以看出Spin lock表现出的性能更好，另外，sys时间是所花费的系统掉头时间，可以看出，Mutex将消耗更多的系统调用时间，这是因为Mutex会在锁冲突时调用System Wait造成的。&lt;br&gt;但是，当临界区很大时，两个线程的锁进程会非常的激烈。这时，Spin lock的“死等”策略效率将会急剧下降。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;

using namespace std;

const int THREAD_NUM = 2;

pthread_t g_thread[THREAD_NUM];
#ifdef USE_SPINLOCK
pthread_spinlock_t g_spin;
#else
pthread_mutex_t g_mutex;
#endif

__uint64_t g_count;

pid_t gettid()
{
    return syscall(SYS_gettid);
}

void* run_amuck(void* arg)
{
   int i, j;

   printf(&amp;quot;Thread %lu started.n&amp;quot;, (unsigned long)gettid());

   for (i = 0; i &amp;lt; 10000; i++) 
   {
#ifdef USE_SPINLOCK
       pthread_spin_lock(&amp;amp;g_spin);
#else
       pthread_mutex_lock(&amp;amp;g_mutex);
#endif
       for (j = 0; j &amp;lt; 100000; j++) 
       {
           if (g_count++ == 123456789)
              printf(&amp;quot;Thread %lu wins!n&amp;quot;, (unsigned long)gettid());
       }
#ifdef USE_SPINLOCK
       pthread_spin_unlock(&amp;amp;g_spin);
#else
       pthread_mutex_unlock(&amp;amp;g_mutex);
#endif
   }
   printf(&amp;quot;Thread %lu finished!n&amp;quot;, (unsigned long)gettid());

   return NULL;
}

int main(int argc, char *argv[])
{
   int i, threads = THREAD_NUM;
   printf(&amp;quot;Creating %d threads...n&amp;quot;, threads);
#ifdef USE_SPINLOCK
   pthread_spin_init(&amp;amp;g_spin, 0);
#else
   pthread_mutex_init(&amp;amp;g_mutex, NULL);
#endif
   for (i = 0; i &amp;lt; threads; i++)
           pthread_create(&amp;amp;g_thread[i], NULL, run_amuck, (void *) i);
   for (i = 0; i &amp;lt; threads; i++)
           pthread_join(g_thread[i], NULL);

   return 0;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/mZQYF49.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;果然，在我们选择使临界区变得很大时，锁竞争也变得很激烈。这样，Spin lock的性能急剧下降，Mutex的性能更好。同样地，可以看出，这种情况下，Spin lock消耗了很多的user time。原因是两个线程分别运行在两个核上，大部分时间只有一个线程能拿到锁，所以另一个线程就一直在它运行的core上进行忙等待，CPU占有率一直是100%；Mutex则不同，当对锁的请求失败后，上下文切换就会发生，这样就能空出一个核来运行别的计算任务。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;根据以上的分析和测试：&lt;br&gt;（1）Mutex适合对锁操作非常频繁的场景，并且具有更好的适应性。尽管相比Spin lock会花费更多的开销（上下文切换），但是它能适合实际开发中复杂的应用场景，在保证一定性能的前提下提供更大的灵活度。&lt;br&gt;（2）spin lock的lock/unlock性能更好(花费更少的cpu指令)，但是它只适应用于临界区运行时间很短的场景。而在实际软件开发中，除非程序员对自己的程序的锁操作行为非常的了解，否则使用spin lock不是一个好主意，实际中的多线程程序对锁的操作一般会很多。&lt;br&gt;（3）最好的方式是先使用Mutex，然后如果对性能还有进一步的需求，可以尝试使用spin lock进行调优。毕竟，需要先保证程序的正确性，再考虑提升性能。    &lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;&lt;a href=&quot;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&lt;/a&gt;  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;
    
    </summary>
    
    
      <category term="进程/线程/并发" scheme="http://blog.dujiong.net/tags/%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B-%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
</feed>
