<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一期一会</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.dujiong.net/"/>
  <updated>2016-09-20T15:49:44.450Z</updated>
  <id>http://blog.dujiong.net/</id>
  
  <author>
    <name>dujiong</name>
    <email>dujiong.uestc@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>浅谈tcp backlog</title>
    <link href="http://blog.dujiong.net/2016/09/28/tcp-backlog/"/>
    <id>http://blog.dujiong.net/2016/09/28/tcp-backlog/</id>
    <published>2016-09-28T13:42:51.000Z</published>
    <updated>2016-09-20T15:49:44.450Z</updated>
    
    <content type="html">&lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;backlog的两种实现&quot;&gt;&lt;a href=&quot;#backlog的两种实现&quot; class=&quot;headerlink&quot; title=&quot;backlog的两种实现&quot;&gt;&lt;/a&gt;backlog的两种实现&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Ymk1keA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;首先通过上图回顾一下TCP建立连接时的状态变化。由于TCP建立连接时使用三次握手，所以监听的服务端在回给客户端SYN+ACK之后，会进入SYN RECEIVED状态，这称之为半连接状态，而只有当收到客户端回送的ACK之后，才完成连接，进入ESTABLISHED状态，等待应用层处理。所以，TCP/IP协议栈有两种方式来实现这个连接队列：&lt;br&gt;（1）第一种是使用一个单一的队列，队列的大小由应用层listen函数的backlog参数确定，当收到一个SYN请求，服务端就回发给客户端SYN+ACK，并且将该连接加入到队列中。当客户端最后的ACK到来时，该连接的状态变为ESTABLISHED，并等待应用层处理。所以，这种实现方式下，队列中包含了两种状态的连接：SYN RECEIVED和ESTABLISHED。只有后一种状态的连接才可以从acception中返回，被应用层处理。&lt;br&gt;（2）另一种实现方式是使用两个队列，一个SYN队列（即半连接队列）和一个全连接队列（ACCEPT队列）。处于SYN RECEIVED状态的连接被加入到SYN队列中，当最后一个ACK到来时，改变状态并移动到全连接队列。所以，accept系统调用直接从全连接队列中取已完成的连接交给应用层处理。这时，listen函数中的backlog值决定了全连接队列的大小。&lt;br&gt;传统的基于BSD的TCP实现采用的是第一种方式，这种实现方式意味着，当队列满的时候，系统再收到SYN，将不会回发SYN+ACK。通常，TCP实现采用的是简单地丢弃SYN，让客户端重传，而不是回发RST。&lt;br&gt;在Linux系统中，backlog的实现形式分为两个阶段，在Linux2.2之前，内核采用的也是上述的方式，队列满之后，服务端再收到SYN时，将不会返回SYN/ACK，也不返回RST，让客户端重试。而在Linux2.2之后，内核选择第二种方式实现，SYN_RECEIVED队列的大小由/proc/sys/net/ipv4/tcp_max_syn_backlog系统参数指定，ESTABLISHED队列由backlog和/proc/sys/net/core/somaxconn中较小的指定。    &lt;/p&gt;
&lt;h3 id=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;a href=&quot;#SYN队列和ACCEPT队列&quot; class=&quot;headerlink&quot; title=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;/a&gt;SYN队列和ACCEPT队列&lt;/h3&gt;&lt;p&gt;以下是操作系统维护两种队列处理TCP连接的示意图。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/sGEPFN7.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;SYN队列和已完成队列是内核实现的，当服务器绑定、监听了某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。客户端使用connect向服务器发起TCP连接时，当SYN包到达服务器之后，内核会把这一报文放入SYN队列，同时回发一个SYN+ACK包给客户端。一段时间后，当三次握手最后的ACK到达服务器，内核会把连接从SYN队列中取出，再把这个连接放入ACCEPT队列（已完成队列）中。所以，服务器调用accept，其实就是直接从ACCEPT队列中取出已经建立成功的连接套接字。&lt;br&gt;当然，随之也产生了一些问题。因为SYN和ACCEPT队列都是有大小限制的，所以，二者都会存在队列满的时候。上图中，如果第一步执行的速度大于第二步执行的速度，SYN队列就会不断增大直到队列满；如果第二步执行的速度大于第三步执行的速度，ACCEPT队列同样会满。&lt;br&gt;当ACCEPT队列已满，这时SYN队列中的一个连接收到最后的ACK，需要移动到ACCEPT队列，会发生什么呢？&lt;br&gt;通过查看内核源码(net/ipv4/tcp_ipv4.c)可知，如果/proc/sys/net/ipv4/tcp_abort_on_overflow被置为1，内核将会回送RST包，否则，将会丢弃ACK，什么都不做。进一步地，当一定时间服务端还没有收到ACK（包括丢弃掉的ACK），将会重发SYN+ACK包（“指数退避”算法）。当客户端收到重发的SYN+ACK时，它便知道ACK包丢失了，需要重传。另一方面，当ACCEPT队列已满的时候，内核将会限制SYN队列的处理速度，如果收到太多的SYN队列，将会丢弃一些。这样，丢弃的SYN对应的客户端将会重发SYN包。&lt;br&gt;另一种情况，当SYN队列满的时候，会发生什么呢？上面已经阐述了，服务器端将会直接丢弃请求，即丢弃SYN网络包。       &lt;/p&gt;
&lt;h3 id=&quot;TCP连接的一些异常情况&quot;&gt;&lt;a href=&quot;#TCP连接的一些异常情况&quot; class=&quot;headerlink&quot; title=&quot;TCP连接的一些异常情况&quot;&gt;&lt;/a&gt;TCP连接的一些异常情况&lt;/h3&gt;&lt;p&gt;针对上述的两个连接队列，有一些常见的连接异常情况。下面做一个简单总结。     &lt;/p&gt;
&lt;h4 id=&quot;服务端SYN超时&quot;&gt;&lt;a href=&quot;#服务端SYN超时&quot; class=&quot;headerlink&quot; title=&quot;服务端SYN超时&quot;&gt;&lt;/a&gt;服务端SYN超时&lt;/h4&gt;&lt;p&gt;当客户端给服务端发送SYN报文时，如果服务端没有返回SYN+ACK报文，那么客户端会重发SYN报文给服务端，重发的次数由参数tcp_syn_retries参数设置，该值默认是5，超过5次服务端还是不返回SYN+ACK报文，那么本次连接失败。服务端没有返回SYN+ACK主要有两种情况，一种是由于网络问题SYN包丢失；另一种是服务端SYN队列满，导致SYN包被丢弃。                &lt;/p&gt;
&lt;h4 id=&quot;客户端ACK超时&quot;&gt;&lt;a href=&quot;#客户端ACK超时&quot; class=&quot;headerlink&quot; title=&quot;客户端ACK超时&quot;&gt;&lt;/a&gt;客户端ACK超时&lt;/h4&gt;&lt;p&gt;如果服务端接到了客户端发的SYN并回发SYN+ACK后，客户端掉线了，这时，服务端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功也没失败。于是，服务端端如果在一定时间内没有收到客户端端的ACK，那么服务端端会重发SYN+ACK。在Linux下，默认重试次数为5次，重发的间隔时间从1s开始每次都翻番（指数退避），5次的重发的时间间隔分别1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s+2s+4s+8s+16s+32s = 2^6-1 = 63s，TCP才会把断开这个连接。              &lt;/p&gt;
&lt;h4 id=&quot;SYN-Flood&quot;&gt;&lt;a href=&quot;#SYN-Flood&quot; class=&quot;headerlink&quot; title=&quot;SYN Flood&quot;&gt;&lt;/a&gt;SYN Flood&lt;/h4&gt;&lt;p&gt;这时一种恶意攻击。客户端给服务器发一个SYN后就下线，这样服务器需要默认等待63s才会断开连接，这样攻击者就可以把服务器的SYN连接队列耗尽，让正常的连接请求不能处理。为了应对SYN Flood攻击，Linux实现了一种称为SYN cookie的机制，通过net.ipv4.tcp_syncookies来设置。当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使不在SYN队列中）。&lt;/p&gt;
&lt;h3 id=&quot;TCP连接过程参数调优&quot;&gt;&lt;a href=&quot;#TCP连接过程参数调优&quot; class=&quot;headerlink&quot; title=&quot;TCP连接过程参数调优&quot;&gt;&lt;/a&gt;TCP连接过程参数调优&lt;/h3&gt;&lt;p&gt;下面罗列一些常用于TCP连接过程优化的参数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-max-syn-backlog&quot;&gt;&lt;a href=&quot;#tcp-max-syn-backlog&quot; class=&quot;headerlink&quot; title=&quot;tcp_max_syn_backlog&quot;&gt;&lt;/a&gt;tcp_max_syn_backlog&lt;/h4&gt;&lt;p&gt;SYN队列长度。如果服务器经常出现过载，可以尝试增加这个数字。   &lt;/p&gt;
&lt;h4 id=&quot;tcp-synack-retries&quot;&gt;&lt;a href=&quot;#tcp-synack-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_synack_retries&quot;&gt;&lt;/a&gt;tcp_synack_retries&lt;/h4&gt;&lt;p&gt;连接被动打开方的确认连接的应答最大重试次数。对于一个新建连接，内核要发送多少SYN连接请求才决定放弃。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syn-retries&quot;&gt;&lt;a href=&quot;#tcp-syn-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_syn_retries&quot;&gt;&lt;/a&gt;tcp_syn_retries&lt;/h4&gt;&lt;p&gt;连接主动打开方的syn尝试次数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syncookies&quot;&gt;&lt;a href=&quot;#tcp-syncookies&quot; class=&quot;headerlink&quot; title=&quot;tcp_syncookies&quot;&gt;&lt;/a&gt;tcp_syncookies&lt;/h4&gt;&lt;p&gt;防止SYN Flood攻击。    &lt;/p&gt;
&lt;h4 id=&quot;tcp-abort-on-overflos&quot;&gt;&lt;a href=&quot;#tcp-abort-on-overflos&quot; class=&quot;headerlink&quot; title=&quot;tcp_abort_on_overflos&quot;&gt;&lt;/a&gt;tcp_abort_on_overflos&lt;/h4&gt;&lt;p&gt;ACCEPT队列满，处理不过来的时候，如果设置了该参数，内核将会回发RST包。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>数据结构之线段树</title>
    <link href="http://blog.dujiong.net/2016/09/23/SegmentTree/"/>
    <id>http://blog.dujiong.net/2016/09/23/SegmentTree/</id>
    <published>2016-09-23T13:28:16.000Z</published>
    <updated>2016-09-17T02:46:29.535Z</updated>
    
    <content type="html">&lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;线段树具有如下性质：&lt;br&gt;（1）线段树是一棵平衡树，使用线段树可以快速地查找某一个节点在若干条线段中出现的次数，时间复杂度为O(logN)。&lt;br&gt;（2）线段树同一层的节点所代表的区间，相互不会重叠。&lt;br&gt;（3）线段树任两节点要么是包含关系要么是没有公共部分，不可能部分重叠。&lt;br&gt;（4）给定一个叶子l，从根到l路径上所有节点代表的区间都包含l，且其他节点代表的区间都不包含l。&lt;br&gt;一棵[1,10]的线段树表示如下。注意，线段树的构造在各区间的端点处的处理方式不一样，会导致线段树最终的表示有些差别，但是本质上是一样的。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/JEkWmlu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;线段树的基本操作&quot;&gt;&lt;a href=&quot;#线段树的基本操作&quot; class=&quot;headerlink&quot; title=&quot;线段树的基本操作&quot;&gt;&lt;/a&gt;线段树的基本操作&lt;/h3&gt;&lt;p&gt;线段树的基本操作和普通二叉树很类似，只不过线段树的节点上存储的是一个区间（左右端点值）。下面以线段树的建立、插入线段和删除线段为例简要说明线段树的基本操作。&lt;/p&gt;
&lt;h4 id=&quot;线段树的构建&quot;&gt;&lt;a href=&quot;#线段树的构建&quot; class=&quot;headerlink&quot; title=&quot;线段树的构建&quot;&gt;&lt;/a&gt;线段树的构建&lt;/h4&gt;&lt;p&gt;首先定义线段树的结构，这里采用链表的方式组织。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Node
{
    int left,right;
    int cover;            
    Node* leftChild;
    Node* rightChild;    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，cover字段用于计算一条线段被覆盖的次数。接下来，以递归的方式构建线段树。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Node* build(int l, int r)
{
    Node* root = new Node();
    root-&amp;gt;left = l;
    root-&amp;gt;right = r;
    root-&amp;gt;cover = 0;
    root-&amp;gt;leftChild = NULL;
    root-&amp;gt;rightChild = NULL;
    if(r-l &amp;gt; 1)
    {
        int mid = (l+r) &amp;gt;&amp;gt; 1;
        root-&amp;gt;leftChild = build(l,mid);
        root-&amp;gt;rightChild = build(mid,r);        //build(mid+1,r)
    }
    return root;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;线段插入与删除&quot;&gt;&lt;a href=&quot;#线段插入与删除&quot; class=&quot;headerlink&quot; title=&quot;线段插入与删除&quot;&gt;&lt;/a&gt;线段插入与删除&lt;/h4&gt;&lt;p&gt;如上所述，通过cover字段来计算一条线段被覆盖的次数。插入与删除时更新相应线段的cover。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Insert(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover++;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Insert(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Insert(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Insert(start,mid,root-&amp;gt;leftChild);
        Insert(mid,end,root-&amp;gt;rightChild); 
    }
}

void Delete(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover--;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Delete(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Delete(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Delete(start,mid,root-&amp;gt;leftChild);
        Delete(mid,end,root-&amp;gt;rightChild);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;线段树的应用&quot;&gt;&lt;a href=&quot;#线段树的应用&quot; class=&quot;headerlink&quot; title=&quot;线段树的应用&quot;&gt;&lt;/a&gt;线段树的应用&lt;/h3&gt;&lt;p&gt;TODO&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Spin lock与Mutex</title>
    <link href="http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/"/>
    <id>http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/</id>
    <published>2016-09-18T13:34:32.000Z</published>
    <updated>2016-09-16T13:26:29.859Z</updated>
    
    <content type="html">&lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Pthreads提供了多种线程同步锁机制：&lt;br&gt;（1）Mutex（互斥量）：pthread_mutex_xxx&lt;br&gt;（2）Spin lock(自旋锁)：pthread_spin_xxx&lt;br&gt;（3）Condition Variable（条件变量）：pthread_cond_xxx&lt;br&gt;（4）Read/Write lock（读写锁）：pthread_rwlock_xxx&lt;br&gt;本文主要讲解Spin lock和其与Mutex（Mutex的用法很常见、也很简单，若还不熟悉，可参考&lt;a href=&quot;http://blog.dujiong.net/2016/07/08/muduo-5/&quot;&gt;muduo中的封装&lt;/a&gt;）之间的区别。     &lt;/p&gt;
&lt;h3 id=&quot;Spin-lock&quot;&gt;&lt;a href=&quot;#Spin-lock&quot; class=&quot;headerlink&quot; title=&quot;Spin lock&quot;&gt;&lt;/a&gt;Spin lock&lt;/h3&gt;&lt;p&gt;Spin lock又称自旋锁，线程通过busy-wait-loop的方式来获取锁，任何时刻都只有一个线程能够获得锁，其他线程忙等待直到获得锁。Spin lock在多处理器多线程环境的场景中有很广泛的使用。   &lt;/p&gt;
&lt;h4 id=&quot;Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;Spin lock和Mutex&quot;&gt;&lt;/a&gt;Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;Spin lock有如下特点：&lt;br&gt;（1）Spin lock是一种死等的锁机制。当发生访问资源冲突的时候，可以有两种机制：一个是死等，一个是挂起当前进程，调度其他线程执行（Mutex）。线程会一直进行忙等待而不停的进行锁清秋，直到得到这个锁为止。&lt;br&gt;（2）执行时间短。由于Spin lock死等这种特性，因此它使用在那些代码不是非常复杂的临界区（当然也不能太简单，否则使用原子操作或者其他适用简单场景的同步机制就可以了），如果临界区执行时间太长，那么不断在临界区门口进行死等的线程十分浪费CPU资源。&lt;br&gt;（3）可以在中断上下文执行。由于不睡眠，因此Spin lock可以在中断上下文中使用。&lt;br&gt;从上述总结的Spin lock的特点，已经可以看出其与Mutex的不同之处了，下面再以一个实例进行说明。&lt;br&gt;例如在一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core 0和Core 1上，假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，Core 0会在此时进行上下文切换将线程A置于等待队列中，此时Core 0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待。而Spin lock则不然，它属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，那么线程A就会一直在Core 0上进行忙等待并不停的进行锁请求，直到得到这个锁为止。&lt;/p&gt;
&lt;h4 id=&quot;使用Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#使用Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;使用Spin lock和Mutex&quot;&gt;&lt;/a&gt;使用Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;下面通过实际的代码来进一步比较说明Spin lock和Mutex。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;list&amp;gt;

using namespace std;

const int LOOPS = 50000000;

list&amp;lt;int&amp;gt; ilist;

#ifdef USE_SPINLOCK
    pthread_spinlock_t spinlock;
#else
    pthread_mutex_t mutex;
#endif

pid_t gettid() 
{
    return syscall( __NR_gettid );
}

void *consumer(void *ptr)
{
    int i;

    printf(&amp;quot;Consumer TID %lun&amp;quot;, (unsigned long)gettid());

    while (1)
    {
#ifdef USE_SPINLOCK
        pthread_spin_lock(&amp;amp;spinlock);
#else
        pthread_mutex_lock(&amp;amp;mutex);
#endif

        if (ilist.empty())
        {
#ifdef USE_SPINLOCK
            pthread_spin_unlock(&amp;amp;spinlock);
#else
            pthread_mutex_unlock(&amp;amp;mutex);
#endif
            break;
        }

        i = ilist.front();
        ilist.pop_front();

#ifdef USE_SPINLOCK
        pthread_spin_unlock(&amp;amp;spinlock);
#else
        pthread_mutex_unlock(&amp;amp;mutex);
#endif
      }

    return NULL;
}

int main()
{
    int i;
       pthread_t thr1, thr2;
    struct timeval tv1, tv2;

#ifdef USE_SPINLOCK
    pthread_spin_init(&amp;amp;spinlock, 0);
#else
    pthread_mutex_init(&amp;amp;mutex, NULL);
#endif

    for (i = 0; i &amp;lt; LOOPS; i++)
        ilist.push_back(i);

    gettimeofday(&amp;amp;tv1, NULL);

    pthread_create(&amp;amp;thr1, NULL, consumer, NULL);
    pthread_create(&amp;amp;thr2, NULL, consumer, NULL);

    pthread_join(thr1, NULL);
    pthread_join(thr2, NULL);

    gettimeofday(&amp;amp;tv2, NULL);

    if (tv1.tv_usec &amp;gt; tv2.tv_usec)
    {
        tv2.tv_sec--;
        tv2.tv_usec += 1000000;
    }
    printf(&amp;quot;Result - %ld.%ld\n&amp;quot;, tv2.tv_sec - tv1.tv_sec,
    tv2.tv_usec - tv1.tv_usec);

#ifdef USE_SPINLOCK
    pthread_spin_destroy(&amp;amp;spinlock);
#else
    pthread_mutex_destroy(&amp;amp;mutex);
#endif

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该程序的逻辑是：主线程先初始化一个list结构，并根据LOOPS的值将对应数量的i插入该list，之后创建两个新线程，它们都执行consumer()这个任务。两个被创建的新线程同时对这个list进行pop()操作。主线程会计算从创建两个新线程到新线程结束之间所用的时间。&lt;br&gt;代码执行平台参数：&lt;br&gt;Ubuntu14.04 X86&lt;br&gt;Inter i5-2430M @ 2.40GHz, Dual Core&lt;br&gt;4.0GB Memory&lt;br&gt;下面是代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/7dmwgzS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果中可以看出Spin lock表现出的性能更好，另外，sys时间是所花费的系统掉头时间，可以看出，Mutex将消耗更多的系统调用时间，这是因为Mutex会在锁冲突时调用System Wait造成的。&lt;br&gt;但是，当临界区很大时，两个线程的锁进程会非常的激烈。这时，Spin lock的“死等”策略效率将会急剧下降。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;

using namespace std;

const int THREAD_NUM = 2;

pthread_t g_thread[THREAD_NUM];
#ifdef USE_SPINLOCK
pthread_spinlock_t g_spin;
#else
pthread_mutex_t g_mutex;
#endif

__uint64_t g_count;

pid_t gettid()
{
    return syscall(SYS_gettid);
}

void* run_amuck(void* arg)
{
   int i, j;

   printf(&amp;quot;Thread %lu started.n&amp;quot;, (unsigned long)gettid());

   for (i = 0; i &amp;lt; 10000; i++) 
   {
#ifdef USE_SPINLOCK
       pthread_spin_lock(&amp;amp;g_spin);
#else
       pthread_mutex_lock(&amp;amp;g_mutex);
#endif
       for (j = 0; j &amp;lt; 100000; j++) 
       {
           if (g_count++ == 123456789)
              printf(&amp;quot;Thread %lu wins!n&amp;quot;, (unsigned long)gettid());
       }
#ifdef USE_SPINLOCK
       pthread_spin_unlock(&amp;amp;g_spin);
#else
       pthread_mutex_unlock(&amp;amp;g_mutex);
#endif
   }
   printf(&amp;quot;Thread %lu finished!n&amp;quot;, (unsigned long)gettid());

   return NULL;
}

int main(int argc, char *argv[])
{
   int i, threads = THREAD_NUM;
   printf(&amp;quot;Creating %d threads...n&amp;quot;, threads);
#ifdef USE_SPINLOCK
   pthread_spin_init(&amp;amp;g_spin, 0);
#else
   pthread_mutex_init(&amp;amp;g_mutex, NULL);
#endif
   for (i = 0; i &amp;lt; threads; i++)
           pthread_create(&amp;amp;g_thread[i], NULL, run_amuck, (void *) i);
   for (i = 0; i &amp;lt; threads; i++)
           pthread_join(g_thread[i], NULL);

   return 0;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/mZQYF49.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;果然，在我们选择使临界区变得很大时，锁竞争也变得很激烈。这样，Spin lock的性能急剧下降，Mutex的性能更好。同样地，可以看出，这种情况下，Spin lock消耗了很多的user time。原因是两个线程分别运行在两个核上，大部分时间只有一个线程能拿到锁，所以另一个线程就一直在它运行的core上进行忙等待，CPU占有率一直是100%；Mutex则不同，当对锁的请求失败后，上下文切换就会发生，这样就能空出一个核来运行别的计算任务。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;根据以上的分析和测试：&lt;br&gt;（1）Mutex适合对锁操作非常频繁的场景，并且具有更好的适应性。尽管相比Spin lock会花费更多的开销（上下文切换），但是它能适合实际开发中复杂的应用场景，在保证一定性能的前提下提供更大的灵活度。&lt;br&gt;（2）spin lock的lock/unlock性能更好(花费更少的cpu指令)，但是它只适应用于临界区运行时间很短的场景。而在实际软件开发中，除非程序员对自己的程序的锁操作行为非常的了解，否则使用spin lock不是一个好主意，实际中的多线程程序对锁的操作一般会很多。&lt;br&gt;（3）最好的方式是先使用Mutex，然后如果对性能还有进一步的需求，可以尝试使用spin lock进行调优。毕竟，需要先保证程序的正确性，再考虑提升性能。    &lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;&lt;a href=&quot;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&lt;/a&gt;  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;
    
    </summary>
    
    
      <category term="多线程" scheme="http://blog.dujiong.net/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>C++引用剖析</title>
    <link href="http://blog.dujiong.net/2016/09/14/cplusplusReference/"/>
    <id>http://blog.dujiong.net/2016/09/14/cplusplusReference/</id>
    <published>2016-09-14T11:58:41.000Z</published>
    <updated>2016-09-14T15:17:56.403Z</updated>
    
    <content type="html">&lt;p&gt;引用是C++对于C语言的一个强有力的补充，它是对象的别名，这里的对象是指广义的，不仅是用类、结构体等复杂类型来声明的变量，还包括用int，float等简单类型声明的变量。引用在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命期是不能被改变的，即自始至终只能依附于同一个变量。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;C-引用的本质&quot;&gt;&lt;a href=&quot;#C-引用的本质&quot; class=&quot;headerlink&quot; title=&quot;C++引用的本质&quot;&gt;&lt;/a&gt;C++引用的本质&lt;/h3&gt;&lt;p&gt;C++引用的本质是指针常量。&lt;br&gt;引用是个常量，不同于指针，其在声明时必须初始化。此外，引用其实也是一种指针，绑定于自身的指针。只不过二者的接口并不相同，引用的接口有一定的限制，下述。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct A
{
    char name_;
    int num_;
    A&amp;amp; a_;
};    

struct B
{
    int num_;
    B&amp;amp; b_;
};

int main()
{
    cout &amp;lt;&amp;lt; sizeof(A) &amp;lt;&amp;lt; endl;        //12
    cout &amp;lt;&amp;lt; sizeof(B) &amp;lt;&amp;lt; endl;        //8
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;32位平台下，运行上述测试代码，可以看出两个结构中对自身的引用占四个字节，是与对象的一种绑定关系，通过引用可以获得对象。&lt;/p&gt;
&lt;h3 id=&quot;指针和引用的区别&quot;&gt;&lt;a href=&quot;#指针和引用的区别&quot; class=&quot;headerlink&quot; title=&quot;指针和引用的区别&quot;&gt;&lt;/a&gt;指针和引用的区别&lt;/h3&gt;&lt;p&gt;虽然引用很多时候表现出指针的特性，但是二者是有很大区别的。&lt;br&gt;首先，引用不可以为空，但指针可以为空。前面说过，引用是对象的别名，若对象不存在，怎么可能有别名？所以，定义一个引用的时候，必须初始化。而如果有一个变量是用于指向另一个对象，但是它可能为空，这时应该使用指针。因此，在实际代码编写中，使用指针之前必须做判空操作(&lt;code&gt;if(!p==NULL)&lt;/code&gt;)，而引用就不必。&lt;br&gt;其次，引用不可以改变指向，始终绑定同一个对象，这也正是上述常量指针的表现。而指针可以改变指向。需要注意的是，虽然引用不可以改变指向，但是可以改变初始化对象的内容。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int i = 10;
int&amp;amp; ref = i;
ref++;
cout &amp;lt;&amp;lt; &amp;quot;i &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; ref &amp;quot; &amp;lt;&amp;lt; ref &amp;lt;&amp;lt; endl;

int j = 20;
ref = j;
ref++;
cout &amp;lt;&amp;lt; &amp;quot;i &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; ref &amp;quot; &amp;lt;&amp;lt; ref &amp;lt;&amp;lt; &amp;quot; j &amp;quot; &amp;lt;&amp;lt; j &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;输出为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/qgy7FOO.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以看出，对ref的++操作是直接反应到所绑定变量之上，所以，第一个cout之后i和ref都变为了11，对ref重新赋值并不影响它的指向。，它仍然指向的是i，而不是j，只是其绑定变量的值变为了j的值20，然后再对ref++，最终，i和ref都变为了21，而j，仍然是20。&lt;br&gt;第三，引用的大小是所绑定的变量的大小，因为引用只是一个别名而已；而指针对应的是指针本身的大小，4个字节（32bits）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct    A
{
    char name_;
    int num_;
    int sum_
};    

int main()
{
    A a;
    A&amp;amp; ref = a;
    cout &amp;lt;&amp;lt; sizeof(ref) &amp;lt;&amp;lt; endl;  //12
    A* p = new A();
    cout &amp;lt;&amp;lt; sizeof(p) &amp;lt;&amp;lt; endl;    //4
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，引用比指针更安全。因为不存在空引用，并且引用一旦被初始化为指向一个对象，它就不能被改变为另一个对象的引用，因此引用很安全。而对于指针来说，它可以随时指向别的对象，并且可以不被初始化，或为NULL，所以不安全。&lt;br&gt;总而言之—指针指向一块内存，它的内容是指向内存的地址；而引用则是某块内存的别名，引用不改变指向。&lt;/p&gt;
&lt;h3 id=&quot;const&quot;&gt;&lt;a href=&quot;#const&quot; class=&quot;headerlink&quot; title=&quot;const&quot;&gt;&lt;/a&gt;const&lt;/h3&gt;&lt;p&gt;很多C++程序员一提到const就头疼，特别是对常量指针、指针常量、常量指针常量等概念，现在还要加上引用…&lt;br&gt;首先总结下如何判定const是修饰指针，还是修饰指针所指向的数据。有一个简单的规则，画一条垂直穿过指针声明星号(*)的线，如果const出现在线的左边，则指针指向的数据位常量；如果const出现在右边，指针本身为常量。   &lt;/p&gt;
&lt;h4 id=&quot;常量指针和常量引用&quot;&gt;&lt;a href=&quot;#常量指针和常量引用&quot; class=&quot;headerlink&quot; title=&quot;常量指针和常量引用&quot;&gt;&lt;/a&gt;常量指针和常量引用&lt;/h4&gt;&lt;p&gt;常量指针：指向常量的指针，表示指向的对象是常量。比如&lt;code&gt;const int* p = &amp;amp;a&lt;/code&gt;，即告诉编译器*p是常量，不能将*p作为左值进行操作。&lt;br&gt;常量引用：指向常量的引用，表示指向的对象是常量。和指针一样不能利用引用对指向的变量进行重新赋值操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int main()
{   
    int i = 10;    
    const int&amp;amp; ref = i;      
    ref = 20;             //error    
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;指针常量和引用常量&quot;&gt;&lt;a href=&quot;#指针常量和引用常量&quot; class=&quot;headerlink&quot; title=&quot;指针常量和引用常量&quot;&gt;&lt;/a&gt;指针常量和引用常量&lt;/h4&gt;&lt;p&gt;指针常量：表示指针本身是常量，所以，在定义指针常量时必须进行初始化。比如&lt;code&gt;int* const p = &amp;amp;b&lt;/code&gt;，即告诉编译器，p是常量，不能作为左值进行操作，但是允许修改间接访问值，即*p可以修改。&lt;br&gt;引用常量：这是引用天生俱来的属性，不用再引用const来定义。   &lt;/p&gt;
&lt;h4 id=&quot;常量指针常量和常量引用常量&quot;&gt;&lt;a href=&quot;#常量指针常量和常量引用常量&quot; class=&quot;headerlink&quot; title=&quot;常量指针常量和常量引用常量&quot;&gt;&lt;/a&gt;常量指针常量和常量引用常量&lt;/h4&gt;&lt;p&gt;常量指针常量：指向常量的指针常量，如&lt;code&gt;const int* const p = &amp;amp;c&lt;/code&gt;，告诉编译器，p和*p都是常量，他们都不能作为左值进行操作。&lt;br&gt;不存在所谓的“常量引用常量”，因为跟上面讲的一样，引用变量就是引用常量。C++不区分变量的const引用和const变量的引用。绝不能给引用本身重新赋值，使它指向另一个变量，因此引用总是const的。如果对引用应用关键字const，起作用就是使其目标成为const变量。即没有：&lt;code&gt;const int const&amp;amp; a = 1&lt;/code&gt;,只有&lt;code&gt;const int&amp;amp; a = 1&lt;/code&gt;。     &lt;/p&gt;
&lt;h3 id=&quot;指针传递和引用传递&quot;&gt;&lt;a href=&quot;#指针传递和引用传递&quot; class=&quot;headerlink&quot; title=&quot;指针传递和引用传递&quot;&gt;&lt;/a&gt;指针传递和引用传递&lt;/h3&gt;&lt;p&gt;最后，介绍一下指针传递参数和引用传递参数的区别。&lt;br&gt;指针传递参数本质上是值传递方式，它所传递的是一个地址值。值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，即在栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。&lt;br&gt;引用传递的过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量。所以，被调函数对形参做的任何操作都影响了主调函数中的实参变量。&lt;br&gt;所以，对于指针传递的参数，如果改变被调函数中的指针地址，它影响不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关指针变量，那就得使用指向指针的指针，或者指针引用。&lt;br&gt;下面以一个代码来说明指针传递和引用传递的区别。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void func1(int x)
{
    x = x + 1;
}

void func2(int *x)
{
    (*x) = (*x) + 1;
}

void func3(int&amp;amp; x)
{
    x = x + 1;
}

int main()
{
    int a = 0;
    func1(a);
    cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;    //0
    int b = 0;
    func2(&amp;amp;b);            
    cout &amp;lt;&amp;lt; b &amp;lt;&amp;lt; endl;    //1
    int c = 0;
    func(c);        
    cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;    //1
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;三个函数分别对应值传递、指针传递和引用传递，值传递中，函数体内的x是外部变量的一份拷贝，改变x不会影响a。而指针传递中，函数体内的x是指向外部b的指针，改变该指针的内容将导致b值改变。引用传递中，函数体内的x是外部变量的引用，即二值是同一个东西，改变x等于改变c。&lt;br&gt;但是，要通过指针参数传递来改变主调函数中的相关指针变量，那就得使用指向指针的指针，或者指针引用。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;引用是C++对于C语言的一个强有力的补充，它是对象的别名，这里的对象是指广义的，不仅是用类、结构体等复杂类型来声明的变量，还包括用int，float等简单类型声明的变量。引用在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命期是不能被改变的，即自始至终只能依附于同一个变量。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>线性排序算法：计数排序、基数排序和桶排序</title>
    <link href="http://blog.dujiong.net/2016/09/07/LinearSort/"/>
    <id>http://blog.dujiong.net/2016/09/07/LinearSort/</id>
    <published>2016-09-07T12:43:51.000Z</published>
    <updated>2016-09-16T11:48:04.705Z</updated>
    
    <content type="html">&lt;p&gt;在计算机科学中，排序是一个非常基础的算法。不同的排序算法有不同的时间和空间开销。在这么多的排序算法中，根据在排序的最终结果中，各元素的次序是否依赖于它们之间的比较，可以将排序算法分为两大类：基于比较的排序和非基于比较的排序。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;基于比较的排序需要对序列中的数据进行比较，如我们最常用的快速排序、堆排序和归并排序。根据决策树模型可以证明：基于比较的排序算法的时间复杂度是不能突破O(NlogN)的。（《算法导论》8.1）&lt;br&gt;而非基于比较的排序，如本文将要介绍的计数排序、基数排序和桶排序，则可以突破O(NlogN)的时间下限。当然，这样的非比较的排序的使用会有一些条件的限制，比如元素的大小，所以，在一般在特定场合下，非基于比较的排序算法能够巧妙地解决一些问题。     &lt;/p&gt;
&lt;h3 id=&quot;计数排序&quot;&gt;&lt;a href=&quot;#计数排序&quot; class=&quot;headerlink&quot; title=&quot;计数排序&quot;&gt;&lt;/a&gt;计数排序&lt;/h3&gt;&lt;p&gt;首先介绍计数排序。&lt;br&gt;计数排序假设n个输入元素的每一个都是在0到K区间内的一个整数，其中K为某个正整数。计数排序的基本思想是，对每一个输入元素x，确定小于x的元素个数。利用这一信息，就可以直接把x放到它在输出数组的位置上了。比如，如果有17个元素小于x，则x就应该放在第18（或17，看数组a[0]怎么处理）个输出位置上。&lt;br&gt;按照这个思想，可以写出计数排序的伪代码：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;COUNTING-SORT(A,B,k)
    let C[0,k] be a new array
    for i=0 to k
        C[i]=0
    for j=0 to A.length-1
        C[A[j]]=C[A[j]]+1
    for i=1 to k
        C[i]=C[i]+C[i-1]
    for j=A.length-1 to 0
        B[C[A[j]]-1]=A[j]
        C[A[j]]=C[A[J]]-1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;说明一下，《算法导论》中的伪代码采用的是输入数组为A[1..n],输出数组为B[1..n]。这里没有这样做，而是采用传统的0~n-1的数组下标作为输入输出，本质是一样的。     &lt;/p&gt;
&lt;p&gt;下面以数据2 5 3 0 2 3 0 3为例说明计数排序的执行过程。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/pgoZnNn.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/Yz80C5w.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/hvHJ4Lx.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;容易看出，第一个for循环所花时间为Θ(k)，第二个for循环所花时间为Θ(n)，第三个for循环所花时间为Θ(k)，最后一个循环所花时间为Θ(n)。这样，总的时间代价就是Θ(n+k)。所以，当k=O(n)时，一般可以采用计数排序，这时运行时间为Θ(n)。          &lt;/p&gt;
&lt;h3 id=&quot;桶排序&quot;&gt;&lt;a href=&quot;#桶排序&quot; class=&quot;headerlink&quot; title=&quot;桶排序&quot;&gt;&lt;/a&gt;桶排序&lt;/h3&gt;&lt;p&gt;桶排序假设输入数据服从均匀分布，平均情况下它的时间代价为O(n)。与计数排序类似，因为对输入数据做了某种假设，桶排序的速度也很快。具体来说，计数排序假设输入数据都属于一个小区间内的整数，而桶排序则假设输入是由一个随机过程产生，该过程将元素均匀、独立地分布在[0,1)区间上。我们把区间[0,1)划分成n个相同大小的子区间，称为桶。将n个记录分布到各个桶中去。如果有多于一个记录分到同一个桶中，需要进行桶内排序。&lt;br&gt;在桶排序的代码中，假设输入是一个包含n个元素的数组A，且每个元素A[i]满足0&amp;lt;=A[i]&amp;lt;1。此外，算法还需要一个临时数组B[0..n-1]来存放链表（即桶），并假设存在一种用于维护这些链表的机制。在分完桶后，对每个桶进行排序，然后合并最后的结果。&lt;br&gt;桶排序用伪代码表示如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;BUCKET-SORT(A)
    n=A.length
    let B[0..n-1] to be a new array
    for i=0 to n-1
        make B[i] an empty list
    for i=1 to n
        insert A[i] to list B[nA[i]]
    for i=0 to n-1
        sort list B[i] with insertion sort
    concatenate the list B[0],B[1],...,B[n-1] together in order
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;例如，要对大小为[1..1000]范围内的n个整数A[1,n]排序，可以把桶设为大小为10的范围，具体而言，设集合B[0]存储[1..10)的整数，集合B[2]存储(10,20]的整数…依次，总共有100个桶。然后对A[1,n]从头到尾扫描一遍，把每个A[i]放入对应的桶B[j]中。然后再对这100个桶中每个桶里的数字进行排序。最后依次输出每个桶里面的数字，这样得到的就是排好序的序列了。&lt;br&gt;桶排序的平均时间复杂度为线性的O(N+C)，其中C为桶内快排的时间复杂度，如果对于同样的N，桶数量M越大，其效率越大，最好的时间复杂度达到O(N)。但是，桶排序的空间复杂度为O(N+M)，如果输入数据很庞大，而桶的数量也非常多，则空间代价是昂贵的。 &lt;/p&gt;
&lt;h3 id=&quot;基数排序&quot;&gt;&lt;a href=&quot;#基数排序&quot; class=&quot;headerlink&quot; title=&quot;基数排序&quot;&gt;&lt;/a&gt;基数排序&lt;/h3&gt;&lt;p&gt;另外一种线性排序方式是基数排序。下面通过一个例子来说明基数排序的思想。&lt;br&gt;假设有待排序的数据序列如下：&lt;br&gt;73 22 93 43 55 14 28 65 39 81&lt;br&gt;首先根据个位数的数值，在遍历数据时将它们各自分到编号为0-9的桶中，分配的结果如下图所示：&lt;br&gt; &lt;img src=&quot;http://i.imgur.com/eOVN7vZ.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;分配结束后，接下来将所有桶中所盛数据按照桶号由小到大依次重新收集起来，得到下列仍然无序的数据序列：&lt;br&gt;81 22 73 93 43 14 55 65 28 39&lt;br&gt;接着，再进行一次分配，这次根据十位数值来分配（原理同上），分配结构如下所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/sLQPdaX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样，原来无序的数据序列已经排序完毕。如果排序的位数大于2，则重复以上动作至最后一位。&lt;br&gt;当然，上面的排序过程中有一个还需探究的问题，即在原来的序列中的73 93 43（个位数相同）三个数的顺序，在经过第一次分配之后，在桶中的顺序由底至上应该为73 93 43（即装的迟的在最上面），但是在3号桶中刚好相反。这正是基数排序稳定的原因，分配时是从预排数据序列的末尾开始进行，逐次分配至首位。&lt;br&gt;所以，不难看出，基数排序原理类似于桶排序，只是这里总是需要十个桶，多次使用。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/*
 * getdigit(arr[i],k)用于获得arr[i]第k位上的数字
 */

void lsdRadixSort(int arr[], int begin, int end, int d)
{
    const int radix = 10;
    int count[radix];
    int i,j;

    int *bucket = (int*)malloc((end-start+1)*sizeof(int));
    for(int k=1;k&amp;lt;=d;k++)
    {
        for(i=0;i&amp;lt;radix;i++)
        {
            count[i]=0;
        }
        for(i=begin;i&amp;lt;=end;i++)
        {
            count[getdigit(arr[i], k)]++;    
        }    
        for(i=1;i&amp;lt;radix;i++)
        {
            count[i] = count[i] + count[i-1];
        }
        for(i=end;i&amp;gt;=end;--i)
        {
            j = getdigit(arr[i], k);
            bucket[count[j]-1] = arr[i];
            --count[j];
        }
        for(i=begin,j=0;i&amp;lt;=end;++i,++j)
        {
            arr[i] = bucket[j];
        }
    }
    free(bucket);    
}            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以，给定n个d位数，其中每一个数位有k个可能的取值，所以，每一轮排序耗时Θ(n+k)，那么整个基数排序的总时间为Θ(d(n+k))，当d为常数且k=O(n)时，基数排序具有线性的时间代价。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;以上三种线性时间排序方法突破了基于比较排序的O(NlogN)的时间下界，这样的非比较排序的方法会有一些使用场景的限制，比如元素的大小，所以，在特定的条件下，会体现出较好的性能。&lt;br&gt;本质上，都体现了用空间换时间的理念。        &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在计算机科学中，排序是一个非常基础的算法。不同的排序算法有不同的时间和空间开销。在这么多的排序算法中，根据在排序的最终结果中，各元素的次序是否依赖于它们之间的比较，可以将排序算法分为两大类：基于比较的排序和非基于比较的排序。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>从BlockingQueue再探线程同步</title>
    <link href="http://blog.dujiong.net/2016/08/26/muduo-7/"/>
    <id>http://blog.dujiong.net/2016/08/26/muduo-7/</id>
    <published>2016-08-26T05:18:11.000Z</published>
    <updated>2016-08-26T07:49:10.062Z</updated>
    
    <content type="html">&lt;p&gt;BlockingQueue（阻塞队列）在程序中被大量使用，特别是在多线程程序中，譬如需要提高吞吐量时采用将请求直接扔到阻塞队列中，然后返回，由其他线程从阻塞队列中获取请求再进一步处理。而经典的生产者-消费者模型，正是阻塞队列大放光彩之处。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Java中java.util.concurrent包便提供了BlockingQueue接口和其几种实现方式。muduo中也实现了无大小限制的BlockingQueue和固定大小的BoundedBlockingQueue。下面以BlockingQueue为例进行说明。     &lt;/p&gt;
&lt;h3 id=&quot;BlockingQueue的实现&quot;&gt;&lt;a href=&quot;#BlockingQueue的实现&quot; class=&quot;headerlink&quot; title=&quot;BlockingQueue的实现&quot;&gt;&lt;/a&gt;BlockingQueue的实现&lt;/h3&gt;&lt;p&gt;muduo中BlockingQueue的实现非常简单，队列采用C++标准库中的deque，无大小限制，唯一需要注意的是使用互斥锁和条件变量做好线程同步。&lt;br&gt;BlockingQueue实现时运用了模板。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class BlockingQueue : boost::noncopyable
{
    public:
        BlockingQueue() : mutex_(), notEmpty_(mutex_), queue_() {}

        void put(const T&amp;amp; x)
        {
            MutexLockGuard lock(mutex_);
            queue_.push_back(x);
            notEmpty_.notift();
        }    

        T take()
        {
            MutexLockGuard lock(mutex_);
            while(queue_.empty())    
            {
                notEmpty_.wait();
            }
            assert(!queue_.empty());
            T front(queue_.front());
            queue_.pop_front();
            return front;
        }

        size_t size() const
        {
            MutexLockGuard lock(mutex_);
            return queue_.size();
        }
    private:
        mutable MutexLock mutex_;
        Condition notEmpty_;
        std::deque&amp;lt;T&amp;gt; queue_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BlockingQueue提供了取元素(take)、放入元素(put)和取得队列大小(size)三个public成员函数完成对阻塞队列的操作。&lt;/p&gt;
&lt;h3 id=&quot;线程同步的一些细究&quot;&gt;&lt;a href=&quot;#线程同步的一些细究&quot; class=&quot;headerlink&quot; title=&quot;线程同步的一些细究&quot;&gt;&lt;/a&gt;线程同步的一些细究&lt;/h3&gt;&lt;p&gt;细究BlockingQueue的实现，可以总结并学习一些问题。&lt;/p&gt;
&lt;h4 id=&quot;spurious-wakeup&quot;&gt;&lt;a href=&quot;#spurious-wakeup&quot; class=&quot;headerlink&quot; title=&quot;spurious wakeup&quot;&gt;&lt;/a&gt;spurious wakeup&lt;/h4&gt;&lt;p&gt;首先是大名鼎鼎的spurious wakeup（虚假唤醒）。即对应代码中&lt;code&gt;while(queue_.empty())&lt;/code&gt;循环，可否改为&lt;code&gt;if(queue_.empty())&lt;/code&gt;？&lt;br&gt;答案是不能，否则会导致虚假唤醒，因为&lt;code&gt;notEmpty_.wait()&lt;/code&gt;封装的&lt;code&gt;pthread_cond_wait()&lt;/code&gt;不仅能被&lt;code&gt;pthread_cond_signal()/pthread_cond_broadcast()&lt;/code&gt;唤醒，而且还可能会被其他的信号唤醒，后者便是虚假唤醒，这时条件并不满足。所以，不仅要在&lt;code&gt;pthread_cond_wait()&lt;/code&gt;前检查条件是否成立，在&lt;code&gt;pthread_cond_wait()&lt;/code&gt;之后也要检查。 &lt;/p&gt;
&lt;h4 id=&quot;unlock和signal的顺序&quot;&gt;&lt;a href=&quot;#unlock和signal的顺序&quot; class=&quot;headerlink&quot; title=&quot;unlock和signal的顺序&quot;&gt;&lt;/a&gt;unlock和signal的顺序&lt;/h4&gt;&lt;p&gt;muduo中采用RAII手法封装了互斥器，所以，在进行put操作时，是先notify其他线程，再释放锁。那么反过来呢，先释放锁，再notify其他线程？这二者有什么差别呢？&lt;br&gt;先notify，再释放锁，在某些平台下存在性能问题，原因是，假设线程1阻塞在条件变量上wait，线程2将其唤醒（notify），系统执行上下文切换，但是线程2仍持有锁，导致线程1不能从&lt;code&gt;pthread_cond_wait()&lt;/code&gt;(需要持有锁)返回，所以线程1又阻塞在互斥锁上，直到线程2释放锁，线程1才可以运行。&lt;br&gt;福音是，对于此问题，Glibc中使用的线程库NPTL对此进行了优化。&lt;br&gt;另一种情况是先释放锁，再notify，这样可以避免上述问题，但是，这样可能会唤醒其他阻塞在此mutex上的线程，而不是处于wait条件变量的线程，所以，这种情况下，在唤醒之后，最好还得再check下predicate（类似于spurious wakeup）。&lt;br&gt;所以，Pthreads实现平台下，建议使用第一种方法，可以避免一些&lt;a href=&quot;http://www.domaigne.com/blog/computing/condvars-signal-with-mutex-locked-or-not/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;obscure bugs&lt;/a&gt;,除非采用第二种有较明显的性能的提升。&lt;/p&gt;
&lt;h4 id=&quot;Linux快速同步机制（Futex）&quot;&gt;&lt;a href=&quot;#Linux快速同步机制（Futex）&quot; class=&quot;headerlink&quot; title=&quot;Linux快速同步机制（Futex）&quot;&gt;&lt;/a&gt;Linux快速同步机制（Futex）&lt;/h4&gt;&lt;p&gt;Futex（Fast Userspace mutexes，快速用户空间互斥体），是在Linux上实现锁定和构建高级抽象锁如信号量和POSIX互斥的基本工具，首先出现在Linux 2.5.7版。&lt;br&gt;在传统的Unix系统中，System V IPC，如消息队列，信号量，socket等进程间同步机制都是对一个内核对象操作来完成的，这个内核对象对于要同步的进程都是可见的，其提供了共享的状态信息和原子操作。当进程间要同步的时候必须要通过系统调用在内核中完成。可是研究发现，很多同步状态是无竞争的，即某个进程进入互斥去，到从互斥区出来这段时间，常常是没有进程进也要进入这个互斥区或者请求同一个同步变量的。而这种情况下，进程也要陷入到内核去看有没有竞争者，退出的时候还要陷入内核去看有没有进程等待在同一变量上。这些不必要的系统调用（陷入内核）造成了大量的性能开销。&lt;br&gt;而Futex就是在这样的背景下被提出的，以减少不必要的系统调用（内核陷入）。Funtex是一种用户态和内核态混合的同步机制。首先，同步的进程间通过mmap共享一段内存，Futex变量就位于这段共享的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex，而不用再执行系统调用了。当通过访问futex变量告诉进程有竞争发生，再去执行系统调用以完成相应的处理。futex通过这样的机制，大大提高了low-contention时的效率。     &lt;/p&gt;
&lt;h5 id=&quot;Futex机制&quot;&gt;&lt;a href=&quot;#Futex机制&quot; class=&quot;headerlink&quot; title=&quot;Futex机制&quot;&gt;&lt;/a&gt;Futex机制&lt;/h5&gt;&lt;p&gt;所有的Futex同步操作都从用户空间开始，首先创建一个futex同步变量，也就是位于共享内存的一个整型计数器。&lt;br&gt;当进程尝试持有锁或者要进入互斥区的时候，对futex执行”down”操作，即原子性的给futex同步变量减1。如果同步变量变为0，则没有竞争发生，进程照常执行。如果同步变量是个负数，则意味着有竞争发生，需要调用futex系统调用的futex_wait操作休眠当前进程。&lt;br&gt;当进程释放锁或者要离开互斥区的时候，对futex进行”up”操作，即原子性的给futex同步变量加1。如果同步变量由0变成1，则没有竞争发生，进程照常执行。如果加之前同步变量是负数，则意味着有竞争发生，需要调用futex系统调用的futex_wake操作唤醒一个或者多个等待进程。&lt;br&gt;这里的原子性加减通常是用CAS(Compare and Swap)完成的，与平台相关。CAS的基本形式是：CAS(addr,old,new),当addr中存放的值等于old时，用new对其替换。在x86平台上有专门的一条指令来完成它: cmpxchg。    &lt;/p&gt;
&lt;h5 id=&quot;Linux下使用glibc开发&quot;&gt;&lt;a href=&quot;#Linux下使用glibc开发&quot; class=&quot;headerlink&quot; title=&quot;Linux下使用glibc开发&quot;&gt;&lt;/a&gt;Linux下使用glibc开发&lt;/h5&gt;&lt;p&gt;上面讲了很多关于Futex的机制，重点是弄清楚其中的原理和思想，我们在实际的多线程程序开发中却没有必要去实现自己的futex同步原语。&lt;br&gt;因为NPTL库实现了POSIX标准定义的线程同步机制，他们都构造与futex之上，而glibc又使用NPTL作为自己的线程库。所以，在日常程序开发中，只需要正确地使用glibc所提供的同步方式，并在使用它们的过程中，意识到它们是利用futex机制和linux配合完成同步操作，重点是思想。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;BlockingQueue（阻塞队列）在程序中被大量使用，特别是在多线程程序中，譬如需要提高吞吐量时采用将请求直接扔到阻塞队列中，然后返回，由其他线程从阻塞队列中获取请求再进一步处理。而经典的生产者-消费者模型，正是阻塞队列大放光彩之处。&lt;br&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
      <category term="多线程" scheme="http://blog.dujiong.net/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>单例模式</title>
    <link href="http://blog.dujiong.net/2016/08/21/Singleton/"/>
    <id>http://blog.dujiong.net/2016/08/21/Singleton/</id>
    <published>2016-08-21T13:57:13.000Z</published>
    <updated>2016-08-26T08:23:05.770Z</updated>
    
    <content type="html">&lt;p&gt;单例（Singleton）模式可能是被使用最广泛的一个设计模式之一，也可能是面试中被问到或被要求书写最多的一个设计模式了。该设计模式的主要目的是要求在整个系统中只出现一个类的实例。&lt;br&gt;下面采用Java语言描述单例模式的几种实现方式。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h3 id=&quot;懒汉-amp-amp-线程不安全&quot;&gt;&lt;a href=&quot;#懒汉-amp-amp-线程不安全&quot; class=&quot;headerlink&quot; title=&quot;懒汉&amp;amp;&amp;amp;线程不安全&quot;&gt;&lt;/a&gt;懒汉&amp;amp;&amp;amp;线程不安全&lt;/h3&gt;&lt;p&gt;懒汉式单例在调用取得实例方法的时候实例化对象。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton{
    private staic Singleton singleton = null;
    private Singleton()　{ }
    public static Singleton getInstance(){
        if(singleton == null){
            singleton = new Singleton();
        }
        return singleton;        
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从代码中可以看出，采用私有的构造函数，表明这个类是不可能形成实例了，这样可以防止类出现多个实例。所以，采用一个静态的方式（getInstance()）来让其形成实例。在getInstance()方法中，先判断是否已经形成实例，如果已经形成则直接返回，否则创建实例，保存在自己类的私有成员中。&lt;br&gt;但是，问题来了，因为是全局性的实例，这种方式最大的问题就是不支持多线程，在多线程情况下，多个线程同时调用getInstance()的话，那么，可能会有多个线程同时通过(singleton == null)的条件检查，最终创建出多个实例。所以，应加入同步机制以适应多线程环境。    &lt;/p&gt;
&lt;h3 id=&quot;懒汉-amp-amp-线程安全&quot;&gt;&lt;a href=&quot;#懒汉-amp-amp-线程安全&quot; class=&quot;headerlink&quot; title=&quot;懒汉&amp;amp;&amp;amp;线程安全&quot;&gt;&lt;/a&gt;懒汉&amp;amp;&amp;amp;线程安全&lt;/h3&gt;&lt;p&gt;所以，加入synchronized做同步。得到如下所示的线程安全版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton{
    private static Singleton singleton = null;
    private Singleton() { }
    public static synchronized Singleton getInstance(){
        if(singleton == null){
            singleton = new Singleton();
        }
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;饿汉&quot;&gt;&lt;a href=&quot;#饿汉&quot; class=&quot;headerlink&quot; title=&quot;饿汉&quot;&gt;&lt;/a&gt;饿汉&lt;/h3&gt;&lt;p&gt;饿汉式单例在单例类被加载的时候，就实例化一个对象交给自己的引用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton {
    private static final Singleton singleton = new Singleton();
    private Singleton(){ } 
    public static Singleton getInstance(){
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这种方式在实际中比较常用，基于classloader机制避免了多线程的同步问题，没有加锁，执行效率较高。但是，仍美中不足的是：singleton在类加载的时候就实例化，这样就算是getInstance()没有被调用，类也被初始化了。这样的话，有时会与我们想要的行为不一样，比如，在类的构造函数中，有一些事需要依赖于别的类，我们希望它能在第一次getInstance()时才被真正创建。这样，可以自己控制真正的类创建的时刻，而不是把类的创建委托给类装载器。&lt;br&gt;所以又出现了下面这种方式。&lt;/p&gt;
&lt;h3 id=&quot;静态内部类&quot;&gt;&lt;a href=&quot;#静态内部类&quot; class=&quot;headerlink&quot; title=&quot;静态内部类&quot;&gt;&lt;/a&gt;静态内部类&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public class Singleton{
    private static class SingletonHolder{
        private static Singleton singleton = new Singleton();
    }        
    private Singleton() { }
    public static Singleton getInstance(){
        return SingletonHolder.singleton;
    } 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样的话，由于SingletonHolder是私有的，除了getInstance()之外没有方法访问它，因此只有在getInstance()被调用时才会真正创建。&lt;/p&gt;
&lt;h3 id=&quot;双重锁校验锁&quot;&gt;&lt;a href=&quot;#双重锁校验锁&quot; class=&quot;headerlink&quot; title=&quot;双重锁校验锁&quot;&gt;&lt;/a&gt;双重锁校验锁&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public class Singleton{
    private volatile static Singleton singleton = null;
    private Singleton() { }
    public static Singleton getInstance(){
        if(singleton == null){
            synchronized(Singleton.class){
                if(singleton == null){
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一个if判定是说，如果实例创建了，就不需要同步了，直接return singleton就可以了。不然的话，就开始同步线程。第二个if判定是说，如果被同步的线程中，已经创建了对象，那么就不用创建了。这样，保证了多线程条件下的安全。&lt;br&gt;此外，由于&lt;code&gt;singleton = new Singleton();&lt;/code&gt;不是原子操作，所以使用volatile关键字禁止指令重排序优化。&lt;/p&gt;
&lt;h3 id=&quot;枚举&quot;&gt;&lt;a href=&quot;#枚举&quot; class=&quot;headerlink&quot; title=&quot;枚举&quot;&gt;&lt;/a&gt;枚举&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public enum Singleton{
    INSTANCE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，简直不要太简单哦！是的，虽然他可能还包含实例变量和实例方法。默认枚举实例的创建是线程安全的，所以不需要担心线程安全的问题。当然，需要自行负责枚举中的其他任何方法的线程安全。&lt;br&gt;这样，通过Singleton.INSTANCE来访问，这比上述的getInstance()方法简单多了。而且，更重要的是，枚举单例，JVM对序列化有保证。 &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;总结一下上述的单例模式实现，一般情况下，不建议使用两种懒汉方式，建议使用饿汉方式。当要求延迟加载时，使用静态内部类形式。而如果涉及到反序列化创建对象时，可以尝试用枚举方式。   &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;单例（Singleton）模式可能是被使用最广泛的一个设计模式之一，也可能是面试中被问到或被要求书写最多的一个设计模式了。该设计模式的主要目的是要求在整个系统中只出现一个类的实例。&lt;br&gt;下面采用Java语言描述单例模式的几种实现方式。&lt;br&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="http://blog.dujiong.net/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>shared_ptr的注意事项</title>
    <link href="http://blog.dujiong.net/2016/08/08/shared-ptr/"/>
    <id>http://blog.dujiong.net/2016/08/08/shared-ptr/</id>
    <published>2016-08-08T13:38:44.000Z</published>
    <updated>2016-08-27T13:24:49.329Z</updated>
    
    <content type="html">&lt;p&gt;前面在&lt;a href=&quot;http://blog.dujiong.net/2016/05/15/cplusplus-sematics/&quot;&gt;浅谈C++值语义和对象语义&lt;/a&gt;一文中简要的阐述了一下智能指针shared_ptr的作用和用法，作为C++11中最为广泛使用的智能指针，shared_ptr虽然解决了裸指针的诸多问题，但是它并非完美、无懈可击，所以，本文就shared_ptr使用过程中需要注意的一些问题做一下总结。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;循环引用&quot;&gt;&lt;a href=&quot;#循环引用&quot; class=&quot;headerlink&quot; title=&quot;循环引用&quot;&gt;&lt;/a&gt;循环引用&lt;/h3&gt;&lt;p&gt;首当其冲的便是shared_ptr造成的循环引用。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class BaseClass;
class DerivedClass;

typedef std::shared_ptr&amp;lt;BaseClass&amp;gt; BaseClassPtr;
typedef std::shared_ptr&amp;lt;DerivedClass&amp;gt; DerivedClassPtr;

class BaseClass
{
    public:
        DerivedClassPtr derivedPtr;
        ~BaseClass()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~BaseClass()&amp;quot; &amp;lt;&amp;lt; endl;
        }
};

class DerivedClass
{
    public:
        BaseClassPtr basePtr;
        ~DerivedClass()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~DerivedClass()&amp;quot; &amp;lt;&amp;lt; endl;
        }
};

int main()
{
    BaseClassPtr base(new BaseClass());
    DerivedClassPtr derived(new DerivedClass());

    base-&amp;gt;derivedPtr = derived;
    derived-&amp;gt;basePtr = base;

    cout &amp;lt;&amp;lt; base.use_count() &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; derived.use_count() &amp;lt;&amp;lt; endl;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;程序运行结果如下。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/dqHRq8F.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果可以看出，堆上的BaseClass和DerivedClass都没有被析构，因为二者的引用都为1，并形成了循环引用，类似于“放开我的引用”，“你先放开我的我就放你的”的恶性循环，所以，造成了内存泄露。&lt;br&gt;解决方法是使用弱智能指针weak_ptr，让BaseClass和DerivedClass分别持有对方的weak_ptr，而不是shared_ptr，weak_ptr也是一个引用计数型智能指针，但是它不增加对象的引用计数。这样，就可以保证内存正常释放。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/cG2fmZx.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;h3 id=&quot;线程安全&quot;&gt;&lt;a href=&quot;#线程安全&quot; class=&quot;headerlink&quot; title=&quot;线程安全&quot;&gt;&lt;/a&gt;线程安全&lt;/h3&gt;&lt;p&gt;shared_ptr是引用计数型智能指针，几乎所有的实现都采用在堆上存放计数值的方法。具体来说，shared_ptr&lt;foo&gt;包含两个成员，一个是指向Foo的指针ptr，另一个是ref_count指针（不一定是原始指针），指向堆上的ref_count对象。ref_count对象有多个成员。&lt;/foo&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/WZNNAPg.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以，如果执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shared_ptr&amp;lt;Foo&amp;gt; x(new Foo);
shared_ptr&amp;lt;Foo&amp;gt; y = x;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;y=x将会涉及两个成员的拷贝,ptr和ref_count指针。这两步不是原子的，所以在多线程中会有race condition，需要加锁保护。     &lt;/p&gt;
&lt;h3 id=&quot;内存多次释放&quot;&gt;&lt;a href=&quot;#内存多次释放&quot; class=&quot;headerlink&quot; title=&quot;内存多次释放&quot;&gt;&lt;/a&gt;内存多次释放&lt;/h3&gt;&lt;p&gt;shared_ptr多次引用同一数据会导致内存多次释放。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

int main()
{
    int* ptr = new int(100);
    std::shared_ptr sptr1(ptr);
    ...
    std::shared_ptr sptr2(ptr);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只分配了一次内存，却两次释放。&lt;/p&gt;
&lt;h3 id=&quot;enable-shared-from-this&quot;&gt;&lt;a href=&quot;#enable-shared-from-this&quot; class=&quot;headerlink&quot; title=&quot;enable_shared_from_this&quot;&gt;&lt;/a&gt;enable_shared_from_this&lt;/h3&gt;&lt;p&gt;当使用智能指针时，类的某些成员函数需要返回的是管理自身的shared_ptr，这时就需要使A继承自enable_shared_from_this（顾名思义，将this指针变身为shared_ptr），然后通过其成员函数shared_from_this()返回指向自身的shared_ptr。      &lt;/p&gt;
&lt;p&gt;首先看没有使用它会发生什么？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class A
{
    public:
        ~A()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~A()&amp;quot; &amp;lt;&amp;lt; endl;
        }
        shared_ptr&amp;lt;A&amp;gt; get_sptr()
        {
            return shared_ptr&amp;lt;A&amp;gt;(this);
        }
};

int main()
{
    shared_ptr&amp;lt;A&amp;gt; a(new A());
    shared_ptr&amp;lt;A&amp;gt; b = a-&amp;gt;get_sptr();

    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/21rnuTE.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以看出，只new了一个A对象，但是却调用了两次析构函数。产生这个错误的原因get_sptr()成员函数中将shared_ptr中的引用计数器的值加了1。所以，需要解决的是，怎样通过一个类的成员函数获取当前对象的shared_ptr？&lt;br&gt;方法就是使类继承enable_shared_from_this，然后在需要shared_ptr的地方调用其成员函数shared_from_this()即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class A : public enable_shared_from_this&amp;lt;A&amp;gt;
{
    public:
        ~A()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~A()&amp;quot; &amp;lt;&amp;lt; endl;
        }
        shared_ptr&amp;lt;A&amp;gt; get_sptr()
        {
            return shared_from_this();
        }
};

int main()
{
    shared_ptr&amp;lt;A&amp;gt; a(new A());
    shared_ptr&amp;lt;A&amp;gt; b = a-&amp;gt;get_sptr();

    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/ZuA23y9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;需要注意的是，不能在构造函数中使用&lt;code&gt;shared_from_this()&lt;/code&gt;，因为虽然对象的基类&lt;code&gt;enable_shared_from_this&lt;/code&gt;的构造函数已经调用，但是&lt;code&gt;shared_ptr&lt;/code&gt;的构造函数并没有调用，所以这个时候调用&lt;code&gt;shared_from_this()&lt;/code&gt;是错的。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;智能指针虽好，但也并非完美，在使用的过程中还是需要注意。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;前面在&lt;a href=&quot;http://blog.dujiong.net/2016/05/15/cplusplus-sematics/&quot;&gt;浅谈C++值语义和对象语义&lt;/a&gt;一文中简要的阐述了一下智能指针shared_ptr的作用和用法，作为C++11中最为广泛使用的智能指针，shared_ptr虽然解决了裸指针的诸多问题，但是它并非完美、无懈可击，所以，本文就shared_ptr使用过程中需要注意的一些问题做一下总结。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>epoll总结</title>
    <link href="http://blog.dujiong.net/2016/07/29/epoll/"/>
    <id>http://blog.dujiong.net/2016/07/29/epoll/</id>
    <published>2016-07-29T11:03:21.000Z</published>
    <updated>2016-08-08T12:29:46.599Z</updated>
    
    <content type="html">&lt;p&gt;在现如今的并发网络服务器程序开发中，我们都会见到IO多路复用（Linux下的epoll、Windows下的IOCP等）的影子，它们是各种服务器并发方案（&lt;a href=&quot;http://blog.dujiong.net/2016/05/28/concurrent-server-conclusion/&quot;&gt;常见并发网络服务程序设计方案&lt;/a&gt;）的基础，而我们知道，绝大部分服务器都是运行在Linux系统下，所以，本文就现如今Linux下用的最多的epoll的原理、用法进行一个简单总结。   &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;什么是epoll？&quot;&gt;&lt;a href=&quot;#什么是epoll？&quot; class=&quot;headerlink&quot; title=&quot;什么是epoll？&quot;&gt;&lt;/a&gt;什么是epoll？&lt;/h3&gt;&lt;p&gt;epoll是在Linux 2.6内核中提出的，是之前select/poll的增强版本，相比如后两种IO多路复用版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集合来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点提升是获取事件的时候，epoll无须遍历整个被侦听的描述符，只要遍历那些被内核IO事件异步唤醒而加入就绪队列中的描述符集合就行了。此外，epoll除了提供select/poll那种IO事件的电平触发（LT）模式外，还提供边沿触发（ET），这样使得用户空间程序可以缓存IO状态，减少epoll_wait的调用，提高应用程序效率。        &lt;/p&gt;
&lt;h3 id=&quot;epoll的优点&quot;&gt;&lt;a href=&quot;#epoll的优点&quot; class=&quot;headerlink&quot; title=&quot;epoll的优点&quot;&gt;&lt;/a&gt;epoll的优点&lt;/h3&gt;&lt;p&gt;上面笼统的说了一下epoll的一些优点，下面分条做一个总结。&lt;br&gt;（1）支持一个大数目的socket描述符（FD）&lt;br&gt;epoll没有文件描述符的限制，它所支持的FD上限是最大可以打开文件的数目，这个数字远远大于select所支持的1024/2048。可以通过&lt;code&gt;cat /proc/sys/fs/file-max&lt;/code&gt;查看这个值，下面是我笔记本上的显示结果。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pt@Ubuntu:~$ cat /proc/sys/fs/file-max   
6815744
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;（2）IO效率不随FD数目增加而线性下降&lt;br&gt;传统select/poll的另一个致命弱点是当拥有一个很大的socket集合，由于网络的时延，使得任一时间只有部分的socket是“活跃”的，而select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。epoll对其进行了优化，它只会对“活跃”的socket进行操作：这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。所以，只有“活跃”的socket才会主动去调用callback函数，其他idle状态的socket则不会。在这点上，epoll实现了一个”伪”AIO”，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的，比如一个高速LAN环境，epoll也不比select/poll效率低，但若过多使用的调用epoll_ctl，效率稍微有些下降。然而一旦使用idle connections模拟WAN环境，那么epoll的效率就远在select/poll之上了。&lt;br&gt;（3）使用mmap加速内核与用户空间的消息传递&lt;br&gt;无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就显得很重要。在这点上，epoll是通过内核于用户空间mmap同一块内存实现。&lt;/p&gt;
&lt;h3 id=&quot;epoll的两种工作模式&quot;&gt;&lt;a href=&quot;#epoll的两种工作模式&quot; class=&quot;headerlink&quot; title=&quot;epoll的两种工作模式&quot;&gt;&lt;/a&gt;epoll的两种工作模式&lt;/h3&gt;&lt;h4 id=&quot;LT模式&quot;&gt;&lt;a href=&quot;#LT模式&quot; class=&quot;headerlink&quot; title=&quot;LT模式&quot;&gt;&lt;/a&gt;LT模式&lt;/h4&gt;&lt;p&gt;LT（Level Triggered，水平触发）模式，这是缺省的工作模式，同时支持block和non-block socket，在这种模式中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表。 &lt;/p&gt;
&lt;h4 id=&quot;ET模式&quot;&gt;&lt;a href=&quot;#ET模式&quot; class=&quot;headerlink&quot; title=&quot;ET模式&quot;&gt;&lt;/a&gt;ET模式&lt;/h4&gt;&lt;p&gt;ET(Edge Triggered，边沿触发)模式，这是高速工作模式，只支持non-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核就通过epoll告诉你，然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作而导致那个文件描述符不再是就绪状态(比如你在发送、接收或是接受请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误)。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核就不会发送更多的通知(only once)。不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。所以，这种方式下，出错率比较高，需要增加一些检测程序。&lt;/p&gt;
&lt;h4 id=&quot;使用ET和LT模式&quot;&gt;&lt;a href=&quot;#使用ET和LT模式&quot; class=&quot;headerlink&quot; title=&quot;使用ET和LT模式&quot;&gt;&lt;/a&gt;使用ET和LT模式&lt;/h4&gt;&lt;p&gt;上面已经说过了二者分别的特点，ET会更高效，但是只支持non-block socket，LT更加易用，且不易出错。个人觉得，一般的场景下，使用LT模式足以解决问题，如果碰到一些特殊场景要使用ET模式，一定要增加出错监测程序。        &lt;/p&gt;
&lt;h3 id=&quot;使用epoll&quot;&gt;&lt;a href=&quot;#使用epoll&quot; class=&quot;headerlink&quot; title=&quot;使用epoll&quot;&gt;&lt;/a&gt;使用epoll&lt;/h3&gt;&lt;p&gt;epoll用到的所有数据结构和函数都是在头文件sys/epoll.h中声明的，下面逐一介绍。    &lt;/p&gt;
&lt;h4 id=&quot;相关数据结构&quot;&gt;&lt;a href=&quot;#相关数据结构&quot; class=&quot;headerlink&quot; title=&quot;相关数据结构&quot;&gt;&lt;/a&gt;相关数据结构&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;typedef union epoll_data{
    void* ptr;
    int fd;
    __uint32_t u32;
    __uint43_t u64;
}epoll_data_t;

struct epoll_event{
    __uint32_t events;    //Epoll events
    epoll_data_t data;    //User data variable    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结构体epoll_event被用于注册所感兴趣的事件和回传发生待处理的事件。epoll_event 结构体的events字段是表示感兴趣的事件和被触发的事件，可能的取值为：&lt;br&gt;EPOLLIN： 表示对应的文件描述符可以读；&lt;br&gt;EPOLLOUT： 表示对应的文件描述符可以写；&lt;br&gt;EPOLLPRI： 表示对应的文件描述符有紧急的数据可读；&lt;br&gt;EPOLLERR： 表示对应的文件描述符发生错误；&lt;br&gt;EPOLLHUP： 表示对应的文件描述符被挂断；&lt;br&gt;EPOLLET： 表示对应的文件描述符有事件发生；&lt;br&gt;联合体epoll_data用来保存触发事件的某个文件描述符相关的数据。例如一个client连接到服务器，服务器通过调用accept函数可以得到于这个client对应的socket文件描述符，可以把这文件描述符赋给epoll_data的fd字段，以便后面的读写操作在这个文件描述符上进行。&lt;/p&gt;
&lt;h4 id=&quot;epoll函数&quot;&gt;&lt;a href=&quot;#epoll函数&quot; class=&quot;headerlink&quot; title=&quot;epoll函数&quot;&gt;&lt;/a&gt;epoll函数&lt;/h4&gt;&lt;p&gt;1.创建函数&lt;br&gt;&lt;code&gt;int epoll_create(int size)&lt;/code&gt;&lt;br&gt;该函数创建一个epoll实例，通知内核需要监听size个fd。size指的并不是最大的后备存储设备，而是衡量内核内部结构大小的一个提示。当创建成功后，会占用一个fd，所以记得在使用完之后调用close()，否则fd可能会被耗尽。不过，自Linux 2.6.8版本之后，size值没什么作用，只需大于0，因为内核可以动态的分配大小，不需要size这个提示了。&lt;br&gt;2.注册函数&lt;br&gt;&lt;code&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event)&lt;/code&gt;&lt;br&gt;第一个参数epfd，为上一步epoll_create()返回的epoll fd。&lt;br&gt;第二个参数op表示操作值，有三个类型：&lt;br&gt;EPOLL_CTL_ADD ：注册目标到epfd中，同时关联内部event到fd上&lt;br&gt;EPOLL_CTL_MOD ：修改已经注册到fd的监听事件&lt;br&gt;EPOLL_CTL_DEL ：从epfd中删除/移除已注册的fd&lt;br&gt;第三个参数fd表示需要监听的fd。&lt;br&gt;第四个参数event表示需要监听的事件。&lt;br&gt;3.等待函数&lt;br&gt;&lt;code&gt;int epoll_wait(int epfd, structepoll_event * events, int maxevents, int timeout)&lt;/code&gt;&lt;br&gt;该函数用于轮询IO事件的发生。函数如果等待成功，则返回fd的数字；0表示等待fd超时，其他错误返回errno值。       &lt;/p&gt;
&lt;h4 id=&quot;使用综述&quot;&gt;&lt;a href=&quot;#使用综述&quot; class=&quot;headerlink&quot; title=&quot;使用综述&quot;&gt;&lt;/a&gt;使用综述&lt;/h4&gt;&lt;p&gt;首先通过&lt;code&gt;int create\_epoll(int maxfds)&lt;/code&gt;来创建一个epoll的句柄fd，其中maxfds为你的epoll所支持的最大句柄数（现只需设置大于0）。这个函数会返回一个新的epoll句柄，之后的所有操作都将通过这个句柄来进行操作。在用完之后，记得用close()来关闭这个创建出来的fd。&lt;br&gt;然后在你的网络主循环里面，调用epoll_wait(int epfd, epoll_event events, int max_events,int timeout)来查询所有的网络接口，看哪一个可以读，哪一个可以写。基本的语法为： &lt;code&gt;nfds = epoll_wait(kdpfd, events, maxevents, -1);&lt;/code&gt; 其中kdpfd为用epoll_create创建之后的句柄，events是一个epoll_event*的指针，当epoll_wait函数操作成功之后，events里面将储存所有的读写事件。max_events是当前需要监听的所有socket句柄数。最后一个timeout参数指示 epoll_wait的超时条件，为0时表示马上返回；为-1时表示函数会一直等下去直到有事件返回；为任意正整数时表示等这么长的时间，如果一直没有事件，则会返回。一般情况下如果网络主循环是单线程的话，可以用-1来等待，这样可以保证一些效率，如果是和主循环在同一个线程的话，则可以用0来保证主循环的效率。epoll_wait返回之后，应该进入一个循环，以便遍历所有的事件。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在现如今的并发网络服务器程序开发中，我们都会见到IO多路复用（Linux下的epoll、Windows下的IOCP等）的影子，它们是各种服务器并发方案（&lt;a href=&quot;http://blog.dujiong.net/2016/05/28/concurrent-server-conclusion/&quot;&gt;常见并发网络服务程序设计方案&lt;/a&gt;）的基础，而我们知道，绝大部分服务器都是运行在Linux系统下，所以，本文就现如今Linux下用的最多的epoll的原理、用法进行一个简单总结。   &lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>2015-2016年互联网公司校招编程题汇总</title>
    <link href="http://blog.dujiong.net/2016/07/21/internetcompany/"/>
    <id>http://blog.dujiong.net/2016/07/21/internetcompany/</id>
    <published>2016-07-21T12:16:02.000Z</published>
    <updated>2016-09-19T15:38:36.004Z</updated>
    
    <content type="html">&lt;p&gt;本文收录了近两年的各大互联网公司校招（实习）笔试的编程题，并提供了自己的思路和解法。希望能对自己和备战互联网校招的同学提供一些帮助。 &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;所有题目均来自于牛客网“校招真题编程题汇总”板块，感谢牛客网的汇总并提供在线编程平台。为了方便大家检验，下面每个题会链接到牛客网的OJ界面。而我提供的思路和解法会链接至我的&lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github&lt;/a&gt;，欢迎大家多沟通、交流。&lt;/p&gt;
&lt;h3 id=&quot;华为&quot;&gt;&lt;a href=&quot;#华为&quot; class=&quot;headerlink&quot; title=&quot;华为&quot;&gt;&lt;/a&gt;华为&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/784efd40ed8e465a84821c8f3970b7b5?tpId=49&amp;amp;tqId=29297&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;字符集合&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8D%8E%E4%B8%BA/%E5%AD%97%E7%AC%A6%E9%9B%86%E5%90%88&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/f9533a71aada4f35867008be22be5b6e?tpId=49&amp;amp;tqId=29296&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;删数&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8D%8E%E4%B8%BA/%E5%88%A0%E6%95%B0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;腾讯&quot;&gt;&lt;a href=&quot;#腾讯&quot; class=&quot;headerlink&quot; title=&quot;腾讯&quot;&gt;&lt;/a&gt;腾讯&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/fbcf95ed620f42a88be24eb2cd57ec54?tpId=49&amp;amp;tqId=29311&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;微信红包&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%85%BE%E8%AE%AF/%E5%BE%AE%E4%BF%A1%E7%BA%A2%E5%8C%85&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/50959b5325c94079a391538c04267e15?tpId=49&amp;amp;tqId=29310&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;生成格雷码&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%85%BE%E8%AE%AF/%E7%94%9F%E6%88%90%E6%A0%BC%E9%9B%B7%E7%A0%81&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;网易&quot;&gt;&lt;a href=&quot;#网易&quot; class=&quot;headerlink&quot; title=&quot;网易&quot;&gt;&lt;/a&gt;网易&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/62cdf520b9d94616b6644ac03a0306ff?tpId=49&amp;amp;tqId=29309&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;路灯&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E8%B7%AF%E7%81%AF&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/cee98a512ec246a2918ea8121f7612c8?tpId=49&amp;amp;tqId=29308&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;奖学金&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E5%A5%96%E5%AD%A6%E9%87%91&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45846&amp;amp;tid=4847537&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;统计回文&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E7%BB%9F%E8%AE%A1%E5%9B%9E%E6%96%87&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45842&amp;amp;tid=4847537&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;两种排序方法&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E4%B8%A4%E7%A7%8D%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45844&amp;amp;tid=4847537&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Fibonacci数列&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/Fibonacci%E6%95%B0%E5%88%97&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45840&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;解救小易&lt;/a&gt; ——————–&amp;gt;  &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E8%A7%A3%E6%95%91%E5%B0%8F%E6%98%93&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45842&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;不要二&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E4%B8%8D%E8%A6%81%E4%BA%8C&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45842&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;饥饿的小易&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E9%A5%A5%E9%A5%BF%E7%9A%84%E5%B0%8F%E6%98%93&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45843&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;数字游戏&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E6%95%B0%E5%AD%97%E6%B8%B8%E6%88%8F&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45847&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;混合颜料&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E6%B7%B7%E5%90%88%E9%A2%9C%E6%96%99&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;京东&quot;&gt;&lt;a href=&quot;#京东&quot; class=&quot;headerlink&quot; title=&quot;京东&quot;&gt;&lt;/a&gt;京东&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/532d89889b974506a0805062fd1089fb?tpId=49&amp;amp;tqId=29307&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;小东分苹果&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E4%BA%AC%E4%B8%9C/%E5%B0%8F%E4%B8%9C%E5%88%86%E8%8B%B9%E6%9E%9C&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/ae45a1d8bc1d43858c83762fe8c2802c?tpId=49&amp;amp;tqId=29306&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;抛小球&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E4%BA%AC%E4%B8%9C/%E6%8A%9B%E5%B0%8F%E7%90%83&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/4b24ebad2ffd4f679320fd464b2036a6?tpId=49&amp;amp;tqId=29321&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;上台阶&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E4%BA%AC%E4%B8%9C/%E4%B8%8A%E5%8F%B0%E9%98%B6&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;小米&quot;&gt;&lt;a href=&quot;#小米&quot; class=&quot;headerlink&quot; title=&quot;小米&quot;&gt;&lt;/a&gt;小米&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/ba033b0d1c2f497da1dd04330cc003af?tpId=49&amp;amp;tqId=29232&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;懂二进制&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%B0%8F%E7%B1%B3/%E6%87%82%E4%BA%8C%E8%BF%9B%E5%88%B6&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/9370d298b8894f48b523931d40a9a4aa?tpId=49&amp;amp;tqId=29233&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;风口的猪-中国牛市&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%B0%8F%E7%B1%B3/%E9%A3%8E%E5%8F%A3%E7%9A%84%E7%8C%AA-%E4%B8%AD%E5%9B%BD%E7%89%9B%E5%B8%82&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;去哪儿&quot;&gt;&lt;a href=&quot;#去哪儿&quot; class=&quot;headerlink&quot; title=&quot;去哪儿&quot;&gt;&lt;/a&gt;去哪儿&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/28d5a9b7fc0b4a078c9a6d59830fb9b9?tpId=49&amp;amp;tqId=29278&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;二分查找&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/dab59997905b4459a42587fece8a75f4?tpId=49&amp;amp;tqId=29279&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;首个重复字符&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E9%A6%96%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/a386fd3a5080435dad3252bac76950a7?tpId=49&amp;amp;tqId=29280&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;寻找Coder&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E5%AF%BB%E6%89%BECoder&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/227893ccf81d4e8589875922f0d9319e?tpId=49&amp;amp;tqId=29299&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;表达式合法判断&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%90%88%E6%B3%95%E5%88%A4%E6%96%AD&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/5541c433dee04c17ba7774c4a20430de?tpId=49&amp;amp;tqId=29303&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;5-血型遗传监测&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/5-%E8%A1%80%E5%9E%8B%E9%81%97%E4%BC%A0%E7%9B%91%E6%B5%8B&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;美团&quot;&gt;&lt;a href=&quot;#美团&quot; class=&quot;headerlink&quot; title=&quot;美团&quot;&gt;&lt;/a&gt;美团&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/13ba51c3fec74b58bbc8fa8c3eedf877?tpId=49&amp;amp;tqId=29284&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;直方图内最大矩形&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%86%85%E6%9C%80%E5%A4%A7%E7%9F%A9%E5%BD%A2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/0b5ab6cc51804dd59f9988ad70d8c4a0?tpId=49&amp;amp;tqId=29282&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;棋子翻转&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E6%A3%8B%E5%AD%90%E7%BF%BB%E8%BD%AC&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/3745638815d04c26babcfc463c25478c?tpId=49&amp;amp;tqId=29286&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;平均年龄&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E5%B9%B3%E5%9D%87%E5%B9%B4%E9%BE%84&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/1f7675ae7a9e40e4bd04eb754b62fd00?tpId=49&amp;amp;tqId=29281&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;最大差值&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E6%9C%80%E5%A4%A7%E5%B7%AE%E5%80%BC&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/12cbdcdf5d1e4059b6ddd420de6342b6?tpId=49&amp;amp;tqId=29283&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;拜访&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E6%8B%9C%E8%AE%BF&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/196141ecd6eb401da3111748d30e9141?tpId=49&amp;amp;tqId=29315&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;奇数位丢弃&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E5%A5%87%E6%95%B0%E4%BD%8D%E4%B8%A2%E5%BC%83&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/6fadc1dac83a443c9434f350a5803b51?tpId=49&amp;amp;tqId=29316&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;二维数组打印&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E6%89%93%E5%8D%B0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/3e8c66829a7949d887334edaa5952c28?tpId=49&amp;amp;tqId=29317&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;股票交易日&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E8%82%A1%E7%A5%A8%E4%BA%A4%E6%98%93%E6%97%A5&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;蘑菇街&quot;&gt;&lt;a href=&quot;#蘑菇街&quot; class=&quot;headerlink&quot; title=&quot;蘑菇街&quot;&gt;&lt;/a&gt;蘑菇街&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/3a571cdc72264d76820396770a151f90?tpId=49&amp;amp;tqId=29292&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;最大间隔&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%98%91%E8%8F%87%E8%A1%97&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/655a43d702cd466093022383c24a38bf?rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;回文串&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%98%91%E8%8F%87%E8%A1%97/%E5%9B%9E%E6%96%87%E4%B8%B2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文收录了近两年的各大互联网公司校招（实习）笔试的编程题，并提供了自己的思路和解法。希望能对自己和备战互联网校招的同学提供一些帮助。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之Thread和ThreadPool</title>
    <link href="http://blog.dujiong.net/2016/07/17/muduo-6/"/>
    <id>http://blog.dujiong.net/2016/07/17/muduo-6/</id>
    <published>2016-07-17T11:14:12.000Z</published>
    <updated>2016-08-30T12:14:05.124Z</updated>
    
    <content type="html">&lt;p&gt;在muduo的one loop per thread + thread pool模型中，线程和线程池应该是其中最基础也是最重要的两个组件了。所以，本文深入代码，学习Thread和ThreadPool两个类的结构和实现。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;Thread类&quot;&gt;&lt;a href=&quot;#Thread类&quot; class=&quot;headerlink&quot; title=&quot;Thread类&quot;&gt;&lt;/a&gt;Thread类&lt;/h3&gt;&lt;h4 id=&quot;thread关键字&quot;&gt;&lt;a href=&quot;#thread关键字&quot; class=&quot;headerlink&quot; title=&quot;__thread关键字&quot;&gt;&lt;/a&gt;__thread关键字&lt;/h4&gt;&lt;p&gt;学习Thread class之前，先了解一个关键字的用法：__thread。&lt;br&gt;__thread是GCC内置的线程局部存储设施。它的实现非常高效，比Pthread库中的pthread_key_t（muduo中ThreadLocal）快很多。__thread变量是表示每个线程有一份独立实体，各个线程的变量值互不干扰。__thread只能修饰POD类型，不能修饰class类型，因为无法自动调用构造函数和析构函数。&lt;br&gt;Thread类的封装用到了命名空间CurrentThread，这个空间中定义了和线程相关的一些独立属性。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;namespace CurrentThread
{
    __thread int t_cachedTid = 0;
    __thread char t_tidString[32];
    __thread int t_tidStringLength = 6;
    __thread const char* t_threadName = &amp;quot;unknown&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，t_cachedTid表示线程的真实id，Pthread库中提供了pthread_self()获取当前线程的标识，类型为pthread_t。但是，pthread_t不一定是数值类型，也可能是一个结构体，这带来了一些问题。&lt;br&gt;（1）无法打印输出pthread_t，因为不知道其确切类型。&lt;br&gt;（2）无法比较pthread_t大小或计算hash值。&lt;br&gt;（3）pthread_t值只在进程内有意义，与操作系统的任务调度之间无法建立有效关系，Pthread库只能保证在同一进程之内，同一时刻的各个线程的id不同。&lt;br&gt;所以，muduo采用gettid()系统调用的返回值作为线程id，muduo中将操作封装为gettid()函数。但是，我们知道，调用系统调用开销比较大，所以，muduo中采用__thread变量t_cachedTid来存储，在线程第一次使用tid时通过系统调用获得，存储在t_cachedTid中，以后使用时不再需要系统调用了。&lt;br&gt;t_tidString[32]：用string类型表示tid，以便输出日志。&lt;br&gt;t_tidStringLength：string类型tid的长度。&lt;br&gt;t_threadName：线程的名字。     &lt;/p&gt;
&lt;h4 id=&quot;相关的数据结构&quot;&gt;&lt;a href=&quot;#相关的数据结构&quot; class=&quot;headerlink&quot; title=&quot;相关的数据结构&quot;&gt;&lt;/a&gt;相关的数据结构&lt;/h4&gt;&lt;p&gt;在Thread的实现中，还用到了两个数据结构，一个位ThreadData，用来辅助调用线程执行的函数。另一个为ThreadNameInitializer，为线程的创建做环境准备。其中用到了&lt;code&gt;pthread_atfork(NULL,NULL,&amp;amp;afterfork)&lt;/code&gt;。该函数的原型为&lt;br&gt;    &lt;code&gt;int pthread_atfork(void (*prepare)(void), void (*parent)(void), void (*child)(void));&lt;/code&gt;&lt;br&gt;这是一个跟进程创建有关的函数，为fork的调用做准备和调用后子进程父进程的初始化。prepare函数在调用fork前执行，parent在调用fork后的父进程中执行，child在调用fork后的子进程中执行。&lt;br&gt;当然，在实际应用中，多线程不要调用fork()，否则会出现一些问题。因为fork智能克隆当前线程的thread of control，却不克隆其他线程。fork()之后，除了当前线程之外，其他线程都消失了。这样，会出现很多问题。比如，如果复制了一个lock的mutex，却没有复制unlock的线程，那么在给mutex加锁时就会出现死锁。&lt;/p&gt;
&lt;h4 id=&quot;Thread类分析&quot;&gt;&lt;a href=&quot;#Thread类分析&quot; class=&quot;headerlink&quot; title=&quot;Thread类分析&quot;&gt;&lt;/a&gt;Thread类分析&lt;/h4&gt;&lt;p&gt;首先来看Thread类的数据成员和构造函数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Thread : boost::noncopyable
{
    typedef boost::function&amp;lt;void ()&amp;gt; ThreadFunc;
    ...
    private:
        bool started_;
        bool joined_;
        pthread_t pthreadId_;
        boost::shared_ptr&amp;lt;pid_t&amp;gt; tid_;
        ThreadFunc func_;
        string name_;

        static AtomicInt32 numCreated_;
};
Thread::Thread(ThreadFunc&amp;amp;&amp;amp; func, const string&amp;amp; n)
    : started_(false), 
      joined_(false),
      pthreadId_(0),
      tid_(new pid_t(0)),
      func_(func),
      name_(n)
{
      setDefaultName();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中有两处需要说明一下，首先是&lt;code&gt;shared_ptr&amp;lt;pid&amp;gt; tid_&lt;/code&gt;，可能有人会有疑问：为什么这里要用shared_ptr包装pid？&lt;br&gt;原因是tid_所属的对象Thread在主线程（A）中创建，而tid_需要在新创建的线程B中进行赋值操作，如果tid使用裸指针的方式传递给线程（B），那么线程A中Thread对象析构（下文）销毁后，线程B持有的就是一个野指针，所以，在Thread对象中将以shared_ptr包装。&lt;br&gt;然后是numCreated_，是一个静态变量，类型为AtomicInt32，原子类型，用来表示第几次创建线程实例，在记录日志时可用记录为：“线程名+numCreated_”。&lt;/p&gt;
&lt;p&gt;接下来看Thread的一些接口函数。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Thread::start()
{
    started = true;
    detail::ThreadData* data = new detail::ThreadData(func_, name_, tid_);
    if(pthread_create(&amp;amp;pthreadId_, NULL, &amp;amp;detail::startThread, data));
    {
        started_ = false;
        delete data;
        LOG_SYSFATAL &amp;lt;&amp;lt; &amp;quot;Failed in pthread_create&amp;quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thread::start()将调用pthread_create()创建新线程，detail::startThread()是新线程的入口函数，data是新线程执行的辅助结构体。detail::startThread()调用data-&amp;gt;runInThread()执行线程逻辑(func_)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int Thread::join()
{
    assert(started_);
    assert(!joined_);
    joined_ = true;
    return pthread_join(pthreadId_, NULL);
}

Thread::~Thread()
{
    if(started_ &amp;amp;&amp;amp; !joined_)
    {
        pthread_detach(pthreadId_);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thread析构的时候没有销毁持有的Pthreads句柄(pthread_t)，也就是说Thread的析构不会等待线程结束。如果Thread对象的生命期长于线程，然后通过Thread::join()来等待线程结束并释放线程资源。如果Thread对象的生命期短于线程，那么析构时会自动detach线程，避免了资源泄露。&lt;/p&gt;
&lt;h3 id=&quot;ThreadPool类&quot;&gt;&lt;a href=&quot;#ThreadPool类&quot; class=&quot;headerlink&quot; title=&quot;ThreadPool类&quot;&gt;&lt;/a&gt;ThreadPool类&lt;/h3&gt;&lt;p&gt;ThreadPool（线程池）本质上是一个生产者-消费者的模型，在实际中主要完成计算任务。在muduo线程池中有一个存放工作线程的容器ptr_vector，相当于消费者；有一个存放任务的队列deque。&lt;br&gt;任务队列是有界的，类似于BoundedBlockingQueue，实现时需要两个条件变量。&lt;br&gt;以下是ThreadPool的数据成员：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class ThreadPool : boost::noncopyable
{
    typedef boost::function&amp;lt;void ()&amp;gt; Task;
    private:
        MutexLock mutex_;
        Condition notEmpty_;
        Condition notFull_;
        string name_;
        Task threadInitCallback_;
        boost::ptr_vector&amp;lt;muduo::Thread&amp;gt; threads_;
        std::deque&amp;lt;Task&amp;gt; queue_;
        size_t maxQueueSize_;
        bool running_;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中threadInitCallback_可由setThreadInitCallback(const Task&amp;amp; cb)设置，设置回调函数，每次在执行任务前先调用。在线程池开始运行之前，需要先设置任务队列的大小（调用setMaxQueueSize()），因为运行线程池时，线程会从任务队列取任务。&lt;br&gt;接下来是ThreadPool的一些接口函数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ThreadPool::start(int numThreads)
{
    assert(threads_.empty());
    running_ = true;
    threads_.reserve(numThreads);
    for (int i = 0; i &amp;lt; numThreads; ++i)
      {
        char id[32];
        snprintf(id, sizeof id, &amp;quot;%d&amp;quot;, i+1);
        threads_.push_back(new muduo::Thread(
              boost::bind(&amp;amp;ThreadPool::runInThread, this), name_+id));
        threads_[i].start();
      }
    if(numThreads == 0 &amp;amp;&amp;amp; threadInitCallback_)
    {
        threadInitCallback_();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;void ThreadPool::start(int numThreads)&lt;/code&gt;开启线程池，按照线程数量numThreads_创建工作线程，线程函数为ThreadPool::runInThread（）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ThreadPool::runInThread()
{
    try
    {
        if(threadInitCallback_)
        {
            threadInitCallback_();
        }
        while(running_)
        {
            Task task(take());
            if(task)
            {
                task();
            }
        }
    }
    catch(const Exception&amp;amp; ex)
    {
        ...
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果设置了threadInitCallback_，则进行执行任务前的一些初始化操作。然后从任务队列中取任务执行，有可能阻塞，当任务队列为空时。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ThreadPool::Task ThreadPool::take()
{
    MutexLockGuard lock(mutex_);
    while(queue_.empty() &amp;amp;&amp;amp; running_)
    {
        notEmpty_.wait();
    }
    Task task;
    if(!queue_.empty())
    {
        task = queue_.front();
        queue_.pop_front();
        if(maxQueueSize_ &amp;gt; 0)
        {
            notFull_.notify();
        }
    }
    return task;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;多线程从消息队列中取任务的时候，需要加锁保护。等到队列非空信号，就取任务。取出之后，便告知任务队列已经非满，可以继续添加任务。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ThreadPool::run(const Task&amp;amp; task)
{
    if(threads_.empty())
    {
        task();
    }
    else
    {
        MutexLockGuard lock(mutex_);
        while(isFull())
        {
            notFull_.wait();
        }
        assert(!isFull());
        queue_.push_back(task);
        notEmpty_.notfy();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果ThreadPool没有子线程（set和start操作在run之前），就在主线程中执行该task，否则，将任务加入到队列，并通知线程从中取task，如果队列已满，便等待。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ThreadPool::~ThreadPool()
{
    if(running_)
    {
        stop();
    }
}
void ThreadPool::stop()
{
    {
        MutexLockGuard lock(mutex_);
        running_ = false;
        notEmpty_.notifyAll();
    }
    for_each(threads_.begin(),threads_.end(),boost::bind(&amp;amp;muduo::Thread::join, _1));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后是ThreadPool的析构函数，在其中调用stop()，唤醒所有等待的线程，然后对线程池中的每一个线程执行join()。     &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;以上就是muduo中Thread和ThreadPool类的学习，有很多源码，有点啰嗦。但是，在muduo的one loop per thread + thread pool模型中，Thread和ThreadPool是很重要的组件，所以需要深入地掌握。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在muduo的one loop per thread + thread pool模型中，线程和线程池应该是其中最基础也是最重要的两个组件了。所以，本文深入代码，学习Thread和ThreadPool两个类的结构和实现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之线程同步</title>
    <link href="http://blog.dujiong.net/2016/07/08/muduo-5/"/>
    <id>http://blog.dujiong.net/2016/07/08/muduo-5/</id>
    <published>2016-07-08T07:07:13.000Z</published>
    <updated>2016-08-30T07:14:40.635Z</updated>
    
    <content type="html">&lt;p&gt;前面的四篇“muduo源码阅读”文章都是从总体上（Reactor模式）出发把握muduo库的一些设计思想和架构，从这篇开始，将更深入细节、更贴近代码地阅读muduo网络库。&lt;br&gt;首先，是多线程编程中重中之重的线程同步问题。     &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;互斥锁&quot;&gt;&lt;a href=&quot;#互斥锁&quot; class=&quot;headerlink&quot; title=&quot;互斥锁&quot;&gt;&lt;/a&gt;互斥锁&lt;/h3&gt;&lt;p&gt;提到线程同步原语，相信绝大多数人首先想到的就是互斥锁(mutex)了，互斥锁保护了临界区，保证任何时刻最多只有一个线程在由mutex保护的临界区内活动。所以，一般使用mutex来保护共享数据。muduo中使用了C++ RAII的手法封装了mutex的创建、销毁、加锁和解锁四个操作，并最终封装成MutexLockGuard类，这样，一切都交给栈上的MutexLockGuard类的对象的构造和析构函数负责，对象的生命期正好等于临界区。        &lt;/p&gt;
&lt;p&gt;下面，首先来看MutexLock类的主要代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class MutexLock : boost noncopyable
{
    public:
        MutexLock() : holder_(0)
        {
            MCHECK(pthread_mutex_init(&amp;amp;mutex_,NULL)); //初始化mutex
        }
        ~MutexLock()
        {
            assert(holder_=0);
            MCHECK(pthread_mutex_destroy(&amp;amp;mutex_));    //销毁mutex
        }
        void lock()
        {
            MCHECK(pthread_mutex_lock(&amp;amp;mutex_));    //加锁
            assignHolder();    
        }
        void unlock()
        {
            unassignHolder();
            MCHECK(pthread_mutex_unlock(&amp;amp;mutex_));    //解锁
        }
    private:
        friend class Condition;
        void assignHolder()
        {
            holder_=CurrentThread::tid();
        }
        void unassignHolder()
        {
            holder_=0;
        }
        pthread_mutex_t mutex_;
        pid_t holder_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;   从代码中，很容易看出MutexLock对mutex的操作的封装。但是，为了防止忘记加锁、解锁操作，muduo做了更进一步的封装，于是有了MutexLockGuard类。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class MutexLockGuard : boost::noncopyable
{
    public:
        explicit MutexLockGuard(MutexLock&amp;amp; mutex) : mutex_(mutex)
        {
            mutex_.lock();        //在构造函数内进行加锁操作
        }    
        ~MutexLockGuard()
        {
            mutex_.unlock();    //在析构函数内进行解锁操作
        }
    private:
        MutexLock&amp;amp; mutex_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样一来，用户只需创建一个栈上的MutexLockGuard对象，便可以完成初始化、加锁操作，MutexLockGuard对象的生命期等于临界区，栈上对象析构的时候，自动完成解锁、销毁等操作。&lt;/p&gt;
&lt;h3 id=&quot;条件变量&quot;&gt;&lt;a href=&quot;#条件变量&quot; class=&quot;headerlink&quot; title=&quot;条件变量&quot;&gt;&lt;/a&gt;条件变量&lt;/h3&gt;&lt;p&gt;互斥锁是加锁原语，用来排他性地访问共享数据，它不是等待原语。如果需要等待某个条件成立，就应该使用条件变量。条件变量是一个或多个线程等待某个条件为真，即等待别的“线程”唤醒它。&lt;br&gt;所以，条件变量涉及等待端和通知端，所以双方都要按照一定的方式保证正常使用。&lt;br&gt;对于wait端：&lt;br&gt;（1）必须与mutex一起使用，条件（布尔表达式）的读写受mutex的保护&lt;br&gt;（2）在mutex已上锁的时候才能调用wait()&lt;br&gt;（3）把判断布尔表达式和wait()放入while()循环中&lt;br&gt;对于signal/broadcast端：&lt;br&gt;（1）在signal之前一般要修改布尔表达式&lt;br&gt;（2）修改布尔表达式要加锁保护&lt;br&gt;（3）signal（通知）通常用于资源可用，broadcast（广播）通常用于表明状态变化&lt;br&gt;写成代码表示：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;muduo::MutexLock mutex;
muduo::Condition cond(mutex);
std::deque&amp;lt;int&amp;gt; queue;     

int dequeue()
{
    MutexLockGuard lock(mutex);
    while(queue.empty())
    {
        cond.wait();           //等待条件变量
    }
    assert(!queue.empty());
    int top = queue.front();
    queue.pop_front();
    return top;
}
void enqueue(int x)
{
    MutexLockGuard lock(mutex);
    queue.push_back(x);
    cond.notify();            //通知资源可用       
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上，可以看成生产者–消费者模型，这里有一个经典的问题，即消费者中使用while()循环等待，可否使用if呢？答案是否定的，因为在多线程中，由于莫名其妙的原因，即使没有线程调用signal或broadcast，原来wait的线程可能也会返回，即被唤醒了。所以，通过while()循环判断来避免虚假唤醒造成的错误，而不能使用if。&lt;br&gt;muduo中使用Condition类提供了对条件变量的封装。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Condition : boost::noncopyable
{
    public:
        explicit Condition(MutexLock&amp;amp; mutex) : mutex_(mutex)
        {
            MCHECK(pthread_cond_init(&amp;amp;pcond_,NULL));
        }
        ~Condition()
        {    
            MCHECK(pthread_cond_destroy(&amp;amp;pcond_));
        }
        void wait()
        {
            MutexLock::UnassginGuard ug(mutex_);
            MCHECK(pthread_cond_wait(&amp;amp;pcond_,mutex_.getPthreadMutex()));
        }
        void notify()
        {
            MCHECK(pthread_cond_signal(&amp;amp;pcond_));
        }
        void notifyAll()
        {
            MCHECK(pthread_cond_broadcast(&amp;amp;pcond_));
        }
    private:
        MutexLock&amp;amp; mutex_;    
        pthread_cond_t pcond_;
};    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;CountDownLatch&quot;&gt;&lt;a href=&quot;#CountDownLatch&quot; class=&quot;headerlink&quot; title=&quot;CountDownLatch&quot;&gt;&lt;/a&gt;CountDownLatch&lt;/h3&gt;&lt;p&gt;条件变量是非常底层的同步原语，很少直接使用，一般都是用它来实现高层的同步措施。muduo中封装的CountDownLatch（倒计时）就是一种常用且易用的同步手段。主要有两方面的用途：&lt;br&gt;（1）主线程发起多个子线程，等这些子线程各自都完成一定的任务之后，主线程才继续执行。通常用于主线程等待多个子线程完成初始化。&lt;br&gt;（2）主线程发起多个子线程，子线程都等待主线程，主线程完成其他一些任务之后通知所有子线程开始执行。通常用于多个子线程等待主线程发起“起跑”命令。&lt;br&gt;下面是muduo中的倒计时CountDownLatch类。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class CountDownLatch : boost::noncopyable
{
    public: 
        explicit CountDownLatch(int count);        //倒数几次
        void wait();                            //等待计数值变为0
        void countDown();                        //计数减1
        void getCount() const;
    private:
        mutable MutexLock mutex_;
        Condition condition_;
        int count_;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;互斥锁和条件变量构成了多线程编程的几乎全部必备的同步原语，正确并熟练地使用它们，即可完成任何多线程同步任务。在此基础上，如果特定的场景下实在还需要性能上的提升，再考虑更高级的同步手段。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;前面的四篇“muduo源码阅读”文章都是从总体上（Reactor模式）出发把握muduo库的一些设计思想和架构，从这篇开始，将更深入细节、更贴近代码地阅读muduo网络库。&lt;br&gt;首先，是多线程编程中重中之重的线程同步问题。     &lt;/p&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议总结（二）</title>
    <link href="http://blog.dujiong.net/2016/06/25/tcp-2/"/>
    <id>http://blog.dujiong.net/2016/06/25/tcp-2/</id>
    <published>2016-06-25T12:06:14.000Z</published>
    <updated>2016-08-07T13:00:43.518Z</updated>
    
    <content type="html">&lt;p&gt;首先，纪念一下，如果不出意外的话（没过or狠心读个博），学生期间所有的考试应该就此结束了，以后就不会大冬天的早上7点起床去图书馆占座了，想想也是佩服自己啊，啧…&lt;br&gt;好了，言归正传，接着上篇，今天学习TCP协议中较难的重传、滑动窗口和拥塞控制。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;TCP重传机制&quot;&gt;&lt;a href=&quot;#TCP重传机制&quot; class=&quot;headerlink&quot; title=&quot;TCP重传机制&quot;&gt;&lt;/a&gt;TCP重传机制&lt;/h3&gt;&lt;p&gt;TCP是可靠的、面向连接的协议，要保证所有的数据包都可以到达，所以，重传机制是必须的。&lt;br&gt;由于接收端给发送端的ACK只会确认最后一个连续的包，比如，发送端发了1、2、3、4、5一共5份数据，接收端收到了1、2，于是回ACK 3，然后收到了4，此时3没收到，怎么办？&lt;/p&gt;
&lt;h4 id=&quot;超时重传机制&quot;&gt;&lt;a href=&quot;#超时重传机制&quot; class=&quot;headerlink&quot; title=&quot;超时重传机制&quot;&gt;&lt;/a&gt;超时重传机制&lt;/h4&gt;&lt;p&gt;一种方法是不回ACK，一直等3，当发送方发现收不到3的ACK，超时后会重传3.一旦接收方收到3后吗，会A回CK 4，表示3和4都收到了。&lt;br&gt;但是，问题来了，因为一直等3，可能会导致4和5即便已经收到了，发送方因为没有收到ACK，悲观地认为4和5也丢了，所以可能导致4和5的重传。对此有两种选择：一种是仅重传timeout的包。也就是第3份数据，另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，很可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长（下面会说TCP怎么动态计算timeout）。&lt;/p&gt;
&lt;h4 id=&quot;快速重传机制&quot;&gt;&lt;a href=&quot;#快速重传机制&quot; class=&quot;headerlink&quot; title=&quot;快速重传机制&quot;&gt;&lt;/a&gt;快速重传机制&lt;/h4&gt;&lt;p&gt;快速重传机制不以时间驱动，而以数据驱动重传。也就是说，如果包没有连续到达，就回复ACK最后那个可能被丢了的包，如果发送方连续收到3次相同的ACK，就重传。这样，好处是不用等timeout了再重传。&lt;br&gt;比如：如果发送方发出了1、2、3、4、5共5份数据，第一份先到了，于是接收方回复ACK 2，结果2因为某些原因没到、3到了，于是还是ACK 2，后面的4和5都到了，但是还是ACK 2，因为2还没有到，于是发送端收到了三个ACK 2的确认，就马上重传2。然后，接收端收到了2，此时3、4、5都已经收到了，于是ACK 6。其图示如下。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/56fKXLt.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;但是，这样还是没有解决重传之前的一个还是重传所有的问题。就上面例子来说，发送端并不清楚这三个ACK 2是接收端收到哪些数据后传回来的。&lt;/p&gt;
&lt;h4 id=&quot;SACK方法&quot;&gt;&lt;a href=&quot;#SACK方法&quot; class=&quot;headerlink&quot; title=&quot;SACK方法&quot;&gt;&lt;/a&gt;SACK方法&lt;/h4&gt;&lt;p&gt;另外一种更好的方式是：Selective ACK，需要在TCP头里加一个SACK的东西，ACK还是上面快速重传机制中的ACK。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/2oZwECU.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些数据没有到。在Linux下，可以通过tcp_sack这个参数打开这个功能。      &lt;/p&gt;
&lt;h4 id=&quot;Timeout与RTT&quot;&gt;&lt;a href=&quot;#Timeout与RTT&quot; class=&quot;headerlink&quot; title=&quot;Timeout与RTT&quot;&gt;&lt;/a&gt;Timeout与RTT&lt;/h4&gt;&lt;p&gt;从上述的TCP重传机制中可以看出，Timeout对于TCP重传的性能非常重要。如果设置长了，重发就慢，丢了很久才重发，效率低、性能差。而如果设置短了，导致并没有丢包就重发，这样重发加快，会增加网络拥塞，导致更多的超时，更多的超时又引起更多的重法，这样恶性循环。&lt;br&gt;所以，根据不同时间、网络情况，Timeout这个值需要设置，所以，TCP引入了RTT（往返时间，也就是一个数据包从发出去到回来的时间），这样就可以方便、有效的设置Timeout。&lt;br&gt;具体的RTT测量算法这里就不详述，细节可以参考《TCP/IP详解 卷一：协议》。&lt;/p&gt;
&lt;h3 id=&quot;TCP滑动窗口&quot;&gt;&lt;a href=&quot;#TCP滑动窗口&quot; class=&quot;headerlink&quot; title=&quot;TCP滑动窗口&quot;&gt;&lt;/a&gt;TCP滑动窗口&lt;/h3&gt;&lt;p&gt;在上一篇中提到了TCP头部里有一个字段Window，即滑动窗口，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。从而发送端可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。为了说明滑动窗口，首先来看一下TCP缓冲区的结构：&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;http://i.imgur.com/8afv8ge.jpg&quot; alt=&quot;&quot;&gt;            &lt;/p&gt;
&lt;p&gt;从上图可以得到，接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续数据包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，可以看到，中间有些数据还没有到达，所有有数据空白区。&lt;br&gt;而发送端的LastByteAcked指向了被接收端ACK了的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有成功确认的地方，LastByteWritten指向的是上层应用正在写的地方。&lt;br&gt;所以，接收端会在给发送端返回的ACK中汇报自己的滑动窗口大小=MaxRcvBuffer-LastByteRcvd-1；而发送端会根据这个窗口大小来控制发送数据的大小，以保证接收方可以处理。要解决这个问题，就是要避免对小的window size做出响应，直到有足够大的window size再响应。     &lt;/p&gt;
&lt;h4 id=&quot;Silly-Window-Syndrome和Nagle算法&quot;&gt;&lt;a href=&quot;#Silly-Window-Syndrome和Nagle算法&quot; class=&quot;headerlink&quot; title=&quot;Silly Window Syndrome和Nagle算法&quot;&gt;&lt;/a&gt;Silly Window Syndrome和Nagle算法&lt;/h4&gt;&lt;p&gt;网络上有个参数叫MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是MSS（Max Segment Size），TCP的RFC中定义这个MSS的默认值是536。&lt;br&gt;那么，如果网络包可以塞满MTU，那么就可以用满整个带宽，如果不能，那么就会浪费带宽。这时，可以将其想象成一架飞机，如果飞机里满载的话，带宽最高，如果一个飞机只运一个人的话，无疑成本增加了。所以，Silly Window Syndrome这个现象就像是本来可以坐200人的飞机里只坐了一两人。&lt;br&gt;要解决这个问题，就要避免对小的窗口大小做出响应，直到有足够大的窗口大小再响应，这就是著名的Nagle算法。&lt;br&gt;Nagle算法要求一个TCP连接上最多只能有一个未被确认的未完成的小分组，在该分组的确认到达之前不能发送其他的小分组。TCP将手机这些少量的分组，并在确认到来时以一个分组的方式发出去。&lt;br&gt;该算法主要用于避免过多小分组在网络中传输，降低网络容量利用率。比如：一个20字节的TCP首部+20字节的IP首部+1个字节的数据组成的TCP数据报，有效传输利用率只有近1/40，这些小分组在广域网上会增加拥塞出现的可能。&lt;br&gt;但是，有时我们又需要关闭Nagle算法，比如说一些需要快速响应、对时延敏感的应用，如窗口程序，可以通过套接字选项TCP_NODELAY来关闭该算法。&lt;/p&gt;
&lt;h3 id=&quot;TCP的拥塞处理&quot;&gt;&lt;a href=&quot;#TCP的拥塞处理&quot; class=&quot;headerlink&quot; title=&quot;TCP的拥塞处理&quot;&gt;&lt;/a&gt;TCP的拥塞处理&lt;/h3&gt;&lt;p&gt;如前面所描述的，TCP通过滑动窗口来做流控，但是这样还不够，因为滑动窗口只是依赖于连接的发送端和接收端，并不知道网络中间发生了什么。想象一下，网络上的延时突然增加，如果TCP对此作出的应对只有重传数据，但是，大量的重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这样就产生了恶性循环，最终会拖垮整个网络。&lt;br&gt;所以，TCP不能一个劲地只是重发数据，所以，TCP的理念是，当拥塞发生的时候，要做自我牺牲，就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。&lt;br&gt;拥塞控制主要是四个算法：慢启动、拥塞避免、拥塞发生和快速恢复。       &lt;/p&gt;
&lt;h4 id=&quot;慢启动、拥塞避免和拥塞发生&quot;&gt;&lt;a href=&quot;#慢启动、拥塞避免和拥塞发生&quot; class=&quot;headerlink&quot; title=&quot;慢启动、拥塞避免和拥塞发生&quot;&gt;&lt;/a&gt;慢启动、拥塞避免和拥塞发生&lt;/h4&gt;&lt;p&gt;慢启动的意思是，刚加入网络的连接，一点一点地提速。慢启动为发送方的TCP增加了另一个窗口：拥塞窗口（cwnd）。当与接收方建立TCP连接时，拥塞窗口被初始化为一个报文段，每收到一个ACK，拥塞窗口就增加一个报文段(cwnd以字节为单位，但是慢启动以报文段大小为单位进行增加)，但是有一个上限sshthresh，当cwnd&amp;gt;=ssthresh时，就会进入“拥塞避免算法”。慢启动算法初始设置cwnd为1个报文段，此后每收到一个确认就加1，这样会使窗口按指数方式增长，而拥塞避免算法要求每次收到一个确认时将cwnd增加1/cwnd。与慢启动的指数增加相比起来，这是一种加性增长。&lt;br&gt;所以，拥塞窗口是发送方使用的流量控制，而通告窗口则是接收方使用的流量控制。拥塞避免算法和慢启动算法需要对每个链接维持两个变量：一个拥塞窗口cwnd和一个慢启动门限ssthresh。这样，算法可以描述如下：&lt;br&gt;1）对于一个连接，初始化cwnd为1个报文段，ssthresh为65535个字节。&lt;br&gt;2）TCP输出例程的输出不能超过cwnd和接收方通告窗口的大小。前者是发送方感受到的网络拥塞的估计，而后者则与接收方在该连接上的可用缓存大小有关。&lt;br&gt;3）当拥塞发生时（超时或收到重复确认），ssthresh被设置为当前窗口（cwnd和接收方通告窗口大小的最小值，但最小为2个报文段）大小的一半。此外，如果是超时引起了拥塞，则cwnd被设置为1个报文段（相当于慢启动）。&lt;br&gt;4）当新的数据被对方确认时，就增加cwnd，但增加的方法依赖于是否正在进行慢启动或拥塞避免。如果cwnd小于或等于ssthresh，则正在进行慢启动，否则正在进行拥塞避免。       &lt;/p&gt;
&lt;h4 id=&quot;快速恢复算法&quot;&gt;&lt;a href=&quot;#快速恢复算法&quot; class=&quot;headerlink&quot; title=&quot;快速恢复算法&quot;&gt;&lt;/a&gt;快速恢复算法&lt;/h4&gt;&lt;p&gt;通常和快速重传算法一起使用，算法流程如下：&lt;br&gt;1）当收到第三个重复的ACK时（前面已述），将ssthresh设置为当前拥塞窗口cwnd的一半。重传丢失的报文段。设置cwnd为ssthresh加上3倍的报文段大小。&lt;br&gt;2）每次收到另一个重复的ACK时，cwnd增加1个报文段大小并发送1个分组。&lt;br&gt;3）当下一个确认新数据的ACK到达时，设置cwnd为ssthresh。这个ACK应该是在进行重传后的一个往返时间内对步骤1中重传的确认。另外，这个ACK也应该对丢失的分组和收到的第1个重复的ACK之间的所有中间报文段的确认。这一步采用的是拥塞避免，因为当分组丢失时将当前速率减半。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;通过这两篇总结，对TCP协议的核心知识点进行了复习和再认识，后面还需要结合具体的实例进一步加深理解，能对网络中的实际问题进行更好的分析和处理。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;首先，纪念一下，如果不出意外的话（没过or狠心读个博），学生期间所有的考试应该就此结束了，以后就不会大冬天的早上7点起床去图书馆占座了，想想也是佩服自己啊，啧…&lt;br&gt;好了，言归正传，接着上篇，今天学习TCP协议中较难的重传、滑动窗口和拥塞控制。&lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议总结（一）</title>
    <link href="http://blog.dujiong.net/2016/06/13/tcp-1/"/>
    <id>http://blog.dujiong.net/2016/06/13/tcp-1/</id>
    <published>2016-06-13T05:07:19.000Z</published>
    <updated>2016-09-20T13:41:36.933Z</updated>
    
    <content type="html">&lt;p&gt;最近，在学习和科研中，越来越发现自己对于TCP协议的掌握不够，作为一个成天和网络打交道的人，TCP/IP简直是我们最核心的知识之一，所以，准备利用接下来准备考试的间隙时间，结合《TCP/IP详解 卷一：协议》再重新学习和巩固一下TCP。          &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;TCP首部&quot;&gt;&lt;a href=&quot;#TCP首部&quot; class=&quot;headerlink&quot; title=&quot;TCP首部&quot;&gt;&lt;/a&gt;TCP首部&lt;/h3&gt;&lt;p&gt;首先，来看一下TCP首部的数据格式，如果不计算Option字段，它通常是20个字节。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/p9FVemz.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;需要重点关注和理解的是:&lt;br&gt;（1） 每个TCP连接包含源端和目的端的端口号，用于标识发端和收端的应用进程。这两个值和下层IP层的源、目的IP地址构成了唯一标识一个TCP连接的四元组。&lt;br&gt;（2）序列号(Sequence Number)是包的序号，用来标识从TCP发端向收端发送的数据字节流，用来解决网络报乱序的问题。&lt;br&gt;（3）ACK，表示收到TCP包的确认。&lt;br&gt;（4）TCP Flags标志位，也就是包的类型，用于标识TCP连接的状态。&lt;br&gt;（5）Window就是著名的滑动窗口，用于流量控制的。&lt;/p&gt;
&lt;h3 id=&quot;TCP连接的建立和终止&quot;&gt;&lt;a href=&quot;#TCP连接的建立和终止&quot; class=&quot;headerlink&quot; title=&quot;TCP连接的建立和终止&quot;&gt;&lt;/a&gt;TCP连接的建立和终止&lt;/h3&gt;&lt;p&gt;很多人对于TCP协议最深的印象应该就是三次握手和四次挥手了。那么，这中间的过程是怎样的呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/lP4JfiN.jpg&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
&lt;h4 id=&quot;三次握手建立连接&quot;&gt;&lt;a href=&quot;#三次握手建立连接&quot; class=&quot;headerlink&quot; title=&quot;三次握手建立连接&quot;&gt;&lt;/a&gt;三次握手建立连接&lt;/h4&gt;&lt;p&gt;1）请求端（C/S模型中的Client）发送一个SYN字段指明客户打算连接的服务器的端口，以及初始序号x。&lt;br&gt;2）服务器发挥包含服务器初始序号y的SYN报文段作为应答。同时，将确认序号设置为客户的序号加1以对客户的SYN报文段进行确认。一个SYN将占用一个序号。&lt;br&gt;3）客户必须将确认序号设置为服务器的序号加1以对服务器的SYN报文段进行确认。&lt;/p&gt;
&lt;h4 id=&quot;四次挥手终止连接&quot;&gt;&lt;a href=&quot;#四次挥手终止连接&quot; class=&quot;headerlink&quot; title=&quot;四次挥手终止连接&quot;&gt;&lt;/a&gt;四次挥手终止连接&lt;/h4&gt;&lt;p&gt;这是由TCP的半关闭造成的。因为TCP连接是全双工，因此每个方向都必须单独的关闭，都需要FIN和ACK。收到一个FIN只意味着在这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。&lt;br&gt;如上图，客户执行主动关闭，发送序列号(seq)为x+1的FIN，服务器收到这个FIN，发回ACK(seq=x+3)。接着服务器关闭它的连接，导致它的TCP端发送一个FIN(seq=y+1)，客户端必须发回一个确认，即ACK(seq=y+2)。&lt;/p&gt;
&lt;h4 id=&quot;连接建立的超时&quot;&gt;&lt;a href=&quot;#连接建立的超时&quot; class=&quot;headerlink&quot; title=&quot;连接建立的超时&quot;&gt;&lt;/a&gt;连接建立的超时&lt;/h4&gt;&lt;p&gt;实际中，有很多情况导致无法建立连接。比如，当Server收到Client的SYN并发回SYN-ACK后Client掉线了，Server端没有收到Client发回的ACK。这种情况下，Server端会重法SYN-ACK。在Linux下，默认重法次数为5次，重试的间隔时间从1s开始每次都翻倍，如果5次后仍旧没有收到，才会断开这个连接。               &lt;/p&gt;
&lt;h3 id=&quot;TCP状态机&quot;&gt;&lt;a href=&quot;#TCP状态机&quot; class=&quot;headerlink&quot; title=&quot;TCP状态机&quot;&gt;&lt;/a&gt;TCP状态机&lt;/h3&gt;&lt;p&gt;下面这个图非常重要，TCP状态机和状态之间的转换是分析网络状态、故障、优化等的重中之重。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/m6HYlnp.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;需要重点关注的：&lt;br&gt;（1）MSL和TIME_WAIT状态。据说，这是90%的互联网后台岗位面试都会考的内容。&lt;br&gt;每个具体TCP实现必须选择一个报文段最大生存时间MSL（Maximum Segment Lifetime），它是任何报文段被丢弃前在网络内的最长时间。这个时间是有限的，因为TCP报文段封装在IP数据包在网络内传输，而IP数据包有限制其生存时间的TTL字段。&lt;br&gt;当TCP执行一个主动关闭，并发回最后一个ACK（收到对端的FIN，并发送ACK），该连接必须在TIME_WAIT状态停留的时间为2MSL。这样做可以确保有足够的时间让对端收到ACK，如果被动关闭的那方没有收到ACK，就会触发被动端重发最后的FIN。一来一去正好2MSL。此外，这样做的另一个结果是标识这个TCP连接的四元组在2MSL期间不能再被使用，只能再2MSL结束后才能再被使用。&lt;br&gt;（2）TIME_WAIT过多&lt;br&gt;出现问题了，在高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动关闭连接，这样，就会有很多连接处在TIME_WAIT状态，会消耗许多系统资源。如果客户端的并发量持续很高，部分客户端就会显示连接不上。这时，可以通过设置tcp_tw_reuse和tcp_tw_recycle两个参数，前者表示开启重用，允许将处于TIME_WAIT的Socket重新用于新的TCP连接，后者表示开启TCP连接中TIME_WAIT socket的快速回收。&lt;br&gt;其实，个人觉得最好的办法就是想方设法让Client来关闭连接，这样Server作为被动关闭的一方，就不存在上述问题了。&lt;br&gt;（3）SYN Flood攻击&lt;br&gt;了解TCP三次握手后，很容易明白SYN Flood攻击的来源了，在客户端给服务器发了建立连接的SYN后，就下线了，于是服务器需要默认等待63s才会断开连接，这样，攻击者就可以把服务器的SYN连接队列耗尽，让正常的连接请求不能处理。于是，Linux下有一个tcp_syncookies的参数来应对攻击，当SYN队列满之后，TCP会根据源地址端口、目标地址端口和时间戳打造一个特别的Sequence Number（SYN Cookie）发回客户端，如果是攻击者则不会有相应，如果是正常连接，则会把这个SYN Cookie发回，然后服务端通过cookie建立连接。&lt;/p&gt;
&lt;h3 id=&quot;TCP保活定时器&quot;&gt;&lt;a href=&quot;#TCP保活定时器&quot; class=&quot;headerlink&quot; title=&quot;TCP保活定时器&quot;&gt;&lt;/a&gt;TCP保活定时器&lt;/h3&gt;&lt;p&gt;许多时候服务器希望知道客户主机是否崩溃并关机或者崩溃又重新启动这样的非正常情况，这就需要保活功能。如果一个特定的连接在固定时间之内没有任何动作，则服务器就向客户端发送一个探查报文。&lt;br&gt;保活功能的实现由两种方式，一是应用层面的心跳机制。通过自定义心跳消息头来完成保活功能。另一种就是TCP自带的保活功能。而这也是许多协议专家所争论的点：到底保活功能应该再哪一层实现。对于这两种方式，我认为应用层面的心跳机制具有灵活、扩展性强的特点，可以随意控制，不依赖与协议，但是也增加了开发的复杂程度。而TCP的保活功能，使用简单，减少了应用层代码的复杂度。所以，开发者可以根据实际的应用场景选择适合的保活功能的实现方式。&lt;/p&gt;
&lt;h3 id=&quot;待续&quot;&gt;&lt;a href=&quot;#待续&quot; class=&quot;headerlink&quot; title=&quot;待续&quot;&gt;&lt;/a&gt;待续&lt;/h3&gt;&lt;p&gt;这一篇是TCP协议的一些基础知识，下一篇将学习较复杂的滑动窗口、重传与拥塞控制。&lt;/p&gt;
&lt;p&gt;参考:  《TCP/IP详解 卷一：协议》   &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在学习和科研中，越来越发现自己对于TCP协议的掌握不够，作为一个成天和网络打交道的人，TCP/IP简直是我们最核心的知识之一，所以，准备利用接下来准备考试的间隙时间，结合《TCP/IP详解 卷一：协议》再重新学习和巩固一下TCP。          &lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>C++构造函数一些常见问题分析</title>
    <link href="http://blog.dujiong.net/2016/06/05/cpp-constructor/"/>
    <id>http://blog.dujiong.net/2016/06/05/cpp-constructor/</id>
    <published>2016-06-05T08:58:57.000Z</published>
    <updated>2016-08-06T12:49:26.202Z</updated>
    
    <content type="html">&lt;p&gt;近期，在阅读陈皓老师博客的时候，看到几年前的一篇&lt;a href=&quot;http://coolshell.cn/articles/804.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;关于C++构造函数的FAQ&lt;/a&gt;，想来自己学习C++也有段时间了，就尝试着回答一下，并乘机总结一下C++构造函数的一些常见问题，记录于此。&lt;br&gt;借此机会逛了逛C++ FAQ，以前都不了解，以后得多去学习学习，检验下自己的C++基础知识扎不扎实。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;构造函数是用来干什么的？&quot;&gt;&lt;a href=&quot;#构造函数是用来干什么的？&quot; class=&quot;headerlink&quot; title=&quot;构造函数是用来干什么的？&quot;&gt;&lt;/a&gt;构造函数是用来干什么的？&lt;/h3&gt;&lt;p&gt;顾名思义，构造函数是用来从无到有的构建对象。它将一些（连续的）最小粒度的内存单元变成对象。它要初始化对象内部所定义的域，还可以分配资源(内存、文件、套接字等)。&lt;/p&gt;
&lt;h3 id=&quot;List-x-和List-x-有什么不同？&quot;&gt;&lt;a href=&quot;#List-x-和List-x-有什么不同？&quot; class=&quot;headerlink&quot; title=&quot;List x;和List x();有什么不同？&quot;&gt;&lt;/a&gt;List x;和List x();有什么不同？&lt;/h3&gt;&lt;p&gt;List x;是声明了一个类List的对象x，而List x()是声明了一个函数x()，它返回一个List对象。二者自然是有本质的差别。 &lt;/p&gt;
&lt;h3 id=&quot;一个类的构造函数可否调用另一个构造函数来初始化自己？&quot;&gt;&lt;a href=&quot;#一个类的构造函数可否调用另一个构造函数来初始化自己？&quot; class=&quot;headerlink&quot; title=&quot;一个类的构造函数可否调用另一个构造函数来初始化自己？&quot;&gt;&lt;/a&gt;一个类的构造函数可否调用另一个构造函数来初始化自己？&lt;/h3&gt;&lt;p&gt;不能。如果调用另一个构造函数，编译器将初始化一个临时局部对象，而不是初始化this对象。&lt;/p&gt;
&lt;h3 id=&quot;是否Fred类的默认的构造函数就一定是Fred-Fred-？&quot;&gt;&lt;a href=&quot;#是否Fred类的默认的构造函数就一定是Fred-Fred-？&quot; class=&quot;headerlink&quot; title=&quot;是否Fred类的默认的构造函数就一定是Fred::Fred()？&quot;&gt;&lt;/a&gt;是否Fred类的默认的构造函数就一定是Fred::Fred()？&lt;/h3&gt;&lt;p&gt;不，默认构造函数是可以带提供默认值的参数的。&lt;br&gt;比如这里：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Fred
{
    public:
        Fred(int i=1);
};
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;如果要创建一个Fred对象数组，什么样的构造函数会被调用？&quot;&gt;&lt;a href=&quot;#如果要创建一个Fred对象数组，什么样的构造函数会被调用？&quot; class=&quot;headerlink&quot; title=&quot;如果要创建一个Fred对象数组，什么样的构造函数会被调用？&quot;&gt;&lt;/a&gt;如果要创建一个Fred对象数组，什么样的构造函数会被调用？&lt;/h3&gt;&lt;p&gt;Fred类的默认构造函数。&lt;br&gt;当然，更多的情况下我们都会选择使用标准容器vector，而且vector的一大优势是可以指定Fred的构造函数，而不仅仅是默认构造函数。&lt;/p&gt;
&lt;h3 id=&quot;构造函数初始化成员变量时，用”初始化列表”还是”赋值”？&quot;&gt;&lt;a href=&quot;#构造函数初始化成员变量时，用”初始化列表”还是”赋值”？&quot; class=&quot;headerlink&quot; title=&quot;构造函数初始化成员变量时，用”初始化列表”还是”赋值”？&quot;&gt;&lt;/a&gt;构造函数初始化成员变量时，用”初始化列表”还是”赋值”？&lt;/h3&gt;&lt;p&gt;无疑，初始化列表，在很多C++语法方面的书上都会讲，这里再总结一下。&lt;br&gt;使用”初始化列表”最大的好处是可以提高性能，比如使用 Fred::Fread() :x_(x)来初始化成员变量x_，x_直接由x构造–编译器不会产生对象的拷贝。&lt;br&gt;而通过赋值的话，&lt;code&gt;Fred::Fred() { x_ = x }&lt;/code&gt;，x作为一个临时对象被建立，并传递给x_成员作为赋值操作，然后临时对象x在语句的结束被析构，所以，这样的效率是较低的。&lt;br&gt;当然，如果x_的类型是int/char这样的内置类型的话，性能是没有区别的。总之，使用初始化列表来初始化成员变量是更佳的选择。&lt;/p&gt;
&lt;h3 id=&quot;构造函数初始化列表的初始化顺序？&quot;&gt;&lt;a href=&quot;#构造函数初始化列表的初始化顺序？&quot; class=&quot;headerlink&quot; title=&quot;构造函数初始化列表的初始化顺序？&quot;&gt;&lt;/a&gt;构造函数初始化列表的初始化顺序？&lt;/h3&gt;&lt;p&gt;C++初始化成员变量的顺序是按照它们定义的顺序，而非在初始化列表的顺序。&lt;br&gt;如果有继承关系的话，先基类，再派生类。&lt;/p&gt;
&lt;h3 id=&quot;在构造函数中用this指针是否有问题？&quot;&gt;&lt;a href=&quot;#在构造函数中用this指针是否有问题？&quot; class=&quot;headerlink&quot; title=&quot;在构造函数中用this指针是否有问题？&quot;&gt;&lt;/a&gt;在构造函数中用this指针是否有问题？&lt;/h3&gt;&lt;p&gt;一般情况下是不应该的，因为在构造阶段，this对象还没有完全形成。&lt;br&gt;当然也不绝对，比如构造函数的函数体或其中调用的函数可以访问基类中声明的数据成员或类的静态数据成员，这时它们都已经完整的建立起来了。&lt;br&gt;所以，一般情况下不这样做，如果要，也得记住，唯一准则是：这时this指针已经完整构造形成了。&lt;/p&gt;
&lt;h3 id=&quot;什么是“命名的构造函数法”？&quot;&gt;&lt;a href=&quot;#什么是“命名的构造函数法”？&quot; class=&quot;headerlink&quot; title=&quot;什么是“命名的构造函数法”？&quot;&gt;&lt;/a&gt;什么是“命名的构造函数法”？&lt;/h3&gt;&lt;p&gt;为类的用户提供一种更安全、直接的构造。&lt;br&gt;因为构造函数的特殊性，函数名和类名相同。因此，区分类的不同的构造函数只能通过参数列表。但如果有多个构造函数，很好地区分它们并不容易。&lt;br&gt;命名的构造函数法就是在private或protected内声明类所有的构造函数，并提供返回对象的public static函数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Point
{
    public:
        static Point rectangular(float x, float y);
        static Point polar(float radius, float angle);
    private:
        Point(float x, float y);
        float x_, y_;
};    
inline Point::Point(float x, float y) : x_(x), y_(y) {}
inline Point::rectangular(float x, float y) { return Point(x, y); }
inline Point::polar(float radius, float angle)
{
    return Point(radius*cos(angle), radius*sin(angle));
}
int main()
{
    Point p1 = Point::rectangular(5.0,5.0);
    Point p2 = Point::polar(5.0,5.0);
}    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;为什么不能在构造函数的初始化列表中初始化static数据？&quot;&gt;&lt;a href=&quot;#为什么不能在构造函数的初始化列表中初始化static数据？&quot; class=&quot;headerlink&quot; title=&quot;为什么不能在构造函数的初始化列表中初始化static数据？&quot;&gt;&lt;/a&gt;为什么不能在构造函数的初始化列表中初始化static数据？&lt;/h3&gt;&lt;p&gt;因为static数据成员是属于类的，而不是类的对象，所以，必须显示定义类的静态数据成员。&lt;/p&gt;
&lt;h3 id=&quot;为什么有静态数据成员的类得到了链接错误？&quot;&gt;&lt;a href=&quot;#为什么有静态数据成员的类得到了链接错误？&quot; class=&quot;headerlink&quot; title=&quot;为什么有静态数据成员的类得到了链接错误？&quot;&gt;&lt;/a&gt;为什么有静态数据成员的类得到了链接错误？&lt;/h3&gt;&lt;p&gt;因为如上一条所述，static数据成员必须显示定义在一个编译单元中。&lt;br&gt;通常在在.cpp源文件中定义static数据成员。&lt;/p&gt;
&lt;h3 id=&quot;什么是”static-initialization-order-fiasco”？&quot;&gt;&lt;a href=&quot;#什么是”static-initialization-order-fiasco”？&quot; class=&quot;headerlink&quot; title=&quot;什么是”static initialization order fiasco”？&quot;&gt;&lt;/a&gt;什么是”static initialization order fiasco”？&lt;/h3&gt;&lt;p&gt;还是初始化顺序的问题，比如两个源文件a.cpp和b.cpp中分别有两个静态对象a和b。假定a对象的构造函数会调用b对象的某些成员函数。由于static对象构造在main()开始之前，且顺序未知，所以，很可能发生a对象的构造函数先运行，当其想调用b对象的成员函数时，发现b对象还没被构造。&lt;/p&gt;
&lt;h3 id=&quot;如何处理构造函数的失败？&quot;&gt;&lt;a href=&quot;#如何处理构造函数的失败？&quot; class=&quot;headerlink&quot; title=&quot;如何处理构造函数的失败？&quot;&gt;&lt;/a&gt;如何处理构造函数的失败？&lt;/h3&gt;&lt;p&gt;当然是抛异常啦。关于C++的异常机制，后面还得好好学学。&lt;/p&gt;
&lt;h3 id=&quot;explicit关键字的作用？&quot;&gt;&lt;a href=&quot;#explicit关键字的作用？&quot; class=&quot;headerlink&quot; title=&quot;explicit关键字的作用？&quot;&gt;&lt;/a&gt;explicit关键字的作用？&lt;/h3&gt;&lt;p&gt;使用explicit就是告诉编译器禁止隐式转换。&lt;br&gt;下面通过实例说明。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Foo
{
    public:
        Foo(int x);
        operator int();
};        
int main()
{
    Foo a = 42;                  
    Foo b(42);              
    Foo c = (Foo)(42);      //显示转换
    int d = c;
    return 0;    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上都会编译成功，需要注意的是main()中的第一、四行，都涉及到了隐式转换。&lt;br&gt;但是，有些时候需要禁止这样的隐式转换。就得使用explicit关键字。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Foo
{
    public:
        explicit Foo(int x);
        explicit operator int();
};     
int main()
{
    Foo a = 42;        //error
    Foo b(42);
    Foo c = (Foo)(42);
    int d = c;        //error
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样的话，main()中的隐式转换（第一、四行）将不被允许。&lt;/p&gt;
&lt;h3 id=&quot;待续&quot;&gt;&lt;a href=&quot;#待续&quot; class=&quot;headerlink&quot; title=&quot;待续&quot;&gt;&lt;/a&gt;待续&lt;/h3&gt;&lt;p&gt;C++博大精深，构造函数又是其中非常重要的部分，后面还需要继续学习、补充。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;近期，在阅读陈皓老师博客的时候，看到几年前的一篇&lt;a href=&quot;http://coolshell.cn/articles/804.html&quot;&gt;关于C++构造函数的FAQ&lt;/a&gt;，想来自己学习C++也有段时间了，就尝试着回答一下，并乘机总结一下C++构造函数的一些常见问题，记录于此。&lt;br&gt;借此机会逛了逛C++ FAQ，以前都不了解，以后得多去学习学习，检验下自己的C++基础知识扎不扎实。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>常见并发网络服务程序设计方案</title>
    <link href="http://blog.dujiong.net/2016/05/28/concurrent-server-conclusion/"/>
    <id>http://blog.dujiong.net/2016/05/28/concurrent-server-conclusion/</id>
    <published>2016-05-28T02:14:00.000Z</published>
    <updated>2016-08-06T07:52:10.237Z</updated>
    
    <content type="html">&lt;p&gt;《Unix网络编程(第三版)》(以下简称[UNP])中第三十章”客户/服务器程序设计范式”总结了一些常见的并发网络服务程序设计方案，而随着互联网、大数据等浪潮的兴起，业界对服务器程序的高并发能力、稳定性等提出了更高的要求，客户/服务器程序设计范式也在随着时代的需求而不断改进和提升，下面就对常见的并发网络服务程序设计方案作简单总结。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;《Unix网络编程》传统方案&quot;&gt;&lt;a href=&quot;#《Unix网络编程》传统方案&quot; class=&quot;headerlink&quot; title=&quot;《Unix网络编程》传统方案&quot;&gt;&lt;/a&gt;《Unix网络编程》传统方案&lt;/h3&gt;&lt;h4 id=&quot;方案0&quot;&gt;&lt;a href=&quot;#方案0&quot; class=&quot;headerlink&quot; title=&quot;方案0&quot;&gt;&lt;/a&gt;方案0&lt;/h4&gt;&lt;p&gt;这并不是并发服务器，正如在[UNP]第一章入门的时间获取客户/服务器程序中所看到的，一次只能服务一个客户。服务器通过循环监听套接字等待连接，在连接建立以后处理所需的逻辑。对应到程序中，服务器和客户端都只是简单的调用socket API，完成连接和处理工作。&lt;/p&gt;
&lt;h4 id=&quot;方案1&quot;&gt;&lt;a href=&quot;#方案1&quot; class=&quot;headerlink&quot; title=&quot;方案1&quot;&gt;&lt;/a&gt;方案1&lt;/h4&gt;&lt;p&gt;这是传统的并发网络编程方案，也是[UNP]中第一个阐述的并发方案，称之为fork()-per-client或process-per-connection，即为每一个客户连接新建一个子进程(fork())，在子进程调用handler()处理客户业务，从而同时服务多个客户端。&lt;br&gt;这种方案适合并发连接数不大、计算响应的工作量远大于fork()的开销等情况，考虑到操作系统对运行服务器的用户能够同时拥有多少子进程的限制和为每个客户现场fork()一个子进程的开销。&lt;/p&gt;
&lt;h4 id=&quot;方案2&quot;&gt;&lt;a href=&quot;#方案2&quot; class=&quot;headerlink&quot; title=&quot;方案2&quot;&gt;&lt;/a&gt;方案2&lt;/h4&gt;&lt;p&gt;对方案1的优化，采用进程池，即在启动阶段预先派生一定数量的子进程，当各个客户连接到达时，这些子进程立即就能为它们服务。&lt;br&gt;这种技术的优点在于无须引入父进程执行fork()的开销就能处理新到的客户。缺点则是父进程必须在服务器启动阶段猜测需要预先派生多少子进程。[UNP]中详细的说明了该方案以及对该方案的一些修订，个人觉得最后一个修订版本是一个较好且实用的方案，即只让父进程调用accept()，然后把所接受的已连接套接字”传递给”（描述符传递）某个子进程，父进程随后关闭这个套接字，由子进程处理，父子进程之间通过管道通信。&lt;/p&gt;
&lt;h4 id=&quot;方案3&quot;&gt;&lt;a href=&quot;#方案3&quot; class=&quot;headerlink&quot; title=&quot;方案3&quot;&gt;&lt;/a&gt;方案3&lt;/h4&gt;&lt;p&gt;传统Java网络编程方案thread-per-connection，即为每个客户连接新建一个线程，由子线程调用handler()处理客户业务，从而同时服务多个客户端。&lt;br&gt;这种方案使用线程来取代子进程，所以开销要比方案1小。&lt;/p&gt;
&lt;h4 id=&quot;方案4&quot;&gt;&lt;a href=&quot;#方案4&quot; class=&quot;headerlink&quot; title=&quot;方案4&quot;&gt;&lt;/a&gt;方案4&lt;/h4&gt;&lt;p&gt;类似于方案2，对方案3中预先创建线程池，就不再赘述。&lt;/p&gt;
&lt;h3 id=&quot;《Unix网络编程》传统方案总结&quot;&gt;&lt;a href=&quot;#《Unix网络编程》传统方案总结&quot; class=&quot;headerlink&quot; title=&quot;《Unix网络编程》传统方案总结&quot;&gt;&lt;/a&gt;《Unix网络编程》传统方案总结&lt;/h3&gt;&lt;p&gt;上述几种方案都是阻塞式网络编程，程序通常会阻塞在系统调用上。比如，当一个进程/线程阻塞在读网络流的时候，但同时程序又想处理键盘输入，就麻烦了。&lt;br&gt;所以，一种常见的方法是使用IO多路复用，使用select/poll/epoll这类的多路选择器（本质是事件驱动），让一个线程能处理多个连接。IO复用其实复用的不是IO连接，而是复用线程。使用IO复用几乎肯定要配合非阻塞IO，而使用非阻塞IO肯定要使用应用层buffer。这样，就诞生了现代网络编程中以事件驱动为核心的Reactor模式，继而出现了一些通用的Reactor库/框架，比如libevent、muduo、Netty等。&lt;/p&gt;
&lt;h3 id=&quot;Reactor方案&quot;&gt;&lt;a href=&quot;#Reactor方案&quot; class=&quot;headerlink&quot; title=&quot;Reactor方案&quot;&gt;&lt;/a&gt;Reactor方案&lt;/h3&gt;&lt;h4 id=&quot;方案5&quot;&gt;&lt;a href=&quot;#方案5&quot; class=&quot;headerlink&quot; title=&quot;方案5&quot;&gt;&lt;/a&gt;方案5&lt;/h4&gt;&lt;p&gt;基本的单线程Reactor方案，使用IO复用，可以同时服务多个连接，但是由于它是单线程的，比较适合IO密集的应用，不太适合CPU密集型的应用，不能发挥多核硬件的能力。&lt;/p&gt;
&lt;h4 id=&quot;方案6&quot;&gt;&lt;a href=&quot;#方案6&quot; class=&quot;headerlink&quot; title=&quot;方案6&quot;&gt;&lt;/a&gt;方案6&lt;/h4&gt;&lt;p&gt;类似于[UNP]中的解决方案，建立客户连接后，不在Reactor线程中计算，而是创建一个新线程来计算，可以充分利用多核CPU的优势。这个方案需要考虑的是线程执行的不确定性，即同时创建多个线程去处理同一个连接上收到的多个请求，那么算出结果的次序是不确定的。此外，还有一个连接到来创建线程的开销，可以通过下述方案7中的线程池避免。&lt;/p&gt;
&lt;h4 id=&quot;方案7&quot;&gt;&lt;a href=&quot;#方案7&quot; class=&quot;headerlink&quot; title=&quot;方案7&quot;&gt;&lt;/a&gt;方案7&lt;/h4&gt;&lt;p&gt;为弥补为每个请求创建线程的缺陷，使用固定大小的线程池解决。全部的IO工作都在一个Reator线程完成，而计算任务交给线程池。这种模型适用于计算任务彼此独立，并且IO压力不大的情况。当IO的压力较大时，一个Reactor线程很可能处理不过来了，就可以考虑下方案8。&lt;/p&gt;
&lt;h4 id=&quot;方案8&quot;&gt;&lt;a href=&quot;#方案8&quot; class=&quot;headerlink&quot; title=&quot;方案8&quot;&gt;&lt;/a&gt;方案8&lt;/h4&gt;&lt;p&gt;该方案的特点是one loop per thread，如下图所示，有一个main Reactor负责accept()连接，然后把连接挂在某个sub Reactor中，这样该连接的所有操作都在sub Reactor所处的线程中完成。这是muduo和Netty内置的多线程方案。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/kccnUkP.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Reactor pool的大小(线程数)通常根据CPU数目确定，这样程序的总体处理能力不会随着连接数增加而下降。此外， 由于一个连接完全由一个线程管理，请求的顺序就有了保证。&lt;br&gt;与前面的Reactor+thread pool相比，该方案减少了进出thread pool的两次上下文切换，在把多个连接分散到多个Reactor线程之后，小规模计算可以在当前IO线程完成并返回结果，从而降低响应的延迟。&lt;/p&gt;
&lt;h4 id=&quot;方案9&quot;&gt;&lt;a href=&quot;#方案9&quot; class=&quot;headerlink&quot; title=&quot;方案9&quot;&gt;&lt;/a&gt;方案9&lt;/h4&gt;&lt;p&gt;将上述两种方案结合，既使用多个Reactor来处理IO，又使用线程池来处理计算，如下图所示。这种方案适合既有突发IO（利用多线程处理多个连接上的IO），又有突发计算的应用(利用线程池把一个连接上的计算任务分配给多个线程去做)。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2bBaThf.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;方案10&quot;&gt;&lt;a href=&quot;#方案10&quot; class=&quot;headerlink&quot; title=&quot;方案10&quot;&gt;&lt;/a&gt;方案10&lt;/h4&gt;&lt;p&gt;Reactor in processes,采用多进程实现。这是Nginx的内置方案，待后续研究Nginx的时候再详述。&lt;/p&gt;
&lt;h3 id=&quot;Reactor方案总结&quot;&gt;&lt;a href=&quot;#Reactor方案总结&quot; class=&quot;headerlink&quot; title=&quot;Reactor方案总结&quot;&gt;&lt;/a&gt;Reactor方案总结&lt;/h3&gt;&lt;p&gt;对上述Reactor模型的方案进行了简单总结，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/n4bAxFY.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中,C1和C2是根据实际情况设置的常数，与CPU数目、用户业务有关。&lt;/p&gt;
&lt;p&gt;参考: 《Linux多线程服务端编程》&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;《Unix网络编程(第三版)》(以下简称[UNP])中第三十章”客户/服务器程序设计范式”总结了一些常见的并发网络服务程序设计方案，而随着互联网、大数据等浪潮的兴起，业界对服务器程序的高并发能力、稳定性等提出了更高的要求，客户/服务器程序设计范式也在随着时代的需求而不断改进和提升，下面就对常见的并发网络服务程序设计方案作简单总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>浅谈C++值语义和对象语义</title>
    <link href="http://blog.dujiong.net/2016/05/15/cplusplus-sematics/"/>
    <id>http://blog.dujiong.net/2016/05/15/cplusplus-sematics/</id>
    <published>2016-05-15T11:29:20.000Z</published>
    <updated>2016-08-02T06:05:27.187Z</updated>
    
    <content type="html">&lt;h3 id=&quot;值语义和对象语义&quot;&gt;&lt;a href=&quot;#值语义和对象语义&quot; class=&quot;headerlink&quot; title=&quot;值语义和对象语义&quot;&gt;&lt;/a&gt;值语义和对象语义&lt;/h3&gt;&lt;p&gt;值语义(value sematics)指的是对象的拷贝与原对象无关，拷贝之后就与原对象脱离关系。C++的内置类型都是值语义，如bool/int/double等，标准库里的pair&amp;lt;&amp;gt;,vector&amp;lt;&amp;gt;,map&amp;lt;&amp;gt;，string等类型也都是值语义。Java语言的primitive types(原生数据类型)也是值语义。&lt;br&gt;与值语义(object sematics)对应的是”对象语义”，或者也叫做”引用语义”。对象语义指的是面向对象意义下的对象，对象是禁止拷贝的或拷贝后与原来的对象存在关联。比如，拷贝一个Employee对象是没有意义的，一个雇员不会变成两个雇员。同样，muduo库中的TcpConnection，显然也是不可复制的，因为牵涉到系统的资源。Java里面的class对象都是对象语义/引用语义。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;下面举Java和C++几个简单的例子看值语义和对象语义:&lt;/p&gt;
&lt;h4 id=&quot;Java&quot;&gt;&lt;a href=&quot;#Java&quot; class=&quot;headerlink&quot; title=&quot;Java&quot;&gt;&lt;/a&gt;Java&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;int a = 8;
int b = a;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的a，b都是int， 属于Java中原生数据类型，他们的特点是复制后二者再无关联。它们表现出来是两个value。&lt;br&gt;与他们形成对比的是用户自定义的class，如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Student a1 = new Student(&amp;quot;dujiong&amp;quot;, 23);
Student a2 = a1;
a2.setAge(25);    
System.out.println(a1.getAge());
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码输出为25，因为第二行语句，导致a和b指向的是同一个对象，修改a2也会影响a1，所以表现的行为是一种reference。&lt;/p&gt;
&lt;h4 id=&quot;C&quot;&gt;&lt;a href=&quot;#C&quot; class=&quot;headerlink&quot; title=&quot;C++&quot;&gt;&lt;/a&gt;C++&lt;/h4&gt;&lt;p&gt;如前所述，C++的内置类型、标准库容器如vector&amp;lt;&amp;gt;，map&amp;lt;&amp;gt;等都是值语义，C++要求凡是可以放入容器的元素都必须具备值语义，即必须具备拷贝的能力，放入标准容器的元素和之前的元素没有任何的关联。&lt;br&gt;而C++的普通类呢?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Book
{
    private:
        string isbn_;
        double price_;
        int amount_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果以下面的代码:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Book a1;
Book a2 = a1;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;那么a1和a2复制后将没有任何关联，他们的表现属于值语义。&lt;/p&gt;
&lt;h3 id=&quot;值语义与C-语言&quot;&gt;&lt;a href=&quot;#值语义与C-语言&quot; class=&quot;headerlink&quot; title=&quot;值语义与C++语言&quot;&gt;&lt;/a&gt;值语义与C++语言&lt;/h3&gt;&lt;p&gt;C++的class本质上是值语义的。C++的设计初衷是让用户定义的类型(class)能像内置类型一样工作，具有同等的地位。为此，C++做了妥协:&lt;br&gt;(1) class的layout与C struct一样，没有额外的开销，定义一个”只包含一个int成员的class”的对象开销和一个int一样。&lt;br&gt;(2) class可以在stack上创建，也可以在heap上创建。。&lt;br&gt;(3) class的data member默认都是uninitialized。&lt;br&gt;(4) class的数组是一个个class对象挨着，没有额外的indirection。&lt;br&gt;(5) 编译器为class默认生成copy constructor和assignment operator。其他语言没有copy constructor，也不允许重载assignment operator。C++的对象默认是可以拷贝的。&lt;br&gt;(6) 当class类型传入函数时，默认是make a copy(除非参数声明为reference)。&lt;br&gt;(7) 当函数返回一个class type时，只能通过make a copy(C++不得不定义RVO来解决性能问题)。&lt;br&gt;(8) 当class type为成员时，数据成员时嵌入的。&lt;br&gt;C++这样的设计带来了性能上的好处。比如在C++里定义复数类(complex&lt;double&gt;class)和其数组(array)、向量(vector)，它们的layout分别是:&lt;/double&gt;&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;http://i.imgur.com/xN0fihh.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;而如果在Java中定义同样的结构，就不一样。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/ptaBium.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Java中每个object都有header。对比Java，C++的对象模型更紧凑。&lt;/p&gt;
&lt;h3 id=&quot;值语义与生命期&quot;&gt;&lt;a href=&quot;#值语义与生命期&quot; class=&quot;headerlink&quot; title=&quot;值语义与生命期&quot;&gt;&lt;/a&gt;值语义与生命期&lt;/h3&gt;&lt;p&gt;值语义的一个巨大好处是生命期管理很简单，就像你不需要操心基本数据类型的生命期一样。值语义的对象要么是栈上对象，要么作为其他对象的成员(一个成员函数使用自己的数据成员对象)。而，对象语义由于不能拷贝，只能通过指针或引用来使用它。而一旦使用指针或引用来操作对象，那么就要担心所指的对象是否已被释放，而这也是C++ bug的主要来源。此外，C++只能通过指针或引用来获得多态，所以，在C++中进行继承和多态的面向对象编程中，资源管理成为了一大难题。            &lt;/p&gt;
&lt;h4 id=&quot;模型1&quot;&gt;&lt;a href=&quot;#模型1&quot; class=&quot;headerlink&quot; title=&quot;模型1&quot;&gt;&lt;/a&gt;模型1&lt;/h4&gt;&lt;p&gt;模型1: a Parent has a Child, a Child knows his/her Parent&lt;br&gt;Java中很好些，不用担心内存泄露，也不用担心空悬指针。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Parent{
    private Child myChild;    
}
public class Child{
    private Parent myParent;    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只要正确初始化myChild和myParent即可。&lt;br&gt;而在C++里就要为资源管理费一番脑筋:Parent 和 Child 都代表的是真人，肯定是不能拷贝的，因此具有对象语义。Parent 是直接持有 Child 吗？抑或 Parent 和 Child 通过指针互指？Child 的生命期由 Parent 控制吗？&lt;br&gt;直接但是易错的写法:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Child;
class Parent : boost::noncopyable
{
    private:
        Child* myChild;
};

class Child : boodt::noncopyable
{
    private:
        Parent* myParent;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;那么，直接使用指针作为成员，那么如何确保指针的有效性？如何防止出现空悬指针？Child 和 Parent 由谁负责释放？在释放某个 Parent 对象的时候，如何确保程序中没有指向它的指针？在释放某个 Child 对象的时候，如何确保程序中没有指向它的指针？&lt;br&gt;这一系列问题都是C++面向对象编程令人头疼的问题。现在可以使用boost智能指针解决(C++11引入,用栈上对象管理堆上对象的生命期），借助于智能指针把对象语义转换为值语义，从而解决对象生命期问题：让Parent持有Child的智能指针，同时让Child持有Parent的智能指针，这样始终引用对方的时候就不用担心出现空悬指针。当然，其中一个智能应该是weak reference，否则会出现循环引用，导致内存泄露。&lt;br&gt;所以，如果Parent拥有Child，Child的生命期由其Parent控制，Child的生命期小于Parent，那么代码：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Parent;
class Child : boost::noncopyable
{
    public:
        explicit Child(Parent* myParent) : myParent_(myParent)
        { }
    private:
        Parent* myParent_;
};
class Parent : boost::noncopyable
{
    public:
        Parent() : myChild(new Child(this))
        { }
    private:
        boost::scoped_ptr&amp;lt;Child&amp;gt; myChild;
}; 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;模型2&quot;&gt;&lt;a href=&quot;#模型2&quot; class=&quot;headerlink&quot; title=&quot;模型2&quot;&gt;&lt;/a&gt;模型2&lt;/h4&gt;&lt;p&gt;模型2: a Child has parents:mom and dad; a Parent has one or more Child; a Parent knows his/her spouser&lt;br&gt;Java描述还是很简单，垃圾收集会搞定对象生命期。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Parent{
    private Parent mySpouser;
    private ArrayList&amp;lt;Child&amp;gt; myChildren;    
}
public class Child{
    private Parent myMom;
    private Parent myDad;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;而如果用C++实现，还是需要借助于智能指针将裸指针转化为值语义。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Parent;
typedef boost::shared_ptr&amp;lt;Parent&amp;gt; ParentPtr;

class Child : boost::noncopyable
{
    public:
        explicit Child(const ParentPtr&amp;amp; myMom, const ParentPtr&amp;amp; myDad)
        : myMom_(myMom), myDad_(myDad)
        { }
    private:
        boost::weak_ptr&amp;lt;Parent&amp;gt; myMom_;
        boost::weak_ptr&amp;lt;Parent&amp;gt; myDad_;
};

typedef boost::shared_ptr&amp;lt;Child&amp;gt; ChildPtr;

class Parent :　boost::noncopyable
{
    public:
        Parent(){}
        void setSpouser(const ParentPtr&amp;amp; spouser)
        {
            mySpouser_ = spouser;
        }
        void addChild(const ChildPtr&amp;amp; child)
        {
            myChildren_.push_back(child);    
        }
    private:
        boost::weak_ptr&amp;lt;Parent&amp;gt; mySpouser_;
        std::vector&amp;lt;ChildPtr&amp;gt; myChildren_;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，如果不使用智能指针，使用C++面向对象编程，有效的资源管理将会很困难。&lt;/p&gt;
&lt;h3 id=&quot;待续&quot;&gt;&lt;a href=&quot;#待续&quot; class=&quot;headerlink&quot; title=&quot;待续&quot;&gt;&lt;/a&gt;待续&lt;/h3&gt;&lt;p&gt;对于智能指针，这里只是有一些简单的介绍，后面还将深入研究。&lt;/p&gt;
&lt;p&gt;参考: &lt;a href=&quot;http://www.cnblogs.com/Solstice/archive/2011/08/16/2141515.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/Solstice/archive/2011/08/16/2141515.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;值语义和对象语义&quot;&gt;&lt;a href=&quot;#值语义和对象语义&quot; class=&quot;headerlink&quot; title=&quot;值语义和对象语义&quot;&gt;&lt;/a&gt;值语义和对象语义&lt;/h3&gt;&lt;p&gt;值语义(value sematics)指的是对象的拷贝与原对象无关，拷贝之后就与原对象脱离关系。C++的内置类型都是值语义，如bool/int/double等，标准库里的pair&amp;lt;&amp;gt;,vector&amp;lt;&amp;gt;,map&amp;lt;&amp;gt;，string等类型也都是值语义。Java语言的primitive types(原生数据类型)也是值语义。&lt;br&gt;与值语义(object sematics)对应的是”对象语义”，或者也叫做”引用语义”。对象语义指的是面向对象意义下的对象，对象是禁止拷贝的或拷贝后与原来的对象存在关联。比如，拷贝一个Employee对象是没有意义的，一个雇员不会变成两个雇员。同样，muduo库中的TcpConnection，显然也是不可复制的，因为牵涉到系统的资源。Java里面的class对象都是对象语义/引用语义。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之Channel与Poller</title>
    <link href="http://blog.dujiong.net/2016/05/06/muduo-4/"/>
    <id>http://blog.dujiong.net/2016/05/06/muduo-4/</id>
    <published>2016-05-06T10:39:19.000Z</published>
    <updated>2016-07-21T12:50:06.928Z</updated>
    
    <content type="html">&lt;p&gt;如前所述，Reactor模式包括四个部分的组件:Handle, Synchronous Event Demultiplexer，Initiation Dispatcher和Event Handler。上一篇已经学习了muduo中的Initiation Dispatcher—EventLoop类，接下来分别讲述Handle—Channel类和Synchronous Event Demultiplexer—Poller类。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;           &lt;/p&gt;
&lt;h3 id=&quot;Channel&quot;&gt;&lt;a href=&quot;#Channel&quot; class=&quot;headerlink&quot; title=&quot;Channel&quot;&gt;&lt;/a&gt;Channel&lt;/h3&gt;&lt;p&gt;Channel类的功能类似于JAVA NIO的SelectableChannel和SelectionKey的组合。每个Channel对象自始至终只属于一个EventLoop，而根据muduo采用的one loop per thread模型，每个Channel对象都只属于某一个IO线程。每个Channel对象只负责一个文件描述符(fd)的IO事件分发，但它不拥有这个fd，也不会在析构的时候关闭这个fd。&lt;br&gt;Channel在Event Handler与Dispatcher之间起到中介的作用。一方面可与Event Handler交互，Event Hanlder设置Channel的：    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;与I/O相关的文件描述符，即成员变量fd_；     &lt;/li&gt;
&lt;li&gt;在当前Channel上感兴趣的事件(events_)，在Event Handler中通过调用Channel的enableReading()、enableWriting()函数设置；   &lt;/li&gt;
&lt;li&gt;处理各种类型事件的回调函数，相应成员变量包括readCallback_、writeCallback_、errorCallback_等，在Event Handler中通过调用Channel的接口函数setXXXCallback()等完成。&lt;br&gt;相应的代码如下(部分)。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;class Channel : boost::noncopyable
{
    public:
        ...
        void handleEvent();
        void setReadCallback(const EventCallback&amp;amp; cb)
        { readCallback_ = cb; }
        ...
        void enableReading() 
        { events_ |= kReadEvent; update(); }
        ...
        int index() { return index_; }
        EventLoop* ownerLoop() { return loop_; }

    private:    
        void update();
        static const int kReadEvent;
        ...
        EventLoop* loop_;
        int fd_;
        int events_;
        int revents_;
        int index_;
        EventCallback readCallback_;
        ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另一方面，EventLoop与Channel通信，包括以下内容:      &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Channel包含EventLoop类型的成员变量loop_，Channel在成员函数update()函数中调用loop_的成员函数updateChannel()，后者转而调用Poller::updateChannel()。   &lt;/li&gt;
&lt;li&gt;通知在当前Channel中就绪的事件。EventLoop通过Demultiplexer得到就绪Channel中发生的事件，并将其保存在成员变量revents_中。    &lt;/li&gt;
&lt;li&gt;Channel事件处理函数handleEvent()的调用。Channel::handleEvent()是Channel的核心，由EventLoop::loop()调用，Channel根据revents_的值调用Event Handler传入的相应回调函数。&lt;br&gt;所以，Channel是Event Handler与Dispatcher之间的桥梁，二者不直接通信，而是分别与Channel交互。&lt;br&gt;Channel::handleEvent()会调用Channel::handleEventWithGuard()，后者完成具体的事件处理过程。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;void Channel::handleEventWithGuard(Timestamp receiveTime)
{
    ...
    if((revents_ &amp;amp; POLLHUP) &amp;amp;&amp;amp; !(revents_ &amp;amp; POLLIN))
    {
        if(closeCallback_) closeCallback_();
    }
    if(revents_ &amp;amp; (POLLIN | POLLPRI | POLLRDHUP))
    {
        if(readCallback_) readCallback_();
    }
    if(revents_ &amp;amp; POLLOUT)
    {
        if(writeCallback_) writeCallback_();
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;函数中的POLLIN，POLLNVAL，POLLERR都是poll函数的测试条件，handleEventWithGuard()根据这些测试条件调用相应的回调函数。&lt;br&gt;最后来看一下对感兴趣事件的设置，具体来说，设置当前Channel是否关系读、写事件的发生。通过update()函数或者将Channel插入Demultiplexer，或者更新Demultiplexer中相应Channel的状态。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const int Channel::kNoneEvent = 0;
const int Channel::kReadEvent = POLLIN | POLLPRI;
const int Chennel::kWriteEvent = POLLOUT;
void enableReading() { events_ |= kReadEvent; update(); }
...
void diableAll() { events_ |= kNoneEvent; update(); }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Poller&quot;&gt;&lt;a href=&quot;#Poller&quot; class=&quot;headerlink&quot; title=&quot;Poller&quot;&gt;&lt;/a&gt;Poller&lt;/h3&gt;&lt;p&gt;Poller类是IO多路复用的封装，在muduo中是个抽象基类，因为muduo同时支持poll()和epoll()两种IO复用机制，是muduo中少有的使用到继承的模块。Poller是EventLoop的间接成员，只供其owner EventLoop在IO线程调用，其生命期与EventLoop相等。Poller并不拥有Channel，Channel在析构之前必须自己unregister(EventLoop::removeChannel()),避免空悬指针。&lt;br&gt;Poller接口很简单，主要包括三个成员函数：      &lt;/p&gt;
&lt;p&gt; &lt;code&gt;1. virtual Timestamp poll(int timeoutMs, ChannelList* activeChannels) = 0；&lt;/code&gt; &lt;/p&gt;
&lt;p&gt;poll()是Poller的核心功能，调用poll(), epoll()获得当前活动的IO事件，然后填充调用方传入的activeChannes，并返回poll()返回的时刻。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Timestamp EPollPoller::poll(int timeoutMs, ChannelList* activeChannels)
{
    int numEvents = ::epoll_wait(epollfd_,
                           &amp;amp;*events_.begin(),
                           static_cast&amp;lt;int&amp;gt;(events_.size()),
                           timeoutMs);
    ...
    if(numEvents&amp;gt;0)
    {
        fillActiveChannels(numEvents, activeChannels);
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以epoll()实现为例，fillActiveChannels()遍历找出有活动事件的fd_，把其对应的Channel填入activeChannels。 &lt;/p&gt;
&lt;p&gt;&lt;code&gt;2. virtual void updateChannel(Channel* channel) = 0；&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Poller::updateChannel()的主要功能是负责维护和更新pollfds_数组(以poll()实现为例)。添加新Channel的复杂度是O(logN)，原因是channels&lt;em&gt;对应的数据结构： &lt;code&gt;typedef std::map&amp;lt;int,Channel*&amp;gt; ChannelMap;&lt;/code&gt;，更新已有的Channel的复杂度是O(1)，因为Channel记住了自己在pollfds\&lt;/em&gt;数组中的下标，可以快速定位。  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;3. virtual void removeChannel(Channel* channel) = 0；&lt;/code&gt; &lt;/p&gt;
&lt;p&gt;Channel的删除。同样，需要更改pollfds_、channels_数据成员。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;至此，Reactor模式中最核心的事件分发机制中的关键结构已讲述完毕，对应muduo中的EventLoop，Channel，Poller三个class。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;如前所述，Reactor模式包括四个部分的组件:Handle, Synchronous Event Demultiplexer，Initiation Dispatcher和Event Handler。上一篇已经学习了muduo中的Initiation Dispatcher—EventLoop类，接下来分别讲述Handle—Channel类和Synchronous Event Demultiplexer—Poller类。&lt;br&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之EventLoop类</title>
    <link href="http://blog.dujiong.net/2016/05/03/muduo-3/"/>
    <id>http://blog.dujiong.net/2016/05/03/muduo-3/</id>
    <published>2016-05-03T13:13:47.000Z</published>
    <updated>2016-07-16T07:38:55.800Z</updated>
    
    <content type="html">&lt;p&gt;EventLoop类似于前面所述的Reactor模式中的Initiation Dispatcher，是用于驱动的主模块，完成与其他模块的调用和交互。EventLoop类提供的主要是一个框架，事件的分发由Demultiplexer提供，事件的处理由Event Handler提供，但事件的循环、怎样将事件的分发与调用结合起来则是由EventLoop类决定的。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;EventLoop继承自boost-noncopyale&quot;&gt;&lt;a href=&quot;#EventLoop继承自boost-noncopyale&quot; class=&quot;headerlink&quot; title=&quot;EventLoop继承自boost::noncopyale&quot;&gt;&lt;/a&gt;EventLoop继承自boost::noncopyale&lt;/h3&gt;&lt;p&gt;EventLoop是不可拷贝的，所以源码中继承了boost::noncopyable。boost::noncopyable的思想是把构造函数和析构函数设置成protected权限，这样子类可以调用，但是外面的类不能调用，那么当子类需要定义构造函数的时候不至于通不过编译。但是更关键的是noncopyable把复制构造函数和复制赋值函数都做成了private，这就意味着除非子类定义自己的复制构造和赋值函数，否则在子类没有定义的情况下，外面的调用者是不能够通过复制构造和赋值等手段来产生一个新的子类对象的。&lt;br&gt;one loop per thread模型意味着每个线程只能有一个EventLoop对象，因此EventLoop的构造函数会检查当前线程是否已经创建了其他EventLoop对象。EventLoop的构造函数会记住本对象所属的线程。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;EventLoop::EventLoop()    
    :looping(false),
     threadId_(CurrentThread::tid())
     ...
{
    if(t_loopInthisThread)
        LOG_FATAL &amp;lt;&amp;lt; ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Event-Hander的注册与删除&quot;&gt;&lt;a href=&quot;#Event-Hander的注册与删除&quot; class=&quot;headerlink&quot; title=&quot;Event Hander的注册与删除&quot;&gt;&lt;/a&gt;Event Hander的注册与删除&lt;/h3&gt;&lt;p&gt;在初始状态，一个EventLoop只是一个框架，其中并没有包含具体需要处理的事件及相应的资源。所以，要处理一个事件，必须要将相应的Handler信息注册到EventLoop中，muduo中，这个用于注册的函数就是EventLoop::updateChannel()。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void EventLoop::updateChannel(Channel* channel)
{
    assert(channel_-&amp;gt;ownerLoop() == this);
    asserInLoopThread();
    poller_-&amp;gt;updateChannel(channel);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;函数形参为Channel*类型，如前所述，Channel类似Reactor模式中的Handle。通过Channel类型的变量，Event Handler的相关信息被注册到了EventLoop中。具体的注册过程由形参为poller_成员变量完成，这是muduo的多路复用机制。Poller在muduo中是个抽象基类，因为muduo同时支持poll()和epoll()两种IO复用机制。Poller::updateChannel()的主要功能就是负责维护和更新pollfds数组。                                                                                                                                &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void EventLoop::removeChannel(Channel* channel)
{
    ...
    poller_-&amp;gt;removeChannel(channel);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同样，Event Handler的删除与注册很相似，具体过程也通过poller_完成。&lt;/p&gt;
&lt;h3 id=&quot;事件循环中的事件分发&quot;&gt;&lt;a href=&quot;#事件循环中的事件分发&quot; class=&quot;headerlink&quot; title=&quot;事件循环中的事件分发&quot;&gt;&lt;/a&gt;事件循环中的事件分发&lt;/h3&gt;&lt;p&gt;loop函数是EventLoop类的核心，用于事件循环的运行。在循环返回时，通过Demultiplexer获得已注册到EventLoop中Event Handler的就绪通知。然后Demultiplexer将所有就绪的事件Channel保存到容器activeChannels_中，接着一一处理其中所有activeChannel的callback。EventLoop只提供框架，对要处理的事件一无所知，Channel中包含感兴趣的事件和对事件的处理方法(注册的回调函数)。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void EventLoop::loop()
{
    while(!quit)
    {
        pollReturnTime=poller_-&amp;gt;poll(kPollTimeMs, &amp;amp;activeChannels_);
        for(ChannelList::iterator it=activeChannels_.begin();
                it!=activeChannels_.end();++it)
        {
            currentActiveChannel_ = *it;
            currentActiveChannel_-&amp;gt;handleEvent(pollReturnTime_);
        }
        doPendingFunctors();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;EventLoop在它的IO线程里执行某个用户任务回调，即EventLoop::runInLoop(const Functor&amp;amp; cb),如果用户在当前IO线程调用这个函数，回调会同步进行，如果用户在其他线程调用runInLoop()，cb会被加入队列(queueInLoop(std::move(cb)))，IO线程会被唤醒来调用Functor。唤醒IO线程传统的方法是用pipe()，IO线程始终监视此管道的readable事件，在需要唤醒的时候，其他线程往管道里写一个字节，这样IO线程就从IO复用阻塞调用中返回。而muudo中使用了Linux新增的eventfd，可以更高效的唤醒。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void EventLoop::runInLoop(Functor&amp;amp;&amp;amp; cb)
{
    if(isInLoopThread())
    {
        cb();
    }
    else
    {
        queueInLoop(std::move(cb));
    }
}
void EventLoop::queueInLoop(Functor&amp;amp;&amp;amp; cb)
{
    {
        MutexLockGuard lock(mutex_);
        pendingFunctors_.push_back(std::move(cb));
    }
    if(!isInLoopThread() || callingPendingFunctors_)
    {
        wakeup();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;几个定时运行函数&quot;&gt;&lt;a href=&quot;#几个定时运行函数&quot; class=&quot;headerlink&quot; title=&quot;几个定时运行函数&quot;&gt;&lt;/a&gt;几个定时运行函数&lt;/h3&gt;&lt;p&gt;muduo EventLoop中有三个定时函数。runAt(…)指在指定的时间调用TimerCallback, runAfter(…)指等一段时间调用TimerCallback, runEvery(…)指以固定时间间隔反复调用TimerCallbck。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TimerId EventLoop::runAt(const Timestamp&amp;amp; time, const TimerCallback&amp;amp; cb)
{
      return timerQueue_-&amp;gt;addTimer(cb, time, 0.0);
}

TimerId EventLoop::runAfter(double delay, const TimerCallback&amp;amp; cb)
{
       Timestamp time(addTime(Timestamp::now(), delay));
       return runAt(time, cb);
}

TimerId EventLoop::runEvery(double interval, const TimerCallback&amp;amp; cb)
{
       Timestamp time(addTime(Timestamp::now(), interval));
       return timerQueue_-&amp;gt;addTimer(cb, time, interval);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;muduo中的TimerQueue的公有接口很简单，只有两个函数addTimer()和cancel()，TimerQueue使用二叉搜索树，以pair&lt;timestamp,timer*&gt;为key(即使两个Timer到期时间相同，地址也必定不同)，能快速根据当前时间找到已到期的定时器，也要高效的添加和删除Timer。TimerQueue关注最早的定时器，getExpired返回所有的超时定时器列表，使用stl算法lower_bound()返回第一个值&amp;gt;=超时定时器的迭代器。&lt;/timestamp,timer*&gt;&lt;/p&gt;
&lt;h3 id=&quot;在事件循环中运行回调函数&quot;&gt;&lt;a href=&quot;#在事件循环中运行回调函数&quot; class=&quot;headerlink&quot; title=&quot;在事件循环中运行回调函数&quot;&gt;&lt;/a&gt;在事件循环中运行回调函数&lt;/h3&gt;&lt;p&gt;前面已经叙述过，EventLoop::runInLoop()用于在一个事件循环中运行回调函数。如果事件循环在当前线程中，那么可以直接运行回调函数。但如果不在当前线程，那么将回调函数放入待完成事件集合中，在loop()函数中的doPendingFunctors()完成处理。在上文中可以看到loop函数的每次while()循环在最后都会运行doPendingFunctors()。&lt;br&gt;pendingFunctors保存了待完成的事件，doPendingFunctors()函数很简单，就是顺序调用pendingFunctors各个回调函数。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;EventLoop类似于前面所述的Reactor模式中的Initiation Dispatcher，是用于驱动的主模块，完成与其他模块的调用和交互。EventLoop类提供的主要是一个框架，事件的分发由Demultiplexer提供，事件的处理由Event Handler提供，但事件的循环、怎样将事件的分发与调用结合起来则是由EventLoop类决定的。&lt;br&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之muduo的回调函数机制</title>
    <link href="http://blog.dujiong.net/2016/04/28/muduo-2/"/>
    <id>http://blog.dujiong.net/2016/04/28/muduo-2/</id>
    <published>2016-04-28T11:18:24.000Z</published>
    <updated>2016-06-28T13:55:56.861Z</updated>
    
    <content type="html">&lt;p&gt;回调是指将一段可执行的代码作为变量传给另外一部分代码，以供同步或异步调用。在Reactor模式中，在事件到来时调用相应的处理函数就是一种异步回调的过程。回调函数的实现可以由各种各样的方式。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;C语言的函数指针&quot;&gt;&lt;a href=&quot;#C语言的函数指针&quot; class=&quot;headerlink&quot; title=&quot;C语言的函数指针&quot;&gt;&lt;/a&gt;C语言的函数指针&lt;/h3&gt;&lt;p&gt;最熟悉的回调机制应该属于C语言的函数指针了。考虑一个简单的例子，实现对两个数的操作，这个操作可以是加减乘除等。&lt;br&gt;首先声明一个函数指针：           &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef int (operFunc*)(int a, int b);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个类型的函数指针可以做为参数传给用于实现两个数操作的函数，这个函数仅仅是简单的调用传入的函数指针：                                                                                  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int operation(int a, int b, operFunc func)
{
    return func(a,b);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在可以定义各种回调函数:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int add(int a, int b) 
{
    return a + b;
}
int minus(int a, int b) 
{   
    return a - b;
}
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，在调用operation()时可以根据传入回调函数的不同，实现不同的功能。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int main()
{
    int a = 4;
    int b = 2;
    std::cout &amp;lt;&amp;lt; operation(a,b,add) &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; operation(a,b,minus);
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;传统C-的回调&quot;&gt;&lt;a href=&quot;#传统C-的回调&quot; class=&quot;headerlink&quot; title=&quot;传统C++的回调&quot;&gt;&lt;/a&gt;传统C++的回调&lt;/h3&gt;&lt;p&gt;在传统的C++程序中，事件回调是通过虚函数进行的。网络库往往会定义一个或几个抽象基类，其中声明一些(纯)虚函数，使用者需要继承这些基类，并覆写这些虚函数，以获得事件回调通知。由于C++的动态绑定只能通过指针和引用实现，使用者必须把派生类（myHandler）对象的指针或引用隐士转换为基类(Handler)的指针或引用。网络库调用积累的虚函数，通过动态绑定机制实际调用的是用户在派生类中覆写的虚函数。&lt;br&gt;下面通过一段代码示例看看虚函数如何实现回调。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
class Handler    //interface
{
    public:
        virtual void say(const char* text) = 0;
};

class MyHandler : public Handler
{
    public:
        void say(const char* text)
        {
            printf(&amp;quot;hello,%s&amp;quot;,text);
        }    
};

int main()
{
    Handler *handler;
    MyHandler myHandler;
    handler = dynamic_cast&amp;lt;Hander*&amp;gt;(myHandler);
    handler.say(&amp;quot;world&amp;quot;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;muduo采用的事件回调&quot;&gt;&lt;a href=&quot;#muduo采用的事件回调&quot; class=&quot;headerlink&quot; title=&quot;muduo采用的事件回调&quot;&gt;&lt;/a&gt;muduo采用的事件回调&lt;/h3&gt;&lt;p&gt;muduo使用的是boost库的boost::function和boost::bind实现函数回调。现在，已经可以在c++11中使用它们。&lt;br&gt;boost::function类似于函数指针的封装，boost::function类型的变量可以保存一个可以调用的函数指针。可以指向任何函数，包括成员函数。所以boost::function与boost::bind结合起来使用可以实现一些函数指针无法完成的功能，比如，绑定特定变量到函数上，实现某些函数式编程语言的功能，甚至是真正的闭包。&lt;br&gt;以下的例子均使用c++11。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;functional&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;iostream&amp;gt;

namespace
{
    void function(int number, float floation, std::string string)
    {
        std::cout &amp;lt;&amp;lt; &amp;quot;Int: \&amp;quot;&amp;quot; &amp;lt;&amp;lt; number &amp;lt;&amp;lt; &amp;quot;\&amp;quot; Float: \&amp;quot;&amp;quot; &amp;lt;&amp;lt; floatation
                  &amp;lt;&amp;lt; &amp;quot;\&amp;quot; String: \&amp;quot;&amp;quot; &amp;lt;&amp;lt; string &amp;lt;&amp;lt; &amp;quot;\&amp;quot;&amp;quot; &amp;lt;&amp;lt; std::endl; 
    }
}

int main()
{
    //declare function pointer variables 
    std::function&amp;lt;void(std::string, float, int)&amp;gt; shuffleFunction;
    std::function&amp;lt;void(void)&amp;gt; voidFunction;
    std::function&amp;lt;void(float)&amp;gt; reduceFunction;

    //bind the method
    shuffleFunction = std::bind(::function,_3,_2,_1);
    voidFunction = std::bind(::function, 5,5.f, &amp;quot;five&amp;quot;);
    reduceFunction = std::bind(::function, 13, _1, &amp;quot;empty&amp;quot;);

    //call
    shuffleFunction(&amp;quot;String&amp;quot;,0.f,0);
    voidFunction();
    reduceFunction(13.f);

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;传统的指向成员函数的回调函数用法如下例。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class A
{
    public:
        int add(int a, int b)
        {
            std::cout &amp;lt;&amp;lt; &amp;quot;A::add()&amp;quot; &amp;lt;&amp;lt; endl
            return a + b;
        }
}；
typedef int (A::*operFunc)(int, int);
int main(void)
{
    operFunc oper = &amp;amp;A::add;
    A ca;
    int a = 2;
    int b = 3;
    int res = (ca.*oper)(a, b);
    std::cout &amp;lt;&amp;lt; res &amp;lt;&amp;lt; std::endl;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;成员函数具有隐含的this指针，在调用成员函数时必须通过类的实例。所以成员函数指针变量不仅在定义时有特殊的语法，更重要的是在实际调用回调函数必须采用(a.*oper)(a,b)这样的形式。这样的语法比较复杂，由于与非成员函数的声明不同，无法传入同一个函数。所以，需要调用函数既能接收成员函数又能接收非成员函数。&lt;br&gt;这就是在muduo库中广泛应用的function和bind的机制，如下示例代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class A
{
    ...
}；
typedef std::function&amp;lt;int(int,int)&amp;gt; operFunc;
int main()
{
    int a = 2;
    int b = 4;
    operFunc oper;
    A ca;
    oper = std::bind(&amp;amp;A::add, &amp;amp;ca, _1, _2);
    std::out &amp;lt;&amp;lt; operation(a,b,oper) &amp;lt;&amp;lt; std::endl;
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;muduo使用function和bind实现了闭包的功能，即，函数+引用环境，或者说是附有数据的行为，因为，在事件到来时调用回调函数处理，通常还需要知道其他的一些信息，比如在网络程序中，可能是连接当前的状态等。&lt;br&gt;在muduo中，一个回调函数通常是一个类的成员函数，所以这个回调函数同时也保存了某个类实例的信息，包括这个类的成员变量、成员函数等，在实际调用函数的时候就可以使用这些信息和状态，这样的处理当时让程序的编写显得非常清晰和方便。    &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;回调是指将一段可执行的代码作为变量传给另外一部分代码，以供同步或异步调用。在Reactor模式中，在事件到来时调用相应的处理函数就是一种异步回调的过程。回调函数的实现可以由各种各样的方式。&lt;br&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
</feed>
