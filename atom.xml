<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一期一会</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.dujiong.net/"/>
  <updated>2016-10-25T07:29:30.196Z</updated>
  <id>http://blog.dujiong.net/</id>
  
  <author>
    <name>dujiong</name>
    <email>dujiong.uestc@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>C++ STL之vector</title>
    <link href="http://blog.dujiong.net/2016/10/25/STL-vector/"/>
    <id>http://blog.dujiong.net/2016/10/25/STL-vector/</id>
    <published>2016-10-25T10:42:24.000Z</published>
    <updated>2016-10-25T07:29:30.196Z</updated>
    
    <content type="html">&lt;p&gt;“用C++开发，尽量用容器类+迭代器来代替数组+指针，因为数组+指针容易越界，或者内存泄露，而容器+迭代器已将底层封装好，使用安全简单”。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;vector是序列式容器里使用最广泛的容器之一，该容器被用来改善数组的缺点，vector是一个动态空间，随着元素的加入，它的内部机制会自行扩充以容纳新元素，因此，vector的运用对于内存的合理利用和灵活性都有很大的帮助，再也不必因为害怕空间不足一开始就配置一个大容量数组了。&lt;br&gt;所以，vector的实现技术，关键在于其对大小的控制以及重新配置时的数据移动效率。下面就一起详细地看看vetcor的设计。     &lt;/p&gt;
&lt;h3 id=&quot;vector成员变量&quot;&gt;&lt;a href=&quot;#vector成员变量&quot; class=&quot;headerlink&quot; title=&quot;vector成员变量&quot;&gt;&lt;/a&gt;vector成员变量&lt;/h3&gt;&lt;p&gt;vector的成员变量比较简单，主要由空间配置器和三个迭代器组成，三个迭代器分别指向目前使用空间的头、尾合目前可用空间的尾。其源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;   
class vector{
public:
    typedef T value_type;
    typedef value_type* pointer;
    typedef value_type* iterator;    //vector的迭代器是普通指针
    ...
protected:
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;

    iterator start;
    iterator finish;
    iterator end_of_storage;
...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;vector提供以下函数用于获取相关成员变量。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iterator begin() { return start; }
iterator end() { return finish; }

//返回vector当前对象的个数
size_type size() const { return size_type(end()-begin()); }
//返回目前可用空间的大小
size_type capacity() const { return size_type(end_of_storage-end()); }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;vector的构造函数&quot;&gt;&lt;a href=&quot;#vector的构造函数&quot; class=&quot;headerlink&quot; title=&quot;vector的构造函数&quot;&gt;&lt;/a&gt;vector的构造函数&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;vector() : start(0), finish(0), end_of_storage(0) { }
vector(size_type n, const T&amp;amp; value) { fill_initialize(n, value); }
vector(int n, const T&amp;amp; value) { fill_initialize(n, value); }
vector(long n, const T&amp;amp; value) { fill_initialize(n, value); }
explicit vector(size_type n) { fill_initialize(n, T()); }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;除了默认构造函数，四个带参构造函数都调用&lt;code&gt;fill_initialize(size_type n, const T&amp;amp; value)&lt;/code&gt;，这个函数调用&lt;code&gt;iterator allocate_and_fill(size_type n, const T&amp;amp; x)&lt;/code&gt;配置空间，并填充数据(&lt;code&gt;uninitialized_fill_n(size_type n, const T&amp;amp; x)&lt;/code&gt;)，并设置vector的三个迭代器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void fill_initialize(size_type n, const T&amp;amp; value){
    start = allocate+_and_fill(n, value);
    finish =  start + n;
    end_of_storage = finish;
}

iterator allocate_and_fill(size_type n, const T&amp;amp; x){
    iterator result = data_allocator::allocate(n);    //分配n个sizeof(T)大小的内存
    uninitialized_fill_n(result, n, x);        //全局函数，填充数据
    return result;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;uninitialized_fill_n是STL的内存基本处理函数，用于在申请的内存上填充数据，存放在stl_uninitialized.h中。该函数的逻辑是，首先萃取出迭代器result的value type，然后判断该型别是否为POD型别，POD指Plain Old Data，也就是标量型别或传统的C struct型别。POD型别必然拥有trival constructor/default constructor/copy/assignment函数，因此，可以对POD型别采用最有效率的初值填写手法，而对non-POD型别采取最保险的做法。&lt;br&gt;相关代码如下：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;
inline ForwardIterator uninitialized_fill_n(ForwardIterator first, 
                                                Size n, const T&amp;amp; x) {
      return __uninitialized_fill_n(first, n, x, value_type(first));
}

template &amp;lt;class ForwardIterator, class Size, class T, class T1&amp;gt;
inline ForwardIterator __uninitialized_fill_n(ForwardIterator first, 
                                                Size n, const T&amp;amp; x, T1*) {
    typedef typename __type_traits&amp;lt;T1&amp;gt;::is_POD_type is_POD;
      return __uninitialized_fill_n_aux(first, n, x, is_POD());                                
}

template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;    
inline ForwardIterator __uninitialized_fill_n_aux(ForwardIterator first, Size n, 
                                                const T&amp;amp; x, __true_type) {
      return fill_n(first, n, x);            //POD类型，直接用fill_n填充即可
}

template &amp;lt;class ForwardIterator, class Size, class T&amp;gt;
ForwardIterator __uninitialized_fill_n_aux(ForwardIterator first, Size n,
                                                   const T&amp;amp; x, __false_type) {
      ForwardIterator cur = first;
      __STL_TRY {
        for ( ; n &amp;gt; 0; --n, ++cur)
              construct(&amp;amp;*cur, x);    //调用构造函数，这里用的是placement new来构造
        return cur;
      }
      __STL_UNWIND(destroy(first, cur));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同样的，在复制构造函数中，也是先分配内存，然后根据是否为POD型别调用不同的复制函数。    &lt;/p&gt;
&lt;h3 id=&quot;vector的析构函数&quot;&gt;&lt;a href=&quot;#vector的析构函数&quot; class=&quot;headerlink&quot; title=&quot;vector的析构函数&quot;&gt;&lt;/a&gt;vector的析构函数&lt;/h3&gt;&lt;p&gt;vector的析构函数比较简单，先析构[start, finish)，然后归还内存。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~vector() {
    destory(start, finish);
    deallocate();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同构造函数类似，destroy函数根据数据类型，如果是POD，则什么都不做，如果不是POD型别，则调用析构函数一个一个的析构。然后调用deallocate函数归还内存,如果大于128bytes，则归还给系统，小于128bytes，则还给内存池，后面还可使用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void deallocate() {
    if(start) data_allocator::deallocate(start, end_of_storage-start);
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;vector常用操作函数&quot;&gt;&lt;a href=&quot;#vector常用操作函数&quot; class=&quot;headerlink&quot; title=&quot;vector常用操作函数&quot;&gt;&lt;/a&gt;vector常用操作函数&lt;/h3&gt;&lt;h4 id=&quot;push-back&quot;&gt;&lt;a href=&quot;#push-back&quot; class=&quot;headerlink&quot; title=&quot;push_back&quot;&gt;&lt;/a&gt;push_back&lt;/h4&gt;&lt;p&gt;当我们以push_back()将新元素插入于vector尾端时，该函数首先检查是否还有备用空间，如果有，就直接在备用空间上构造函数，并调整迭代器finish，使vetcor变大，如果没有，就扩充空间（重新配置、移动数据、释放原空间）。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void push_back(const T&amp;amp; x){
    if(finish != end_of_storage){
        construct(finish, x);
        ++finish;        
    }else{
        insert_aux(end(), x);            //已无备用空间
    }
}

template &amp;lt;class T, class Alloc&amp;gt;
void vector&amp;lt;T, Alloc&amp;gt;::insert_aux(iterator position, const T&amp;amp;x){
    if(finish != end_of_storage){
        construct(finish, *(finish-1));    
        ++finish;
        T x_copy = x;
        copy_backward(position, finish-2, finish-1);
        *position = x_copy;
    }else{
        const size_type old_size = size();
        const size_type len = old_size!=0 ? 2 * old_size : 1;
        iterator new_start = data_Allocator::allocate(len);
        iterator new_finish = new_start;

        try{
            new_finish = uninitialized_copy(start, position, new_start);
            construct(new_finish, x);
            ++new_finish;
            new_finish = uninitialized_copy(position, finish, new_finish);
        }catch(...){
            destroy(new_start, new_finish);
            data_allocator::deallocate(new_start, len);
            throw;
        }

        destroy(begin(), end());        //析构
        deallocate();                    //释放原来的内存
        //调整三个迭代器
        start = new_start;
        finish = new_finish;
        end_of_storage = new_start + len;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;erase&quot;&gt;&lt;a href=&quot;#erase&quot; class=&quot;headerlink&quot; title=&quot;erase&quot;&gt;&lt;/a&gt;erase&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;iterator erase(iterator first, iterator last){
    iterator i = copy(last, finish, first);
    destroy(i, finish);
    finish = finish-(last-first);
    return first;
}

iterator erase(iterator position){
    if(position+1 != end()){
        copy(position+1, finish, position);
    }
    --finish;
    destroy(finish);
    return position;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以，调用erase()函数时，size()会变化，而capacity()不会发生变化。可以看出，erase()函数会涉及到元素的移动，可能会导致原有的迭代器失效，使用时需要注意。此外，remove()和erase()的区别：remove只是将待删除元素移动到vector的尾端，不是删除，erase才是真正的删除元素。一定不要误用。&lt;/p&gt;
&lt;h4 id=&quot;其他&quot;&gt;&lt;a href=&quot;#其他&quot; class=&quot;headerlink&quot; title=&quot;其他&quot;&gt;&lt;/a&gt;其他&lt;/h4&gt;&lt;p&gt;另外，还有一些常用的函数操作，如pop_back(), clear(), insert()等，这里就不再逐一介绍，方法和原理都和上述差不多，在日常编程中多使用，自然就熟了。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;“用C++开发，尽量用容器类+迭代器来代替数组+指针，因为数组+指针容易越界，或者内存泄露，而容器+迭代器已将底层封装好，使用安全简单”。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>字符串的排列与组合</title>
    <link href="http://blog.dujiong.net/2016/10/23/permutation/"/>
    <id>http://blog.dujiong.net/2016/10/23/permutation/</id>
    <published>2016-10-23T11:09:33.000Z</published>
    <updated>2016-10-21T14:09:27.309Z</updated>
    
    <content type="html">&lt;p&gt;很久没有深入研究数据结构和算法了…&lt;br&gt;这次换个套路，先不说那些干瘪瘪的理论，首先来看一道编程题。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h3 id=&quot;题目描述&quot;&gt;&lt;a href=&quot;#题目描述&quot; class=&quot;headerlink&quot; title=&quot;题目描述&quot;&gt;&lt;/a&gt;题目描述&lt;/h3&gt;&lt;p&gt;编写一个方法，确定某字符串的所有排列组合。&lt;br&gt;给定一个string A[]和一个int n，代表字符串和其长度，请返回所有该字符串字符的排列，保证字符串长度小于等于11且字符串中字符均为大写英文字符，排列中的字符串按字典序从大到小排序。&lt;br&gt;样例： “ABC”&lt;br&gt;返回：[“CBA”,”CAB”,”BCA”,”BAC”,”ACB”,”ABC”]&lt;/p&gt;
&lt;h3 id=&quot;思考&quot;&gt;&lt;a href=&quot;#思考&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h3&gt;&lt;p&gt;…&lt;/p&gt;
&lt;h3 id=&quot;分析&quot;&gt;&lt;a href=&quot;#分析&quot; class=&quot;headerlink&quot; title=&quot;分析&quot;&gt;&lt;/a&gt;分析&lt;/h3&gt;&lt;h4 id=&quot;next-permutation&quot;&gt;&lt;a href=&quot;#next-permutation&quot; class=&quot;headerlink&quot; title=&quot;next_permutation&quot;&gt;&lt;/a&gt;next_permutation&lt;/h4&gt;&lt;p&gt;很容易看出来这是一道排列的问题。由于自己最近对STL甚是着迷，却又没有掌握透彻，故先写出了下面的错误代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vector&amp;lt;string&amp;gt; getPermutation(string A){
    std::sort(A.begin(), A.end());
    vector&amp;lt;string&amp;gt; ret;
    do{
        ret.push_back(A);
    }while(next_permutation(A.begin(), A.end()));
    std::sort(ret.begin(), ret.end(), greater&amp;lt;string&amp;gt;());
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当我满怀欣喜地提交代码运行时，却被告知通过率只有13.3%，给出的错误分析表明，当字符串中含有两个及以上的相同字符时，所得结果错误，即原题的意思是字符串中的每一个字符都是独立的，即使它们相同。所以，得出的结果应该有n!个字符串。而算法next_permutation不能处理这样的情况。比如输入”AAB”，使用next_permutation得到的结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/40N1AVT.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;递归&quot;&gt;&lt;a href=&quot;#递归&quot; class=&quot;headerlink&quot; title=&quot;递归&quot;&gt;&lt;/a&gt;递归&lt;/h4&gt;&lt;p&gt;递归方法的思想很容易理解，即从串中依次选出每一个元素，作为排列的第一个元素，然后对剩余的元素递归的进行全排列。&lt;br&gt;以对字符串”abc”进行全排列为例：&lt;br&gt;（1）固定a，求后面bc的排列：abc、acb，求好后，b放在第一位置，得到bac；&lt;br&gt;（2）固定b，求后面ac的排列：bac、bca，求好后，c放在第一位置，得到cba；&lt;br&gt;（3）固定c，求后面ba的排列，cba、cab。&lt;br&gt;其过程如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/iqS7F6D.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;分析了算法思想后，就很容易写出代码了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void getPermutation(vector&amp;lt;string&amp;gt;&amp;amp; ret, string A, int start){
    int end = A.size()-1;
    if(start == end){
        ret.push_back(A);
        return;
    }else{
        for(int j=start; j&amp;lt;=end; ++j){
            std::swap(A[start], A[j]);        //轮流固定在第一个位置
            getPermutation(ret, A, start+1);
            std::swap(A[start], A[j]);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行上面的例子，结果如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/aVKXDCF.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;所以，其实STL算法next_permutation是去掉了重复的全排列。&lt;/p&gt;
&lt;h3 id=&quot;组合&quot;&gt;&lt;a href=&quot;#组合&quot; class=&quot;headerlink&quot; title=&quot;组合&quot;&gt;&lt;/a&gt;组合&lt;/h3&gt;&lt;p&gt;如果不是求字符的所有排列，而是求其所有组合呢？比如字符a、b、c，它们的组合有a,b,c,ab,ac,bc,abc。    &lt;/p&gt;
&lt;h4 id=&quot;基于位图的算法&quot;&gt;&lt;a href=&quot;#基于位图的算法&quot; class=&quot;headerlink&quot; title=&quot;基于位图的算法&quot;&gt;&lt;/a&gt;基于位图的算法&lt;/h4&gt;&lt;p&gt;简单的数学知识：假设原有n个字符，则最终组合结果是2^n-1个。采用位操作：假设有元素a、b、c三个，规定二进制1表示取该元素，0表示不取。故取a的二进制表示为001，ab为001，依次类推，000没有意义。&lt;br&gt;所以，这些结果与位图的对应关系：&lt;br&gt;001, 010, 011, 100, 101, 110, 111&lt;br&gt;a, b, ab, c, ac, bc, abc&lt;br&gt;因此，可以循环1~2^n-1，然后输出对应代表的组合即可。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Combination(string A){
    int n=1&amp;lt;&amp;lt;A.size();
    for(int i=1;i&amp;lt;n;++i){
        for(int j=0;j&amp;lt;A.size();++j){
            if((1&amp;gt;&amp;gt;j)&amp;amp;i)        //对应位上为1，则输出对应的字符
                cout &amp;lt;&amp;lt; A[j];
        }                        //每一个组合
        cout &amp;lt;&amp;lt; endl;
    }
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码运行结果如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/hJmuKDD.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;很久没有深入研究数据结构和算法了…&lt;br&gt;这次换个套路，先不说那些干瘪瘪的理论，首先来看一道编程题。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL仿函数</title>
    <link href="http://blog.dujiong.net/2016/10/21/STL-functor/"/>
    <id>http://blog.dujiong.net/2016/10/21/STL-functor/</id>
    <published>2016-10-21T12:10:17.000Z</published>
    <updated>2016-10-18T12:10:54.242Z</updated>
    
    <content type="html">&lt;p&gt;仿函数，又称为函数对象，即一种具有函数特质的对象，指的是那些可以被传入其他函数或是从其他函数返回的函数。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;函数指针与函数对象&quot;&gt;&lt;a href=&quot;#函数指针与函数对象&quot; class=&quot;headerlink&quot; title=&quot;函数指针与函数对象&quot;&gt;&lt;/a&gt;函数指针与函数对象&lt;/h3&gt;&lt;p&gt;我们知道，STL所提供的各种算法，往往有两个版本，其中一个版本表现出最常用（或最直观）的某种运算，第二个版本则表现出最泛化的演算流程，允许用户“以template参数来指定所要采取的策略”。以accumulate()为例，其第一版本是将指定范围内的所有元素相加，第二版本则允许你指定某种“操作”，取代第一版本的“相加”行为。所以，要将某种“操作”当做算法的参数，首先想到的办法就是先将该“操作”设计为一个函数，再将函数指针当做算法的一个参数；或者将该“操作”设计为一个仿函数（语言层面而言是个class），再以该仿函数产生一个对象，并以此对象作为算法的一个参数。      下面通过一个实际的例子说明这两种方法。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;

using namespace std;

int add_func(int a, int b){
    return a+b;
}

class AddClass{
public:
       int operator()(int a, int b) { return a+b; }
};

typedef int (*AddFunction)(int a, int b);

int main()
{
    {
        AddClass addClass;
        int sum = addClass(1,2);
        cout &amp;lt;&amp;lt; &amp;quot;addClass: &amp;quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    }

    {
        AddFunction addFunction = &amp;amp;add_func;
        int sum = addFunction(1,2);
        cout &amp;lt;&amp;lt; &amp;quot;addFunction: &amp;quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，函数对象实际上就是一个重载了operator()操作符的类，这就是函数对象与普通类的差别。另外，函数对象和函数指针在定义的方式不一样，但是调用的方式是一样的。那既然已经有了函数指针这个东西，为什么还要发明函数对象呢？其实很简单，函数对象可以将附加数据保存在成员变量中，从而实现携带附加数据，而函数指针就不行了。考虑下面一个应用场景，我们需要使用std::for_ecah将一个std::vector中的每一个值加上某个值然后输出，如果使用普通函数，则其声明应该为&lt;code&gt;void add_num(int value, int num);&lt;/code&gt;，其中value为容器中的元素，num为要加上的数。但是由于std::for_each函数的第三个参数要求传入接受一个参数的函数或函数对象，所以将add_num函数传入std::for_each是错误的，然而函数对象可以携带附加数据解决这个问题。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;algorithm&amp;gt;

using namespace std;

class Add
{
    public:
        void operator()(int value){
            cout &amp;lt;&amp;lt; value + num_ &amp;lt;&amp;lt; endl;
        }
    private:
        int num_;
}；

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    Add add(2);
    std::for_each(ivec.begin(), ivec.end(), add);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;仿函数的型别&quot;&gt;&lt;a href=&quot;#仿函数的型别&quot; class=&quot;headerlink&quot; title=&quot;仿函数的型别&quot;&gt;&lt;/a&gt;仿函数的型别&lt;/h3&gt;&lt;p&gt;仿函数的相应型别主要用来表现函数参数型别和传回值型别。为了方便起见，&lt;stl\_function.h&gt;定义了两个classes，分别代表一元仿函数和二元仿函数（STL不支持三元仿函数），其中没有任何data members或member functions，唯有一些型别定义，任何仿函数，只要依个人需求选择继承其中一个class，便自动拥有了那些相应型别，也就自动拥有了配接能力。&lt;br&gt;unary_function和binary_function分别用来呈现一元和二元函数的参数型别和返回值型别。用户可以继承它们，从而定义自己的仿函数。   &lt;/stl\_function.h&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct negate : public unary_function&amp;lt;T,T&amp;gt; {
    T operator() (const T&amp;amp; x) const { return -x; }
}

template &amp;lt;class T&amp;gt;
struct plus : public binary_function&amp;lt;T,T,T&amp;gt; {
    T operator() (const T&amp;amp; x, const T&amp;amp; y) const { return x + y; }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;STL仿函数的分类，若以操作数的个数划分，可分为一元和二元仿函数，若以功能划分，可分为算术运算、关系运算和逻辑运算三大类。     &lt;/p&gt;
&lt;h3 id=&quot;lambda&quot;&gt;&lt;a href=&quot;#lambda&quot; class=&quot;headerlink&quot; title=&quot;lambda&quot;&gt;&lt;/a&gt;lambda&lt;/h3&gt;&lt;p&gt;lambda是C++11中引入的新特性，使程序员能定义匿名对象，而不必定义独立的函数和函数对象，这样使代码更容易编写和理解，又能防止别人的访问(调用)。简而言之，一个lambda函数是一个可以内联在代码中的函数，且通常也会传递给另外的函数（类似于仿函数）。&lt;br&gt;下面用lambda来重写上面的for_each例子。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;algorithm&amp;gt;

using namespace std;    

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    std::for_each(ivec.begin(), ivec.end(),
                  [](int x) { cout &amp;lt;&amp;lt; x + x &amp;lt;&amp;lt; endl; });
    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;lambda表达式&lt;code&gt;[] (int x) { cout &amp;lt;&amp;lt; x + 2 &amp;lt;&amp;lt; endl; }&lt;/code&gt;会让编译器产生一个类似前面例子中Add的未命名函数对象类。相比于函数对象类，lambda表达式具有如下优点：（1）简洁，不需要自己去实现函数对象类；（2）不会为临时的使用而引入新的名字，所以不会导致名字污染；（3）函数对象类名不如它的实际代码表达能力强，把代码放在更靠近它的地方将提高代码的清晰度。    &lt;/p&gt;
&lt;h3 id=&quot;std-function&quot;&gt;&lt;a href=&quot;#std-function&quot; class=&quot;headerlink&quot; title=&quot;std::function&quot;&gt;&lt;/a&gt;std::function&lt;/h3&gt;&lt;p&gt;lambda产生的闭包类型可以转换成std::function。std::function对象是对C++中现有的可调用实体的一种类型安全的包裹。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;functional&amp;gt;
#include &amp;lt;algorithm?
#include &amp;lt;vector&amp;gt;

using namespace std;

int main()
{
    vector&amp;lt;int&amp;gt; ivec;
    ivec.push_back(1);
    ivec.push_back(2);
    ivec.push_back(3);

    std::function&amp;lt;void(int)&amp;gt; func = [](int val) { std::cout &amp;lt;&amp;lt; val+2 &amp;lt;&amp;lt; endl; }
    std::for_each(ivec.begin(), ivec.end(), func);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;std::function是个类模板，可以对函数（普通函数、成员函数）、lambda表达式、std::bind的绑定表达式、函数对象等进行封装。std::function的实例可以对这些封装的目标进行存储、复制和调用等操作。  &lt;/p&gt;
&lt;h3 id=&quot;std-bind&quot;&gt;&lt;a href=&quot;#std-bind&quot; class=&quot;headerlink&quot; title=&quot;std::bind&quot;&gt;&lt;/a&gt;std::bind&lt;/h3&gt;&lt;p&gt;函数模板std::bind能对普通函数、成员函数、静态成员函数、公共成员变量、公共静态成员变量等进行包装，调用std::bind的包装相当与将函数名和参数绑定在函数内部。std::bind函数模板返回的函数对象的类型是不确定的，但是可以存储在std::function内。std::bind绑定的参数是通过传值的方式传递的，如果需要通过引用传递则参数先需要用std::ref、std::cref进行引用，然后在传递给std::bind 将std::bind函数模板的返回值保存在std::function后，调用时需要传递的参数个数由std::bind中的占位符（std::placeholders::1、std::placeholders::2、std::placeholders::_3等）个数决定，即有几个占位符调用时就需要几个参数。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;functional&amp;gt;

using namespace std;

int testFunc(int a, char c, float f){
    cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; f &amp;lt;&amp;lt; endl;

    return a;
}

int main()
{
    auto bindFunc1 = std::bind(testFunc, std::placeholders::_1, &amp;apos;A&amp;apos;, 100.1);
    bindFunc1(10);

    auto bindFunc2 = std::bind(testFunc, std::placeholders::_1, std::placeholders::_1, 100.1);
    bindFunc2(&amp;apos;B&amp;apos;, 10);

    auto bindFunc3 = bind(TestFunc, std::placeholders::_2, std::placeholders::_3, std::placeholders::_1);
    bindFunc3(100.1, 30, &amp;apos;C&amp;apos;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;本文从STL functor开始，研究了那些可以被传入其他函数或是从其他函数返回的函数，包括函数指针、函数对象、lambda、function和bind。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;仿函数，又称为函数对象，即一种具有函数特质的对象，指的是那些可以被传入其他函数或是从其他函数返回的函数。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Data Center Bridging</title>
    <link href="http://blog.dujiong.net/2016/10/18/DataCenterBridging/"/>
    <id>http://blog.dujiong.net/2016/10/18/DataCenterBridging/</id>
    <published>2016-10-18T04:34:17.000Z</published>
    <updated>2016-10-18T07:14:35.762Z</updated>
    
    <content type="html">&lt;p&gt;最近，在参与一个数据中心-云存储的项目，用到了DCB（Data Center Bridging，数据中心桥接）协议。现将学到的相关知识总结出来，以供同行交流，同时加深自己的理解。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;在企业中，传统数据中心通常会使用不同的技术来实现不同数据流量的传输，例如LAN（Local Area Network，以太网）技术用来实现IP流量的传输，SAN（Storage Area Network，存储网络）技术用来实现光纤通道存储流量的传输，除此之外，还会用InifiniBand技术来为高性能集群计算提供支持。此时，虽然通过不同的技术解决了数据中心业务需求，但是以上技术的结合使用也导致了企业将面临如下问题，并且随着数据中心规模的逐步增大，问题的严重性也日益增加；首先存在服务器兼容问题，不同的服务器需要多个专用适配器，同时也需要不同的布线系统；其次是设备统一管理问题，由于多套网络无法统一管理，因此需要不同的维护人员，这将导致设备的部署、配置、管理都会很困难。最后是设备成本问题，以上技术的结合使用导致机房需要支持更多的设备，随之而来的则是服务器的电费预算将上升，并且对于服务器的制冷要求也会增加。&lt;br&gt;以上只是硬件问题，不同的技术在满足QoS（Quality of Service，服务质量）的需求上也存在较大差异。例如，LAN流量允许丢包，只需要设备提供尽力而为的服务，丢包和乱序问题则由两端的主机来处理，不需要网络节点做过多的干预；SAN流量对丢包敏感，且要求报文在传输过程中是有序的；IPC（Inter-Process Communication，进程间通信）则对低延时要求很高。&lt;br&gt;多网融合是解决上述问题的方向，即将采用多种技术的网络整合成统一技术的网络。而随着以太网IP技术的高速发展，使用以太网来统一承载上述各种流量在数据中心得到了广泛应用；此外，为了进一步满足各种流量（尤其是SAN流量）的QoS需求，在传统以太网的基础上产生了DCB协议。&lt;br&gt;DCB协议是一组由IEEE 802.1工作组定义的以太网增强协议，广泛应用于现有的数据中心网络中。DCB协议充分利用了传统以太网的优势，通过增添多种关键扩展功能来为数据中心网络提供无损数据传输、低延时和物理链路带宽共享的功能。DCB协议的主要特性有：PFC（Priority-based Flow Control，基于优先级的流量控制）、ETS（Enhanced Transmission Selection，增强流量选择）、DCBX（Data Center Bridging Capabilities Exchange Protocol，数据中心桥接交换协议）和ECN（Explicit Congestion Notification，显示拥塞通告）。 &lt;/p&gt;
&lt;h3 id=&quot;PFC&quot;&gt;&lt;a href=&quot;#PFC&quot; class=&quot;headerlink&quot; title=&quot;PFC&quot;&gt;&lt;/a&gt;PFC&lt;/h3&gt;&lt;p&gt;PFC是一种对IEEE802.3定义的流控机制的增强技术，主要用于消除链路阻塞而导致的丢包。PFC属于DCB的一部分，适用于DCB网络中点到点的全双工链路。在传统的以太网流控机制中，当下游设备发现接收能力小于上游设备的发送能力时，会主动发一个Pause帧给上游设备，要求暂停流量的发送，上游设备等待一定时间后再继续发送数据。此时虽然能够解决流控问题，但是该机制是将链路上所有的流量都暂停，即流量暂停是针对整个接口，这与数据中心的链路共享机制发生了冲突。因为链路共享机制有两个要求：（1）一种类型的突发流量不能影响其他类型流量的转发；（2）一种类型的流量大量积压在队列中不能抢占其他类型的流量的缓存资源。所以，为了解决现有以太网流控机制和链路共享之间的冲突，产生了PFC机制。&lt;br&gt;PFC是一种基于优先级的流量控制机制。PFC可以在一条以太网物理链路上创建8个独立的虚拟通道，并为每条虚拟通道指定一个优先等级，允许单独暂停和重启其中任意一条虚拟通道，同时不影响其他通道的流量。其工作机制如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/1HVTK7q.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Device A发送接口分成了8个优先级队列，Device B接收接口分成了8个接收缓存，两者一一对应。当Device B的端口上某个接收缓存即将产生拥塞时，向Device A发送一个反压信号“STOP”，Device A收到该信号后停止发送对应优先级队列的报文。“反压信号”实际上就是PFC帧，其具体报文格式如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/PKAQ8Df.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;报文中各字段的定义如下表所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/yddhfp4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;由此可见，PFC机制下流量暂停只针对某一个或几个优先级队列，不针对整个端口进行中断。这样将会使得每个队列都能单独进行暂停或重启，而不影响其他队列上的流量，从而实现了多种流量对链路的共享。而对于非PFC控制的优先级队列，系统则不进行反压处理，在发生拥塞时直接丢弃报文。&lt;/p&gt;
&lt;h3 id=&quot;ETS&quot;&gt;&lt;a href=&quot;#ETS&quot; class=&quot;headerlink&quot; title=&quot;ETS&quot;&gt;&lt;/a&gt;ETS&lt;/h3&gt;&lt;p&gt;ETS是DCB的另一个重要组成部分，它主要是通过灵活的层次化调度来实现对QoS的高需求。ETS提供两级调度，分别为基于PG（Priority Group，优先级组）的调度和基于优先级的调度；ETS的调度流程如下图所示，即：首先，接口对PG进行第一级调度，然后针对PG内的不同优先级队列进行第二级调度。通过采用ETS技术，可以为网络中不同类型的流量提供不同的服务和带宽。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2KZIJgX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在ETS中定义了3个优先级组PG0、PG1和PG15，分别代表LAN流量、SAN流量和IPC流量。ETS协议根据不同流量的QoS需求规定了不同的调度方式。IEEE 802.1Qaz中定义了三种ETS调度算法：WRR（Weighted Round Robin，基于权重的轮询）算法、SP（Strict Priority，严格优先级）算法和CBS（Credit-Based Shaper，令牌整形调度）算法；ETS协议对三个优先级组PG0、PG1、PG15常见的调度方式是SP算法和WRR算法，其中PG15采用的是SP算法，主要是由于PG15承载的是IPC流量，对延时要求很高；PG0和PG1则采用了WRR算法，其主要承载的是LAN流量和SAN流量。同时，用户可以根据自身的实际需求对优先级组PG0、PG1、PG15等划分不同的带宽。&lt;br&gt;下面简要介绍SP算法和WRR算法。&lt;/p&gt;
&lt;h4 id=&quot;SP算法&quot;&gt;&lt;a href=&quot;#SP算法&quot; class=&quot;headerlink&quot; title=&quot;SP算法&quot;&gt;&lt;/a&gt;SP算法&lt;/h4&gt;&lt;p&gt;如图所示，SP算法要求严格按照优先级来发送队列中的报文，优先发送高优先级队列中的报文，当高优先级队列为空时，再发送低优先级队列中的报文，在图1-4中的8个队列中，队列7优先级最高，队列0优先级最低，所以先发送队列7中的报文，最后发送队列0的报文。根据以上原理，SP算法常用于通过将关键业务报文放入高优先级队列，从而保证这些业务的正常运行的场景。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/24sjzR3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;WRR算法&quot;&gt;&lt;a href=&quot;#WRR算法&quot; class=&quot;headerlink&quot; title=&quot;WRR算法&quot;&gt;&lt;/a&gt;WRR算法&lt;/h4&gt;&lt;p&gt;WRR算法是一种常用的轮询调度算法，该算法先给每个队列分配一定的权重，然后在队列之间进行轮流调度。每个队列的权重决定了调度到该队列时可以发送的数据量。通过轮询，WRR算法保证每个队列都能得到调度，避免出现低优先级队列饿死的情况。WRR算法的工作过程如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/TCA7P5g.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;DCBX&quot;&gt;&lt;a href=&quot;#DCBX&quot; class=&quot;headerlink&quot; title=&quot;DCBX&quot;&gt;&lt;/a&gt;DCBX&lt;/h3&gt;&lt;p&gt;在数据中心网络融合场景下，为实现上述以太网增强协议，链路两端的PFC和ETS的参数配置需要保持一致，因此对于PFC和ETS的参数需要进行配置。但是如果这些配置单纯依靠管理员手动设置，不仅工作量庞大而且极易出错。因此提出了DCBX协议，DCBX协议是一种链路发现协议，主要是为链路两端的设备发现并交换DCB配置信息提供了通信方式。&lt;br&gt;DCBX协议作为信息的载体，运行在点对点的链路上，用于通告本机的PFC、ETS等参数的配置信息，同时，它也期望接收对端发送的配置的信息用以引导本机配置。DCBX将需要交互的DCB配置信息封装到LLDP（Link Layer Discovery Protocol，链路层发现协议）中的TLV中，借由LLDP来进行链路两端设备的DCB配置交换。下面以DCB的PFC参数为例，简要说明LLDP承载DCBX的实现过程。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/yUXsCiR.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上图所示，端口Port A和Port B已经开启了LLDP功能和DCBX功能。主要信息交互流程如下：首先，Port A的LLDP模块根据自己的报文发送周期定期地向Port B发送携带DCBX TLV的LLDP报文；然后，Port B收到LLDP报文后解析出DCBX TLV，将Port A的PFC参数通知给DCBX模块；最后，DCBX模块将Port A参数和本地的PFC参数进行比较，协商一致后生成配置文件，保证两端配置一致。DCBX的TLV结构定义如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/j8iw750.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，Type字段固定为127，OUI字段固定为0x0080c2，Subtype字段为DCBX TLV承载的消息类型，包括ETS Configuration TLV、ETS Recommendation TLV和PFC Configuration TLV，其具体内容如下表所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/3sEu8Cp.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;h3 id=&quot;ECN&quot;&gt;&lt;a href=&quot;#ECN&quot; class=&quot;headerlink&quot; title=&quot;ECN&quot;&gt;&lt;/a&gt;ECN&lt;/h3&gt;&lt;p&gt;传统的TCP/IP网络中，网络拥塞控制算法都是用包丢失作为指示信息，通知端系统网络中发生了拥塞，进而通过降低发送方的发送速率来减轻拥塞程度。&lt;br&gt;而ECN则采用了一种完全不同的方法，其核心思想是通过路由器标记IP头部的特定比特位来反映网络拥塞状况。当标记报文到达目的地址后，接收方使用下一个ACK通知发送方有拥塞发生，最后，发送方做出响应，缩小拥塞窗口，降低发送速率。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/LFQRQa7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;根据上图IP首部信息可知，ECN拥塞控制主要用到了IP首部TOS域中的最后两位，称作为ECN域，其字段定义如下表所示。当一个支持ECN的主机发送数据包时首先将ECN域设置为01或10，如果在该数据包的传输路径上的路由器支持ECN并且监测到拥塞信息，它将会把ECN域设置为11，表示网络出现拥塞。而如果ECN域已经被标记为11，下游路由器不会修改其值。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/90Qe1wt.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此外，ECN仍然需要传输层协议的支持。TCP使用6位保留位的后两位来支持ECN。其字段定义如下图所示。其中，ECE（ECN-Echo）标志位有两个作用：（1）在TCP三次握手中表明TCP端是否支持ECN；（2）在传输数据时表明接收到的TCP段的IP首部的ECN被设置为11，即出现了拥塞。CWR标志位为发送端缩小拥塞窗口标志，用来通知接收端它已经收到设置了ECE标志的ACK，并减小了发送窗口。当接收端收到CWR标志的包时，停止在接下来的ACK中设置ECE标志。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/2SXhQy4.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;DCB协议是一组由IEEE 802.1工作组定义的以太网增强协议，广泛应用于现有的数据中心网络中。DCB协议充分利用了传统以太网的优势，通过增添多种关键扩展功能来为数据中心网络提供无损数据传输、低延时和物理链路带宽共享的功能。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在参与一个数据中心-云存储的项目，用到了DCB（Data Center Bridging，数据中心桥接）协议。现将学到的相关知识总结出来，以供同行交流，同时加深自己的理解。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL迭代器</title>
    <link href="http://blog.dujiong.net/2016/10/14/STL-iterator/"/>
    <id>http://blog.dujiong.net/2016/10/14/STL-iterator/</id>
    <published>2016-10-14T09:49:12.000Z</published>
    <updated>2016-10-17T13:31:20.941Z</updated>
    
    <content type="html">&lt;p&gt;我们知道，STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一帖胶着剂将他们撮合在一起。容器和算法的泛型化，可分别通过C++的class templates和function templates达成目标，而如何设计出两者之间的良好胶着剂，是一个值得深究的问题。本文所要学习的迭代器（iterator）就是在STL中扮演粘胶的角色。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Traits编程手法&quot;&gt;&lt;a href=&quot;#Traits编程手法&quot; class=&quot;headerlink&quot; title=&quot;Traits编程手法&quot;&gt;&lt;/a&gt;Traits编程手法&lt;/h3&gt;&lt;p&gt;在迭代器的实现中，经常需要访问迭代器所指对象的类型，称之为该迭代器的value type。利用内嵌类型声明typedef可以轻松实现隐藏所指对象类型。如下迭代器的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct Iterator{
    typedef T value_type;
    ...
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;泛型算法就可以通过typename Iterator::value_type来获得value type。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
typename Iterator::value_type
getValue(Iterator iter){
    return *iter;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里，关键字typename必不可少，因为T是一个一个template参数，在它被实例化之前，编译器不知道T是一个类型还是一个其他的对象，typename用于告诉编译器这是一个类型，这样才能通过编译。&lt;br&gt;如此，可以解决“函数的template参数推导机制推导的只是参数，无法推导函数的返回值型别“的问题，但是有个问题，并不是所有迭代器都是class type，比如原生指针。如果不是class type，就无法为它定义内嵌型别。但STL（以及整个泛型思维）都必须接受原生指针作为一种迭代器，所以上面这样还不够。&lt;br&gt;所以，这里需要多一层的封装，即萃取编译技术。&lt;/p&gt;
&lt;h4 id=&quot;template-partial-specialization&quot;&gt;&lt;a href=&quot;#template-partial-specialization&quot; class=&quot;headerlink&quot; title=&quot;template partial specialization&quot;&gt;&lt;/a&gt;template partial specialization&lt;/h4&gt;&lt;p&gt;template partial specialization的大致意思是：如果class template拥有一个以上的template参数，我们可以针对其中某个（或数个，但非全部）template参数进行特化工作。换句话说，我们可以在泛化设计中提供一个特化版本。所以，所谓的partial specialization就是“针对（任何）template参数更进一步的条件限制所设计出来的一个特化版本”。&lt;br&gt;比如，面对以下的class template:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class C { ... };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后，有一个如下形式的partial specialization:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class C&amp;lt;T*&amp;gt; { ... };
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个特化版本仅适用于“T为原生指针”的情况，即“T为原生指针”便是“T为任何型别”的一个更进一步的条件限制。&lt;br&gt;如此，我们便可以使用partial specialization解决“内嵌型别”未能解决的问题。即对“迭代器之template参数为指针”者，设计特定版的迭代器。&lt;br&gt;下面这个class template专门用来“萃取”迭代器的特性，而value_type正是迭代器的特性之一：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
struct iterator_traits {
    typedef typename Iterator::value_type value_type;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里所谓的traits，其意义是，如果Iterator定义有自己的value_type，那么通过这个traits的作用，萃取出来的value_type就是Iterator::value_type。&lt;br&gt;因此，先前的func可以改写成这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
typename iterator_traits&amp;lt;Iterator&amp;gt;::value_type
getValue(Iterator iter){
    return *iter;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如此，多了一层间接性，traits便可以拥有特化版本。令iterator_traits拥有一个partial specialization：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T&amp;gt;
struct iterator_traits&amp;lt;T*&amp;gt;{      //模板是一个原生指针
    typedef T value_type;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是，原生指针虽然不是一种class type，亦可通过traits取其value type。&lt;/p&gt;
&lt;h3 id=&quot;STL的五种迭代器&quot;&gt;&lt;a href=&quot;#STL的五种迭代器&quot; class=&quot;headerlink&quot; title=&quot;STL的五种迭代器&quot;&gt;&lt;/a&gt;STL的五种迭代器&lt;/h3&gt;&lt;p&gt;根据移动特性与施行操作，迭代器被分为五类：&lt;br&gt;（1）Input Iterator:这种迭代器所指的对象，不允许外界改变，客户只可读取它们所指的东西，且只能向前移动，一次一步。C++标准库中的istream_iterator是这一类的代表。&lt;br&gt;（2）Output Iterator：与Input Iterator类似，但一切只为输出，C++标准库中的ostream_iterator是这类的代表。&lt;br&gt;（3）Forward Iterator：这种迭代器可以做前述两种分类所做的每一件事，而且可以读或写所指物一次以上。&lt;br&gt;（4）Bidirectional Iterator：比上一个分类威力更大，它除了可以向前移动，还可以向后移动。STL的list迭代器就属于这一分类，set、multiset、map和multimap的迭代器也都是这一分类。&lt;br&gt;（5）最具威力的当属Random Access Iterator。这种迭代器比上一个分类威力更大的地方在于它可以执行“迭代器算术”，也就是可以在常量时间内向前或向后跳跃任意距离，这样的算术很类似指针算术，因为random access迭代器正是以内置（原始）指针为榜样，而内置指针也可被当做random access迭代器使用。 vector, deque和string提供的迭代器都是这一分类。&lt;br&gt;这些迭代器的分类与从属关系，如下图所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/WSUJIqE.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;设计算法时，如果可能，我们尽量针对上图中的某种迭代器提供一个明确定义，并针对更强化的某种迭代器提供另一种定义，这样才能在不同情况下提供最大效率。假设有个算法可接受Forward Iterator，而传入Random Access Iterator，它当然也会接受，因为一个Random Access Iterator必然是一个Forward Iterator，但是并不是最佳。&lt;br&gt;以advance()为例说明使用函数重载机制来选择最佳的迭代器版本。advance()函数有两个参数，迭代器p和数值n，函数内部将p累进n次。下面有分别针对Input Iterator、Bidirectional Iterator和Random Access Iterator的三种函数定义版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_II(InputIterator&amp;amp; i, Distance n){
    while(n--) ++i;        
}

template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_BI(InputIterator&amp;amp; i, Distance n){
    if(n&amp;gt;=0)
        while(n--) ++i;
    else
        while(n++) ++i;
}    

template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance_RAI(InputIterator&amp;amp; i, Distance n){
    i+=n;        
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在，当程序调用advance()时，应该选择跟自己最匹配的版本，所以，我们需要将三者合一。首先想到的是运用条件判断。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
void advance(InputIterator&amp;amp; i, Distance n){
    if(is_random_access_iterator(i)){
        advance_RAI(i, n);
    }else if(is_bidirectional_iterator(i)){
        advance_BI(i, n);
    }else{
        advance_II(i, n);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是像这样在执行时期才决定使用哪一个版本，会影响程序效率。最好能在编译期就选择正确的版本，所以，采用函数重载机制。&lt;br&gt;前面三个advance_xx()都有两个函数参数，型别都未定（都是template参数），为了令其同名，形成重载函数，我们必须加上一个型别已确定的函数参数，使函数重载机制得以有效运作起来。&lt;br&gt;STL设计思想为：如果traits有能力萃取出迭代器的种类，我们便可利用这个“迭代器类型”相应型别作为advanced()的三个参数，这个相应型别一定必须是一个class type，因为编译器需要依赖它（一个型别）来进行重载决议。&lt;br&gt;定义五个class，代表五种迭代器类型：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct input_iterator_tag { };
struct output_iterator_tag { };
struct forward_iterator_tag : public input_iterator_tag｛｝；
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在重新设计__advance，并加上第三参数，使它们形成重载:   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
inline void __advance(InputIterator&amp;amp; i, Distance n,
                      input_iterator_tag){
    while(n--) ++i;
}

template &amp;lt;class BidirectionalIterator, class Distance n&amp;gt;
inline void __advance(BidirectionalIterator&amp;amp; i, Distance n,
                      bidirectional_iterator_tag){
    if(n&amp;gt;=0)
        while(n--) ++i;
    else
        while(n++) --i;
}
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个__advance()的最后一个参数都只声明型别，并未指定参数名称，因为它纯粹只是用来激活重载机制，函数之中根本不使用该参数。&lt;br&gt;最后，还需要一个对外开放的上层接口，调用上述各个重载的__advance()，这一上层接口只需要两个参数，当它准备将工作转给上述的__advance()时，才自行加上第三参数：迭代器类型。因此，这个上层函数必须有能力从它所能获得的迭代器中推导出其类型（traits机制）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class InputIterator, class Distance&amp;gt;
inline void advance(InputIterator&amp;amp; i, Distance n){
    __advance(i, n, 
                iterator_traits&amp;lt;InputIterator&amp;gt;::iterator_category());
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;iterator_traits&lt;inputiterator&gt;::iterator&lt;em&gt;category())将产生一个暂时对象，其型别应该隶属于前述四个迭代器类型，然后根据这个型别，编译器才决定调用哪一个\&lt;/em&gt;_advance()重载函数。&lt;br&gt;因此，为了满足上述行为，traits必须再增加一个相应的型别：&lt;/inputiterator&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class Iterator&amp;gt;
struct iterator_traits{
    ...
    typedef typename Iterator::iterator_category iterator_category;
};

//针对原生指针
template &amp;lt;class T&amp;gt;
struct iterator_traits&amp;lt;T*&amp;gt;{
    ...
    typedef typename random_access_iterator_tag iterator_category;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后一个问题，STL算法的命名规则：以算法所能接收之最低阶迭代器类型，来为其迭代器型别参数命名。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;我们知道，STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一帖胶着剂将他们撮合在一起。容器和算法的泛型化，可分别通过C++的class templates和function templates达成目标，而如何设计出两者之间的良好胶着剂，是一个值得深究的问题。本文所要学习的迭代器（iterator）就是在STL中扮演粘胶的角色。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ STL空间配置器</title>
    <link href="http://blog.dujiong.net/2016/10/09/STL-allocator/"/>
    <id>http://blog.dujiong.net/2016/10/09/STL-allocator/</id>
    <published>2016-10-09T05:54:15.000Z</published>
    <updated>2016-10-13T11:18:08.167Z</updated>
    
    <content type="html">&lt;p&gt;最近准备结合《STL源码剖析》把学习的STL知识整理一遍，加深自己的理解的同时，也方便以后需要的时候查看。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;首先总结的是STL中的内存分配—空间配置器，从STL的运用角度而言，空间配置器是最不需要介绍的东西，因为用户使用过程中不会直接与其打交道，但是，从STL的实现角度看，空间配置器又是最重要的知识点之一，因为整个STL的操作对象都存放在容器之内，而容器一定需要配置空间以放置数据。&lt;br&gt;C++ STL配置器分为两层配置器，当请求的内存大于128bytes时，视为“足够大”，用第一层配置器分配内存，当请求的内存小于128bytes时，视为“过小”，调用第二级配置器，第二级配置器采用复杂的内存池整理方式，而不再求助于第一级配置器。&lt;/p&gt;
&lt;h3 id=&quot;第一级配置器&quot;&gt;&lt;a href=&quot;#第一级配置器&quot; class=&quot;headerlink&quot; title=&quot;第一级配置器&quot;&gt;&lt;/a&gt;第一级配置器&lt;/h3&gt;&lt;p&gt;首先来看下主要的源代码：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;int inst&amp;gt;
class __malloc_alloc_template{
private:
    static void *oom_malloc(size_t);    //malloc调用内存不足
    static void *oom_realloc(void*, size_t);    //realloc调用内存不足
    static void (*__malloc_alloc_oom_handler)();    //错误处理函数
public:
    static void* allocate(size_t){
        void *result = malloc(n);        //第一级配置器直接调用malloc()
        if(0 == result) result = oom_malloc(n);
        return result;
    }
    static void* deallocate(void *p, size_t){
        free(p);            
    }
    static void *reallocate(void *p, size_t/* old_sz */, size_t new_sz){
        void *result = realloc(p, new_sz);    //第一级配置器直接调用realloc()
        if(0 == result) result = oom_realloc(p, new_sz);
        return result;    
    }
    static void (*set_malloc_handler(void (*f)()))(){    //设置错误处理函数
        void (* old)() = __malloc_alloc_oom_handler;
        __malloc_alloc_oom_handler = f;
        return(old);    
    }
};

template &amp;lt;int inst&amp;gt;
void* __malloc_alloc_template&amp;lt;inst&amp;gt;::oom_alloc(size_t n){
    void (* my_alloc_handler)();     //声明函数指针
    void *result;                     //返回的内存指针
    for(;;){                          //循环，直到成功
        my_alloc_handler = __malloc_alloc_oom_handler;    
        if(0 == my_alloc_handler){ __THROW_BAD_ALLOC; }        //抛出异常
        (*my_alloc_handler)();
        result = malloc(n);            //再重新分配内存
        if(result) return(result);        
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一级配置器相对简单，其使用malloc(), free(), realloc()等C函数执行实际的内存分配，释放，重新配置等操作。此外，这个配置器提供了当内存配置错误时的处理函数oom&lt;em&gt;malloc，这个函数会调用\&lt;/em&gt;_malloc_alloc_oom_handler()这个错误处理函数，去企图释放内存，然后重新调用malloc分配内存。如此循环，直到分配成功，返回指针。&lt;/p&gt;
&lt;h3 id=&quot;第二级配置器&quot;&gt;&lt;a href=&quot;#第二级配置器&quot; class=&quot;headerlink&quot; title=&quot;第二级配置器&quot;&gt;&lt;/a&gt;第二级配置器&lt;/h3&gt;&lt;p&gt;STL第二级配置器的做法是，如果区块够大，超过128bytes时，就移交第一级配置器处理。当区块小于128bytes时，则以内存池管理，即每次配置一大块内存，并维护对应之自由链表，下次若再有相同大小的内存需求，就直接从free lists中拔出，而如果客户端释还小额区块，就由配置器回收到free lists中。&lt;br&gt;为了方便管理，SGI第二级配置器会主动将任何小额区块的内存需求量上调至8的倍数（例如客端要求30bytes，就会自动调整为32bytes），并维护16个free lists，各自管理大小分别为8,16,24,32,40,48,56,64,72,80,88,96,104,112,120,128的小额区块。&lt;br&gt;free-lists的节点结构定义如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;union obj {
    union obj *free_list_link;     //指向下一个内存的地址
    char client_data[1];           //内存的首地址 
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据union的特性，obj的内存布局应该如下所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/IE7fZAU.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从起第一字段观之，obj被视为一个指针，指向相同形式的另一个obj，从其第二字段观之，obj可被视为一个指针，指向实际区块。这样一物二用的结果是，不会为了维护链表所必须的指针而造成内存的另一种浪费。&lt;br&gt;下面来看一下相关的源代码。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;enum {__ALIGN = 8}；
enum {__MAX_BYTES = 128};
enum {__NFREELISTS = __MAX_BYTES/__ALIGN};

template &amp;lt;bool threads, int inst&amp;gt;
class __default_alloc_template{
    ...
    static size_t ROUND_UP(size_t bytes){        //将bytes上调至8的倍数
        return (((bytes)+__ALIGN-1) &amp;amp; ~(__ALIGN-1));
    }
    static obj* volatile free_list[__NFREELISTS];    //内存池链表
    static size_t FREELIST_INDEX(size_t bytes){    
        return (((bytes)+__ALIGN-1)/__ALIGN-1);        //根据区块大小，决定使用第n号free-list
    }
    ...    
};

static void* allocate(size_t n){
    obj * volatile * my_free_list;
    obj * result;
    if(n &amp;gt; (size_t)__MAX_BYTES){
        return (malloc_alloc::allocate(n));
    }
    my_free_list = free_list + FREELIST_INDEX(n);    //寻找合适的那个free_list
    result = *my_free_list;
    if(result == 0){        //没找到可用的free_list,准备重新填充free_list
        void* r = refill(ROUND_UP(n));
        return r;
    }
    *my_free_list = result-&amp;gt;free_list_link;        //调整free_list
    return (result);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;具体操作如下图所示（摘自《STL源码剖析》）。当有内存请求到达时（第二级配置器），先找到负责这个内存大小的数据元素指向的内存链表，取出第一块内存，然后把数据元素(obj指针)指向第二块内存的首地址。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/VrO5VMA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此外，当程序释放这块内存时，第二级配置器还负责回收这块内存，等下次有请求时，可以直接使用这块内存。示意图（摘自《STL源码剖析》）如下：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/um5jnaS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;先计算这块内存属于哪个数组元素负责，然后将这块回收的内存放置链表的第一个位置，这块内存的下一块内存为这个链表原先的第一块内存。源代码如下；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void deallocate(void *p, size_t n){
    obj *q = (obj *)p;
    obj * volatile * my_free_list;

    if(n &amp;gt; (size_t)__MAX_BYTES) {    //大于128bytes,调用第一级配置器回收
        malloc_alloc::deallocate(p, n);
        return;
    }
    my_free_list = free_list + FREELIST_INDEX(n);    //找到负责这块内存的数据元素
    q -&amp;gt;free_list_link = *my_free_list;         
    *my_free_list = q;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;重新填充free-lists&quot;&gt;&lt;a href=&quot;#重新填充free-lists&quot; class=&quot;headerlink&quot; title=&quot;重新填充free lists&quot;&gt;&lt;/a&gt;重新填充free lists&lt;/h3&gt;&lt;p&gt;在上面的allocate()中，当发现free list中没有可用区块了时，就调用refill()，准备为free list重现填充空间。新的空间将取自内存池（经由chunk_alloc()完成）。缺省取得20个新节点（新区块），但万一内存池空间不足，获得的区块数可能小于20。例如，如果请求内存为32bytes，此时内存链表中没有足够的内存了，那么refill会分配20块32bytes的内存块，然后把第一块返回给程序，其他19块由数组相应链表管理。相应的源代码为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;bool threads, int inst&amp;gt;
void* __default_alloc_template&amp;lt;threads, inst&amp;gt;::refill(size_t n){
    int nobjs = 20;
    char *chunk = chunk_alloc(n, nobjs);   //nobjs: pass by reference
    obj * volatile * my_free_list;
    obj * result;
    obj * current_obj, next_obj;
    int i;

    if(1 == nodejs) return chunk;    //如果只返回一块内存，直接返回
    my_free_list = free_list + FREELIST_INDEX(n);

    result = (obj*)chunk;        //不止一块内存，取出第一块内存
    *my_free_list = next_obj = (obj *)(chunk + n );   //数组元素链表指针指向第二块内存
    for(i=1; ;i++){
        curent_obj = next_obj;
        next_obj = (*obj)((char*)next_obj+n);
        if(nobjs - 1 ==i){
            current_obj-&amp;gt;free_list_link = 0;
            break;
        }else{
            current_obj-&amp;gt;free_list_link = next_obj;
        }
    }
    return(result);
}            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;接下来分析真正从内存池获取内存的函数chunk_alloc。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;bool threads, int inst&amp;gt;
char* __default_alloc_template&amp;lt;threads, inst&amp;gt;::chunk_alloc(size_t size, int&amp;amp; nobjs){
    char* result;
    size_t total_bytes = size * nobjs;
    size_t bytes_left = end_free - start_free;        //内存池剩余的内存

    if(bytes_left &amp;gt;= total_bytes){        //当内存持内存足够时
        result = start_free;
        start_free += total_free;
        return(result);
    }else if(bytes_left &amp;gt;= size){        //内存池不能满足total，但是可以满足一块以上
        nobjs = bytes_left/size;
        total_bytes = size * nobjs;
        result = start_free;
        start_free += total_bytes;
        return(result);
    }else{                //试着让内存池的残余零头还有利用价值
        size_t bytes_to_get = 2*total_bytes + ROUND_UP(heap_size &amp;gt;&amp;gt; 4);
        if(bytes_left &amp;gt; 0){
            obj * volatile * my_free_list = free_list + FREELIST_INDEX(bytes_left);
            ((obj *)start_free) -&amp;gt; free_list_link = *my_free_list;    //调整free list，将内存池中的残余空间编入
            *my_free_list = (*obj)start_free;
        }
        //调用malloc从内存分配
        start_free = (char*)malloc(bytes_to_get);
        if(0 == start_free){                //当系统内存不足时
            int i;
            obj * volatile * my_free_list, *p;
            for(i=size;i&amp;lt;=__MAX_BYTES;i+=__ALIGN){
                my_free_list = free_list + FREELIST_INDEX(i);
                p = *my_free_list;
                if(0 != p){
                    *my_free_list = p-&amp;gt;free_list_link;
                    start_free = (char*)p;
                    end_free = start_free + i;
                    return(chunk_alloc(size, nobjs));
                }
            }
            end_free = 0;        //从其他链表也没获取到内存，到处都没内存可用了
            start_free = (char*)malloc_alloc::allocate(byte_to_get);        //调用第一级配置器，因为有错误处理函数，最后的补救办法了
        }
        heap_size += bytes_to_get;
        end_free = start_free + bytes_to_get;
        return(chunk_alloc(size, nobjs));
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;chunk_alloc()函数以end_free-start_free来判断内存池的水量，如果水量充足，就直接调出20个区块返回给free list，如果水量不足以提供20个区块，但还足够供应一个以上的区块，就拨出这不足20个区块的空间出去，这时候pass by reference的nobjs参数被修改为实际能够供应的区块数。如果内存池连一个区块空间都无法供应，此时便利用malloc()从heap中配置内存，为内存注入源头活水以应付需求。其过程如下图所示：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/SCDG2Gu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;对象内容的构造与析构&quot;&gt;&lt;a href=&quot;#对象内容的构造与析构&quot; class=&quot;headerlink&quot; title=&quot;对象内容的构造与析构&quot;&gt;&lt;/a&gt;对象内容的构造与析构&lt;/h3&gt;&lt;p&gt;我们知道，C++中的new操作符包含两阶段的操作：（1）调用::operator new配置内存；（2）调用构造函数构造对象内容，所以，为了精密分工，STL allocator决定将这两阶段 操作区分开来，内存配置操作由alloc::allocate()负责，对象构造函数由::construct()负责。同理，对象的析构与内存释放也是由两部分操作组成。&lt;/p&gt;
&lt;h3 id=&quot;使用配置器&quot;&gt;&lt;a href=&quot;#使用配置器&quot; class=&quot;headerlink&quot; title=&quot;使用配置器&quot;&gt;&lt;/a&gt;使用配置器&lt;/h3&gt;&lt;p&gt;最后，来看下配置器是如何使用的。      &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;class T, class Alloc&amp;gt;
class simple_alloc {
public:
    static T *allocate(size_t n)
        { return 0 == n ? 0 : (T*)Alloc::allocate(n * sizeof(T)); }
    static T *allocate(void)
        { return 0 == n ? 0 : (T*)Alloc::allocate(sizeof(T)); }
    static void deallocate(T* p, size_t n)
        { if(0 != n) Alloc::deallocate(p, n * sizeof(T)); }
    static void deallocate(T* p)
        { Alloc::deallocate(p, sizeof(T)); }
};        
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;simple_alloc类封装了Alloc的分配和回收内存函数，并提供了四个用于内存操作的函数接口。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template &amp;lt;class T, class Alloc = alloc&amp;gt;        //alloc被默认为第二级配置器
class vector{
public:
    typedef T value_type;
    ...
protected:
    typedef simple_alloc&amp;lt;value_type, Alloc&amp;gt; data_allocator;    
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看出，vector内嵌了data_allocator类型，当需要分配内存时，调用simple_alloc的成员方法即可。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近准备结合《STL源码剖析》把学习的STL知识整理一遍，加深自己的理解的同时，也方便以后需要的时候查看。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>浅谈tcp backlog</title>
    <link href="http://blog.dujiong.net/2016/09/28/tcp-backlog/"/>
    <id>http://blog.dujiong.net/2016/09/28/tcp-backlog/</id>
    <published>2016-09-28T13:42:51.000Z</published>
    <updated>2016-09-20T15:49:44.450Z</updated>
    
    <content type="html">&lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;backlog的两种实现&quot;&gt;&lt;a href=&quot;#backlog的两种实现&quot; class=&quot;headerlink&quot; title=&quot;backlog的两种实现&quot;&gt;&lt;/a&gt;backlog的两种实现&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/Ymk1keA.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;首先通过上图回顾一下TCP建立连接时的状态变化。由于TCP建立连接时使用三次握手，所以监听的服务端在回给客户端SYN+ACK之后，会进入SYN RECEIVED状态，这称之为半连接状态，而只有当收到客户端回送的ACK之后，才完成连接，进入ESTABLISHED状态，等待应用层处理。所以，TCP/IP协议栈有两种方式来实现这个连接队列：&lt;br&gt;（1）第一种是使用一个单一的队列，队列的大小由应用层listen函数的backlog参数确定，当收到一个SYN请求，服务端就回发给客户端SYN+ACK，并且将该连接加入到队列中。当客户端最后的ACK到来时，该连接的状态变为ESTABLISHED，并等待应用层处理。所以，这种实现方式下，队列中包含了两种状态的连接：SYN RECEIVED和ESTABLISHED。只有后一种状态的连接才可以从acception中返回，被应用层处理。&lt;br&gt;（2）另一种实现方式是使用两个队列，一个SYN队列（即半连接队列）和一个全连接队列（ACCEPT队列）。处于SYN RECEIVED状态的连接被加入到SYN队列中，当最后一个ACK到来时，改变状态并移动到全连接队列。所以，accept系统调用直接从全连接队列中取已完成的连接交给应用层处理。这时，listen函数中的backlog值决定了全连接队列的大小。&lt;br&gt;传统的基于BSD的TCP实现采用的是第一种方式，这种实现方式意味着，当队列满的时候，系统再收到SYN，将不会回发SYN+ACK。通常，TCP实现采用的是简单地丢弃SYN，让客户端重传，而不是回发RST。&lt;br&gt;在Linux系统中，backlog的实现形式分为两个阶段，在Linux2.2之前，内核采用的也是上述的方式，队列满之后，服务端再收到SYN时，将不会返回SYN/ACK，也不返回RST，让客户端重试。而在Linux2.2之后，内核选择第二种方式实现，SYN_RECEIVED队列的大小由/proc/sys/net/ipv4/tcp_max_syn_backlog系统参数指定，ESTABLISHED队列由backlog和/proc/sys/net/core/somaxconn中较小的指定。    &lt;/p&gt;
&lt;h3 id=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;a href=&quot;#SYN队列和ACCEPT队列&quot; class=&quot;headerlink&quot; title=&quot;SYN队列和ACCEPT队列&quot;&gt;&lt;/a&gt;SYN队列和ACCEPT队列&lt;/h3&gt;&lt;p&gt;以下是操作系统维护两种队列处理TCP连接的示意图。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/sGEPFN7.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;SYN队列和已完成队列是内核实现的，当服务器绑定、监听了某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。客户端使用connect向服务器发起TCP连接时，当SYN包到达服务器之后，内核会把这一报文放入SYN队列，同时回发一个SYN+ACK包给客户端。一段时间后，当三次握手最后的ACK到达服务器，内核会把连接从SYN队列中取出，再把这个连接放入ACCEPT队列（已完成队列）中。所以，服务器调用accept，其实就是直接从ACCEPT队列中取出已经建立成功的连接套接字。&lt;br&gt;当然，随之也产生了一些问题。因为SYN和ACCEPT队列都是有大小限制的，所以，二者都会存在队列满的时候。上图中，如果第一步执行的速度大于第二步执行的速度，SYN队列就会不断增大直到队列满；如果第二步执行的速度大于第三步执行的速度，ACCEPT队列同样会满。&lt;br&gt;当ACCEPT队列已满，这时SYN队列中的一个连接收到最后的ACK，需要移动到ACCEPT队列，会发生什么呢？&lt;br&gt;通过查看内核源码(net/ipv4/tcp_ipv4.c)可知，如果/proc/sys/net/ipv4/tcp_abort_on_overflow被置为1，内核将会回送RST包，否则，将会丢弃ACK，什么都不做。进一步地，当一定时间服务端还没有收到ACK（包括丢弃掉的ACK），将会重发SYN+ACK包（“指数退避”算法）。当客户端收到重发的SYN+ACK时，它便知道ACK包丢失了，需要重传。另一方面，当ACCEPT队列已满的时候，内核将会限制SYN队列的处理速度，如果收到太多的SYN队列，将会丢弃一些。这样，丢弃的SYN对应的客户端将会重发SYN包。&lt;br&gt;另一种情况，当SYN队列满的时候，会发生什么呢？上面已经阐述了，服务器端将会直接丢弃请求，即丢弃SYN网络包。       &lt;/p&gt;
&lt;h3 id=&quot;TCP连接的一些异常情况&quot;&gt;&lt;a href=&quot;#TCP连接的一些异常情况&quot; class=&quot;headerlink&quot; title=&quot;TCP连接的一些异常情况&quot;&gt;&lt;/a&gt;TCP连接的一些异常情况&lt;/h3&gt;&lt;p&gt;针对上述的两个连接队列，有一些常见的连接异常情况。下面做一个简单总结。     &lt;/p&gt;
&lt;h4 id=&quot;服务端SYN超时&quot;&gt;&lt;a href=&quot;#服务端SYN超时&quot; class=&quot;headerlink&quot; title=&quot;服务端SYN超时&quot;&gt;&lt;/a&gt;服务端SYN超时&lt;/h4&gt;&lt;p&gt;当客户端给服务端发送SYN报文时，如果服务端没有返回SYN+ACK报文，那么客户端会重发SYN报文给服务端，重发的次数由参数tcp_syn_retries参数设置，该值默认是5，超过5次服务端还是不返回SYN+ACK报文，那么本次连接失败。服务端没有返回SYN+ACK主要有两种情况，一种是由于网络问题SYN包丢失；另一种是服务端SYN队列满，导致SYN包被丢弃。                &lt;/p&gt;
&lt;h4 id=&quot;客户端ACK超时&quot;&gt;&lt;a href=&quot;#客户端ACK超时&quot; class=&quot;headerlink&quot; title=&quot;客户端ACK超时&quot;&gt;&lt;/a&gt;客户端ACK超时&lt;/h4&gt;&lt;p&gt;如果服务端接到了客户端发的SYN并回发SYN+ACK后，客户端掉线了，这时，服务端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功也没失败。于是，服务端端如果在一定时间内没有收到客户端端的ACK，那么服务端端会重发SYN+ACK。在Linux下，默认重试次数为5次，重发的间隔时间从1s开始每次都翻番（指数退避），5次的重发的时间间隔分别1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s+2s+4s+8s+16s+32s = 2^6-1 = 63s，TCP才会把断开这个连接。              &lt;/p&gt;
&lt;h4 id=&quot;SYN-Flood&quot;&gt;&lt;a href=&quot;#SYN-Flood&quot; class=&quot;headerlink&quot; title=&quot;SYN Flood&quot;&gt;&lt;/a&gt;SYN Flood&lt;/h4&gt;&lt;p&gt;这时一种恶意攻击。客户端给服务器发一个SYN后就下线，这样服务器需要默认等待63s才会断开连接，这样攻击者就可以把服务器的SYN连接队列耗尽，让正常的连接请求不能处理。为了应对SYN Flood攻击，Linux实现了一种称为SYN cookie的机制，通过net.ipv4.tcp_syncookies来设置。当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使不在SYN队列中）。&lt;/p&gt;
&lt;h3 id=&quot;TCP连接过程参数调优&quot;&gt;&lt;a href=&quot;#TCP连接过程参数调优&quot; class=&quot;headerlink&quot; title=&quot;TCP连接过程参数调优&quot;&gt;&lt;/a&gt;TCP连接过程参数调优&lt;/h3&gt;&lt;p&gt;下面罗列一些常用于TCP连接过程优化的参数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-max-syn-backlog&quot;&gt;&lt;a href=&quot;#tcp-max-syn-backlog&quot; class=&quot;headerlink&quot; title=&quot;tcp_max_syn_backlog&quot;&gt;&lt;/a&gt;tcp_max_syn_backlog&lt;/h4&gt;&lt;p&gt;SYN队列长度。如果服务器经常出现过载，可以尝试增加这个数字。   &lt;/p&gt;
&lt;h4 id=&quot;tcp-synack-retries&quot;&gt;&lt;a href=&quot;#tcp-synack-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_synack_retries&quot;&gt;&lt;/a&gt;tcp_synack_retries&lt;/h4&gt;&lt;p&gt;连接被动打开方的确认连接的应答最大重试次数。对于一个新建连接，内核要发送多少SYN连接请求才决定放弃。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syn-retries&quot;&gt;&lt;a href=&quot;#tcp-syn-retries&quot; class=&quot;headerlink&quot; title=&quot;tcp_syn_retries&quot;&gt;&lt;/a&gt;tcp_syn_retries&lt;/h4&gt;&lt;p&gt;连接主动打开方的syn尝试次数。&lt;/p&gt;
&lt;h4 id=&quot;tcp-syncookies&quot;&gt;&lt;a href=&quot;#tcp-syncookies&quot; class=&quot;headerlink&quot; title=&quot;tcp_syncookies&quot;&gt;&lt;/a&gt;tcp_syncookies&lt;/h4&gt;&lt;p&gt;防止SYN Flood攻击。    &lt;/p&gt;
&lt;h4 id=&quot;tcp-abort-on-overflos&quot;&gt;&lt;a href=&quot;#tcp-abort-on-overflos&quot; class=&quot;headerlink&quot; title=&quot;tcp_abort_on_overflos&quot;&gt;&lt;/a&gt;tcp_abort_on_overflos&lt;/h4&gt;&lt;p&gt;ACCEPT队列满，处理不过来的时候，如果设置了该参数，内核将会回发RST包。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;熟悉Linux网络(socket)编程的同学应该都记得，在服务端建立监听套接字的API &lt;code&gt;int listen(int sockfd, int backlog)；&lt;/code&gt;中有一个参数backlog，通常称之为积压值。积压值用来描述一个固定长度的连接队列的大小，该队列用于TCP连接建立的过程中。&lt;br&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>数据结构之线段树</title>
    <link href="http://blog.dujiong.net/2016/09/23/SegmentTree/"/>
    <id>http://blog.dujiong.net/2016/09/23/SegmentTree/</id>
    <published>2016-09-23T13:28:16.000Z</published>
    <updated>2016-09-17T02:46:29.535Z</updated>
    
    <content type="html">&lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;线段树具有如下性质：&lt;br&gt;（1）线段树是一棵平衡树，使用线段树可以快速地查找某一个节点在若干条线段中出现的次数，时间复杂度为O(logN)。&lt;br&gt;（2）线段树同一层的节点所代表的区间，相互不会重叠。&lt;br&gt;（3）线段树任两节点要么是包含关系要么是没有公共部分，不可能部分重叠。&lt;br&gt;（4）给定一个叶子l，从根到l路径上所有节点代表的区间都包含l，且其他节点代表的区间都不包含l。&lt;br&gt;一棵[1,10]的线段树表示如下。注意，线段树的构造在各区间的端点处的处理方式不一样，会导致线段树最终的表示有些差别，但是本质上是一样的。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/JEkWmlu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;线段树的基本操作&quot;&gt;&lt;a href=&quot;#线段树的基本操作&quot; class=&quot;headerlink&quot; title=&quot;线段树的基本操作&quot;&gt;&lt;/a&gt;线段树的基本操作&lt;/h3&gt;&lt;p&gt;线段树的基本操作和普通二叉树很类似，只不过线段树的节点上存储的是一个区间（左右端点值）。下面以线段树的建立、插入线段和删除线段为例简要说明线段树的基本操作。&lt;/p&gt;
&lt;h4 id=&quot;线段树的构建&quot;&gt;&lt;a href=&quot;#线段树的构建&quot; class=&quot;headerlink&quot; title=&quot;线段树的构建&quot;&gt;&lt;/a&gt;线段树的构建&lt;/h4&gt;&lt;p&gt;首先定义线段树的结构，这里采用链表的方式组织。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct Node
{
    int left,right;
    int cover;            
    Node* leftChild;
    Node* rightChild;    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，cover字段用于计算一条线段被覆盖的次数。接下来，以递归的方式构建线段树。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Node* build(int l, int r)
{
    Node* root = new Node();
    root-&amp;gt;left = l;
    root-&amp;gt;right = r;
    root-&amp;gt;cover = 0;
    root-&amp;gt;leftChild = NULL;
    root-&amp;gt;rightChild = NULL;
    if(r-l &amp;gt; 1)
    {
        int mid = (l+r) &amp;gt;&amp;gt; 1;
        root-&amp;gt;leftChild = build(l,mid);
        root-&amp;gt;rightChild = build(mid,r);        //build(mid+1,r)
    }
    return root;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;线段插入与删除&quot;&gt;&lt;a href=&quot;#线段插入与删除&quot; class=&quot;headerlink&quot; title=&quot;线段插入与删除&quot;&gt;&lt;/a&gt;线段插入与删除&lt;/h4&gt;&lt;p&gt;如上所述，通过cover字段来计算一条线段被覆盖的次数。插入与删除时更新相应线段的cover。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Insert(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover++;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Insert(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Insert(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Insert(start,mid,root-&amp;gt;leftChild);
        Insert(mid,end,root-&amp;gt;rightChild); 
    }
}

void Delete(int start, int end, Node* root)
{
    if(root==NULL || start&amp;gt;root-&amp;gt;right || end&amp;lt;root-&amp;gt;left)
    {
        cout &amp;lt;&amp;lt; &amp;quot;error&amp;quot; &amp;lt;&amp;lt; endl;
        return;
    }
    if(start&amp;lt;=root-&amp;gt;left &amp;amp;&amp;amp; end&amp;gt;=root-&amp;gt;right)
    {
        root-&amp;gt;cover--;
        return;
    }
    int mid=(root-&amp;gt;left+root-&amp;gt;right)&amp;gt;&amp;gt;1;
    if(end&amp;lt;=mid)
    {
        Delete(start,end,root-&amp;gt;leftChild);
    }
    else if(start&amp;gt;=mid)
    {
        Delete(start,end,root-&amp;gt;rightChild);
    }
    else
    {
        Delete(start,mid,root-&amp;gt;leftChild);
        Delete(mid,end,root-&amp;gt;rightChild);
    }
}    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;线段树的应用&quot;&gt;&lt;a href=&quot;#线段树的应用&quot; class=&quot;headerlink&quot; title=&quot;线段树的应用&quot;&gt;&lt;/a&gt;线段树的应用&lt;/h3&gt;&lt;p&gt;TODO&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线段树，又称为区间数，是一种二叉搜索树，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶节点。而对于线段树中的每一个非叶节点[a,b]，它的左子树表示的区间为[a,(a+b)/2]，右子树表示的区间为[(a+b)/2+1,b]，因此线段树是平衡二叉树（结构平衡的二叉搜索树，即叶节点的深度差不超过1）。叶节点数目为N，即整个线段区间的长度。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Spin lock与Mutex</title>
    <link href="http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/"/>
    <id>http://blog.dujiong.net/2016/09/18/spinlock-vs-mutex/</id>
    <published>2016-09-18T13:34:32.000Z</published>
    <updated>2016-09-16T13:26:29.859Z</updated>
    
    <content type="html">&lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Pthreads提供了多种线程同步锁机制：&lt;br&gt;（1）Mutex（互斥量）：pthread_mutex_xxx&lt;br&gt;（2）Spin lock(自旋锁)：pthread_spin_xxx&lt;br&gt;（3）Condition Variable（条件变量）：pthread_cond_xxx&lt;br&gt;（4）Read/Write lock（读写锁）：pthread_rwlock_xxx&lt;br&gt;本文主要讲解Spin lock和其与Mutex（Mutex的用法很常见、也很简单，若还不熟悉，可参考&lt;a href=&quot;http://blog.dujiong.net/2016/07/08/muduo-5/&quot;&gt;muduo中的封装&lt;/a&gt;）之间的区别。     &lt;/p&gt;
&lt;h3 id=&quot;Spin-lock&quot;&gt;&lt;a href=&quot;#Spin-lock&quot; class=&quot;headerlink&quot; title=&quot;Spin lock&quot;&gt;&lt;/a&gt;Spin lock&lt;/h3&gt;&lt;p&gt;Spin lock又称自旋锁，线程通过busy-wait-loop的方式来获取锁，任何时刻都只有一个线程能够获得锁，其他线程忙等待直到获得锁。Spin lock在多处理器多线程环境的场景中有很广泛的使用。   &lt;/p&gt;
&lt;h4 id=&quot;Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;Spin lock和Mutex&quot;&gt;&lt;/a&gt;Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;Spin lock有如下特点：&lt;br&gt;（1）Spin lock是一种死等的锁机制。当发生访问资源冲突的时候，可以有两种机制：一个是死等，一个是挂起当前进程，调度其他线程执行（Mutex）。线程会一直进行忙等待而不停的进行锁清秋，直到得到这个锁为止。&lt;br&gt;（2）执行时间短。由于Spin lock死等这种特性，因此它使用在那些代码不是非常复杂的临界区（当然也不能太简单，否则使用原子操作或者其他适用简单场景的同步机制就可以了），如果临界区执行时间太长，那么不断在临界区门口进行死等的线程十分浪费CPU资源。&lt;br&gt;（3）可以在中断上下文执行。由于不睡眠，因此Spin lock可以在中断上下文中使用。&lt;br&gt;从上述总结的Spin lock的特点，已经可以看出其与Mutex的不同之处了，下面再以一个实例进行说明。&lt;br&gt;例如在一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core 0和Core 1上，假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，Core 0会在此时进行上下文切换将线程A置于等待队列中，此时Core 0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待。而Spin lock则不然，它属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，那么线程A就会一直在Core 0上进行忙等待并不停的进行锁请求，直到得到这个锁为止。&lt;/p&gt;
&lt;h4 id=&quot;使用Spin-lock和Mutex&quot;&gt;&lt;a href=&quot;#使用Spin-lock和Mutex&quot; class=&quot;headerlink&quot; title=&quot;使用Spin lock和Mutex&quot;&gt;&lt;/a&gt;使用Spin lock和Mutex&lt;/h4&gt;&lt;p&gt;下面通过实际的代码来进一步比较说明Spin lock和Mutex。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;list&amp;gt;

using namespace std;

const int LOOPS = 50000000;

list&amp;lt;int&amp;gt; ilist;

#ifdef USE_SPINLOCK
    pthread_spinlock_t spinlock;
#else
    pthread_mutex_t mutex;
#endif

pid_t gettid() 
{
    return syscall( __NR_gettid );
}

void *consumer(void *ptr)
{
    int i;

    printf(&amp;quot;Consumer TID %lun&amp;quot;, (unsigned long)gettid());

    while (1)
    {
#ifdef USE_SPINLOCK
        pthread_spin_lock(&amp;amp;spinlock);
#else
        pthread_mutex_lock(&amp;amp;mutex);
#endif

        if (ilist.empty())
        {
#ifdef USE_SPINLOCK
            pthread_spin_unlock(&amp;amp;spinlock);
#else
            pthread_mutex_unlock(&amp;amp;mutex);
#endif
            break;
        }

        i = ilist.front();
        ilist.pop_front();

#ifdef USE_SPINLOCK
        pthread_spin_unlock(&amp;amp;spinlock);
#else
        pthread_mutex_unlock(&amp;amp;mutex);
#endif
      }

    return NULL;
}

int main()
{
    int i;
       pthread_t thr1, thr2;
    struct timeval tv1, tv2;

#ifdef USE_SPINLOCK
    pthread_spin_init(&amp;amp;spinlock, 0);
#else
    pthread_mutex_init(&amp;amp;mutex, NULL);
#endif

    for (i = 0; i &amp;lt; LOOPS; i++)
        ilist.push_back(i);

    gettimeofday(&amp;amp;tv1, NULL);

    pthread_create(&amp;amp;thr1, NULL, consumer, NULL);
    pthread_create(&amp;amp;thr2, NULL, consumer, NULL);

    pthread_join(thr1, NULL);
    pthread_join(thr2, NULL);

    gettimeofday(&amp;amp;tv2, NULL);

    if (tv1.tv_usec &amp;gt; tv2.tv_usec)
    {
        tv2.tv_sec--;
        tv2.tv_usec += 1000000;
    }
    printf(&amp;quot;Result - %ld.%ld\n&amp;quot;, tv2.tv_sec - tv1.tv_sec,
    tv2.tv_usec - tv1.tv_usec);

#ifdef USE_SPINLOCK
    pthread_spin_destroy(&amp;amp;spinlock);
#else
    pthread_mutex_destroy(&amp;amp;mutex);
#endif

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该程序的逻辑是：主线程先初始化一个list结构，并根据LOOPS的值将对应数量的i插入该list，之后创建两个新线程，它们都执行consumer()这个任务。两个被创建的新线程同时对这个list进行pop()操作。主线程会计算从创建两个新线程到新线程结束之间所用的时间。&lt;br&gt;代码执行平台参数：&lt;br&gt;Ubuntu14.04 X86&lt;br&gt;Inter i5-2430M @ 2.40GHz, Dual Core&lt;br&gt;4.0GB Memory&lt;br&gt;下面是代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/7dmwgzS.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果中可以看出Spin lock表现出的性能更好，另外，sys时间是所花费的系统掉头时间，可以看出，Mutex将消耗更多的系统调用时间，这是因为Mutex会在锁冲突时调用System Wait造成的。&lt;br&gt;但是，当临界区很大时，两个线程的锁进程会非常的激烈。这时，Spin lock的“死等”策略效率将会急剧下降。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;

using namespace std;

const int THREAD_NUM = 2;

pthread_t g_thread[THREAD_NUM];
#ifdef USE_SPINLOCK
pthread_spinlock_t g_spin;
#else
pthread_mutex_t g_mutex;
#endif

__uint64_t g_count;

pid_t gettid()
{
    return syscall(SYS_gettid);
}

void* run_amuck(void* arg)
{
   int i, j;

   printf(&amp;quot;Thread %lu started.n&amp;quot;, (unsigned long)gettid());

   for (i = 0; i &amp;lt; 10000; i++) 
   {
#ifdef USE_SPINLOCK
       pthread_spin_lock(&amp;amp;g_spin);
#else
       pthread_mutex_lock(&amp;amp;g_mutex);
#endif
       for (j = 0; j &amp;lt; 100000; j++) 
       {
           if (g_count++ == 123456789)
              printf(&amp;quot;Thread %lu wins!n&amp;quot;, (unsigned long)gettid());
       }
#ifdef USE_SPINLOCK
       pthread_spin_unlock(&amp;amp;g_spin);
#else
       pthread_mutex_unlock(&amp;amp;g_mutex);
#endif
   }
   printf(&amp;quot;Thread %lu finished!n&amp;quot;, (unsigned long)gettid());

   return NULL;
}

int main(int argc, char *argv[])
{
   int i, threads = THREAD_NUM;
   printf(&amp;quot;Creating %d threads...n&amp;quot;, threads);
#ifdef USE_SPINLOCK
   pthread_spin_init(&amp;amp;g_spin, 0);
#else
   pthread_mutex_init(&amp;amp;g_mutex, NULL);
#endif
   for (i = 0; i &amp;lt; threads; i++)
           pthread_create(&amp;amp;g_thread[i], NULL, run_amuck, (void *) i);
   for (i = 0; i &amp;lt; threads; i++)
           pthread_join(g_thread[i], NULL);

   return 0;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;代码执行结果：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/mZQYF49.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;果然，在我们选择使临界区变得很大时，锁竞争也变得很激烈。这样，Spin lock的性能急剧下降，Mutex的性能更好。同样地，可以看出，这种情况下，Spin lock消耗了很多的user time。原因是两个线程分别运行在两个核上，大部分时间只有一个线程能拿到锁，所以另一个线程就一直在它运行的core上进行忙等待，CPU占有率一直是100%；Mutex则不同，当对锁的请求失败后，上下文切换就会发生，这样就能空出一个核来运行别的计算任务。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;根据以上的分析和测试：&lt;br&gt;（1）Mutex适合对锁操作非常频繁的场景，并且具有更好的适应性。尽管相比Spin lock会花费更多的开销（上下文切换），但是它能适合实际开发中复杂的应用场景，在保证一定性能的前提下提供更大的灵活度。&lt;br&gt;（2）spin lock的lock/unlock性能更好(花费更少的cpu指令)，但是它只适应用于临界区运行时间很短的场景。而在实际软件开发中，除非程序员对自己的程序的锁操作行为非常的了解，否则使用spin lock不是一个好主意，实际中的多线程程序对锁的操作一般会很多。&lt;br&gt;（3）最好的方式是先使用Mutex，然后如果对性能还有进一步的需求，可以尝试使用spin lock进行调优。毕竟，需要先保证程序的正确性，再考虑提升性能。    &lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;&lt;a href=&quot;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/&lt;/a&gt;  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;线程同步是多线程编程中最重要的问题之一，Linux下的POSIX threads库(Pthreads)是在Linux平台下进行多线程编程的一套API，其中线程同步最典型的应用就是用Pthreads提供的锁机制(lock)来对多个线程共享的临界区进行保护。&lt;br&gt;
    
    </summary>
    
    
      <category term="多线程" scheme="http://blog.dujiong.net/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>C++引用剖析</title>
    <link href="http://blog.dujiong.net/2016/09/14/cplusplusReference/"/>
    <id>http://blog.dujiong.net/2016/09/14/cplusplusReference/</id>
    <published>2016-09-14T11:58:41.000Z</published>
    <updated>2016-09-14T15:17:56.403Z</updated>
    
    <content type="html">&lt;p&gt;引用是C++对于C语言的一个强有力的补充，它是对象的别名，这里的对象是指广义的，不仅是用类、结构体等复杂类型来声明的变量，还包括用int，float等简单类型声明的变量。引用在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命期是不能被改变的，即自始至终只能依附于同一个变量。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;C-引用的本质&quot;&gt;&lt;a href=&quot;#C-引用的本质&quot; class=&quot;headerlink&quot; title=&quot;C++引用的本质&quot;&gt;&lt;/a&gt;C++引用的本质&lt;/h3&gt;&lt;p&gt;C++引用的本质是指针常量。&lt;br&gt;引用是个常量，不同于指针，其在声明时必须初始化。此外，引用其实也是一种指针，绑定于自身的指针。只不过二者的接口并不相同，引用的接口有一定的限制，下述。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct A
{
    char name_;
    int num_;
    A&amp;amp; a_;
};    

struct B
{
    int num_;
    B&amp;amp; b_;
};

int main()
{
    cout &amp;lt;&amp;lt; sizeof(A) &amp;lt;&amp;lt; endl;        //12
    cout &amp;lt;&amp;lt; sizeof(B) &amp;lt;&amp;lt; endl;        //8
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;32位平台下，运行上述测试代码，可以看出两个结构中对自身的引用占四个字节，是与对象的一种绑定关系，通过引用可以获得对象。&lt;/p&gt;
&lt;h3 id=&quot;指针和引用的区别&quot;&gt;&lt;a href=&quot;#指针和引用的区别&quot; class=&quot;headerlink&quot; title=&quot;指针和引用的区别&quot;&gt;&lt;/a&gt;指针和引用的区别&lt;/h3&gt;&lt;p&gt;虽然引用很多时候表现出指针的特性，但是二者是有很大区别的。&lt;br&gt;首先，引用不可以为空，但指针可以为空。前面说过，引用是对象的别名，若对象不存在，怎么可能有别名？所以，定义一个引用的时候，必须初始化。而如果有一个变量是用于指向另一个对象，但是它可能为空，这时应该使用指针。因此，在实际代码编写中，使用指针之前必须做判空操作(&lt;code&gt;if(!p==NULL)&lt;/code&gt;)，而引用就不必。&lt;br&gt;其次，引用不可以改变指向，始终绑定同一个对象，这也正是上述常量指针的表现。而指针可以改变指向。需要注意的是，虽然引用不可以改变指向，但是可以改变初始化对象的内容。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int i = 10;
int&amp;amp; ref = i;
ref++;
cout &amp;lt;&amp;lt; &amp;quot;i &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; ref &amp;quot; &amp;lt;&amp;lt; ref &amp;lt;&amp;lt; endl;

int j = 20;
ref = j;
ref++;
cout &amp;lt;&amp;lt; &amp;quot;i &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; ref &amp;quot; &amp;lt;&amp;lt; ref &amp;lt;&amp;lt; &amp;quot; j &amp;quot; &amp;lt;&amp;lt; j &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;输出为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/qgy7FOO.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以看出，对ref的++操作是直接反应到所绑定变量之上，所以，第一个cout之后i和ref都变为了11，对ref重新赋值并不影响它的指向。，它仍然指向的是i，而不是j，只是其绑定变量的值变为了j的值20，然后再对ref++，最终，i和ref都变为了21，而j，仍然是20。&lt;br&gt;第三，引用的大小是所绑定的变量的大小，因为引用只是一个别名而已；而指针对应的是指针本身的大小，4个字节（32bits）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct    A
{
    char name_;
    int num_;
    int sum_
};    

int main()
{
    A a;
    A&amp;amp; ref = a;
    cout &amp;lt;&amp;lt; sizeof(ref) &amp;lt;&amp;lt; endl;  //12
    A* p = new A();
    cout &amp;lt;&amp;lt; sizeof(p) &amp;lt;&amp;lt; endl;    //4
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，引用比指针更安全。因为不存在空引用，并且引用一旦被初始化为指向一个对象，它就不能被改变为另一个对象的引用，因此引用很安全。而对于指针来说，它可以随时指向别的对象，并且可以不被初始化，或为NULL，所以不安全。&lt;br&gt;总而言之—指针指向一块内存，它的内容是指向内存的地址；而引用则是某块内存的别名，引用不改变指向。&lt;/p&gt;
&lt;h3 id=&quot;const&quot;&gt;&lt;a href=&quot;#const&quot; class=&quot;headerlink&quot; title=&quot;const&quot;&gt;&lt;/a&gt;const&lt;/h3&gt;&lt;p&gt;很多C++程序员一提到const就头疼，特别是对常量指针、指针常量、常量指针常量等概念，现在还要加上引用…&lt;br&gt;首先总结下如何判定const是修饰指针，还是修饰指针所指向的数据。有一个简单的规则，画一条垂直穿过指针声明星号(*)的线，如果const出现在线的左边，则指针指向的数据位常量；如果const出现在右边，指针本身为常量。   &lt;/p&gt;
&lt;h4 id=&quot;常量指针和常量引用&quot;&gt;&lt;a href=&quot;#常量指针和常量引用&quot; class=&quot;headerlink&quot; title=&quot;常量指针和常量引用&quot;&gt;&lt;/a&gt;常量指针和常量引用&lt;/h4&gt;&lt;p&gt;常量指针：指向常量的指针，表示指向的对象是常量。比如&lt;code&gt;const int* p = &amp;amp;a&lt;/code&gt;，即告诉编译器*p是常量，不能将*p作为左值进行操作。&lt;br&gt;常量引用：指向常量的引用，表示指向的对象是常量。和指针一样不能利用引用对指向的变量进行重新赋值操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int main()
{   
    int i = 10;    
    const int&amp;amp; ref = i;      
    ref = 20;             //error    
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;指针常量和引用常量&quot;&gt;&lt;a href=&quot;#指针常量和引用常量&quot; class=&quot;headerlink&quot; title=&quot;指针常量和引用常量&quot;&gt;&lt;/a&gt;指针常量和引用常量&lt;/h4&gt;&lt;p&gt;指针常量：表示指针本身是常量，所以，在定义指针常量时必须进行初始化。比如&lt;code&gt;int* const p = &amp;amp;b&lt;/code&gt;，即告诉编译器，p是常量，不能作为左值进行操作，但是允许修改间接访问值，即*p可以修改。&lt;br&gt;引用常量：这是引用天生俱来的属性，不用再引用const来定义。   &lt;/p&gt;
&lt;h4 id=&quot;常量指针常量和常量引用常量&quot;&gt;&lt;a href=&quot;#常量指针常量和常量引用常量&quot; class=&quot;headerlink&quot; title=&quot;常量指针常量和常量引用常量&quot;&gt;&lt;/a&gt;常量指针常量和常量引用常量&lt;/h4&gt;&lt;p&gt;常量指针常量：指向常量的指针常量，如&lt;code&gt;const int* const p = &amp;amp;c&lt;/code&gt;，告诉编译器，p和*p都是常量，他们都不能作为左值进行操作。&lt;br&gt;不存在所谓的“常量引用常量”，因为跟上面讲的一样，引用变量就是引用常量。C++不区分变量的const引用和const变量的引用。绝不能给引用本身重新赋值，使它指向另一个变量，因此引用总是const的。如果对引用应用关键字const，起作用就是使其目标成为const变量。即没有：&lt;code&gt;const int const&amp;amp; a = 1&lt;/code&gt;,只有&lt;code&gt;const int&amp;amp; a = 1&lt;/code&gt;。     &lt;/p&gt;
&lt;h3 id=&quot;指针传递和引用传递&quot;&gt;&lt;a href=&quot;#指针传递和引用传递&quot; class=&quot;headerlink&quot; title=&quot;指针传递和引用传递&quot;&gt;&lt;/a&gt;指针传递和引用传递&lt;/h3&gt;&lt;p&gt;最后，介绍一下指针传递参数和引用传递参数的区别。&lt;br&gt;指针传递参数本质上是值传递方式，它所传递的是一个地址值。值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，即在栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。&lt;br&gt;引用传递的过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量。所以，被调函数对形参做的任何操作都影响了主调函数中的实参变量。&lt;br&gt;所以，对于指针传递的参数，如果改变被调函数中的指针地址，它影响不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关指针变量，那就得使用指向指针的指针，或者指针引用。&lt;br&gt;下面以一个代码来说明指针传递和引用传递的区别。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void func1(int x)
{
    x = x + 1;
}

void func2(int *x)
{
    (*x) = (*x) + 1;
}

void func3(int&amp;amp; x)
{
    x = x + 1;
}

int main()
{
    int a = 0;
    func1(a);
    cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;    //0
    int b = 0;
    func2(&amp;amp;b);            
    cout &amp;lt;&amp;lt; b &amp;lt;&amp;lt; endl;    //1
    int c = 0;
    func(c);        
    cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; endl;    //1
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;三个函数分别对应值传递、指针传递和引用传递，值传递中，函数体内的x是外部变量的一份拷贝，改变x不会影响a。而指针传递中，函数体内的x是指向外部b的指针，改变该指针的内容将导致b值改变。引用传递中，函数体内的x是外部变量的引用，即二值是同一个东西，改变x等于改变c。&lt;br&gt;但是，要通过指针参数传递来改变主调函数中的相关指针变量，那就得使用指向指针的指针，或者指针引用。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;引用是C++对于C语言的一个强有力的补充，它是对象的别名，这里的对象是指广义的，不仅是用类、结构体等复杂类型来声明的变量，还包括用int，float等简单类型声明的变量。引用在逻辑上不是独立的，它的存在具有依附性，所以引用必须在一开始就被初始化，而且其引用的对象在其整个生命期是不能被改变的，即自始至终只能依附于同一个变量。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>线性排序算法：计数排序、基数排序和桶排序</title>
    <link href="http://blog.dujiong.net/2016/09/07/LinearSort/"/>
    <id>http://blog.dujiong.net/2016/09/07/LinearSort/</id>
    <published>2016-09-07T12:43:51.000Z</published>
    <updated>2016-09-16T11:48:04.705Z</updated>
    
    <content type="html">&lt;p&gt;在计算机科学中，排序是一个非常基础的算法。不同的排序算法有不同的时间和空间开销。在这么多的排序算法中，根据在排序的最终结果中，各元素的次序是否依赖于它们之间的比较，可以将排序算法分为两大类：基于比较的排序和非基于比较的排序。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;基于比较的排序需要对序列中的数据进行比较，如我们最常用的快速排序、堆排序和归并排序。根据决策树模型可以证明：基于比较的排序算法的时间复杂度是不能突破O(NlogN)的。（《算法导论》8.1）&lt;br&gt;而非基于比较的排序，如本文将要介绍的计数排序、基数排序和桶排序，则可以突破O(NlogN)的时间下限。当然，这样的非比较的排序的使用会有一些条件的限制，比如元素的大小，所以，在一般在特定场合下，非基于比较的排序算法能够巧妙地解决一些问题。     &lt;/p&gt;
&lt;h3 id=&quot;计数排序&quot;&gt;&lt;a href=&quot;#计数排序&quot; class=&quot;headerlink&quot; title=&quot;计数排序&quot;&gt;&lt;/a&gt;计数排序&lt;/h3&gt;&lt;p&gt;首先介绍计数排序。&lt;br&gt;计数排序假设n个输入元素的每一个都是在0到K区间内的一个整数，其中K为某个正整数。计数排序的基本思想是，对每一个输入元素x，确定小于x的元素个数。利用这一信息，就可以直接把x放到它在输出数组的位置上了。比如，如果有17个元素小于x，则x就应该放在第18（或17，看数组a[0]怎么处理）个输出位置上。&lt;br&gt;按照这个思想，可以写出计数排序的伪代码：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;COUNTING-SORT(A,B,k)
    let C[0,k] be a new array
    for i=0 to k
        C[i]=0
    for j=0 to A.length-1
        C[A[j]]=C[A[j]]+1
    for i=1 to k
        C[i]=C[i]+C[i-1]
    for j=A.length-1 to 0
        B[C[A[j]]-1]=A[j]
        C[A[j]]=C[A[J]]-1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;说明一下，《算法导论》中的伪代码采用的是输入数组为A[1..n],输出数组为B[1..n]。这里没有这样做，而是采用传统的0~n-1的数组下标作为输入输出，本质是一样的。     &lt;/p&gt;
&lt;p&gt;下面以数据2 5 3 0 2 3 0 3为例说明计数排序的执行过程。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/pgoZnNn.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/Yz80C5w.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/hvHJ4Lx.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;容易看出，第一个for循环所花时间为Θ(k)，第二个for循环所花时间为Θ(n)，第三个for循环所花时间为Θ(k)，最后一个循环所花时间为Θ(n)。这样，总的时间代价就是Θ(n+k)。所以，当k=O(n)时，一般可以采用计数排序，这时运行时间为Θ(n)。          &lt;/p&gt;
&lt;h3 id=&quot;桶排序&quot;&gt;&lt;a href=&quot;#桶排序&quot; class=&quot;headerlink&quot; title=&quot;桶排序&quot;&gt;&lt;/a&gt;桶排序&lt;/h3&gt;&lt;p&gt;桶排序假设输入数据服从均匀分布，平均情况下它的时间代价为O(n)。与计数排序类似，因为对输入数据做了某种假设，桶排序的速度也很快。具体来说，计数排序假设输入数据都属于一个小区间内的整数，而桶排序则假设输入是由一个随机过程产生，该过程将元素均匀、独立地分布在[0,1)区间上。我们把区间[0,1)划分成n个相同大小的子区间，称为桶。将n个记录分布到各个桶中去。如果有多于一个记录分到同一个桶中，需要进行桶内排序。&lt;br&gt;在桶排序的代码中，假设输入是一个包含n个元素的数组A，且每个元素A[i]满足0&amp;lt;=A[i]&amp;lt;1。此外，算法还需要一个临时数组B[0..n-1]来存放链表（即桶），并假设存在一种用于维护这些链表的机制。在分完桶后，对每个桶进行排序，然后合并最后的结果。&lt;br&gt;桶排序用伪代码表示如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;BUCKET-SORT(A)
    n=A.length
    let B[0..n-1] to be a new array
    for i=0 to n-1
        make B[i] an empty list
    for i=1 to n
        insert A[i] to list B[nA[i]]
    for i=0 to n-1
        sort list B[i] with insertion sort
    concatenate the list B[0],B[1],...,B[n-1] together in order
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;例如，要对大小为[1..1000]范围内的n个整数A[1,n]排序，可以把桶设为大小为10的范围，具体而言，设集合B[0]存储[1..10)的整数，集合B[2]存储(10,20]的整数…依次，总共有100个桶。然后对A[1,n]从头到尾扫描一遍，把每个A[i]放入对应的桶B[j]中。然后再对这100个桶中每个桶里的数字进行排序。最后依次输出每个桶里面的数字，这样得到的就是排好序的序列了。&lt;br&gt;桶排序的平均时间复杂度为线性的O(N+C)，其中C为桶内快排的时间复杂度，如果对于同样的N，桶数量M越大，其效率越大，最好的时间复杂度达到O(N)。但是，桶排序的空间复杂度为O(N+M)，如果输入数据很庞大，而桶的数量也非常多，则空间代价是昂贵的。 &lt;/p&gt;
&lt;h3 id=&quot;基数排序&quot;&gt;&lt;a href=&quot;#基数排序&quot; class=&quot;headerlink&quot; title=&quot;基数排序&quot;&gt;&lt;/a&gt;基数排序&lt;/h3&gt;&lt;p&gt;另外一种线性排序方式是基数排序。下面通过一个例子来说明基数排序的思想。&lt;br&gt;假设有待排序的数据序列如下：&lt;br&gt;73 22 93 43 55 14 28 65 39 81&lt;br&gt;首先根据个位数的数值，在遍历数据时将它们各自分到编号为0-9的桶中，分配的结果如下图所示：&lt;br&gt; &lt;img src=&quot;http://i.imgur.com/eOVN7vZ.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;分配结束后，接下来将所有桶中所盛数据按照桶号由小到大依次重新收集起来，得到下列仍然无序的数据序列：&lt;br&gt;81 22 73 93 43 14 55 65 28 39&lt;br&gt;接着，再进行一次分配，这次根据十位数值来分配（原理同上），分配结构如下所示。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/sLQPdaX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样，原来无序的数据序列已经排序完毕。如果排序的位数大于2，则重复以上动作至最后一位。&lt;br&gt;当然，上面的排序过程中有一个还需探究的问题，即在原来的序列中的73 93 43（个位数相同）三个数的顺序，在经过第一次分配之后，在桶中的顺序由底至上应该为73 93 43（即装的迟的在最上面），但是在3号桶中刚好相反。这正是基数排序稳定的原因，分配时是从预排数据序列的末尾开始进行，逐次分配至首位。&lt;br&gt;所以，不难看出，基数排序原理类似于桶排序，只是这里总是需要十个桶，多次使用。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/*
 * getdigit(arr[i],k)用于获得arr[i]第k位上的数字
 */

void lsdRadixSort(int arr[], int begin, int end, int d)
{
    const int radix = 10;
    int count[radix];
    int i,j;

    int *bucket = (int*)malloc((end-start+1)*sizeof(int));
    for(int k=1;k&amp;lt;=d;k++)
    {
        for(i=0;i&amp;lt;radix;i++)
        {
            count[i]=0;
        }
        for(i=begin;i&amp;lt;=end;i++)
        {
            count[getdigit(arr[i], k)]++;    
        }    
        for(i=1;i&amp;lt;radix;i++)
        {
            count[i] = count[i] + count[i-1];
        }
        for(i=end;i&amp;gt;=end;--i)
        {
            j = getdigit(arr[i], k);
            bucket[count[j]-1] = arr[i];
            --count[j];
        }
        for(i=begin,j=0;i&amp;lt;=end;++i,++j)
        {
            arr[i] = bucket[j];
        }
    }
    free(bucket);    
}            
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以，给定n个d位数，其中每一个数位有k个可能的取值，所以，每一轮排序耗时Θ(n+k)，那么整个基数排序的总时间为Θ(d(n+k))，当d为常数且k=O(n)时，基数排序具有线性的时间代价。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;以上三种线性时间排序方法突破了基于比较排序的O(NlogN)的时间下界，这样的非比较排序的方法会有一些使用场景的限制，比如元素的大小，所以，在特定的条件下，会体现出较好的性能。&lt;br&gt;本质上，都体现了用空间换时间的理念。        &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在计算机科学中，排序是一个非常基础的算法。不同的排序算法有不同的时间和空间开销。在这么多的排序算法中，根据在排序的最终结果中，各元素的次序是否依赖于它们之间的比较，可以将排序算法分为两大类：基于比较的排序和非基于比较的排序。&lt;br&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>从BlockingQueue再探线程同步</title>
    <link href="http://blog.dujiong.net/2016/08/26/muduo-7/"/>
    <id>http://blog.dujiong.net/2016/08/26/muduo-7/</id>
    <published>2016-08-26T05:18:11.000Z</published>
    <updated>2016-08-26T07:49:10.062Z</updated>
    
    <content type="html">&lt;p&gt;BlockingQueue（阻塞队列）在程序中被大量使用，特别是在多线程程序中，譬如需要提高吞吐量时采用将请求直接扔到阻塞队列中，然后返回，由其他线程从阻塞队列中获取请求再进一步处理。而经典的生产者-消费者模型，正是阻塞队列大放光彩之处。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Java中java.util.concurrent包便提供了BlockingQueue接口和其几种实现方式。muduo中也实现了无大小限制的BlockingQueue和固定大小的BoundedBlockingQueue。下面以BlockingQueue为例进行说明。     &lt;/p&gt;
&lt;h3 id=&quot;BlockingQueue的实现&quot;&gt;&lt;a href=&quot;#BlockingQueue的实现&quot; class=&quot;headerlink&quot; title=&quot;BlockingQueue的实现&quot;&gt;&lt;/a&gt;BlockingQueue的实现&lt;/h3&gt;&lt;p&gt;muduo中BlockingQueue的实现非常简单，队列采用C++标准库中的deque，无大小限制，唯一需要注意的是使用互斥锁和条件变量做好线程同步。&lt;br&gt;BlockingQueue实现时运用了模板。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template&amp;lt;typename T&amp;gt;
class BlockingQueue : boost::noncopyable
{
    public:
        BlockingQueue() : mutex_(), notEmpty_(mutex_), queue_() {}

        void put(const T&amp;amp; x)
        {
            MutexLockGuard lock(mutex_);
            queue_.push_back(x);
            notEmpty_.notift();
        }    

        T take()
        {
            MutexLockGuard lock(mutex_);
            while(queue_.empty())    
            {
                notEmpty_.wait();
            }
            assert(!queue_.empty());
            T front(queue_.front());
            queue_.pop_front();
            return front;
        }

        size_t size() const
        {
            MutexLockGuard lock(mutex_);
            return queue_.size();
        }
    private:
        mutable MutexLock mutex_;
        Condition notEmpty_;
        std::deque&amp;lt;T&amp;gt; queue_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BlockingQueue提供了取元素(take)、放入元素(put)和取得队列大小(size)三个public成员函数完成对阻塞队列的操作。&lt;/p&gt;
&lt;h3 id=&quot;线程同步的一些细究&quot;&gt;&lt;a href=&quot;#线程同步的一些细究&quot; class=&quot;headerlink&quot; title=&quot;线程同步的一些细究&quot;&gt;&lt;/a&gt;线程同步的一些细究&lt;/h3&gt;&lt;p&gt;细究BlockingQueue的实现，可以总结并学习一些问题。&lt;/p&gt;
&lt;h4 id=&quot;spurious-wakeup&quot;&gt;&lt;a href=&quot;#spurious-wakeup&quot; class=&quot;headerlink&quot; title=&quot;spurious wakeup&quot;&gt;&lt;/a&gt;spurious wakeup&lt;/h4&gt;&lt;p&gt;首先是大名鼎鼎的spurious wakeup（虚假唤醒）。即对应代码中&lt;code&gt;while(queue_.empty())&lt;/code&gt;循环，可否改为&lt;code&gt;if(queue_.empty())&lt;/code&gt;？&lt;br&gt;答案是不能，否则会导致虚假唤醒，因为&lt;code&gt;notEmpty_.wait()&lt;/code&gt;封装的&lt;code&gt;pthread_cond_wait()&lt;/code&gt;不仅能被&lt;code&gt;pthread_cond_signal()/pthread_cond_broadcast()&lt;/code&gt;唤醒，而且还可能会被其他的信号唤醒，后者便是虚假唤醒，这时条件并不满足。所以，不仅要在&lt;code&gt;pthread_cond_wait()&lt;/code&gt;前检查条件是否成立，在&lt;code&gt;pthread_cond_wait()&lt;/code&gt;之后也要检查。 &lt;/p&gt;
&lt;h4 id=&quot;unlock和signal的顺序&quot;&gt;&lt;a href=&quot;#unlock和signal的顺序&quot; class=&quot;headerlink&quot; title=&quot;unlock和signal的顺序&quot;&gt;&lt;/a&gt;unlock和signal的顺序&lt;/h4&gt;&lt;p&gt;muduo中采用RAII手法封装了互斥器，所以，在进行put操作时，是先notify其他线程，再释放锁。那么反过来呢，先释放锁，再notify其他线程？这二者有什么差别呢？&lt;br&gt;先notify，再释放锁，在某些平台下存在性能问题，原因是，假设线程1阻塞在条件变量上wait，线程2将其唤醒（notify），系统执行上下文切换，但是线程2仍持有锁，导致线程1不能从&lt;code&gt;pthread_cond_wait()&lt;/code&gt;(需要持有锁)返回，所以线程1又阻塞在互斥锁上，直到线程2释放锁，线程1才可以运行。&lt;br&gt;福音是，对于此问题，Glibc中使用的线程库NPTL对此进行了优化。&lt;br&gt;另一种情况是先释放锁，再notify，这样可以避免上述问题，但是，这样可能会唤醒其他阻塞在此mutex上的线程，而不是处于wait条件变量的线程，所以，这种情况下，在唤醒之后，最好还得再check下predicate（类似于spurious wakeup）。&lt;br&gt;所以，Pthreads实现平台下，建议使用第一种方法，可以避免一些&lt;a href=&quot;http://www.domaigne.com/blog/computing/condvars-signal-with-mutex-locked-or-not/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;obscure bugs&lt;/a&gt;,除非采用第二种有较明显的性能的提升。&lt;/p&gt;
&lt;h4 id=&quot;Linux快速同步机制（Futex）&quot;&gt;&lt;a href=&quot;#Linux快速同步机制（Futex）&quot; class=&quot;headerlink&quot; title=&quot;Linux快速同步机制（Futex）&quot;&gt;&lt;/a&gt;Linux快速同步机制（Futex）&lt;/h4&gt;&lt;p&gt;Futex（Fast Userspace mutexes，快速用户空间互斥体），是在Linux上实现锁定和构建高级抽象锁如信号量和POSIX互斥的基本工具，首先出现在Linux 2.5.7版。&lt;br&gt;在传统的Unix系统中，System V IPC，如消息队列，信号量，socket等进程间同步机制都是对一个内核对象操作来完成的，这个内核对象对于要同步的进程都是可见的，其提供了共享的状态信息和原子操作。当进程间要同步的时候必须要通过系统调用在内核中完成。可是研究发现，很多同步状态是无竞争的，即某个进程进入互斥去，到从互斥区出来这段时间，常常是没有进程进也要进入这个互斥区或者请求同一个同步变量的。而这种情况下，进程也要陷入到内核去看有没有竞争者，退出的时候还要陷入内核去看有没有进程等待在同一变量上。这些不必要的系统调用（陷入内核）造成了大量的性能开销。&lt;br&gt;而Futex就是在这样的背景下被提出的，以减少不必要的系统调用（内核陷入）。Funtex是一种用户态和内核态混合的同步机制。首先，同步的进程间通过mmap共享一段内存，Futex变量就位于这段共享的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex，而不用再执行系统调用了。当通过访问futex变量告诉进程有竞争发生，再去执行系统调用以完成相应的处理。futex通过这样的机制，大大提高了low-contention时的效率。     &lt;/p&gt;
&lt;h5 id=&quot;Futex机制&quot;&gt;&lt;a href=&quot;#Futex机制&quot; class=&quot;headerlink&quot; title=&quot;Futex机制&quot;&gt;&lt;/a&gt;Futex机制&lt;/h5&gt;&lt;p&gt;所有的Futex同步操作都从用户空间开始，首先创建一个futex同步变量，也就是位于共享内存的一个整型计数器。&lt;br&gt;当进程尝试持有锁或者要进入互斥区的时候，对futex执行”down”操作，即原子性的给futex同步变量减1。如果同步变量变为0，则没有竞争发生，进程照常执行。如果同步变量是个负数，则意味着有竞争发生，需要调用futex系统调用的futex_wait操作休眠当前进程。&lt;br&gt;当进程释放锁或者要离开互斥区的时候，对futex进行”up”操作，即原子性的给futex同步变量加1。如果同步变量由0变成1，则没有竞争发生，进程照常执行。如果加之前同步变量是负数，则意味着有竞争发生，需要调用futex系统调用的futex_wake操作唤醒一个或者多个等待进程。&lt;br&gt;这里的原子性加减通常是用CAS(Compare and Swap)完成的，与平台相关。CAS的基本形式是：CAS(addr,old,new),当addr中存放的值等于old时，用new对其替换。在x86平台上有专门的一条指令来完成它: cmpxchg。    &lt;/p&gt;
&lt;h5 id=&quot;Linux下使用glibc开发&quot;&gt;&lt;a href=&quot;#Linux下使用glibc开发&quot; class=&quot;headerlink&quot; title=&quot;Linux下使用glibc开发&quot;&gt;&lt;/a&gt;Linux下使用glibc开发&lt;/h5&gt;&lt;p&gt;上面讲了很多关于Futex的机制，重点是弄清楚其中的原理和思想，我们在实际的多线程程序开发中却没有必要去实现自己的futex同步原语。&lt;br&gt;因为NPTL库实现了POSIX标准定义的线程同步机制，他们都构造与futex之上，而glibc又使用NPTL作为自己的线程库。所以，在日常程序开发中，只需要正确地使用glibc所提供的同步方式，并在使用它们的过程中，意识到它们是利用futex机制和linux配合完成同步操作，重点是思想。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;BlockingQueue（阻塞队列）在程序中被大量使用，特别是在多线程程序中，譬如需要提高吞吐量时采用将请求直接扔到阻塞队列中，然后返回，由其他线程从阻塞队列中获取请求再进一步处理。而经典的生产者-消费者模型，正是阻塞队列大放光彩之处。&lt;br&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
      <category term="多线程" scheme="http://blog.dujiong.net/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>单例模式</title>
    <link href="http://blog.dujiong.net/2016/08/21/Singleton/"/>
    <id>http://blog.dujiong.net/2016/08/21/Singleton/</id>
    <published>2016-08-21T13:57:13.000Z</published>
    <updated>2016-08-26T08:23:05.770Z</updated>
    
    <content type="html">&lt;p&gt;单例（Singleton）模式可能是被使用最广泛的一个设计模式之一，也可能是面试中被问到或被要求书写最多的一个设计模式了。该设计模式的主要目的是要求在整个系统中只出现一个类的实例。&lt;br&gt;下面采用Java语言描述单例模式的几种实现方式。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h3 id=&quot;懒汉-amp-amp-线程不安全&quot;&gt;&lt;a href=&quot;#懒汉-amp-amp-线程不安全&quot; class=&quot;headerlink&quot; title=&quot;懒汉&amp;amp;&amp;amp;线程不安全&quot;&gt;&lt;/a&gt;懒汉&amp;amp;&amp;amp;线程不安全&lt;/h3&gt;&lt;p&gt;懒汉式单例在调用取得实例方法的时候实例化对象。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton{
    private staic Singleton singleton = null;
    private Singleton()　{ }
    public static Singleton getInstance(){
        if(singleton == null){
            singleton = new Singleton();
        }
        return singleton;        
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从代码中可以看出，采用私有的构造函数，表明这个类是不可能形成实例了，这样可以防止类出现多个实例。所以，采用一个静态的方式（getInstance()）来让其形成实例。在getInstance()方法中，先判断是否已经形成实例，如果已经形成则直接返回，否则创建实例，保存在自己类的私有成员中。&lt;br&gt;但是，问题来了，因为是全局性的实例，这种方式最大的问题就是不支持多线程，在多线程情况下，多个线程同时调用getInstance()的话，那么，可能会有多个线程同时通过(singleton == null)的条件检查，最终创建出多个实例。所以，应加入同步机制以适应多线程环境。    &lt;/p&gt;
&lt;h3 id=&quot;懒汉-amp-amp-线程安全&quot;&gt;&lt;a href=&quot;#懒汉-amp-amp-线程安全&quot; class=&quot;headerlink&quot; title=&quot;懒汉&amp;amp;&amp;amp;线程安全&quot;&gt;&lt;/a&gt;懒汉&amp;amp;&amp;amp;线程安全&lt;/h3&gt;&lt;p&gt;所以，加入synchronized做同步。得到如下所示的线程安全版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton{
    private static Singleton singleton = null;
    private Singleton() { }
    public static synchronized Singleton getInstance(){
        if(singleton == null){
            singleton = new Singleton();
        }
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;饿汉&quot;&gt;&lt;a href=&quot;#饿汉&quot; class=&quot;headerlink&quot; title=&quot;饿汉&quot;&gt;&lt;/a&gt;饿汉&lt;/h3&gt;&lt;p&gt;饿汉式单例在单例类被加载的时候，就实例化一个对象交给自己的引用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Singleton {
    private static final Singleton singleton = new Singleton();
    private Singleton(){ } 
    public static Singleton getInstance(){
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这种方式在实际中比较常用，基于classloader机制避免了多线程的同步问题，没有加锁，执行效率较高。但是，仍美中不足的是：singleton在类加载的时候就实例化，这样就算是getInstance()没有被调用，类也被初始化了。这样的话，有时会与我们想要的行为不一样，比如，在类的构造函数中，有一些事需要依赖于别的类，我们希望它能在第一次getInstance()时才被真正创建。这样，可以自己控制真正的类创建的时刻，而不是把类的创建委托给类装载器。&lt;br&gt;所以又出现了下面这种方式。&lt;/p&gt;
&lt;h3 id=&quot;静态内部类&quot;&gt;&lt;a href=&quot;#静态内部类&quot; class=&quot;headerlink&quot; title=&quot;静态内部类&quot;&gt;&lt;/a&gt;静态内部类&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public class Singleton{
    private static class SingletonHolder{
        private static Singleton singleton = new Singleton();
    }        
    private Singleton() { }
    public static Singleton getInstance(){
        return SingletonHolder.singleton;
    } 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样的话，由于SingletonHolder是私有的，除了getInstance()之外没有方法访问它，因此只有在getInstance()被调用时才会真正创建。&lt;/p&gt;
&lt;h3 id=&quot;双重锁校验锁&quot;&gt;&lt;a href=&quot;#双重锁校验锁&quot; class=&quot;headerlink&quot; title=&quot;双重锁校验锁&quot;&gt;&lt;/a&gt;双重锁校验锁&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public class Singleton{
    private volatile static Singleton singleton = null;
    private Singleton() { }
    public static Singleton getInstance(){
        if(singleton == null){
            synchronized(Singleton.class){
                if(singleton == null){
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一个if判定是说，如果实例创建了，就不需要同步了，直接return singleton就可以了。不然的话，就开始同步线程。第二个if判定是说，如果被同步的线程中，已经创建了对象，那么就不用创建了。这样，保证了多线程条件下的安全。&lt;br&gt;此外，由于&lt;code&gt;singleton = new Singleton();&lt;/code&gt;不是原子操作，所以使用volatile关键字禁止指令重排序优化。&lt;/p&gt;
&lt;h3 id=&quot;枚举&quot;&gt;&lt;a href=&quot;#枚举&quot; class=&quot;headerlink&quot; title=&quot;枚举&quot;&gt;&lt;/a&gt;枚举&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;public enum Singleton{
    INSTANCE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，简直不要太简单哦！是的，虽然他可能还包含实例变量和实例方法。默认枚举实例的创建是线程安全的，所以不需要担心线程安全的问题。当然，需要自行负责枚举中的其他任何方法的线程安全。&lt;br&gt;这样，通过Singleton.INSTANCE来访问，这比上述的getInstance()方法简单多了。而且，更重要的是，枚举单例，JVM对序列化有保证。 &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;总结一下上述的单例模式实现，一般情况下，不建议使用两种懒汉方式，建议使用饿汉方式。当要求延迟加载时，使用静态内部类形式。而如果涉及到反序列化创建对象时，可以尝试用枚举方式。   &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;单例（Singleton）模式可能是被使用最广泛的一个设计模式之一，也可能是面试中被问到或被要求书写最多的一个设计模式了。该设计模式的主要目的是要求在整个系统中只出现一个类的实例。&lt;br&gt;下面采用Java语言描述单例模式的几种实现方式。&lt;br&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="http://blog.dujiong.net/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>shared_ptr的注意事项</title>
    <link href="http://blog.dujiong.net/2016/08/08/shared-ptr/"/>
    <id>http://blog.dujiong.net/2016/08/08/shared-ptr/</id>
    <published>2016-08-08T13:38:44.000Z</published>
    <updated>2016-08-27T13:24:49.329Z</updated>
    
    <content type="html">&lt;p&gt;前面在&lt;a href=&quot;http://blog.dujiong.net/2016/05/15/cplusplus-sematics/&quot;&gt;浅谈C++值语义和对象语义&lt;/a&gt;一文中简要的阐述了一下智能指针shared_ptr的作用和用法，作为C++11中最为广泛使用的智能指针，shared_ptr虽然解决了裸指针的诸多问题，但是它并非完美、无懈可击，所以，本文就shared_ptr使用过程中需要注意的一些问题做一下总结。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;循环引用&quot;&gt;&lt;a href=&quot;#循环引用&quot; class=&quot;headerlink&quot; title=&quot;循环引用&quot;&gt;&lt;/a&gt;循环引用&lt;/h3&gt;&lt;p&gt;首当其冲的便是shared_ptr造成的循环引用。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class BaseClass;
class DerivedClass;

typedef std::shared_ptr&amp;lt;BaseClass&amp;gt; BaseClassPtr;
typedef std::shared_ptr&amp;lt;DerivedClass&amp;gt; DerivedClassPtr;

class BaseClass
{
    public:
        DerivedClassPtr derivedPtr;
        ~BaseClass()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~BaseClass()&amp;quot; &amp;lt;&amp;lt; endl;
        }
};

class DerivedClass
{
    public:
        BaseClassPtr basePtr;
        ~DerivedClass()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~DerivedClass()&amp;quot; &amp;lt;&amp;lt; endl;
        }
};

int main()
{
    BaseClassPtr base(new BaseClass());
    DerivedClassPtr derived(new DerivedClass());

    base-&amp;gt;derivedPtr = derived;
    derived-&amp;gt;basePtr = base;

    cout &amp;lt;&amp;lt; base.use_count() &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; derived.use_count() &amp;lt;&amp;lt; endl;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;程序运行结果如下。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/dqHRq8F.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;从结果可以看出，堆上的BaseClass和DerivedClass都没有被析构，因为二者的引用都为1，并形成了循环引用，类似于“放开我的引用”，“你先放开我的我就放你的”的恶性循环，所以，造成了内存泄露。&lt;br&gt;解决方法是使用弱智能指针weak_ptr，让BaseClass和DerivedClass分别持有对方的weak_ptr，而不是shared_ptr，weak_ptr也是一个引用计数型智能指针，但是它不增加对象的引用计数。这样，就可以保证内存正常释放。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/cG2fmZx.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;h3 id=&quot;线程安全&quot;&gt;&lt;a href=&quot;#线程安全&quot; class=&quot;headerlink&quot; title=&quot;线程安全&quot;&gt;&lt;/a&gt;线程安全&lt;/h3&gt;&lt;p&gt;shared_ptr是引用计数型智能指针，几乎所有的实现都采用在堆上存放计数值的方法。具体来说，shared_ptr&lt;foo&gt;包含两个成员，一个是指向Foo的指针ptr，另一个是ref_count指针（不一定是原始指针），指向堆上的ref_count对象。ref_count对象有多个成员。&lt;/foo&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/WZNNAPg.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以，如果执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shared_ptr&amp;lt;Foo&amp;gt; x(new Foo);
shared_ptr&amp;lt;Foo&amp;gt; y = x;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;y=x将会涉及两个成员的拷贝,ptr和ref_count指针。这两步不是原子的，所以在多线程中会有race condition，需要加锁保护。     &lt;/p&gt;
&lt;h3 id=&quot;内存多次释放&quot;&gt;&lt;a href=&quot;#内存多次释放&quot; class=&quot;headerlink&quot; title=&quot;内存多次释放&quot;&gt;&lt;/a&gt;内存多次释放&lt;/h3&gt;&lt;p&gt;shared_ptr多次引用同一数据会导致内存多次释放。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

int main()
{
    int* ptr = new int(100);
    std::shared_ptr sptr1(ptr);
    ...
    std::shared_ptr sptr2(ptr);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只分配了一次内存，却两次释放。&lt;/p&gt;
&lt;h3 id=&quot;enable-shared-from-this&quot;&gt;&lt;a href=&quot;#enable-shared-from-this&quot; class=&quot;headerlink&quot; title=&quot;enable_shared_from_this&quot;&gt;&lt;/a&gt;enable_shared_from_this&lt;/h3&gt;&lt;p&gt;当使用智能指针时，类的某些成员函数需要返回的是管理自身的shared_ptr，这时就需要使A继承自enable_shared_from_this（顾名思义，将this指针变身为shared_ptr），然后通过其成员函数shared_from_this()返回指向自身的shared_ptr。      &lt;/p&gt;
&lt;p&gt;首先看没有使用它会发生什么？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class A
{
    public:
        ~A()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~A()&amp;quot; &amp;lt;&amp;lt; endl;
        }
        shared_ptr&amp;lt;A&amp;gt; get_sptr()
        {
            return shared_ptr&amp;lt;A&amp;gt;(this);
        }
};

int main()
{
    shared_ptr&amp;lt;A&amp;gt; a(new A());
    shared_ptr&amp;lt;A&amp;gt; b = a-&amp;gt;get_sptr();

    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/21rnuTE.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以看出，只new了一个A对象，但是却调用了两次析构函数。产生这个错误的原因get_sptr()成员函数中将shared_ptr中的引用计数器的值加了1。所以，需要解决的是，怎样通过一个类的成员函数获取当前对象的shared_ptr？&lt;br&gt;方法就是使类继承enable_shared_from_this，然后在需要shared_ptr的地方调用其成员函数shared_from_this()即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;memory&amp;gt;

using namespace std;

class A : public enable_shared_from_this&amp;lt;A&amp;gt;
{
    public:
        ~A()
        {
            cout &amp;lt;&amp;lt; &amp;quot;~A()&amp;quot; &amp;lt;&amp;lt; endl;
        }
        shared_ptr&amp;lt;A&amp;gt; get_sptr()
        {
            return shared_from_this();
        }
};

int main()
{
    shared_ptr&amp;lt;A&amp;gt; a(new A());
    shared_ptr&amp;lt;A&amp;gt; b = a-&amp;gt;get_sptr();

    return 0;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果为：&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/ZuA23y9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;需要注意的是，不能在构造函数中使用&lt;code&gt;shared_from_this()&lt;/code&gt;，因为虽然对象的基类&lt;code&gt;enable_shared_from_this&lt;/code&gt;的构造函数已经调用，但是&lt;code&gt;shared_ptr&lt;/code&gt;的构造函数并没有调用，所以这个时候调用&lt;code&gt;shared_from_this()&lt;/code&gt;是错的。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;智能指针虽好，但也并非完美，在使用的过程中还是需要注意。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;前面在&lt;a href=&quot;http://blog.dujiong.net/2016/05/15/cplusplus-sematics/&quot;&gt;浅谈C++值语义和对象语义&lt;/a&gt;一文中简要的阐述了一下智能指针shared_ptr的作用和用法，作为C++11中最为广泛使用的智能指针，shared_ptr虽然解决了裸指针的诸多问题，但是它并非完美、无懈可击，所以，本文就shared_ptr使用过程中需要注意的一些问题做一下总结。&lt;br&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://blog.dujiong.net/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>epoll总结</title>
    <link href="http://blog.dujiong.net/2016/07/29/epoll/"/>
    <id>http://blog.dujiong.net/2016/07/29/epoll/</id>
    <published>2016-07-29T11:03:21.000Z</published>
    <updated>2016-08-08T12:29:46.599Z</updated>
    
    <content type="html">&lt;p&gt;在现如今的并发网络服务器程序开发中，我们都会见到IO多路复用（Linux下的epoll、Windows下的IOCP等）的影子，它们是各种服务器并发方案（&lt;a href=&quot;http://blog.dujiong.net/2016/05/28/concurrent-server-conclusion/&quot;&gt;常见并发网络服务程序设计方案&lt;/a&gt;）的基础，而我们知道，绝大部分服务器都是运行在Linux系统下，所以，本文就现如今Linux下用的最多的epoll的原理、用法进行一个简单总结。   &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;什么是epoll？&quot;&gt;&lt;a href=&quot;#什么是epoll？&quot; class=&quot;headerlink&quot; title=&quot;什么是epoll？&quot;&gt;&lt;/a&gt;什么是epoll？&lt;/h3&gt;&lt;p&gt;epoll是在Linux 2.6内核中提出的，是之前select/poll的增强版本，相比如后两种IO多路复用版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集合来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点提升是获取事件的时候，epoll无须遍历整个被侦听的描述符，只要遍历那些被内核IO事件异步唤醒而加入就绪队列中的描述符集合就行了。此外，epoll除了提供select/poll那种IO事件的电平触发（LT）模式外，还提供边沿触发（ET），这样使得用户空间程序可以缓存IO状态，减少epoll_wait的调用，提高应用程序效率。        &lt;/p&gt;
&lt;h3 id=&quot;epoll的优点&quot;&gt;&lt;a href=&quot;#epoll的优点&quot; class=&quot;headerlink&quot; title=&quot;epoll的优点&quot;&gt;&lt;/a&gt;epoll的优点&lt;/h3&gt;&lt;p&gt;上面笼统的说了一下epoll的一些优点，下面分条做一个总结。&lt;br&gt;（1）支持一个大数目的socket描述符（FD）&lt;br&gt;epoll没有文件描述符的限制，它所支持的FD上限是最大可以打开文件的数目，这个数字远远大于select所支持的1024/2048。可以通过&lt;code&gt;cat /proc/sys/fs/file-max&lt;/code&gt;查看这个值，下面是我笔记本上的显示结果。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pt@Ubuntu:~$ cat /proc/sys/fs/file-max   
6815744
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;（2）IO效率不随FD数目增加而线性下降&lt;br&gt;传统select/poll的另一个致命弱点是当拥有一个很大的socket集合，由于网络的时延，使得任一时间只有部分的socket是“活跃”的，而select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。epoll对其进行了优化，它只会对“活跃”的socket进行操作：这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。所以，只有“活跃”的socket才会主动去调用callback函数，其他idle状态的socket则不会。在这点上，epoll实现了一个”伪”AIO”，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的，比如一个高速LAN环境，epoll也不比select/poll效率低，但若过多使用的调用epoll_ctl，效率稍微有些下降。然而一旦使用idle connections模拟WAN环境，那么epoll的效率就远在select/poll之上了。&lt;br&gt;（3）使用mmap加速内核与用户空间的消息传递&lt;br&gt;无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就显得很重要。在这点上，epoll是通过内核于用户空间mmap同一块内存实现。&lt;/p&gt;
&lt;h3 id=&quot;epoll的两种工作模式&quot;&gt;&lt;a href=&quot;#epoll的两种工作模式&quot; class=&quot;headerlink&quot; title=&quot;epoll的两种工作模式&quot;&gt;&lt;/a&gt;epoll的两种工作模式&lt;/h3&gt;&lt;h4 id=&quot;LT模式&quot;&gt;&lt;a href=&quot;#LT模式&quot; class=&quot;headerlink&quot; title=&quot;LT模式&quot;&gt;&lt;/a&gt;LT模式&lt;/h4&gt;&lt;p&gt;LT（Level Triggered，水平触发）模式，这是缺省的工作模式，同时支持block和non-block socket，在这种模式中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表。 &lt;/p&gt;
&lt;h4 id=&quot;ET模式&quot;&gt;&lt;a href=&quot;#ET模式&quot; class=&quot;headerlink&quot; title=&quot;ET模式&quot;&gt;&lt;/a&gt;ET模式&lt;/h4&gt;&lt;p&gt;ET(Edge Triggered，边沿触发)模式，这是高速工作模式，只支持non-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核就通过epoll告诉你，然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作而导致那个文件描述符不再是就绪状态(比如你在发送、接收或是接受请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误)。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核就不会发送更多的通知(only once)。不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。所以，这种方式下，出错率比较高，需要增加一些检测程序。&lt;/p&gt;
&lt;h4 id=&quot;使用ET和LT模式&quot;&gt;&lt;a href=&quot;#使用ET和LT模式&quot; class=&quot;headerlink&quot; title=&quot;使用ET和LT模式&quot;&gt;&lt;/a&gt;使用ET和LT模式&lt;/h4&gt;&lt;p&gt;上面已经说过了二者分别的特点，ET会更高效，但是只支持non-block socket，LT更加易用，且不易出错。个人觉得，一般的场景下，使用LT模式足以解决问题，如果碰到一些特殊场景要使用ET模式，一定要增加出错监测程序。        &lt;/p&gt;
&lt;h3 id=&quot;使用epoll&quot;&gt;&lt;a href=&quot;#使用epoll&quot; class=&quot;headerlink&quot; title=&quot;使用epoll&quot;&gt;&lt;/a&gt;使用epoll&lt;/h3&gt;&lt;p&gt;epoll用到的所有数据结构和函数都是在头文件sys/epoll.h中声明的，下面逐一介绍。    &lt;/p&gt;
&lt;h4 id=&quot;相关数据结构&quot;&gt;&lt;a href=&quot;#相关数据结构&quot; class=&quot;headerlink&quot; title=&quot;相关数据结构&quot;&gt;&lt;/a&gt;相关数据结构&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;typedef union epoll_data{
    void* ptr;
    int fd;
    __uint32_t u32;
    __uint43_t u64;
}epoll_data_t;

struct epoll_event{
    __uint32_t events;    //Epoll events
    epoll_data_t data;    //User data variable    
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结构体epoll_event被用于注册所感兴趣的事件和回传发生待处理的事件。epoll_event 结构体的events字段是表示感兴趣的事件和被触发的事件，可能的取值为：&lt;br&gt;EPOLLIN： 表示对应的文件描述符可以读；&lt;br&gt;EPOLLOUT： 表示对应的文件描述符可以写；&lt;br&gt;EPOLLPRI： 表示对应的文件描述符有紧急的数据可读；&lt;br&gt;EPOLLERR： 表示对应的文件描述符发生错误；&lt;br&gt;EPOLLHUP： 表示对应的文件描述符被挂断；&lt;br&gt;EPOLLET： 表示对应的文件描述符有事件发生；&lt;br&gt;联合体epoll_data用来保存触发事件的某个文件描述符相关的数据。例如一个client连接到服务器，服务器通过调用accept函数可以得到于这个client对应的socket文件描述符，可以把这文件描述符赋给epoll_data的fd字段，以便后面的读写操作在这个文件描述符上进行。&lt;/p&gt;
&lt;h4 id=&quot;epoll函数&quot;&gt;&lt;a href=&quot;#epoll函数&quot; class=&quot;headerlink&quot; title=&quot;epoll函数&quot;&gt;&lt;/a&gt;epoll函数&lt;/h4&gt;&lt;p&gt;1.创建函数&lt;br&gt;&lt;code&gt;int epoll_create(int size)&lt;/code&gt;&lt;br&gt;该函数创建一个epoll实例，通知内核需要监听size个fd。size指的并不是最大的后备存储设备，而是衡量内核内部结构大小的一个提示。当创建成功后，会占用一个fd，所以记得在使用完之后调用close()，否则fd可能会被耗尽。不过，自Linux 2.6.8版本之后，size值没什么作用，只需大于0，因为内核可以动态的分配大小，不需要size这个提示了。&lt;br&gt;2.注册函数&lt;br&gt;&lt;code&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event)&lt;/code&gt;&lt;br&gt;第一个参数epfd，为上一步epoll_create()返回的epoll fd。&lt;br&gt;第二个参数op表示操作值，有三个类型：&lt;br&gt;EPOLL_CTL_ADD ：注册目标到epfd中，同时关联内部event到fd上&lt;br&gt;EPOLL_CTL_MOD ：修改已经注册到fd的监听事件&lt;br&gt;EPOLL_CTL_DEL ：从epfd中删除/移除已注册的fd&lt;br&gt;第三个参数fd表示需要监听的fd。&lt;br&gt;第四个参数event表示需要监听的事件。&lt;br&gt;3.等待函数&lt;br&gt;&lt;code&gt;int epoll_wait(int epfd, structepoll_event * events, int maxevents, int timeout)&lt;/code&gt;&lt;br&gt;该函数用于轮询IO事件的发生。函数如果等待成功，则返回fd的数字；0表示等待fd超时，其他错误返回errno值。       &lt;/p&gt;
&lt;h4 id=&quot;使用综述&quot;&gt;&lt;a href=&quot;#使用综述&quot; class=&quot;headerlink&quot; title=&quot;使用综述&quot;&gt;&lt;/a&gt;使用综述&lt;/h4&gt;&lt;p&gt;首先通过&lt;code&gt;int create\_epoll(int maxfds)&lt;/code&gt;来创建一个epoll的句柄fd，其中maxfds为你的epoll所支持的最大句柄数（现只需设置大于0）。这个函数会返回一个新的epoll句柄，之后的所有操作都将通过这个句柄来进行操作。在用完之后，记得用close()来关闭这个创建出来的fd。&lt;br&gt;然后在你的网络主循环里面，调用epoll_wait(int epfd, epoll_event events, int max_events,int timeout)来查询所有的网络接口，看哪一个可以读，哪一个可以写。基本的语法为： &lt;code&gt;nfds = epoll_wait(kdpfd, events, maxevents, -1);&lt;/code&gt; 其中kdpfd为用epoll_create创建之后的句柄，events是一个epoll_event*的指针，当epoll_wait函数操作成功之后，events里面将储存所有的读写事件。max_events是当前需要监听的所有socket句柄数。最后一个timeout参数指示 epoll_wait的超时条件，为0时表示马上返回；为-1时表示函数会一直等下去直到有事件返回；为任意正整数时表示等这么长的时间，如果一直没有事件，则会返回。一般情况下如果网络主循环是单线程的话，可以用-1来等待，这样可以保证一些效率，如果是和主循环在同一个线程的话，则可以用0来保证主循环的效率。epoll_wait返回之后，应该进入一个循环，以便遍历所有的事件。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在现如今的并发网络服务器程序开发中，我们都会见到IO多路复用（Linux下的epoll、Windows下的IOCP等）的影子，它们是各种服务器并发方案（&lt;a href=&quot;http://blog.dujiong.net/2016/05/28/concurrent-server-conclusion/&quot;&gt;常见并发网络服务程序设计方案&lt;/a&gt;）的基础，而我们知道，绝大部分服务器都是运行在Linux系统下，所以，本文就现如今Linux下用的最多的epoll的原理、用法进行一个简单总结。   &lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>2015-2016年互联网公司校招编程题汇总</title>
    <link href="http://blog.dujiong.net/2016/07/21/internetcompany/"/>
    <id>http://blog.dujiong.net/2016/07/21/internetcompany/</id>
    <published>2016-07-21T12:16:02.000Z</published>
    <updated>2016-09-19T15:38:36.004Z</updated>
    
    <content type="html">&lt;p&gt;本文收录了近两年的各大互联网公司校招（实习）笔试的编程题，并提供了自己的思路和解法。希望能对自己和备战互联网校招的同学提供一些帮助。 &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;所有题目均来自于牛客网“校招真题编程题汇总”板块，感谢牛客网的汇总并提供在线编程平台。为了方便大家检验，下面每个题会链接到牛客网的OJ界面。而我提供的思路和解法会链接至我的&lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github&lt;/a&gt;，欢迎大家多沟通、交流。&lt;/p&gt;
&lt;h3 id=&quot;华为&quot;&gt;&lt;a href=&quot;#华为&quot; class=&quot;headerlink&quot; title=&quot;华为&quot;&gt;&lt;/a&gt;华为&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/784efd40ed8e465a84821c8f3970b7b5?tpId=49&amp;amp;tqId=29297&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;字符集合&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8D%8E%E4%B8%BA/%E5%AD%97%E7%AC%A6%E9%9B%86%E5%90%88&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/f9533a71aada4f35867008be22be5b6e?tpId=49&amp;amp;tqId=29296&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;删数&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8D%8E%E4%B8%BA/%E5%88%A0%E6%95%B0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;腾讯&quot;&gt;&lt;a href=&quot;#腾讯&quot; class=&quot;headerlink&quot; title=&quot;腾讯&quot;&gt;&lt;/a&gt;腾讯&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/fbcf95ed620f42a88be24eb2cd57ec54?tpId=49&amp;amp;tqId=29311&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;微信红包&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%85%BE%E8%AE%AF/%E5%BE%AE%E4%BF%A1%E7%BA%A2%E5%8C%85&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/50959b5325c94079a391538c04267e15?tpId=49&amp;amp;tqId=29310&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;生成格雷码&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%85%BE%E8%AE%AF/%E7%94%9F%E6%88%90%E6%A0%BC%E9%9B%B7%E7%A0%81&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;网易&quot;&gt;&lt;a href=&quot;#网易&quot; class=&quot;headerlink&quot; title=&quot;网易&quot;&gt;&lt;/a&gt;网易&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/62cdf520b9d94616b6644ac03a0306ff?tpId=49&amp;amp;tqId=29309&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;路灯&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E8%B7%AF%E7%81%AF&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/cee98a512ec246a2918ea8121f7612c8?tpId=49&amp;amp;tqId=29308&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;奖学金&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E5%A5%96%E5%AD%A6%E9%87%91&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45846&amp;amp;tid=4847537&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;统计回文&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E7%BB%9F%E8%AE%A1%E5%9B%9E%E6%96%87&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45842&amp;amp;tid=4847537&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;两种排序方法&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E4%B8%A4%E7%A7%8D%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45844&amp;amp;tid=4847537&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Fibonacci数列&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/Fibonacci%E6%95%B0%E5%88%97&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45840&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;解救小易&lt;/a&gt; ——————–&amp;gt;  &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E8%A7%A3%E6%95%91%E5%B0%8F%E6%98%93&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45842&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;不要二&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E4%B8%8D%E8%A6%81%E4%BA%8C&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45842&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;饥饿的小易&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E9%A5%A5%E9%A5%BF%E7%9A%84%E5%B0%8F%E6%98%93&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45843&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;数字游戏&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E6%95%B0%E5%AD%97%E6%B8%B8%E6%88%8F&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/question/next?pid=2252291&amp;amp;qid=45847&amp;amp;tid=5196556&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;混合颜料&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BD%91%E6%98%93/%E6%B7%B7%E5%90%88%E9%A2%9C%E6%96%99&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;京东&quot;&gt;&lt;a href=&quot;#京东&quot; class=&quot;headerlink&quot; title=&quot;京东&quot;&gt;&lt;/a&gt;京东&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/532d89889b974506a0805062fd1089fb?tpId=49&amp;amp;tqId=29307&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;小东分苹果&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E4%BA%AC%E4%B8%9C/%E5%B0%8F%E4%B8%9C%E5%88%86%E8%8B%B9%E6%9E%9C&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/ae45a1d8bc1d43858c83762fe8c2802c?tpId=49&amp;amp;tqId=29306&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;抛小球&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E4%BA%AC%E4%B8%9C/%E6%8A%9B%E5%B0%8F%E7%90%83&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/4b24ebad2ffd4f679320fd464b2036a6?tpId=49&amp;amp;tqId=29321&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;上台阶&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E4%BA%AC%E4%B8%9C/%E4%B8%8A%E5%8F%B0%E9%98%B6&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;小米&quot;&gt;&lt;a href=&quot;#小米&quot; class=&quot;headerlink&quot; title=&quot;小米&quot;&gt;&lt;/a&gt;小米&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/ba033b0d1c2f497da1dd04330cc003af?tpId=49&amp;amp;tqId=29232&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;懂二进制&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%B0%8F%E7%B1%B3/%E6%87%82%E4%BA%8C%E8%BF%9B%E5%88%B6&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/9370d298b8894f48b523931d40a9a4aa?tpId=49&amp;amp;tqId=29233&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;风口的猪-中国牛市&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%B0%8F%E7%B1%B3/%E9%A3%8E%E5%8F%A3%E7%9A%84%E7%8C%AA-%E4%B8%AD%E5%9B%BD%E7%89%9B%E5%B8%82&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;去哪儿&quot;&gt;&lt;a href=&quot;#去哪儿&quot; class=&quot;headerlink&quot; title=&quot;去哪儿&quot;&gt;&lt;/a&gt;去哪儿&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/28d5a9b7fc0b4a078c9a6d59830fb9b9?tpId=49&amp;amp;tqId=29278&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;二分查找&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/dab59997905b4459a42587fece8a75f4?tpId=49&amp;amp;tqId=29279&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;首个重复字符&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E9%A6%96%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/a386fd3a5080435dad3252bac76950a7?tpId=49&amp;amp;tqId=29280&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;寻找Coder&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E5%AF%BB%E6%89%BECoder&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/227893ccf81d4e8589875922f0d9319e?tpId=49&amp;amp;tqId=29299&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;表达式合法判断&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%90%88%E6%B3%95%E5%88%A4%E6%96%AD&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/5541c433dee04c17ba7774c4a20430de?tpId=49&amp;amp;tqId=29303&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;5-血型遗传监测&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E5%8E%BB%E5%93%AA%E5%84%BF/5-%E8%A1%80%E5%9E%8B%E9%81%97%E4%BC%A0%E7%9B%91%E6%B5%8B&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;美团&quot;&gt;&lt;a href=&quot;#美团&quot; class=&quot;headerlink&quot; title=&quot;美团&quot;&gt;&lt;/a&gt;美团&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/13ba51c3fec74b58bbc8fa8c3eedf877?tpId=49&amp;amp;tqId=29284&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;直方图内最大矩形&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%86%85%E6%9C%80%E5%A4%A7%E7%9F%A9%E5%BD%A2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/0b5ab6cc51804dd59f9988ad70d8c4a0?tpId=49&amp;amp;tqId=29282&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;棋子翻转&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E6%A3%8B%E5%AD%90%E7%BF%BB%E8%BD%AC&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/3745638815d04c26babcfc463c25478c?tpId=49&amp;amp;tqId=29286&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;平均年龄&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E5%B9%B3%E5%9D%87%E5%B9%B4%E9%BE%84&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/1f7675ae7a9e40e4bd04eb754b62fd00?tpId=49&amp;amp;tqId=29281&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;最大差值&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E6%9C%80%E5%A4%A7%E5%B7%AE%E5%80%BC&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/12cbdcdf5d1e4059b6ddd420de6342b6?tpId=49&amp;amp;tqId=29283&amp;amp;rp=1&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;拜访&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E6%8B%9C%E8%AE%BF&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/196141ecd6eb401da3111748d30e9141?tpId=49&amp;amp;tqId=29315&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;奇数位丢弃&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E5%A5%87%E6%95%B0%E4%BD%8D%E4%B8%A2%E5%BC%83&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/6fadc1dac83a443c9434f350a5803b51?tpId=49&amp;amp;tqId=29316&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;二维数组打印&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E6%89%93%E5%8D%B0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/3e8c66829a7949d887334edaa5952c28?tpId=49&amp;amp;tqId=29317&amp;amp;rp=3&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;股票交易日&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E7%BE%8E%E5%9B%A2/%E8%82%A1%E7%A5%A8%E4%BA%A4%E6%98%93%E6%97%A5&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;蘑菇街&quot;&gt;&lt;a href=&quot;#蘑菇街&quot; class=&quot;headerlink&quot; title=&quot;蘑菇街&quot;&gt;&lt;/a&gt;蘑菇街&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/3a571cdc72264d76820396770a151f90?tpId=49&amp;amp;tqId=29292&amp;amp;rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;最大间隔&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%98%91%E8%8F%87%E8%A1%97&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.nowcoder.com/practice/655a43d702cd466093022383c24a38bf?rp=2&amp;amp;ru=/ta/2016test&amp;amp;qru=/ta/2016test/question-ranking&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;回文串&lt;/a&gt; ——————–&amp;gt; &lt;a href=&quot;https://github.com/jiongdu/Algorithm/tree/master/%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E9%A2%98/%E8%98%91%E8%8F%87%E8%A1%97/%E5%9B%9E%E6%96%87%E4%B8%B2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;思路和解答&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本文收录了近两年的各大互联网公司校招（实习）笔试的编程题，并提供了自己的思路和解法。希望能对自己和备战互联网校招的同学提供一些帮助。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="http://blog.dujiong.net/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之Thread和ThreadPool</title>
    <link href="http://blog.dujiong.net/2016/07/17/muduo-6/"/>
    <id>http://blog.dujiong.net/2016/07/17/muduo-6/</id>
    <published>2016-07-17T11:14:12.000Z</published>
    <updated>2016-08-30T12:14:05.124Z</updated>
    
    <content type="html">&lt;p&gt;在muduo的one loop per thread + thread pool模型中，线程和线程池应该是其中最基础也是最重要的两个组件了。所以，本文深入代码，学习Thread和ThreadPool两个类的结构和实现。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;Thread类&quot;&gt;&lt;a href=&quot;#Thread类&quot; class=&quot;headerlink&quot; title=&quot;Thread类&quot;&gt;&lt;/a&gt;Thread类&lt;/h3&gt;&lt;h4 id=&quot;thread关键字&quot;&gt;&lt;a href=&quot;#thread关键字&quot; class=&quot;headerlink&quot; title=&quot;__thread关键字&quot;&gt;&lt;/a&gt;__thread关键字&lt;/h4&gt;&lt;p&gt;学习Thread class之前，先了解一个关键字的用法：__thread。&lt;br&gt;__thread是GCC内置的线程局部存储设施。它的实现非常高效，比Pthread库中的pthread_key_t（muduo中ThreadLocal）快很多。__thread变量是表示每个线程有一份独立实体，各个线程的变量值互不干扰。__thread只能修饰POD类型，不能修饰class类型，因为无法自动调用构造函数和析构函数。&lt;br&gt;Thread类的封装用到了命名空间CurrentThread，这个空间中定义了和线程相关的一些独立属性。   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;namespace CurrentThread
{
    __thread int t_cachedTid = 0;
    __thread char t_tidString[32];
    __thread int t_tidStringLength = 6;
    __thread const char* t_threadName = &amp;quot;unknown&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，t_cachedTid表示线程的真实id，Pthread库中提供了pthread_self()获取当前线程的标识，类型为pthread_t。但是，pthread_t不一定是数值类型，也可能是一个结构体，这带来了一些问题。&lt;br&gt;（1）无法打印输出pthread_t，因为不知道其确切类型。&lt;br&gt;（2）无法比较pthread_t大小或计算hash值。&lt;br&gt;（3）pthread_t值只在进程内有意义，与操作系统的任务调度之间无法建立有效关系，Pthread库只能保证在同一进程之内，同一时刻的各个线程的id不同。&lt;br&gt;所以，muduo采用gettid()系统调用的返回值作为线程id，muduo中将操作封装为gettid()函数。但是，我们知道，调用系统调用开销比较大，所以，muduo中采用__thread变量t_cachedTid来存储，在线程第一次使用tid时通过系统调用获得，存储在t_cachedTid中，以后使用时不再需要系统调用了。&lt;br&gt;t_tidString[32]：用string类型表示tid，以便输出日志。&lt;br&gt;t_tidStringLength：string类型tid的长度。&lt;br&gt;t_threadName：线程的名字。     &lt;/p&gt;
&lt;h4 id=&quot;相关的数据结构&quot;&gt;&lt;a href=&quot;#相关的数据结构&quot; class=&quot;headerlink&quot; title=&quot;相关的数据结构&quot;&gt;&lt;/a&gt;相关的数据结构&lt;/h4&gt;&lt;p&gt;在Thread的实现中，还用到了两个数据结构，一个位ThreadData，用来辅助调用线程执行的函数。另一个为ThreadNameInitializer，为线程的创建做环境准备。其中用到了&lt;code&gt;pthread_atfork(NULL,NULL,&amp;amp;afterfork)&lt;/code&gt;。该函数的原型为&lt;br&gt;    &lt;code&gt;int pthread_atfork(void (*prepare)(void), void (*parent)(void), void (*child)(void));&lt;/code&gt;&lt;br&gt;这是一个跟进程创建有关的函数，为fork的调用做准备和调用后子进程父进程的初始化。prepare函数在调用fork前执行，parent在调用fork后的父进程中执行，child在调用fork后的子进程中执行。&lt;br&gt;当然，在实际应用中，多线程不要调用fork()，否则会出现一些问题。因为fork智能克隆当前线程的thread of control，却不克隆其他线程。fork()之后，除了当前线程之外，其他线程都消失了。这样，会出现很多问题。比如，如果复制了一个lock的mutex，却没有复制unlock的线程，那么在给mutex加锁时就会出现死锁。&lt;/p&gt;
&lt;h4 id=&quot;Thread类分析&quot;&gt;&lt;a href=&quot;#Thread类分析&quot; class=&quot;headerlink&quot; title=&quot;Thread类分析&quot;&gt;&lt;/a&gt;Thread类分析&lt;/h4&gt;&lt;p&gt;首先来看Thread类的数据成员和构造函数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Thread : boost::noncopyable
{
    typedef boost::function&amp;lt;void ()&amp;gt; ThreadFunc;
    ...
    private:
        bool started_;
        bool joined_;
        pthread_t pthreadId_;
        boost::shared_ptr&amp;lt;pid_t&amp;gt; tid_;
        ThreadFunc func_;
        string name_;

        static AtomicInt32 numCreated_;
};
Thread::Thread(ThreadFunc&amp;amp;&amp;amp; func, const string&amp;amp; n)
    : started_(false), 
      joined_(false),
      pthreadId_(0),
      tid_(new pid_t(0)),
      func_(func),
      name_(n)
{
      setDefaultName();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中有两处需要说明一下，首先是&lt;code&gt;shared_ptr&amp;lt;pid&amp;gt; tid_&lt;/code&gt;，可能有人会有疑问：为什么这里要用shared_ptr包装pid？&lt;br&gt;原因是tid_所属的对象Thread在主线程（A）中创建，而tid_需要在新创建的线程B中进行赋值操作，如果tid使用裸指针的方式传递给线程（B），那么线程A中Thread对象析构（下文）销毁后，线程B持有的就是一个野指针，所以，在Thread对象中将以shared_ptr包装。&lt;br&gt;然后是numCreated_，是一个静态变量，类型为AtomicInt32，原子类型，用来表示第几次创建线程实例，在记录日志时可用记录为：“线程名+numCreated_”。&lt;/p&gt;
&lt;p&gt;接下来看Thread的一些接口函数。       &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void Thread::start()
{
    started = true;
    detail::ThreadData* data = new detail::ThreadData(func_, name_, tid_);
    if(pthread_create(&amp;amp;pthreadId_, NULL, &amp;amp;detail::startThread, data));
    {
        started_ = false;
        delete data;
        LOG_SYSFATAL &amp;lt;&amp;lt; &amp;quot;Failed in pthread_create&amp;quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thread::start()将调用pthread_create()创建新线程，detail::startThread()是新线程的入口函数，data是新线程执行的辅助结构体。detail::startThread()调用data-&amp;gt;runInThread()执行线程逻辑(func_)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int Thread::join()
{
    assert(started_);
    assert(!joined_);
    joined_ = true;
    return pthread_join(pthreadId_, NULL);
}

Thread::~Thread()
{
    if(started_ &amp;amp;&amp;amp; !joined_)
    {
        pthread_detach(pthreadId_);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thread析构的时候没有销毁持有的Pthreads句柄(pthread_t)，也就是说Thread的析构不会等待线程结束。如果Thread对象的生命期长于线程，然后通过Thread::join()来等待线程结束并释放线程资源。如果Thread对象的生命期短于线程，那么析构时会自动detach线程，避免了资源泄露。&lt;/p&gt;
&lt;h3 id=&quot;ThreadPool类&quot;&gt;&lt;a href=&quot;#ThreadPool类&quot; class=&quot;headerlink&quot; title=&quot;ThreadPool类&quot;&gt;&lt;/a&gt;ThreadPool类&lt;/h3&gt;&lt;p&gt;ThreadPool（线程池）本质上是一个生产者-消费者的模型，在实际中主要完成计算任务。在muduo线程池中有一个存放工作线程的容器ptr_vector，相当于消费者；有一个存放任务的队列deque。&lt;br&gt;任务队列是有界的，类似于BoundedBlockingQueue，实现时需要两个条件变量。&lt;br&gt;以下是ThreadPool的数据成员：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class ThreadPool : boost::noncopyable
{
    typedef boost::function&amp;lt;void ()&amp;gt; Task;
    private:
        MutexLock mutex_;
        Condition notEmpty_;
        Condition notFull_;
        string name_;
        Task threadInitCallback_;
        boost::ptr_vector&amp;lt;muduo::Thread&amp;gt; threads_;
        std::deque&amp;lt;Task&amp;gt; queue_;
        size_t maxQueueSize_;
        bool running_;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中threadInitCallback_可由setThreadInitCallback(const Task&amp;amp; cb)设置，设置回调函数，每次在执行任务前先调用。在线程池开始运行之前，需要先设置任务队列的大小（调用setMaxQueueSize()），因为运行线程池时，线程会从任务队列取任务。&lt;br&gt;接下来是ThreadPool的一些接口函数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ThreadPool::start(int numThreads)
{
    assert(threads_.empty());
    running_ = true;
    threads_.reserve(numThreads);
    for (int i = 0; i &amp;lt; numThreads; ++i)
      {
        char id[32];
        snprintf(id, sizeof id, &amp;quot;%d&amp;quot;, i+1);
        threads_.push_back(new muduo::Thread(
              boost::bind(&amp;amp;ThreadPool::runInThread, this), name_+id));
        threads_[i].start();
      }
    if(numThreads == 0 &amp;amp;&amp;amp; threadInitCallback_)
    {
        threadInitCallback_();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;void ThreadPool::start(int numThreads)&lt;/code&gt;开启线程池，按照线程数量numThreads_创建工作线程，线程函数为ThreadPool::runInThread（）。    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ThreadPool::runInThread()
{
    try
    {
        if(threadInitCallback_)
        {
            threadInitCallback_();
        }
        while(running_)
        {
            Task task(take());
            if(task)
            {
                task();
            }
        }
    }
    catch(const Exception&amp;amp; ex)
    {
        ...
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果设置了threadInitCallback_，则进行执行任务前的一些初始化操作。然后从任务队列中取任务执行，有可能阻塞，当任务队列为空时。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ThreadPool::Task ThreadPool::take()
{
    MutexLockGuard lock(mutex_);
    while(queue_.empty() &amp;amp;&amp;amp; running_)
    {
        notEmpty_.wait();
    }
    Task task;
    if(!queue_.empty())
    {
        task = queue_.front();
        queue_.pop_front();
        if(maxQueueSize_ &amp;gt; 0)
        {
            notFull_.notify();
        }
    }
    return task;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;多线程从消息队列中取任务的时候，需要加锁保护。等到队列非空信号，就取任务。取出之后，便告知任务队列已经非满，可以继续添加任务。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ThreadPool::run(const Task&amp;amp; task)
{
    if(threads_.empty())
    {
        task();
    }
    else
    {
        MutexLockGuard lock(mutex_);
        while(isFull())
        {
            notFull_.wait();
        }
        assert(!isFull());
        queue_.push_back(task);
        notEmpty_.notfy();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果ThreadPool没有子线程（set和start操作在run之前），就在主线程中执行该task，否则，将任务加入到队列，并通知线程从中取task，如果队列已满，便等待。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ThreadPool::~ThreadPool()
{
    if(running_)
    {
        stop();
    }
}
void ThreadPool::stop()
{
    {
        MutexLockGuard lock(mutex_);
        running_ = false;
        notEmpty_.notifyAll();
    }
    for_each(threads_.begin(),threads_.end(),boost::bind(&amp;amp;muduo::Thread::join, _1));
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后是ThreadPool的析构函数，在其中调用stop()，唤醒所有等待的线程，然后对线程池中的每一个线程执行join()。     &lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;以上就是muduo中Thread和ThreadPool类的学习，有很多源码，有点啰嗦。但是，在muduo的one loop per thread + thread pool模型中，Thread和ThreadPool是很重要的组件，所以需要深入地掌握。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;在muduo的one loop per thread + thread pool模型中，线程和线程池应该是其中最基础也是最重要的两个组件了。所以，本文深入代码，学习Thread和ThreadPool两个类的结构和实现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>muduo源码阅读之线程同步</title>
    <link href="http://blog.dujiong.net/2016/07/08/muduo-5/"/>
    <id>http://blog.dujiong.net/2016/07/08/muduo-5/</id>
    <published>2016-07-08T07:07:13.000Z</published>
    <updated>2016-08-30T07:14:40.635Z</updated>
    
    <content type="html">&lt;p&gt;前面的四篇“muduo源码阅读”文章都是从总体上（Reactor模式）出发把握muduo库的一些设计思想和架构，从这篇开始，将更深入细节、更贴近代码地阅读muduo网络库。&lt;br&gt;首先，是多线程编程中重中之重的线程同步问题。     &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;互斥锁&quot;&gt;&lt;a href=&quot;#互斥锁&quot; class=&quot;headerlink&quot; title=&quot;互斥锁&quot;&gt;&lt;/a&gt;互斥锁&lt;/h3&gt;&lt;p&gt;提到线程同步原语，相信绝大多数人首先想到的就是互斥锁(mutex)了，互斥锁保护了临界区，保证任何时刻最多只有一个线程在由mutex保护的临界区内活动。所以，一般使用mutex来保护共享数据。muduo中使用了C++ RAII的手法封装了mutex的创建、销毁、加锁和解锁四个操作，并最终封装成MutexLockGuard类，这样，一切都交给栈上的MutexLockGuard类的对象的构造和析构函数负责，对象的生命期正好等于临界区。        &lt;/p&gt;
&lt;p&gt;下面，首先来看MutexLock类的主要代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class MutexLock : boost noncopyable
{
    public:
        MutexLock() : holder_(0)
        {
            MCHECK(pthread_mutex_init(&amp;amp;mutex_,NULL)); //初始化mutex
        }
        ~MutexLock()
        {
            assert(holder_=0);
            MCHECK(pthread_mutex_destroy(&amp;amp;mutex_));    //销毁mutex
        }
        void lock()
        {
            MCHECK(pthread_mutex_lock(&amp;amp;mutex_));    //加锁
            assignHolder();    
        }
        void unlock()
        {
            unassignHolder();
            MCHECK(pthread_mutex_unlock(&amp;amp;mutex_));    //解锁
        }
    private:
        friend class Condition;
        void assignHolder()
        {
            holder_=CurrentThread::tid();
        }
        void unassignHolder()
        {
            holder_=0;
        }
        pthread_mutex_t mutex_;
        pid_t holder_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;   从代码中，很容易看出MutexLock对mutex的操作的封装。但是，为了防止忘记加锁、解锁操作，muduo做了更进一步的封装，于是有了MutexLockGuard类。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class MutexLockGuard : boost::noncopyable
{
    public:
        explicit MutexLockGuard(MutexLock&amp;amp; mutex) : mutex_(mutex)
        {
            mutex_.lock();        //在构造函数内进行加锁操作
        }    
        ~MutexLockGuard()
        {
            mutex_.unlock();    //在析构函数内进行解锁操作
        }
    private:
        MutexLock&amp;amp; mutex_;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样一来，用户只需创建一个栈上的MutexLockGuard对象，便可以完成初始化、加锁操作，MutexLockGuard对象的生命期等于临界区，栈上对象析构的时候，自动完成解锁、销毁等操作。&lt;/p&gt;
&lt;h3 id=&quot;条件变量&quot;&gt;&lt;a href=&quot;#条件变量&quot; class=&quot;headerlink&quot; title=&quot;条件变量&quot;&gt;&lt;/a&gt;条件变量&lt;/h3&gt;&lt;p&gt;互斥锁是加锁原语，用来排他性地访问共享数据，它不是等待原语。如果需要等待某个条件成立，就应该使用条件变量。条件变量是一个或多个线程等待某个条件为真，即等待别的“线程”唤醒它。&lt;br&gt;所以，条件变量涉及等待端和通知端，所以双方都要按照一定的方式保证正常使用。&lt;br&gt;对于wait端：&lt;br&gt;（1）必须与mutex一起使用，条件（布尔表达式）的读写受mutex的保护&lt;br&gt;（2）在mutex已上锁的时候才能调用wait()&lt;br&gt;（3）把判断布尔表达式和wait()放入while()循环中&lt;br&gt;对于signal/broadcast端：&lt;br&gt;（1）在signal之前一般要修改布尔表达式&lt;br&gt;（2）修改布尔表达式要加锁保护&lt;br&gt;（3）signal（通知）通常用于资源可用，broadcast（广播）通常用于表明状态变化&lt;br&gt;写成代码表示：     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;muduo::MutexLock mutex;
muduo::Condition cond(mutex);
std::deque&amp;lt;int&amp;gt; queue;     

int dequeue()
{
    MutexLockGuard lock(mutex);
    while(queue.empty())
    {
        cond.wait();           //等待条件变量
    }
    assert(!queue.empty());
    int top = queue.front();
    queue.pop_front();
    return top;
}
void enqueue(int x)
{
    MutexLockGuard lock(mutex);
    queue.push_back(x);
    cond.notify();            //通知资源可用       
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上，可以看成生产者–消费者模型，这里有一个经典的问题，即消费者中使用while()循环等待，可否使用if呢？答案是否定的，因为在多线程中，由于莫名其妙的原因，即使没有线程调用signal或broadcast，原来wait的线程可能也会返回，即被唤醒了。所以，通过while()循环判断来避免虚假唤醒造成的错误，而不能使用if。&lt;br&gt;muduo中使用Condition类提供了对条件变量的封装。     &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Condition : boost::noncopyable
{
    public:
        explicit Condition(MutexLock&amp;amp; mutex) : mutex_(mutex)
        {
            MCHECK(pthread_cond_init(&amp;amp;pcond_,NULL));
        }
        ~Condition()
        {    
            MCHECK(pthread_cond_destroy(&amp;amp;pcond_));
        }
        void wait()
        {
            MutexLock::UnassginGuard ug(mutex_);
            MCHECK(pthread_cond_wait(&amp;amp;pcond_,mutex_.getPthreadMutex()));
        }
        void notify()
        {
            MCHECK(pthread_cond_signal(&amp;amp;pcond_));
        }
        void notifyAll()
        {
            MCHECK(pthread_cond_broadcast(&amp;amp;pcond_));
        }
    private:
        MutexLock&amp;amp; mutex_;    
        pthread_cond_t pcond_;
};    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;CountDownLatch&quot;&gt;&lt;a href=&quot;#CountDownLatch&quot; class=&quot;headerlink&quot; title=&quot;CountDownLatch&quot;&gt;&lt;/a&gt;CountDownLatch&lt;/h3&gt;&lt;p&gt;条件变量是非常底层的同步原语，很少直接使用，一般都是用它来实现高层的同步措施。muduo中封装的CountDownLatch（倒计时）就是一种常用且易用的同步手段。主要有两方面的用途：&lt;br&gt;（1）主线程发起多个子线程，等这些子线程各自都完成一定的任务之后，主线程才继续执行。通常用于主线程等待多个子线程完成初始化。&lt;br&gt;（2）主线程发起多个子线程，子线程都等待主线程，主线程完成其他一些任务之后通知所有子线程开始执行。通常用于多个子线程等待主线程发起“起跑”命令。&lt;br&gt;下面是muduo中的倒计时CountDownLatch类。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class CountDownLatch : boost::noncopyable
{
    public: 
        explicit CountDownLatch(int count);        //倒数几次
        void wait();                            //等待计数值变为0
        void countDown();                        //计数减1
        void getCount() const;
    private:
        mutable MutexLock mutex_;
        Condition condition_;
        int count_;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;互斥锁和条件变量构成了多线程编程的几乎全部必备的同步原语，正确并熟练地使用它们，即可完成任何多线程同步任务。在此基础上，如果特定的场景下实在还需要性能上的提升，再考虑更高级的同步手段。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;前面的四篇“muduo源码阅读”文章都是从总体上（Reactor模式）出发把握muduo库的一些设计思想和架构，从这篇开始，将更深入细节、更贴近代码地阅读muduo网络库。&lt;br&gt;首先，是多线程编程中重中之重的线程同步问题。     &lt;/p&gt;
    
    </summary>
    
    
      <category term="muduo" scheme="http://blog.dujiong.net/tags/muduo/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议总结（二）</title>
    <link href="http://blog.dujiong.net/2016/06/25/tcp-2/"/>
    <id>http://blog.dujiong.net/2016/06/25/tcp-2/</id>
    <published>2016-06-25T12:06:14.000Z</published>
    <updated>2016-08-07T13:00:43.518Z</updated>
    
    <content type="html">&lt;p&gt;首先，纪念一下，如果不出意外的话（没过or狠心读个博），学生期间所有的考试应该就此结束了，以后就不会大冬天的早上7点起床去图书馆占座了，想想也是佩服自己啊，啧…&lt;br&gt;好了，言归正传，接着上篇，今天学习TCP协议中较难的重传、滑动窗口和拥塞控制。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;TCP重传机制&quot;&gt;&lt;a href=&quot;#TCP重传机制&quot; class=&quot;headerlink&quot; title=&quot;TCP重传机制&quot;&gt;&lt;/a&gt;TCP重传机制&lt;/h3&gt;&lt;p&gt;TCP是可靠的、面向连接的协议，要保证所有的数据包都可以到达，所以，重传机制是必须的。&lt;br&gt;由于接收端给发送端的ACK只会确认最后一个连续的包，比如，发送端发了1、2、3、4、5一共5份数据，接收端收到了1、2，于是回ACK 3，然后收到了4，此时3没收到，怎么办？&lt;/p&gt;
&lt;h4 id=&quot;超时重传机制&quot;&gt;&lt;a href=&quot;#超时重传机制&quot; class=&quot;headerlink&quot; title=&quot;超时重传机制&quot;&gt;&lt;/a&gt;超时重传机制&lt;/h4&gt;&lt;p&gt;一种方法是不回ACK，一直等3，当发送方发现收不到3的ACK，超时后会重传3.一旦接收方收到3后吗，会A回CK 4，表示3和4都收到了。&lt;br&gt;但是，问题来了，因为一直等3，可能会导致4和5即便已经收到了，发送方因为没有收到ACK，悲观地认为4和5也丢了，所以可能导致4和5的重传。对此有两种选择：一种是仅重传timeout的包。也就是第3份数据，另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，很可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长（下面会说TCP怎么动态计算timeout）。&lt;/p&gt;
&lt;h4 id=&quot;快速重传机制&quot;&gt;&lt;a href=&quot;#快速重传机制&quot; class=&quot;headerlink&quot; title=&quot;快速重传机制&quot;&gt;&lt;/a&gt;快速重传机制&lt;/h4&gt;&lt;p&gt;快速重传机制不以时间驱动，而以数据驱动重传。也就是说，如果包没有连续到达，就回复ACK最后那个可能被丢了的包，如果发送方连续收到3次相同的ACK，就重传。这样，好处是不用等timeout了再重传。&lt;br&gt;比如：如果发送方发出了1、2、3、4、5共5份数据，第一份先到了，于是接收方回复ACK 2，结果2因为某些原因没到、3到了，于是还是ACK 2，后面的4和5都到了，但是还是ACK 2，因为2还没有到，于是发送端收到了三个ACK 2的确认，就马上重传2。然后，接收端收到了2，此时3、4、5都已经收到了，于是ACK 6。其图示如下。&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/56fKXLt.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;但是，这样还是没有解决重传之前的一个还是重传所有的问题。就上面例子来说，发送端并不清楚这三个ACK 2是接收端收到哪些数据后传回来的。&lt;/p&gt;
&lt;h4 id=&quot;SACK方法&quot;&gt;&lt;a href=&quot;#SACK方法&quot; class=&quot;headerlink&quot; title=&quot;SACK方法&quot;&gt;&lt;/a&gt;SACK方法&lt;/h4&gt;&lt;p&gt;另外一种更好的方式是：Selective ACK，需要在TCP头里加一个SACK的东西，ACK还是上面快速重传机制中的ACK。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/2oZwECU.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些数据没有到。在Linux下，可以通过tcp_sack这个参数打开这个功能。      &lt;/p&gt;
&lt;h4 id=&quot;Timeout与RTT&quot;&gt;&lt;a href=&quot;#Timeout与RTT&quot; class=&quot;headerlink&quot; title=&quot;Timeout与RTT&quot;&gt;&lt;/a&gt;Timeout与RTT&lt;/h4&gt;&lt;p&gt;从上述的TCP重传机制中可以看出，Timeout对于TCP重传的性能非常重要。如果设置长了，重发就慢，丢了很久才重发，效率低、性能差。而如果设置短了，导致并没有丢包就重发，这样重发加快，会增加网络拥塞，导致更多的超时，更多的超时又引起更多的重法，这样恶性循环。&lt;br&gt;所以，根据不同时间、网络情况，Timeout这个值需要设置，所以，TCP引入了RTT（往返时间，也就是一个数据包从发出去到回来的时间），这样就可以方便、有效的设置Timeout。&lt;br&gt;具体的RTT测量算法这里就不详述，细节可以参考《TCP/IP详解 卷一：协议》。&lt;/p&gt;
&lt;h3 id=&quot;TCP滑动窗口&quot;&gt;&lt;a href=&quot;#TCP滑动窗口&quot; class=&quot;headerlink&quot; title=&quot;TCP滑动窗口&quot;&gt;&lt;/a&gt;TCP滑动窗口&lt;/h3&gt;&lt;p&gt;在上一篇中提到了TCP头部里有一个字段Window，即滑动窗口，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。从而发送端可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。为了说明滑动窗口，首先来看一下TCP缓冲区的结构：&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;http://i.imgur.com/8afv8ge.jpg&quot; alt=&quot;&quot;&gt;            &lt;/p&gt;
&lt;p&gt;从上图可以得到，接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续数据包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，可以看到，中间有些数据还没有到达，所有有数据空白区。&lt;br&gt;而发送端的LastByteAcked指向了被接收端ACK了的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有成功确认的地方，LastByteWritten指向的是上层应用正在写的地方。&lt;br&gt;所以，接收端会在给发送端返回的ACK中汇报自己的滑动窗口大小=MaxRcvBuffer-LastByteRcvd-1；而发送端会根据这个窗口大小来控制发送数据的大小，以保证接收方可以处理。要解决这个问题，就是要避免对小的window size做出响应，直到有足够大的window size再响应。     &lt;/p&gt;
&lt;h4 id=&quot;Silly-Window-Syndrome和Nagle算法&quot;&gt;&lt;a href=&quot;#Silly-Window-Syndrome和Nagle算法&quot; class=&quot;headerlink&quot; title=&quot;Silly Window Syndrome和Nagle算法&quot;&gt;&lt;/a&gt;Silly Window Syndrome和Nagle算法&lt;/h4&gt;&lt;p&gt;网络上有个参数叫MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是MSS（Max Segment Size），TCP的RFC中定义这个MSS的默认值是536。&lt;br&gt;那么，如果网络包可以塞满MTU，那么就可以用满整个带宽，如果不能，那么就会浪费带宽。这时，可以将其想象成一架飞机，如果飞机里满载的话，带宽最高，如果一个飞机只运一个人的话，无疑成本增加了。所以，Silly Window Syndrome这个现象就像是本来可以坐200人的飞机里只坐了一两人。&lt;br&gt;要解决这个问题，就要避免对小的窗口大小做出响应，直到有足够大的窗口大小再响应，这就是著名的Nagle算法。&lt;br&gt;Nagle算法要求一个TCP连接上最多只能有一个未被确认的未完成的小分组，在该分组的确认到达之前不能发送其他的小分组。TCP将手机这些少量的分组，并在确认到来时以一个分组的方式发出去。&lt;br&gt;该算法主要用于避免过多小分组在网络中传输，降低网络容量利用率。比如：一个20字节的TCP首部+20字节的IP首部+1个字节的数据组成的TCP数据报，有效传输利用率只有近1/40，这些小分组在广域网上会增加拥塞出现的可能。&lt;br&gt;但是，有时我们又需要关闭Nagle算法，比如说一些需要快速响应、对时延敏感的应用，如窗口程序，可以通过套接字选项TCP_NODELAY来关闭该算法。&lt;/p&gt;
&lt;h3 id=&quot;TCP的拥塞处理&quot;&gt;&lt;a href=&quot;#TCP的拥塞处理&quot; class=&quot;headerlink&quot; title=&quot;TCP的拥塞处理&quot;&gt;&lt;/a&gt;TCP的拥塞处理&lt;/h3&gt;&lt;p&gt;如前面所描述的，TCP通过滑动窗口来做流控，但是这样还不够，因为滑动窗口只是依赖于连接的发送端和接收端，并不知道网络中间发生了什么。想象一下，网络上的延时突然增加，如果TCP对此作出的应对只有重传数据，但是，大量的重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这样就产生了恶性循环，最终会拖垮整个网络。&lt;br&gt;所以，TCP不能一个劲地只是重发数据，所以，TCP的理念是，当拥塞发生的时候，要做自我牺牲，就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。&lt;br&gt;拥塞控制主要是四个算法：慢启动、拥塞避免、拥塞发生和快速恢复。       &lt;/p&gt;
&lt;h4 id=&quot;慢启动、拥塞避免和拥塞发生&quot;&gt;&lt;a href=&quot;#慢启动、拥塞避免和拥塞发生&quot; class=&quot;headerlink&quot; title=&quot;慢启动、拥塞避免和拥塞发生&quot;&gt;&lt;/a&gt;慢启动、拥塞避免和拥塞发生&lt;/h4&gt;&lt;p&gt;慢启动的意思是，刚加入网络的连接，一点一点地提速。慢启动为发送方的TCP增加了另一个窗口：拥塞窗口（cwnd）。当与接收方建立TCP连接时，拥塞窗口被初始化为一个报文段，每收到一个ACK，拥塞窗口就增加一个报文段(cwnd以字节为单位，但是慢启动以报文段大小为单位进行增加)，但是有一个上限sshthresh，当cwnd&amp;gt;=ssthresh时，就会进入“拥塞避免算法”。慢启动算法初始设置cwnd为1个报文段，此后每收到一个确认就加1，这样会使窗口按指数方式增长，而拥塞避免算法要求每次收到一个确认时将cwnd增加1/cwnd。与慢启动的指数增加相比起来，这是一种加性增长。&lt;br&gt;所以，拥塞窗口是发送方使用的流量控制，而通告窗口则是接收方使用的流量控制。拥塞避免算法和慢启动算法需要对每个链接维持两个变量：一个拥塞窗口cwnd和一个慢启动门限ssthresh。这样，算法可以描述如下：&lt;br&gt;1）对于一个连接，初始化cwnd为1个报文段，ssthresh为65535个字节。&lt;br&gt;2）TCP输出例程的输出不能超过cwnd和接收方通告窗口的大小。前者是发送方感受到的网络拥塞的估计，而后者则与接收方在该连接上的可用缓存大小有关。&lt;br&gt;3）当拥塞发生时（超时或收到重复确认），ssthresh被设置为当前窗口（cwnd和接收方通告窗口大小的最小值，但最小为2个报文段）大小的一半。此外，如果是超时引起了拥塞，则cwnd被设置为1个报文段（相当于慢启动）。&lt;br&gt;4）当新的数据被对方确认时，就增加cwnd，但增加的方法依赖于是否正在进行慢启动或拥塞避免。如果cwnd小于或等于ssthresh，则正在进行慢启动，否则正在进行拥塞避免。       &lt;/p&gt;
&lt;h4 id=&quot;快速恢复算法&quot;&gt;&lt;a href=&quot;#快速恢复算法&quot; class=&quot;headerlink&quot; title=&quot;快速恢复算法&quot;&gt;&lt;/a&gt;快速恢复算法&lt;/h4&gt;&lt;p&gt;通常和快速重传算法一起使用，算法流程如下：&lt;br&gt;1）当收到第三个重复的ACK时（前面已述），将ssthresh设置为当前拥塞窗口cwnd的一半。重传丢失的报文段。设置cwnd为ssthresh加上3倍的报文段大小。&lt;br&gt;2）每次收到另一个重复的ACK时，cwnd增加1个报文段大小并发送1个分组。&lt;br&gt;3）当下一个确认新数据的ACK到达时，设置cwnd为ssthresh。这个ACK应该是在进行重传后的一个往返时间内对步骤1中重传的确认。另外，这个ACK也应该对丢失的分组和收到的第1个重复的ACK之间的所有中间报文段的确认。这一步采用的是拥塞避免，因为当分组丢失时将当前速率减半。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h3&gt;&lt;p&gt;通过这两篇总结，对TCP协议的核心知识点进行了复习和再认识，后面还需要结合具体的实例进一步加深理解，能对网络中的实际问题进行更好的分析和处理。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;首先，纪念一下，如果不出意外的话（没过or狠心读个博），学生期间所有的考试应该就此结束了，以后就不会大冬天的早上7点起床去图书馆占座了，想想也是佩服自己啊，啧…&lt;br&gt;好了，言归正传，接着上篇，今天学习TCP协议中较难的重传、滑动窗口和拥塞控制。&lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议总结（一）</title>
    <link href="http://blog.dujiong.net/2016/06/13/tcp-1/"/>
    <id>http://blog.dujiong.net/2016/06/13/tcp-1/</id>
    <published>2016-06-13T05:07:19.000Z</published>
    <updated>2016-09-20T13:41:36.933Z</updated>
    
    <content type="html">&lt;p&gt;最近，在学习和科研中，越来越发现自己对于TCP协议的掌握不够，作为一个成天和网络打交道的人，TCP/IP简直是我们最核心的知识之一，所以，准备利用接下来准备考试的间隙时间，结合《TCP/IP详解 卷一：协议》再重新学习和巩固一下TCP。          &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;TCP首部&quot;&gt;&lt;a href=&quot;#TCP首部&quot; class=&quot;headerlink&quot; title=&quot;TCP首部&quot;&gt;&lt;/a&gt;TCP首部&lt;/h3&gt;&lt;p&gt;首先，来看一下TCP首部的数据格式，如果不计算Option字段，它通常是20个字节。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/p9FVemz.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;需要重点关注和理解的是:&lt;br&gt;（1） 每个TCP连接包含源端和目的端的端口号，用于标识发端和收端的应用进程。这两个值和下层IP层的源、目的IP地址构成了唯一标识一个TCP连接的四元组。&lt;br&gt;（2）序列号(Sequence Number)是包的序号，用来标识从TCP发端向收端发送的数据字节流，用来解决网络报乱序的问题。&lt;br&gt;（3）ACK，表示收到TCP包的确认。&lt;br&gt;（4）TCP Flags标志位，也就是包的类型，用于标识TCP连接的状态。&lt;br&gt;（5）Window就是著名的滑动窗口，用于流量控制的。&lt;/p&gt;
&lt;h3 id=&quot;TCP连接的建立和终止&quot;&gt;&lt;a href=&quot;#TCP连接的建立和终止&quot; class=&quot;headerlink&quot; title=&quot;TCP连接的建立和终止&quot;&gt;&lt;/a&gt;TCP连接的建立和终止&lt;/h3&gt;&lt;p&gt;很多人对于TCP协议最深的印象应该就是三次握手和四次挥手了。那么，这中间的过程是怎样的呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/lP4JfiN.jpg&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
&lt;h4 id=&quot;三次握手建立连接&quot;&gt;&lt;a href=&quot;#三次握手建立连接&quot; class=&quot;headerlink&quot; title=&quot;三次握手建立连接&quot;&gt;&lt;/a&gt;三次握手建立连接&lt;/h4&gt;&lt;p&gt;1）请求端（C/S模型中的Client）发送一个SYN字段指明客户打算连接的服务器的端口，以及初始序号x。&lt;br&gt;2）服务器发挥包含服务器初始序号y的SYN报文段作为应答。同时，将确认序号设置为客户的序号加1以对客户的SYN报文段进行确认。一个SYN将占用一个序号。&lt;br&gt;3）客户必须将确认序号设置为服务器的序号加1以对服务器的SYN报文段进行确认。&lt;/p&gt;
&lt;h4 id=&quot;四次挥手终止连接&quot;&gt;&lt;a href=&quot;#四次挥手终止连接&quot; class=&quot;headerlink&quot; title=&quot;四次挥手终止连接&quot;&gt;&lt;/a&gt;四次挥手终止连接&lt;/h4&gt;&lt;p&gt;这是由TCP的半关闭造成的。因为TCP连接是全双工，因此每个方向都必须单独的关闭，都需要FIN和ACK。收到一个FIN只意味着在这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。&lt;br&gt;如上图，客户执行主动关闭，发送序列号(seq)为x+1的FIN，服务器收到这个FIN，发回ACK(seq=x+3)。接着服务器关闭它的连接，导致它的TCP端发送一个FIN(seq=y+1)，客户端必须发回一个确认，即ACK(seq=y+2)。&lt;/p&gt;
&lt;h4 id=&quot;连接建立的超时&quot;&gt;&lt;a href=&quot;#连接建立的超时&quot; class=&quot;headerlink&quot; title=&quot;连接建立的超时&quot;&gt;&lt;/a&gt;连接建立的超时&lt;/h4&gt;&lt;p&gt;实际中，有很多情况导致无法建立连接。比如，当Server收到Client的SYN并发回SYN-ACK后Client掉线了，Server端没有收到Client发回的ACK。这种情况下，Server端会重法SYN-ACK。在Linux下，默认重法次数为5次，重试的间隔时间从1s开始每次都翻倍，如果5次后仍旧没有收到，才会断开这个连接。               &lt;/p&gt;
&lt;h3 id=&quot;TCP状态机&quot;&gt;&lt;a href=&quot;#TCP状态机&quot; class=&quot;headerlink&quot; title=&quot;TCP状态机&quot;&gt;&lt;/a&gt;TCP状态机&lt;/h3&gt;&lt;p&gt;下面这个图非常重要，TCP状态机和状态之间的转换是分析网络状态、故障、优化等的重中之重。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/m6HYlnp.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;需要重点关注的：&lt;br&gt;（1）MSL和TIME_WAIT状态。据说，这是90%的互联网后台岗位面试都会考的内容。&lt;br&gt;每个具体TCP实现必须选择一个报文段最大生存时间MSL（Maximum Segment Lifetime），它是任何报文段被丢弃前在网络内的最长时间。这个时间是有限的，因为TCP报文段封装在IP数据包在网络内传输，而IP数据包有限制其生存时间的TTL字段。&lt;br&gt;当TCP执行一个主动关闭，并发回最后一个ACK（收到对端的FIN，并发送ACK），该连接必须在TIME_WAIT状态停留的时间为2MSL。这样做可以确保有足够的时间让对端收到ACK，如果被动关闭的那方没有收到ACK，就会触发被动端重发最后的FIN。一来一去正好2MSL。此外，这样做的另一个结果是标识这个TCP连接的四元组在2MSL期间不能再被使用，只能再2MSL结束后才能再被使用。&lt;br&gt;（2）TIME_WAIT过多&lt;br&gt;出现问题了，在高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动关闭连接，这样，就会有很多连接处在TIME_WAIT状态，会消耗许多系统资源。如果客户端的并发量持续很高，部分客户端就会显示连接不上。这时，可以通过设置tcp_tw_reuse和tcp_tw_recycle两个参数，前者表示开启重用，允许将处于TIME_WAIT的Socket重新用于新的TCP连接，后者表示开启TCP连接中TIME_WAIT socket的快速回收。&lt;br&gt;其实，个人觉得最好的办法就是想方设法让Client来关闭连接，这样Server作为被动关闭的一方，就不存在上述问题了。&lt;br&gt;（3）SYN Flood攻击&lt;br&gt;了解TCP三次握手后，很容易明白SYN Flood攻击的来源了，在客户端给服务器发了建立连接的SYN后，就下线了，于是服务器需要默认等待63s才会断开连接，这样，攻击者就可以把服务器的SYN连接队列耗尽，让正常的连接请求不能处理。于是，Linux下有一个tcp_syncookies的参数来应对攻击，当SYN队列满之后，TCP会根据源地址端口、目标地址端口和时间戳打造一个特别的Sequence Number（SYN Cookie）发回客户端，如果是攻击者则不会有相应，如果是正常连接，则会把这个SYN Cookie发回，然后服务端通过cookie建立连接。&lt;/p&gt;
&lt;h3 id=&quot;TCP保活定时器&quot;&gt;&lt;a href=&quot;#TCP保活定时器&quot; class=&quot;headerlink&quot; title=&quot;TCP保活定时器&quot;&gt;&lt;/a&gt;TCP保活定时器&lt;/h3&gt;&lt;p&gt;许多时候服务器希望知道客户主机是否崩溃并关机或者崩溃又重新启动这样的非正常情况，这就需要保活功能。如果一个特定的连接在固定时间之内没有任何动作，则服务器就向客户端发送一个探查报文。&lt;br&gt;保活功能的实现由两种方式，一是应用层面的心跳机制。通过自定义心跳消息头来完成保活功能。另一种就是TCP自带的保活功能。而这也是许多协议专家所争论的点：到底保活功能应该再哪一层实现。对于这两种方式，我认为应用层面的心跳机制具有灵活、扩展性强的特点，可以随意控制，不依赖与协议，但是也增加了开发的复杂程度。而TCP的保活功能，使用简单，减少了应用层代码的复杂度。所以，开发者可以根据实际的应用场景选择适合的保活功能的实现方式。&lt;/p&gt;
&lt;h3 id=&quot;待续&quot;&gt;&lt;a href=&quot;#待续&quot; class=&quot;headerlink&quot; title=&quot;待续&quot;&gt;&lt;/a&gt;待续&lt;/h3&gt;&lt;p&gt;这一篇是TCP协议的一些基础知识，下一篇将学习较复杂的滑动窗口、重传与拥塞控制。&lt;/p&gt;
&lt;p&gt;参考:  《TCP/IP详解 卷一：协议》   &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在学习和科研中，越来越发现自己对于TCP协议的掌握不够，作为一个成天和网络打交道的人，TCP/IP简直是我们最核心的知识之一，所以，准备利用接下来准备考试的间隙时间，结合《TCP/IP详解 卷一：协议》再重新学习和巩固一下TCP。          &lt;/p&gt;
    
    </summary>
    
    
      <category term="network/linux" scheme="http://blog.dujiong.net/tags/network-linux/"/>
    
  </entry>
  
</feed>
